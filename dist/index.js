var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __require = /* @__PURE__ */ ((x) => typeof require !== "undefined" ? require : typeof Proxy !== "undefined" ? new Proxy(x, {
  get: (a, b) => (typeof require !== "undefined" ? require : a)[b]
}) : x)(function(x) {
  if (typeof require !== "undefined") return require.apply(this, arguments);
  throw Error('Dynamic require of "' + x + '" is not supported');
});
var __esm = (fn, res) => function __init() {
  return fn && (res = (0, fn[__getOwnPropNames(fn)[0]])(fn = 0)), res;
};
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc15) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc15 = __getOwnPropDesc(from, key)) || desc15.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// shared/schema.ts
var schema_exports = {};
__export(schema_exports, {
  accountBalanceLedger: () => accountBalanceLedger,
  achBatch: () => achBatch,
  achEntry: () => achEntry,
  achReturns: () => achReturns,
  artifact: () => artifact,
  authEvents: () => authEvents,
  bankAccounts: () => bankAccounts,
  bankStatementFiles: () => bankStatementFiles,
  bankTxn: () => bankTxn,
  borrowerEntities: () => borrowerEntities,
  borrowerNotices: () => borrowerNotices,
  borrowerPaymentMethods: () => borrowerPaymentMethods,
  borrowerPreferences: () => borrowerPreferences,
  borrowerUsers: () => borrowerUsers,
  cashMatchCandidates: () => cashMatchCandidates,
  collectionActivities: () => collectionActivities,
  collectionStatusEnum: () => collectionStatusEnum,
  communicationPreference: () => communicationPreference,
  complianceAuditLog: () => complianceAuditLog,
  consentRecord: () => consentRecord,
  crmActivity: () => crmActivity,
  crmAppointments: () => crmAppointments,
  crmCalls: () => crmCalls,
  crmCollaborators: () => crmCollaborators,
  crmDeals: () => crmDeals,
  crmNotes: () => crmNotes,
  crmTasks: () => crmTasks,
  dataSubjectRequest: () => dataSubjectRequest,
  deletionReceipt: () => deletionReceipt,
  disbursementPaymentMethodEnum: () => disbursementPaymentMethodEnum,
  disbursementStatusEnum: () => disbursementStatusEnum,
  disbursementTypeEnum: () => disbursementTypeEnum,
  documentCategoryEnum: () => documentCategoryEnum,
  documentTemplate: () => documentTemplate,
  documentTemplates: () => documentTemplates,
  documents: () => documents,
  emailArtifacts: () => emailArtifacts,
  emailTemplateFolders: () => emailTemplateFolders,
  emailTemplates: () => emailTemplates,
  entityTypeEnum: () => entityTypeEnum,
  escrowAccounts: () => escrowAccounts2,
  escrowAdvances: () => escrowAdvances,
  escrowDisbursementPayments: () => escrowDisbursementPayments,
  escrowDisbursements: () => escrowDisbursements2,
  escrowForecasts: () => escrowForecasts,
  escrowPayments: () => escrowPayments,
  escrowTransactions: () => escrowTransactions,
  exceptionCases: () => exceptionCases,
  feeTemplates: () => feeTemplates,
  frequencyEnum: () => frequencyEnum,
  generalLedgerEntries: () => generalLedgerEntries,
  generalLedgerEvents: () => generalLedgerEvents,
  guarantors: () => guarantors,
  idMappings: () => idMappings,
  inbox: () => inbox,
  insertAccountBalanceLedgerSchema: () => insertAccountBalanceLedgerSchema,
  insertAchBatchSchema: () => insertAchBatchSchema,
  insertAchEntrySchema: () => insertAchEntrySchema,
  insertAchReturnSchema: () => insertAchReturnSchema,
  insertArtifactSchema: () => insertArtifactSchema,
  insertAuthEventSchema: () => insertAuthEventSchema,
  insertBankAccountSchema: () => insertBankAccountSchema,
  insertBankStatementFileSchema: () => insertBankStatementFileSchema,
  insertBankTxnSchema: () => insertBankTxnSchema,
  insertBorrowerEntitySchema: () => insertBorrowerEntitySchema,
  insertBorrowerNoticeSchema: () => insertBorrowerNoticeSchema,
  insertBorrowerPaymentMethodSchema: () => insertBorrowerPaymentMethodSchema,
  insertBorrowerPreferencesSchema: () => insertBorrowerPreferencesSchema,
  insertBorrowerUserSchema: () => insertBorrowerUserSchema,
  insertCashMatchCandidateSchema: () => insertCashMatchCandidateSchema,
  insertCollectionActivitySchema: () => insertCollectionActivitySchema,
  insertCommunicationPreferenceSchema: () => insertCommunicationPreferenceSchema,
  insertComplianceAuditLogSchema: () => insertComplianceAuditLogSchema,
  insertConsentRecordSchema: () => insertConsentRecordSchema,
  insertDataSubjectRequestSchema: () => insertDataSubjectRequestSchema,
  insertDeletionReceiptSchema: () => insertDeletionReceiptSchema,
  insertDocumentSchema: () => insertDocumentSchema,
  insertDocumentTemplateSchema: () => insertDocumentTemplateSchema,
  insertDocumentTemplateSystemSchema: () => insertDocumentTemplateSystemSchema,
  insertEmailTemplateFolderSchema: () => insertEmailTemplateFolderSchema,
  insertEmailTemplateSchema: () => insertEmailTemplateSchema,
  insertEscrowAccountSchema: () => insertEscrowAccountSchema,
  insertEscrowAdvanceSchema: () => insertEscrowAdvanceSchema,
  insertEscrowDisbursementPaymentSchema: () => insertEscrowDisbursementPaymentSchema,
  insertEscrowDisbursementSchema: () => insertEscrowDisbursementSchema,
  insertEscrowForecastSchema: () => insertEscrowForecastSchema,
  insertEscrowPaymentSchema: () => insertEscrowPaymentSchema,
  insertEscrowTransactionSchema: () => insertEscrowTransactionSchema,
  insertExceptionCaseSchema: () => insertExceptionCaseSchema,
  insertFeeTemplateSchema: () => insertFeeTemplateSchema,
  insertGeneralLedgerEntrySchema: () => insertGeneralLedgerEntrySchema,
  insertGeneralLedgerEventSchema: () => insertGeneralLedgerEventSchema,
  insertGuarantorSchema: () => insertGuarantorSchema,
  insertIdMappingSchema: () => insertIdMappingSchema,
  insertInboxSchema: () => insertInboxSchema,
  insertInsurancePolicySchema: () => insertInsurancePolicySchema,
  insertInterestAccrualSchema: () => insertInterestAccrualSchema,
  insertInvestorDistributionSchema: () => insertInvestorDistributionSchema,
  insertInvestorSchema: () => insertInvestorSchema,
  insertLedgerEntrySchema: () => insertLedgerEntrySchema,
  insertLegalHoldSchema: () => insertLegalHoldSchema,
  insertLegalProceedingSchema: () => insertLegalProceedingSchema,
  insertLoanBalancesSchema: () => insertLoanBalancesSchema,
  insertLoanBorrowerLinkSchema: () => insertLoanBorrowerLinkSchema,
  insertLoanBorrowerSchema: () => insertLoanBorrowerSchema,
  insertLoanFeeSchema: () => insertLoanFeeSchema,
  insertLoanLedgerSchema: () => insertLoanLedgerSchema,
  insertLoanSchema: () => insertLoanSchema,
  insertLoanTermsSchema: () => insertLoanTermsSchema,
  insertLoginAttemptSchema: () => insertLoginAttemptSchema,
  insertMfaAuditLogSchema: () => insertMfaAuditLogSchema,
  insertMfaBackupCodeSchema: () => insertMfaBackupCodeSchema,
  insertMfaChallengeSchema: () => insertMfaChallengeSchema,
  insertNoticeDeliveryLogSchema: () => insertNoticeDeliveryLogSchema,
  insertNoticeScheduleSchema: () => insertNoticeScheduleSchema,
  insertNotificationSchema: () => insertNotificationSchema,
  insertOutboxMessageSchema: () => insertOutboxMessageSchema,
  insertOutboxSchema: () => insertOutboxSchema,
  insertPasswordResetTokenSchema: () => insertPasswordResetTokenSchema,
  insertPayeeSchema: () => insertPayeeSchema,
  insertPaymentArtifactSchema: () => insertPaymentArtifactSchema,
  insertPaymentEventSchema: () => insertPaymentEventSchema,
  insertPaymentInboxSchema: () => insertPaymentInboxSchema,
  insertPaymentIngestionSchema: () => insertPaymentIngestionSchema,
  insertPaymentScheduleSchema: () => insertPaymentScheduleSchema,
  insertPaymentSchema: () => insertPaymentSchema,
  insertPermissionSchema: () => insertPermissionSchema,
  insertProcessTimerSchema: () => insertProcessTimerSchema,
  insertPropertySchema: () => insertPropertySchema,
  insertReconExceptionSchema: () => insertReconExceptionSchema,
  insertReconciliationSchema: () => insertReconciliationSchema,
  insertRemittanceExportSchema: () => insertRemittanceExportSchema,
  insertRetentionPolicySchema: () => insertRetentionPolicySchema,
  insertRolePermissionSchema: () => insertRolePermissionSchema,
  insertRoleSchema: () => insertRoleSchema,
  insertSagaStepHistorySchema: () => insertSagaStepHistorySchema,
  insertServicingEventSchema: () => insertServicingEventSchema,
  insertServicingExceptionSchema: () => insertServicingExceptionSchema,
  insertServicingInstructionSchema: () => insertServicingInstructionSchema,
  insertServicingRunSchema: () => insertServicingRunSchema,
  insertSessionSchema: () => insertSessionSchema,
  insertSystemSettingSchema: () => insertSystemSettingSchema,
  insertTaskSchema: () => insertTaskSchema,
  insertUserIpAllowlistSchema: () => insertUserIpAllowlistSchema,
  insertUserMfaFactorSchema: () => insertUserMfaFactorSchema,
  insertUserRoleSchema: () => insertUserRoleSchema,
  insertUserSchema: () => insertUserSchema,
  insurancePolicies: () => insurancePolicies,
  interestAccruals: () => interestAccruals,
  investorDistributions: () => investorDistributions,
  investors: () => investors,
  ledgerEntries: () => ledgerEntries,
  legalHold: () => legalHold,
  legalProceedings: () => legalProceedings,
  loanBalances: () => loanBalances,
  loanBorrowerLinks: () => loanBorrowerLinks,
  loanBorrowers: () => loanBorrowers,
  loanFees: () => loanFees,
  loanLedger: () => loanLedger,
  loanStatusEnum: () => loanStatusEnum,
  loanTerms: () => loanTerms,
  loanTypeEnum: () => loanTypeEnum,
  loans: () => loans,
  loansRelations: () => loansRelations,
  loginAttempts: () => loginAttempts,
  loginOutcomeEnum: () => loginOutcomeEnum,
  mfaAuditLog: () => mfaAuditLog,
  mfaBackupCodes: () => mfaBackupCodes,
  mfaChallenges: () => mfaChallenges,
  noticeDeliveryLog: () => noticeDeliveryLog,
  noticeSchedule: () => noticeSchedule,
  noticeSettings: () => noticeSettings,
  noticeStatusEnum: () => noticeStatusEnum,
  noticeTemplates: () => noticeTemplates,
  notificationTypeEnum: () => notificationTypeEnum,
  notifications: () => notifications,
  outbox: () => outbox,
  outboxMessages: () => outboxMessages,
  passwordResetTokens: () => passwordResetTokens,
  payees: () => payees,
  paymentArtifacts: () => paymentArtifacts,
  paymentEvents: () => paymentEvents,
  paymentIngestions: () => paymentIngestions,
  paymentMethodEnum: () => paymentMethodEnum,
  paymentSchedule: () => paymentSchedule,
  paymentStatusEnum: () => paymentStatusEnum,
  payments: () => payments,
  paymentsInbox: () => paymentsInbox,
  permissionLevelEnum: () => permissionLevelEnum,
  permissions: () => permissions,
  priorityEnum: () => priorityEnum,
  processTimer: () => processTimer,
  properties: () => properties,
  propertyTypeEnum: () => propertyTypeEnum,
  reconExceptions: () => reconExceptions,
  reconciliations: () => reconciliations,
  remittanceExport: () => remittanceExport,
  retentionPolicy: () => retentionPolicy,
  rolePermissions: () => rolePermissions,
  roles: () => roles,
  sagaStepHistory: () => sagaStepHistory,
  servicingEvents: () => servicingEvents,
  servicingExceptions: () => servicingExceptions,
  servicingInstructions: () => servicingInstructions,
  servicingRuns: () => servicingRuns,
  sessions: () => sessions,
  systemSettings: () => systemSettings,
  tasks: () => tasks,
  transactionTypeEnum: () => transactionTypeEnum,
  userIpAllowlist: () => userIpAllowlist,
  userMfaFactors: () => userMfaFactors,
  userRoleEnum: () => userRoleEnum,
  userRoles: () => userRoles,
  userStatusEnum: () => userStatusEnum,
  users: () => users,
  usersRelations: () => usersRelations
});
import { createInsertSchema } from "drizzle-zod";
import { z } from "zod";
import {
  pgTable,
  text,
  timestamp,
  integer,
  serial,
  boolean,
  jsonb,
  json,
  decimal,
  uuid,
  varchar,
  date,
  index,
  pgEnum,
  uniqueIndex,
  primaryKey,
  unique,
  bigint
} from "drizzle-orm/pg-core";
import { relations, sql as sql2 } from "drizzle-orm";
var userRoleEnum, loanStatusEnum, loanTypeEnum, propertyTypeEnum, entityTypeEnum, paymentStatusEnum, documentCategoryEnum, transactionTypeEnum, notificationTypeEnum, priorityEnum, frequencyEnum, disbursementTypeEnum, paymentMethodEnum, disbursementPaymentMethodEnum, disbursementStatusEnum, collectionStatusEnum, users, borrowerEntities, properties, loans, loanBorrowers, guarantors, investors, paymentSchedule, payments, escrowAccounts2, escrowDisbursements2, escrowDisbursementPayments, escrowTransactions, payees, documents, documentTemplate, documentTemplates, servicingInstructions, collectionActivities, legalProceedings, feeTemplates, loanLedger, loanFees, insurancePolicies, notifications, tasks, systemSettings, noticeTemplates, noticeSettings, usersRelations, loansRelations, userStatusEnum, permissionLevelEnum, loginOutcomeEnum, roles, userRoles, permissions, rolePermissions, userIpAllowlist, authEvents, loginAttempts, passwordResetTokens, sessions, crmNotes, crmTasks, crmAppointments, crmCalls, crmActivity, crmCollaborators, crmDeals, insertUserSchema, insertBorrowerEntitySchema, insertPropertySchema, insertRoleSchema, insertUserRoleSchema, insertPermissionSchema, insertRolePermissionSchema, insertUserIpAllowlistSchema, insertAuthEventSchema, insertLoginAttemptSchema, insertPasswordResetTokenSchema, insertSessionSchema, insertLoanSchema, insertLoanBorrowerSchema, insertGuarantorSchema, insertInvestorSchema, insertPaymentScheduleSchema, insertPaymentSchema, insertEscrowAccountSchema, insertEscrowDisbursementSchema, insertEscrowDisbursementPaymentSchema, insertEscrowTransactionSchema, insertPayeeSchema, insertDocumentSchema, insertDocumentTemplateSchema, insertDocumentTemplateSystemSchema, insertServicingInstructionSchema, insertCollectionActivitySchema, insertLegalProceedingSchema, insertFeeTemplateSchema, insertLoanFeeSchema, insertLoanLedgerSchema, insertInsurancePolicySchema, insertNotificationSchema, insertTaskSchema, insertSystemSettingSchema, escrowPayments, insertEscrowPaymentSchema, servicingRuns, servicingEvents, servicingExceptions, paymentsInbox, interestAccruals, investorDistributions, escrowAdvances, userMfaFactors, mfaBackupCodes, mfaChallenges, mfaAuditLog, insertServicingRunSchema, insertServicingEventSchema, insertServicingExceptionSchema, insertPaymentInboxSchema, insertInterestAccrualSchema, insertInvestorDistributionSchema, insertEscrowAdvanceSchema, insertUserMfaFactorSchema, insertMfaBackupCodeSchema, insertMfaChallengeSchema, insertMfaAuditLogSchema, emailTemplateFolders, insertEmailTemplateFolderSchema, emailTemplates, insertEmailTemplateSchema, idMappings, paymentIngestions, paymentArtifacts, paymentEvents, ledgerEntries, inbox, outbox, outboxMessages, reconciliations, exceptionCases, generalLedgerEvents, generalLedgerEntries, loanTerms, loanBalances, escrowForecasts, insertIdMappingSchema, insertPaymentIngestionSchema, insertPaymentArtifactSchema, insertPaymentEventSchema, insertLedgerEntrySchema, insertInboxSchema, insertOutboxSchema, insertOutboxMessageSchema, emailArtifacts, insertReconciliationSchema, insertExceptionCaseSchema, insertGeneralLedgerEventSchema, insertGeneralLedgerEntrySchema, insertLoanTermsSchema, insertLoanBalancesSchema, insertEscrowForecastSchema, bankAccounts, bankTxn, bankStatementFiles, achBatch, achEntry, achReturns, cashMatchCandidates, reconExceptions, borrowerUsers, loanBorrowerLinks, borrowerPaymentMethods, borrowerNotices, borrowerPreferences, insertBorrowerUserSchema, insertLoanBorrowerLinkSchema, insertBorrowerPaymentMethodSchema, insertBorrowerNoticeSchema, insertBorrowerPreferencesSchema, insertBankAccountSchema, insertBankTxnSchema, insertBankStatementFileSchema, insertAchBatchSchema, insertAchEntrySchema, insertAchReturnSchema, insertCashMatchCandidateSchema, insertReconExceptionSchema, complianceAuditLog, consentRecord, communicationPreference, retentionPolicy, legalHold, processTimer, deletionReceipt, noticeDeliveryLog, accountBalanceLedger, artifact, dataSubjectRequest, insertComplianceAuditLogSchema, insertConsentRecordSchema, insertCommunicationPreferenceSchema, insertRetentionPolicySchema, insertLegalHoldSchema, insertProcessTimerSchema, insertDeletionReceiptSchema, insertNoticeDeliveryLogSchema, insertAccountBalanceLedgerSchema, insertArtifactSchema, insertDataSubjectRequestSchema, noticeStatusEnum, noticeSchedule, sagaStepHistory, remittanceExport, insertNoticeScheduleSchema, insertSagaStepHistorySchema, insertRemittanceExportSchema;
var init_schema = __esm({
  "shared/schema.ts"() {
    "use strict";
    userRoleEnum = pgEnum("user_role", [
      "lender",
      "borrower",
      "investor",
      "escrow_officer",
      "legal",
      "servicer",
      "admin"
    ]);
    loanStatusEnum = pgEnum("loan_status", [
      "application",
      "underwriting",
      "approved",
      "active",
      "current",
      "delinquent",
      "default",
      "forbearance",
      "modification",
      "foreclosure",
      "reo",
      "closed",
      "paid_off",
      "charged_off"
    ]);
    loanTypeEnum = pgEnum("loan_type", [
      "conventional",
      "fha",
      "va",
      "usda",
      "jumbo",
      "portfolio",
      "hard_money",
      "bridge",
      "construction",
      "commercial",
      "reverse_mortgage"
    ]);
    propertyTypeEnum = pgEnum("property_type", [
      "single_family",
      "condo",
      "townhouse",
      "multi_family",
      "manufactured",
      "commercial",
      "land",
      "mixed_use"
    ]);
    entityTypeEnum = pgEnum("entity_type", [
      "individual",
      "corporation",
      "llc",
      "partnership",
      "trust",
      "estate",
      "government"
    ]);
    paymentStatusEnum = pgEnum("payment_status", [
      "scheduled",
      "pending",
      "processing",
      "completed",
      "failed",
      "reversed",
      "partial",
      "late",
      "nsf",
      "waived"
    ]);
    documentCategoryEnum = pgEnum("document_category", [
      "loan_application",
      "loan_agreement",
      "promissory_note",
      "deed_of_trust",
      "mortgage",
      "security_agreement",
      "ucc_filing",
      "assignment",
      "modification",
      "forbearance_agreement",
      "insurance_policy",
      "tax_document",
      "escrow_statement",
      "title_report",
      "appraisal",
      "inspection",
      "financial_statement",
      "income_verification",
      "closing_disclosure",
      "settlement_statement",
      "reconveyance",
      "release",
      "legal_notice",
      "correspondence",
      "servicing_transfer",
      "compliance",
      "other"
    ]);
    transactionTypeEnum = pgEnum("transaction_type", [
      "deposit",
      "withdrawal",
      "transfer",
      "payment_principal",
      "payment_interest",
      "payment_escrow",
      "payment_fee",
      "payment_late_fee",
      "insurance_premium",
      "property_tax",
      "hoa_fee",
      "disbursement",
      "adjustment",
      "refund"
    ]);
    notificationTypeEnum = pgEnum("notification_type", [
      "payment_due",
      "payment_received",
      "payment_failed",
      "payment_late",
      "document_required",
      "document_received",
      "escrow_shortage",
      "escrow_surplus",
      "escrow_analysis",
      "insurance_expiring",
      "tax_due",
      "rate_change",
      "maturity_approaching",
      "system",
      "legal",
      "compliance"
    ]);
    priorityEnum = pgEnum("priority", [
      "low",
      "medium",
      "high",
      "urgent",
      "critical"
    ]);
    frequencyEnum = pgEnum("frequency", [
      "once",
      "daily",
      "weekly",
      "bi_weekly",
      "semi_monthly",
      "monthly",
      "quarterly",
      "semi_annual",
      "annual"
    ]);
    disbursementTypeEnum = pgEnum("disbursement_type", [
      "taxes",
      "insurance",
      "hoa",
      "other"
    ]);
    paymentMethodEnum = pgEnum("payment_method", [
      "check",
      "ach",
      "wire",
      "cash",
      "credit_card",
      "online"
    ]);
    disbursementPaymentMethodEnum = pgEnum(
      "disbursement_payment_method",
      ["check", "ach", "wire"]
    );
    disbursementStatusEnum = pgEnum("disbursement_status", [
      "active",
      "on_hold",
      "suspended",
      "cancelled",
      "completed",
      "terminated"
      // For historical records that are no longer active (e.g., old insurance policies)
    ]);
    collectionStatusEnum = pgEnum("collection_status", [
      "current",
      "contact_made",
      "promise_to_pay",
      "arrangement_made",
      "broken_promise",
      "skip_trace",
      "legal_review",
      "foreclosure_initiated",
      "charge_off_pending"
    ]);
    users = pgTable(
      "users",
      {
        id: serial("id").primaryKey(),
        username: text("username").unique().notNull(),
        password: text("password").notNull(),
        email: text("email").unique().notNull(),
        firstName: text("first_name").notNull(),
        lastName: text("last_name").notNull(),
        middleName: text("middle_name"),
        // role field removed - using RBAC system with user_roles junction table instead
        phone: text("phone"),
        mobilePhone: text("mobile_phone"),
        fax: text("fax"),
        address: text("address"),
        address2: text("address_2"),
        city: text("city"),
        state: text("state"),
        zipCode: text("zip_code"),
        country: text("country").default("USA"),
        dateOfBirth: date("date_of_birth"),
        ssn: text("ssn"),
        // Encrypted
        employerName: text("employer_name"),
        employerPhone: text("employer_phone"),
        jobTitle: text("job_title"),
        yearsEmployed: integer("years_employed"),
        monthlyIncome: decimal("monthly_income", { precision: 12, scale: 2 }),
        isActive: boolean("is_active").default(true).notNull(),
        emailVerified: boolean("email_verified").default(false).notNull(),
        twoFactorEnabled: boolean("two_factor_enabled").default(false).notNull(),
        mfaEnabled: boolean("mfa_enabled").default(false),
        mfaRequired: boolean("mfa_required").default(false),
        require_mfa_for_sensitive: boolean("require_mfa_for_sensitive").default(
          true
        ),
        profileImage: text("profile_image"),
        preferences: jsonb("preferences"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull(),
        lastLogin: timestamp("last_login"),
        failedLoginAttempts: integer("failed_login_attempts").default(0),
        lockedUntil: timestamp("locked_until")
      },
      (table) => {
        return {
          emailIdx: index("user_email_idx").on(table.email),
          // roleIdx removed - using RBAC system with user_roles junction table instead
          activeIdx: index("user_active_idx").on(table.isActive)
        };
      }
    );
    borrowerEntities = pgTable(
      "borrower_entities",
      {
        id: serial("id").primaryKey(),
        entityType: entityTypeEnum("entity_type").notNull(),
        // Individual fields
        firstName: text("first_name"),
        lastName: text("last_name"),
        middleName: text("middle_name"),
        suffix: text("suffix"),
        dateOfBirth: date("date_of_birth"),
        ssn: text("ssn"),
        // Encrypted
        // Entity fields
        entityName: text("entity_name"),
        ein: text("ein"),
        // Employer Identification Number
        formationDate: date("formation_date"),
        formationState: text("formation_state"),
        // Common fields
        email: text("email"),
        phone: text("phone"),
        mobilePhone: text("mobile_phone"),
        fax: text("fax"),
        website: text("website"),
        // Address
        mailingAddress: text("mailing_address"),
        mailingAddress2: text("mailing_address_2"),
        mailingCity: text("mailing_city"),
        mailingState: text("mailing_state"),
        mailingZip: text("mailing_zip"),
        mailingCountry: text("mailing_country").default("USA"),
        // Financial information
        creditScore: integer("credit_score"),
        monthlyIncome: decimal("monthly_income", { precision: 12, scale: 2 }),
        totalAssets: decimal("total_assets", { precision: 15, scale: 2 }),
        totalLiabilities: decimal("total_liabilities", { precision: 15, scale: 2 }),
        // Status
        isActive: boolean("is_active").default(true).notNull(),
        verificationStatus: text("verification_status").default("pending"),
        verificationDate: timestamp("verification_date"),
        notes: text("notes"),
        metadata: jsonb("metadata"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          entityTypeIdx: index("borrower_entity_type_idx").on(table.entityType),
          emailIdx: index("borrower_email_idx").on(table.email),
          ssnIdx: index("borrower_ssn_idx").on(table.ssn),
          einIdx: index("borrower_ein_idx").on(table.ein)
        };
      }
    );
    properties = pgTable(
      "properties",
      {
        id: serial("id").primaryKey(),
        propertyType: propertyTypeEnum("property_type").notNull(),
        // Address
        address: text("address").notNull(),
        address2: text("address_2"),
        city: text("city").notNull(),
        state: text("state").notNull(),
        zipCode: text("zip_code").notNull(),
        county: text("county"),
        country: text("country").default("USA"),
        // Legal description
        legalDescription: text("legal_description"),
        apn: text("apn"),
        // Assessor's Parcel Number
        lotNumber: text("lot_number"),
        blockNumber: text("block_number"),
        subdivision: text("subdivision"),
        // Property details
        yearBuilt: integer("year_built"),
        squareFeet: integer("square_feet"),
        lotSize: decimal("lot_size", { precision: 10, scale: 2 }),
        bedrooms: integer("bedrooms"),
        bathrooms: decimal("bathrooms", { precision: 3, scale: 1 }),
        stories: integer("stories"),
        garage: boolean("garage").default(false),
        garageSpaces: integer("garage_spaces"),
        pool: boolean("pool").default(false),
        // Valuation
        purchasePrice: decimal("purchase_price", { precision: 15, scale: 2 }),
        purchaseDate: date("purchase_date"),
        originalAppraisalValue: decimal("original_appraisal_value", {
          precision: 15,
          scale: 2
        }),
        originalAppraisalDate: date("original_appraisal_date"),
        currentValue: decimal("current_value", { precision: 15, scale: 2 }),
        currentValueDate: date("current_value_date"),
        currentValueSource: text("current_value_source"),
        // Tax and insurance
        annualPropertyTax: decimal("annual_property_tax", {
          precision: 10,
          scale: 2
        }),
        annualInsurance: decimal("annual_insurance", { precision: 10, scale: 2 }),
        annualHOA: decimal("annual_hoa", { precision: 10, scale: 2 }),
        taxId: text("tax_id"),
        // Status
        occupancyStatus: text("occupancy_status"),
        // 'owner_occupied', 'rental', 'second_home', 'vacant'
        rentalIncome: decimal("rental_income", { precision: 10, scale: 2 }),
        primaryResidence: boolean("primary_residence").default(false),
        metadata: jsonb("metadata"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          apnIdx: index("property_apn_idx").on(table.apn),
          addressIdx: index("property_address_idx").on(
            table.address,
            table.city,
            table.state
          ),
          typeIdx: index("property_type_idx").on(table.propertyType)
        };
      }
    );
    loans = pgTable(
      "loans",
      {
        id: serial("id").primaryKey(),
        loanNumber: text("loan_number").unique().notNull(),
        loanType: loanTypeEnum("loan_type").notNull(),
        loanPurpose: text("loan_purpose"),
        // 'purchase', 'refinance', 'cash_out', 'construction'
        // Parties
        lenderId: integer("lender_id").references(() => users.id),
        servicerId: integer("servicer_id").references(() => users.id),
        investorId: integer("investor_id").references(() => users.id),
        // Property
        propertyId: integer("property_id").references(() => properties.id).notNull(),
        // Loan terms
        originalAmount: decimal("original_amount", {
          precision: 15,
          scale: 2
        }).notNull(),
        principalBalance: decimal("principal_balance", {
          precision: 15,
          scale: 2
        }).notNull(),
        interestRate: decimal("interest_rate", {
          precision: 6,
          scale: 4
        }).notNull(),
        rateType: text("rate_type").notNull(),
        // 'fixed', 'variable', 'adjustable'
        indexType: text("index_type"),
        // 'SOFR', 'prime', 'LIBOR'
        margin: decimal("margin", { precision: 6, scale: 4 }),
        rateAdjustmentFrequency: integer("rate_adjustment_frequency"),
        // months
        rateCapInitial: decimal("rate_cap_initial", { precision: 6, scale: 4 }),
        rateCapPeriodic: decimal("rate_cap_periodic", { precision: 6, scale: 4 }),
        rateCapLifetime: decimal("rate_cap_lifetime", { precision: 6, scale: 4 }),
        rateFloor: decimal("rate_floor", { precision: 6, scale: 4 }),
        // Terms
        loanTerm: integer("loan_term").notNull(),
        // months
        amortizationTerm: integer("amortization_term"),
        // months
        balloonMonths: integer("balloon_months"),
        balloonAmount: decimal("balloon_amount", { precision: 15, scale: 2 }),
        prepaymentPenalty: boolean("prepayment_penalty").default(false),
        prepaymentPenaltyTerm: integer("prepayment_penalty_term"),
        // months
        prepaymentPenaltyAmount: decimal("prepayment_penalty_amount", {
          precision: 10,
          scale: 2
        }),
        prepaymentExpirationDate: date("prepayment_expiration_date"),
        // Dates
        applicationDate: date("application_date"),
        approvalDate: date("approval_date"),
        fundingDate: date("funding_date"),
        firstPaymentDate: date("first_payment_date"),
        maturityDate: date("maturity_date").notNull(),
        nextPaymentDate: date("next_payment_date"),
        lastPaymentDate: date("last_payment_date"),
        // Payment information
        paymentFrequency: frequencyEnum("payment_frequency").default("monthly").notNull(),
        paymentAmount: decimal("payment_amount", {
          precision: 10,
          scale: 2
        }).notNull(),
        principalAndInterest: decimal("principal_and_interest", {
          precision: 10,
          scale: 2
        }),
        monthlyEscrow: decimal("monthly_escrow", { precision: 10, scale: 2 }),
        monthlyMI: decimal("monthly_mi", { precision: 10, scale: 2 }),
        paymentDueDay: integer("payment_due_day"),
        // Day of month (1-31)
        // LTV and Insurance
        originalLTV: decimal("original_ltv", { precision: 5, scale: 2 }),
        currentLTV: decimal("current_ltv", { precision: 5, scale: 2 }),
        combinedLTV: decimal("combined_ltv", { precision: 5, scale: 2 }),
        miRequired: boolean("mi_required").default(false),
        miProvider: text("mi_provider"),
        miCertificateNumber: text("mi_certificate_number"),
        // Escrow
        escrowRequired: boolean("escrow_required").default(false),
        escrowWaived: boolean("escrow_waived").default(false),
        // Status
        status: loanStatusEnum("status").notNull(),
        statusDate: timestamp("status_date").defaultNow().notNull(),
        statusReason: text("status_reason"),
        delinquentDays: integer("delinquent_days").default(0),
        timesDelinquent30: integer("times_delinquent_30").default(0),
        timesDelinquent60: integer("times_delinquent_60").default(0),
        timesDelinquent90: integer("times_delinquent_90").default(0),
        foreclosureDate: date("foreclosure_date"),
        saleDate: date("sale_date"),
        // Servicing - single field with type toggle (like late charge)
        servicingFee: decimal("servicing_fee", { precision: 10, scale: 2 }),
        servicingFeeType: text("servicing_fee_type").notNull().default("percentage"),
        // 'amount' or 'percentage' - indicates how to interpret servicingFee
        lateCharge: decimal("late_charge", { precision: 10, scale: 2 }),
        lateChargeType: text("late_charge_type").notNull().default("percentage"),
        // 'fixed' or 'percentage' - explicitly named
        feePayer: text("fee_payer"),
        // 'B', 'S', 'SP'
        gracePeriodDays: integer("grace_period_days"),
        investorLoanNumber: text("investor_loan_number"),
        poolNumber: text("pool_number"),
        // Compliance
        hmda: boolean("hmda").default(false),
        hoepa: boolean("hoepa").default(false),
        qm: boolean("qm").default(false),
        // Qualified Mortgage
        // Borrower Information (basic contact info stored in loan for quick access)
        borrowerName: text("borrower_name"),
        borrowerCompanyName: text("borrower_company_name"),
        borrowerEmail: text("borrower_email"),
        borrowerPhone: text("borrower_phone"),
        borrowerMobile: text("borrower_mobile"),
        borrowerPhoto: text("borrower_photo"),
        // Borrower mailing address (separate from property address)
        borrowerAddress: text("borrower_address"),
        borrowerCity: text("borrower_city"),
        borrowerState: text("borrower_state"),
        borrowerZip: text("borrower_zip"),
        // Enhanced AI-extracted fields
        borrowerSSN: text("borrower_ssn"),
        borrowerIncome: decimal("borrower_income", { precision: 15, scale: 2 }),
        // Credit scores for borrower
        creditScoreEquifax: integer("credit_score_equifax"),
        creditScoreExperian: integer("credit_score_experian"),
        creditScoreTransunion: integer("credit_score_transunion"),
        // Co-Borrower information
        coBorrowerName: text("co_borrower_name"),
        coBorrowerCompanyName: text("co_borrower_company_name"),
        coBorrowerEmail: text("co_borrower_email"),
        coBorrowerPhone: text("co_borrower_phone"),
        coBorrowerAddress: text("co_borrower_address"),
        coBorrowerCity: text("co_borrower_city"),
        coBorrowerState: text("co_borrower_state"),
        coBorrowerZip: text("co_borrower_zip"),
        coBorrowerSSN: text("co_borrower_ssn"),
        coBorrowerIncome: decimal("co_borrower_income", {
          precision: 15,
          scale: 2
        }),
        coBorrowerCreditScoreEquifax: integer("co_borrower_credit_score_equifax"),
        coBorrowerCreditScoreExperian: integer("co_borrower_credit_score_experian"),
        coBorrowerCreditScoreTransunion: integer(
          "co_borrower_credit_score_transunion"
        ),
        // Trustee information
        trusteeName: text("trustee_name"),
        trusteeCompanyName: text("trustee_company_name"),
        trusteePhone: text("trustee_phone"),
        trusteeEmail: text("trustee_email"),
        trusteeStreetAddress: text("trustee_street_address"),
        trusteeCity: text("trustee_city"),
        trusteeState: text("trustee_state"),
        trusteeZipCode: text("trustee_zip_code"),
        // Beneficiary information
        beneficiaryName: text("beneficiary_name"),
        beneficiaryCompanyName: text("beneficiary_company_name"),
        beneficiaryPhone: text("beneficiary_phone"),
        beneficiaryEmail: text("beneficiary_email"),
        beneficiaryStreetAddress: text("beneficiary_street_address"),
        beneficiaryCity: text("beneficiary_city"),
        beneficiaryState: text("beneficiary_state"),
        beneficiaryZipCode: text("beneficiary_zip_code"),
        // Escrow company information
        escrowCompanyName: text("escrow_company_name"),
        escrowNumber: text("escrow_number"),
        escrowCompanyPhone: text("escrow_company_phone"),
        escrowCompanyEmail: text("escrow_company_email"),
        escrowCompanyStreetAddress: text("escrow_company_street_address"),
        escrowCompanyCity: text("escrow_company_city"),
        escrowCompanyState: text("escrow_company_state"),
        escrowCompanyZipCode: text("escrow_company_zip_code"),
        loanDocuments: jsonb("loan_documents"),
        defaultConditions: jsonb("default_conditions"),
        insuranceRequirements: jsonb("insurance_requirements"),
        crossDefaultParties: jsonb("cross_default_parties"),
        closingCosts: decimal("closing_costs", { precision: 15, scale: 2 }),
        downPayment: decimal("down_payment", { precision: 15, scale: 2 }),
        // Insurance and Tax fields (for temporary storage during creation)
        hazardInsurance: decimal("hazard_insurance", { precision: 10, scale: 2 }),
        propertyTaxes: decimal("property_taxes", { precision: 10, scale: 2 }),
        hoaFees: decimal("hoa_fees", { precision: 10, scale: 2 }),
        pmiAmount: decimal("pmi_amount", { precision: 10, scale: 2 }),
        // servicingFee removed - using servicingFeeRate/servicingFeeAmount instead
        // Additional payment fields for UI compatibility
        propertyTax: decimal("property_tax", { precision: 10, scale: 2 }),
        homeInsurance: decimal("home_insurance", { precision: 10, scale: 2 }),
        pmi: decimal("pmi", { precision: 10, scale: 2 }),
        otherMonthly: decimal("other_monthly", { precision: 10, scale: 2 }),
        // Additional fields
        notes: text("notes"),
        metadata: jsonb("metadata"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanNumberIdx: uniqueIndex("loan_number_idx").on(table.loanNumber),
          statusIdx: index("loan_status_idx").on(table.status),
          propertyIdx: index("loan_property_idx").on(table.propertyId),
          maturityIdx: index("loan_maturity_idx").on(table.maturityDate),
          nextPaymentIdx: index("loan_next_payment_idx").on(table.nextPaymentDate)
        };
      }
    );
    loanBorrowers = pgTable(
      "loan_borrowers",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").references(() => loans.id).notNull(),
        borrowerId: integer("borrower_id").references(() => borrowerEntities.id).notNull(),
        borrowerType: text("borrower_type").notNull(),
        // 'primary', 'co_borrower', 'guarantor'
        ownershipPercentage: decimal("ownership_percentage", {
          precision: 8,
          scale: 6
        }),
        // Aligned with investors table for precise splits
        signingAuthority: boolean("signing_authority").default(true),
        liabilityPercentage: decimal("liability_percentage", {
          precision: 5,
          scale: 2
        }),
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanBorrowerIdx: uniqueIndex("loan_borrower_idx").on(
            table.loanId,
            table.borrowerId
          ),
          loanIdx: index("loan_borrowers_loan_idx").on(table.loanId),
          borrowerIdx: index("loan_borrowers_borrower_idx").on(table.borrowerId)
        };
      }
    );
    guarantors = pgTable(
      "guarantors",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").references(() => loans.id).notNull(),
        guarantorEntityId: integer("guarantor_entity_id").references(() => borrowerEntities.id).notNull(),
        guaranteeAmount: decimal("guarantee_amount", { precision: 15, scale: 2 }),
        guaranteePercentage: decimal("guarantee_percentage", {
          precision: 5,
          scale: 2
        }),
        guaranteeType: text("guarantee_type"),
        // 'full', 'limited', 'payment', 'collection'
        startDate: date("start_date"),
        endDate: date("end_date"),
        isActive: boolean("is_active").default(true),
        notes: text("notes"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanIdx: index("guarantor_loan_idx").on(table.loanId),
          entityIdx: index("guarantor_entity_idx").on(table.guarantorEntityId)
        };
      }
    );
    investors = pgTable(
      "investors",
      {
        id: serial("id").primaryKey(),
        investorId: text("investor_id").unique().notNull(),
        // Unique investor identifier
        loanId: integer("loan_id").references(() => loans.id).notNull(),
        // Investor details
        entityType: entityTypeEnum("entity_type").notNull(),
        // 'individual' or 'entity'
        name: text("name").notNull(),
        // Individual or entity name
        contactName: text("contact_name"),
        // Contact person if entity
        ssnOrEin: text("ssn_or_ein"),
        // SSN for individuals or EIN for entities
        email: text("email"),
        phone: text("phone"),
        // Address
        streetAddress: text("street_address"),
        city: text("city"),
        state: text("state"),
        zipCode: text("zip_code"),
        // Banking information
        bankName: text("bank_name"),
        bankStreetAddress: text("bank_street_address"),
        bankCity: text("bank_city"),
        bankState: text("bank_state"),
        bankZipCode: text("bank_zip_code"),
        accountNumber: text("account_number"),
        // Encrypted
        routingNumber: text("routing_number"),
        accountType: text("account_type"),
        // 'checking', 'savings'
        // Ownership
        ownershipPercentage: decimal("ownership_percentage", {
          precision: 8,
          scale: 6
        }).notNull(),
        // 0.000000 to 99.999999 for precise splits
        investmentAmount: decimal("investment_amount", { precision: 15, scale: 2 }),
        investmentDate: date("investment_date"),
        // Status
        isActive: boolean("is_active").default(true).notNull(),
        notes: text("notes"),
        metadata: jsonb("metadata"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanIdx: index("investor_loan_idx").on(table.loanId),
          investorIdIdx: uniqueIndex("investor_id_idx").on(table.investorId),
          activeIdx: index("investor_active_idx").on(table.isActive)
        };
      }
    );
    paymentSchedule = pgTable(
      "payment_schedule",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").references(() => loans.id).notNull(),
        paymentNumber: integer("payment_number").notNull(),
        dueDate: date("due_date").notNull(),
        principalAmount: decimal("principal_amount", {
          precision: 10,
          scale: 2
        }).notNull(),
        interestAmount: decimal("interest_amount", {
          precision: 10,
          scale: 2
        }).notNull(),
        escrowAmount: decimal("escrow_amount", { precision: 10, scale: 2 }),
        miAmount: decimal("mi_amount", { precision: 10, scale: 2 }),
        totalAmount: decimal("total_amount", { precision: 10, scale: 2 }).notNull(),
        principalBalance: decimal("principal_balance", {
          precision: 15,
          scale: 2
        }).notNull(),
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanPaymentIdx: uniqueIndex("schedule_loan_payment_idx").on(
            table.loanId,
            table.paymentNumber
          ),
          dueDateIdx: index("schedule_due_date_idx").on(table.dueDate)
        };
      }
    );
    payments = pgTable(
      "payments",
      {
        id: varchar("id", { length: 36 }).primaryKey().default(sql2`gen_random_uuid()`),
        loanId: integer("loan_id").references(() => loans.id).notNull(),
        scheduleId: integer("schedule_id").references(() => paymentSchedule.id),
        paymentNumber: integer("payment_number"),
        // Dates
        dueDate: date("due_date"),
        receivedDate: timestamp("received_date"),
        effectiveDate: date("effective_date").notNull(),
        // Amounts
        scheduledAmount: decimal("scheduled_amount", { precision: 10, scale: 2 }),
        totalReceived: decimal("total_received", {
          precision: 10,
          scale: 2
        }).notNull(),
        principalAmount: decimal("principal_amount", { precision: 10, scale: 2 }),
        interestAmount: decimal("interest_amount", { precision: 10, scale: 2 }),
        escrowAmount: decimal("escrow_amount", { precision: 10, scale: 2 }),
        miAmount: decimal("mi_amount", { precision: 10, scale: 2 }),
        lateFeeAmount: decimal("late_fee_amount", { precision: 8, scale: 2 }),
        otherFeeAmount: decimal("other_fee_amount", { precision: 8, scale: 2 }),
        // Payment details
        paymentMethod: text("payment_method"),
        // 'check', 'ach', 'wire', 'cash', 'credit_card'
        checkNumber: text("check_number"),
        transactionId: text("transaction_id"),
        confirmationNumber: text("confirmation_number"),
        // Status
        status: paymentStatusEnum("status").notNull(),
        nsfCount: integer("nsf_count").default(0),
        reversalReason: text("reversal_reason"),
        // Processing
        processedBy: integer("processed_by").references(() => users.id),
        processedDate: timestamp("processed_date"),
        batchId: text("batch_id"),
        // Column Bank Integration
        columnTransferId: varchar("column_transfer_id", { length: 100 }),
        columnAccountId: text("column_account_id"),
        columnEventLastSeen: text("column_event_last_seen"),
        columnWebhookId: varchar("column_webhook_id", { length: 100 }),
        // Source and Idempotency
        sourceChannel: text("source_channel"),
        // 'manual', 'ach', 'wire', 'api', 'column'
        idempotencyKey: varchar("idempotency_key", { length: 256 }).unique(),
        // Suspense and Reconciliation
        suspenseAmount: decimal("suspense_amount", { precision: 18, scale: 2 }).default("0").notNull(),
        reconciledAt: timestamp("reconciled_at"),
        reconciledBy: integer("reconciled_by").references(() => users.id),
        // AI Processing
        aiProcessed: boolean("ai_processed").default(false),
        aiConfidenceScore: decimal("ai_confidence_score", {
          precision: 3,
          scale: 2
        }),
        aiSuggestedAllocation: jsonb("ai_suggested_allocation"),
        // Additional
        notes: text("notes"),
        metadata: jsonb("metadata"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanIdx: index("payment_loan_idx").on(table.loanId),
          dueDateIdx: index("payment_due_date_idx").on(table.dueDate),
          effectiveDateIdx: index("payment_effective_date_idx").on(
            table.effectiveDate
          ),
          statusIdx: index("payment_status_idx").on(table.status),
          batchIdx: index("payment_batch_idx").on(table.batchId),
          columnTransferIdx: index("payments_column_transfer_idx").on(
            table.columnTransferId
          )
        };
      }
    );
    escrowAccounts2 = pgTable(
      "escrow_accounts",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").references(() => loans.id).unique().notNull(),
        accountNumber: text("account_number").unique().notNull(),
        // Balances
        currentBalance: decimal("current_balance", { precision: 12, scale: 2 }).default("0").notNull(),
        availableBalance: decimal("available_balance", {
          precision: 12,
          scale: 2
        }).default("0"),
        pendingDeposits: decimal("pending_deposits", {
          precision: 12,
          scale: 2
        }).default("0"),
        pendingDisbursements: decimal("pending_disbursements", {
          precision: 12,
          scale: 2
        }).default("0"),
        // Requirements
        monthlyPayment: decimal("monthly_payment", {
          precision: 10,
          scale: 2
        }).default("0"),
        minimumBalance: decimal("minimum_balance", {
          precision: 10,
          scale: 2
        }).default("0"),
        cushionAmount: decimal("cushion_amount", {
          precision: 10,
          scale: 2
        }).default("0"),
        targetBalance: decimal("target_balance", {
          precision: 12,
          scale: 2
        }).default("0"),
        // Analysis
        projectedLowestBalance: decimal("projected_lowest_balance", {
          precision: 12,
          scale: 2
        }),
        projectedLowestMonth: text("projected_lowest_month"),
        shortageAmount: decimal("shortage_amount", {
          precision: 10,
          scale: 2
        }).default("0"),
        surplusAmount: decimal("surplus_amount", {
          precision: 10,
          scale: 2
        }).default("0"),
        shortageSpreadMonths: integer("shortage_spread_months"),
        // Analysis dates
        lastAnalysisDate: date("last_analysis_date"),
        nextAnalysisDate: date("next_analysis_date"),
        analysisEffectiveDate: date("analysis_effective_date"),
        // Status
        isActive: boolean("is_active").default(true).notNull(),
        waived: boolean("waived").default(false),
        waivedDate: date("waived_date"),
        waivedBy: integer("waived_by").references(() => users.id),
        waivedReason: text("waived_reason"),
        // Additional
        notes: text("notes"),
        metadata: jsonb("metadata"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          accountNumberIdx: uniqueIndex("escrow_account_number_idx").on(
            table.accountNumber
          ),
          loanIdx: uniqueIndex("escrow_loan_idx").on(table.loanId),
          activeIdx: index("escrow_active_idx").on(table.isActive)
        };
      }
    );
    escrowDisbursements2 = pgTable(
      "escrow_disbursements",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").references(() => loans.id).notNull(),
        escrowAccountId: integer("escrow_account_id").references(() => escrowAccounts2.id).notNull(),
        // Disbursement classification
        disbursementType: disbursementTypeEnum("disbursement_type").notNull(),
        description: text("description").notNull(),
        category: text("category"),
        // subcategory within type
        // Payee information
        payeeName: text("payee_name").notNull(),
        payeeContactName: text("payee_contact_name"),
        payeePhone: text("payee_phone"),
        payeeEmail: text("payee_email"),
        payeeFax: text("payee_fax"),
        // Payee address
        payeeStreetAddress: text("payee_street_address"),
        payeeCity: text("payee_city"),
        payeeState: text("payee_state"),
        payeeZipCode: text("payee_zip_code"),
        // Type-specific fields
        parcelNumber: text("parcel_number"),
        // For property taxes
        // Insurance-specific fields
        policyNumber: text("policy_number"),
        // For insurance
        insuredName: text("insured_name"),
        // Name of the insured party
        insuranceCompanyName: text("insurance_company_name"),
        // Insurance company name
        policyDescription: text("policy_description"),
        // Type of insurance (Hazard, Flood, etc.)
        policyExpirationDate: date("policy_expiration_date"),
        // Policy expiration date
        coverageAmount: decimal("coverage_amount", { precision: 12, scale: 2 }),
        // Coverage amount in dollars
        // Insurance property information
        insurancePropertyAddress: text("insurance_property_address"),
        // Property covered by insurance
        insurancePropertyCity: text("insurance_property_city"),
        insurancePropertyState: text("insurance_property_state"),
        insurancePropertyZipCode: text("insurance_property_zip_code"),
        // Insurance agent information
        agentName: text("agent_name"),
        // Insurance agent's name
        agentBusinessAddress: text("agent_business_address"),
        // Agent's business address
        agentCity: text("agent_city"),
        agentState: text("agent_state"),
        agentZipCode: text("agent_zip_code"),
        agentPhone: text("agent_phone"),
        // Agent's phone number
        agentFax: text("agent_fax"),
        // Agent's fax number
        agentEmail: text("agent_email"),
        // Agent's email
        // Insurance document reference
        insuranceDocumentId: integer("insurance_document_id").references(
          () => documents.id
        ),
        // Link to uploaded insurance document
        insuranceTracking: boolean("insurance_tracking").default(true),
        // Active insurance tracking status
        // Payment method and banking information
        paymentMethod: disbursementPaymentMethodEnum("payment_method").notNull().default("check"),
        bankAccountNumber: text("bank_account_number"),
        // Encrypted - replaces accountNumber
        achRoutingNumber: text("ach_routing_number"),
        wireRoutingNumber: text("wire_routing_number"),
        accountType: text("account_type"),
        // 'checking', 'savings'
        bankName: text("bank_name"),
        wireInstructions: text("wire_instructions"),
        // Remittance information
        remittanceAddress: text("remittance_address"),
        remittanceCity: text("remittance_city"),
        remittanceState: text("remittance_state"),
        remittanceZipCode: text("remittance_zip_code"),
        accountNumber: text("account_number"),
        // For taxes - property tax account number
        referenceNumber: text("reference_number"),
        // Recurrence pattern
        frequency: frequencyEnum("frequency").notNull(),
        monthlyAmount: decimal("monthly_amount", { precision: 10, scale: 2 }),
        annualAmount: decimal("annual_amount", {
          precision: 10,
          scale: 2
        }).notNull(),
        paymentAmount: decimal("payment_amount", {
          precision: 10,
          scale: 2
        }).notNull(),
        // Due dates and scheduling
        firstDueDate: date("first_due_date"),
        nextDueDate: date("next_due_date").notNull(),
        lastPaidDate: date("last_paid_date"),
        specificDueDates: jsonb("specific_due_dates"),
        // For taxes with specific bi-annual dates
        // Status and holds
        status: disbursementStatusEnum("status").notNull().default("active"),
        isOnHold: boolean("is_on_hold").default(false).notNull(),
        holdReason: text("hold_reason"),
        holdRequestedBy: text("hold_requested_by"),
        holdDate: timestamp("hold_date"),
        // Auto-pay settings
        autoPayEnabled: boolean("auto_pay_enabled").default(true),
        daysBeforeDue: integer("days_before_due").default(10),
        // How many days before due date to pay
        // Additional tracking
        notes: text("notes"),
        metadata: jsonb("metadata"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanIdx: index("escrow_disb_loan_idx").on(table.loanId),
          accountIdx: index("escrow_disb_account_idx").on(table.escrowAccountId),
          typeIdx: index("escrow_disb_type_idx").on(table.disbursementType),
          nextDueIdx: index("escrow_disb_next_due_idx").on(table.nextDueDate),
          statusIdx: index("escrow_disb_status_idx").on(table.status),
          holdIdx: index("escrow_disb_hold_idx").on(table.isOnHold)
        };
      }
    );
    escrowDisbursementPayments = pgTable(
      "escrow_disbursement_payments",
      {
        id: serial("id").primaryKey(),
        disbursementId: integer("disbursement_id").references(() => escrowDisbursements2.id).notNull(),
        loanId: integer("loan_id").references(() => loans.id).notNull(),
        ledgerEntryId: integer("ledger_entry_id"),
        // References accounting ledger entry
        // Payment details
        paymentDate: timestamp("payment_date").notNull(),
        dueDate: date("due_date").notNull(),
        amount: decimal("amount", { precision: 10, scale: 2 }).notNull(),
        // Payment method used
        paymentMethod: paymentMethodEnum("payment_method").notNull(),
        checkNumber: text("check_number"),
        wireConfirmation: text("wire_confirmation"),
        achTransactionId: text("ach_transaction_id"),
        // Status
        status: paymentStatusEnum("status").notNull().default("scheduled"),
        confirmationNumber: text("confirmation_number"),
        // Processing
        processedBy: integer("processed_by").references(() => users.id),
        processedDate: timestamp("processed_date"),
        // Additional
        notes: text("notes"),
        metadata: jsonb("metadata"),
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (table) => {
        return {
          disbursementIdx: index("escrow_payment_disbursement_idx").on(
            table.disbursementId
          ),
          loanIdx: index("escrow_payment_loan_idx").on(table.loanId),
          dueDateIdx: index("escrow_payment_due_date_idx").on(table.dueDate),
          statusIdx: index("escrow_payment_status_idx").on(table.status)
        };
      }
    );
    escrowTransactions = pgTable(
      "escrow_transactions",
      {
        id: serial("id").primaryKey(),
        escrowAccountId: integer("escrow_account_id").references(() => escrowAccounts2.id).notNull(),
        escrowItemId: integer("escrow_item_id"),
        // References escrow item
        // Transaction details
        transactionDate: timestamp("transaction_date").notNull(),
        effectiveDate: date("effective_date").notNull(),
        transactionType: transactionTypeEnum("transaction_type").notNull(),
        amount: decimal("amount", { precision: 10, scale: 2 }).notNull(),
        runningBalance: decimal("running_balance", {
          precision: 12,
          scale: 2
        }).notNull(),
        // Payment details
        payeeId: integer("payee_id").references(() => payees.id),
        checkNumber: text("check_number"),
        wireConfirmation: text("wire_confirmation"),
        referenceNumber: text("reference_number"),
        // Source
        paymentId: integer("payment_id").references(() => payments.id),
        // Processing
        processedBy: integer("processed_by").references(() => users.id),
        approvedBy: integer("approved_by").references(() => users.id),
        batchId: text("batch_id"),
        // Additional
        description: text("description").notNull(),
        notes: text("notes"),
        metadata: jsonb("metadata"),
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (table) => {
        return {
          accountIdx: index("escrow_trans_account_idx").on(table.escrowAccountId),
          dateIdx: index("escrow_trans_date_idx").on(table.transactionDate),
          typeIdx: index("escrow_trans_type_idx").on(table.transactionType)
        };
      }
    );
    payees = pgTable(
      "payees",
      {
        id: serial("id").primaryKey(),
        payeeType: text("payee_type").notNull(),
        // 'tax_authority', 'insurance_company', 'hoa', 'utility', 'other'
        name: text("name").notNull(),
        // Contact
        contactName: text("contact_name"),
        phone: text("phone"),
        fax: text("fax"),
        email: text("email"),
        website: text("website"),
        // Address
        address: text("address"),
        address2: text("address_2"),
        city: text("city"),
        state: text("state"),
        zipCode: text("zip_code"),
        country: text("country").default("USA"),
        // Payment information
        paymentMethod: text("payment_method"),
        // 'check', 'ach', 'wire'
        accountNumber: text("account_number"),
        routingNumber: text("routing_number"),
        wireInstructions: text("wire_instructions"),
        // Tax specific
        taxAuthority: boolean("tax_authority").default(false),
        taxDistrict: text("tax_district"),
        // Insurance specific
        naicCode: text("naic_code"),
        // Status
        isActive: boolean("is_active").default(true).notNull(),
        isPreferred: boolean("is_preferred").default(false),
        // Additional
        notes: text("notes"),
        metadata: jsonb("metadata"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          nameIdx: index("payee_name_idx").on(table.name),
          typeIdx: index("payee_type_idx").on(table.payeeType),
          activeIdx: index("payee_active_idx").on(table.isActive)
        };
      }
    );
    documents = pgTable(
      "documents",
      {
        id: serial("id").primaryKey(),
        // References
        loanId: integer("loan_id").references(() => loans.id),
        borrowerId: integer("borrower_id").references(() => borrowerEntities.id),
        propertyId: integer("property_id").references(() => properties.id),
        // Document details
        category: documentCategoryEnum("category").notNull(),
        documentType: text("document_type"),
        title: text("title").notNull(),
        description: text("description"),
        // File information
        fileName: text("file_name").notNull(),
        fileSize: integer("file_size"),
        mimeType: text("mime_type"),
        storageUrl: text("storage_url").notNull(),
        thumbnailUrl: text("thumbnail_url"),
        // Document metadata
        documentDate: date("document_date"),
        recordedDate: date("recorded_date"),
        expirationDate: date("expiration_date"),
        // Recording information
        recordingNumber: text("recording_number"),
        bookNumber: text("book_number"),
        pageNumber: text("page_number"),
        instrumentNumber: text("instrument_number"),
        // Security and access
        isPublic: boolean("is_public").default(false).notNull(),
        isConfidential: boolean("is_confidential").default(false),
        requiresSignature: boolean("requires_signature").default(false),
        isSigned: boolean("is_signed").default(false),
        // Version control
        version: integer("version").default(1).notNull(),
        parentDocumentId: integer("parent_document_id").references(
          () => documents.id
        ),
        isCurrentVersion: boolean("is_current_version").default(true),
        // User tracking
        uploadedBy: integer("uploaded_by").references(() => users.id).notNull(),
        lastAccessedBy: integer("last_accessed_by").references(() => users.id),
        lastAccessedAt: timestamp("last_accessed_at"),
        // Status
        isActive: boolean("is_active").default(true).notNull(),
        archivedDate: timestamp("archived_date"),
        archivedBy: integer("archived_by").references(() => users.id),
        // Additional
        tags: text("tags").array(),
        notes: text("notes"),
        // Store AI extraction JSON or other notes
        metadata: jsonb("metadata"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanIdx: index("document_loan_idx").on(table.loanId),
          borrowerIdx: index("document_borrower_idx").on(table.borrowerId),
          categoryIdx: index("document_category_idx").on(table.category),
          uploadedByIdx: index("document_uploaded_by_idx").on(table.uploadedBy),
          documentDateIdx: index("document_date_idx").on(table.documentDate)
        };
      }
    );
    documentTemplate = pgTable("document_template", {
      templateId: varchar("template_id").primaryKey(),
      type: text("type").notNull(),
      jurisdiction: text("jurisdiction"),
      version: integer("version").notNull(),
      engine: text("engine").notNull(),
      htmlSource: text("html_source").notNull(),
      cssSource: text("css_source"),
      fontFamily: text("font_family"),
      createdAt: timestamp("created_at").defaultNow().notNull(),
      retiredAt: timestamp("retired_at")
    });
    documentTemplates = pgTable("document_templates", {
      id: serial("id").primaryKey(),
      name: text("name").notNull(),
      category: documentCategoryEnum("category").notNull(),
      description: text("description"),
      templateContent: text("template_content"),
      templateUrl: text("template_url"),
      variables: jsonb("variables"),
      // List of merge fields
      isActive: boolean("is_active").default(true),
      createdBy: integer("created_by").references(() => users.id),
      createdAt: timestamp("created_at").defaultNow().notNull(),
      updatedAt: timestamp("updated_at").defaultNow().notNull()
    });
    servicingInstructions = pgTable(
      "servicing_instructions",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").references(() => loans.id).notNull(),
        instructionType: text("instruction_type").notNull(),
        // 'payment', 'escrow', 'collection', 'reporting'
        priority: priorityEnum("priority").default("medium"),
        effectiveDate: date("effective_date").notNull(),
        expirationDate: date("expiration_date"),
        instructions: text("instructions").notNull(),
        isActive: boolean("is_active").default(true),
        createdBy: integer("created_by").references(() => users.id),
        approvedBy: integer("approved_by").references(() => users.id),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanIdx: index("servicing_loan_idx").on(table.loanId),
          typeIdx: index("servicing_type_idx").on(table.instructionType),
          activeIdx: index("servicing_active_idx").on(table.isActive)
        };
      }
    );
    collectionActivities = pgTable(
      "collection_activities",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").references(() => loans.id).notNull(),
        activityDate: timestamp("activity_date").defaultNow().notNull(),
        activityType: text("activity_type").notNull(),
        // 'call', 'letter', 'email', 'visit', 'legal'
        status: collectionStatusEnum("status").notNull(),
        contactMethod: text("contact_method"),
        contactPerson: text("contact_person"),
        phoneNumber: text("phone_number"),
        promiseDate: date("promise_date"),
        promiseAmount: decimal("promise_amount", { precision: 10, scale: 2 }),
        result: text("result"),
        nextActionDate: date("next_action_date"),
        nextAction: text("next_action"),
        notes: text("notes").notNull(),
        performedBy: integer("performed_by").references(() => users.id),
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanIdx: index("collection_loan_idx").on(table.loanId),
          dateIdx: index("collection_date_idx").on(table.activityDate),
          statusIdx: index("collection_status_idx").on(table.status)
        };
      }
    );
    legalProceedings = pgTable(
      "legal_proceedings",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").references(() => loans.id).notNull(),
        proceedingType: text("proceeding_type").notNull(),
        // 'foreclosure', 'bankruptcy', 'litigation', 'eviction'
        caseNumber: text("case_number"),
        courtName: text("court_name"),
        filingDate: date("filing_date"),
        attorneyName: text("attorney_name"),
        attorneyFirm: text("attorney_firm"),
        attorneyPhone: text("attorney_phone"),
        attorneyEmail: text("attorney_email"),
        status: text("status").notNull(),
        statusDate: date("status_date"),
        saleDate: date("sale_date"),
        redemptionDeadline: date("redemption_deadline"),
        notes: text("notes"),
        metadata: jsonb("metadata"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanIdx: index("legal_loan_idx").on(table.loanId),
          typeIdx: index("legal_type_idx").on(table.proceedingType),
          caseIdx: index("legal_case_idx").on(table.caseNumber)
        };
      }
    );
    feeTemplates = pgTable(
      "fee_templates",
      {
        id: serial("id").primaryKey(),
        lenderId: integer("lender_id").references(() => users.id).notNull(),
        templateName: text("template_name").notNull(),
        description: text("description"),
        isDefault: boolean("is_default").default(false),
        fees: jsonb("fees").notNull(),
        // Array of fee definitions
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          lenderIdx: index("fee_template_lender_idx").on(table.lenderId),
          defaultIdx: index("fee_template_default_idx").on(table.isDefault)
        };
      }
    );
    loanLedger = pgTable(
      "loan_ledger",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").references(() => loans.id).notNull(),
        transactionDate: timestamp("transaction_date").notNull(),
        transactionId: text("transaction_id").notNull().unique(),
        description: text("description").notNull(),
        transactionType: text("transaction_type").notNull(),
        // 'principal', 'interest', 'fee', 'payment', 'escrow', 'penalty', 'reversal'
        category: text("category"),
        // 'origination', 'servicing', 'late_fee', 'nsf', 'modification', 'payoff', 'recording', etc.
        debitAmount: decimal("debit_amount", { precision: 12, scale: 2 }),
        creditAmount: decimal("credit_amount", { precision: 12, scale: 2 }),
        runningBalance: decimal("running_balance", {
          precision: 12,
          scale: 2
        }).notNull(),
        principalBalance: decimal("principal_balance", {
          precision: 12,
          scale: 2
        }).notNull(),
        interestBalance: decimal("interest_balance", {
          precision: 12,
          scale: 2
        }).default("0"),
        status: text("status").notNull().default("posted"),
        // 'pending', 'posted', 'pending_approval', 'reversed'
        reversalOf: integer("reversal_of").references(() => loanLedger.id),
        reversedBy: integer("reversed_by").references(() => loanLedger.id),
        approvalRequired: boolean("approval_required").default(false),
        approvedBy: integer("approved_by").references(() => users.id),
        approvalDate: timestamp("approval_date"),
        approvalNotes: text("approval_notes"),
        createdBy: integer("created_by").references(() => users.id),
        notes: text("notes"),
        metadata: jsonb("metadata"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanIdx: index("ledger_loan_idx").on(table.loanId),
          dateIdx: index("ledger_date_idx").on(table.transactionDate),
          statusIdx: index("ledger_status_idx").on(table.status),
          typeIdx: index("ledger_type_idx").on(table.transactionType)
        };
      }
    );
    loanFees = pgTable(
      "loan_fees",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").references(() => loans.id).notNull(),
        feeType: text("fee_type").notNull(),
        // 'origination', 'servicing', 'late', 'nsf', 'modification', 'payoff', 'recording', etc.
        feeName: text("fee_name").notNull(),
        feeAmount: decimal("fee_amount", { precision: 10, scale: 2 }).notNull(),
        feePercentage: decimal("fee_percentage", { precision: 5, scale: 3 }),
        // For percentage-based fees
        frequency: text("frequency"),
        // 'one-time', 'monthly', 'quarterly', 'annual'
        chargeDate: date("charge_date"),
        dueDate: date("due_date"),
        paidDate: date("paid_date"),
        waived: boolean("waived").default(false),
        waivedBy: integer("waived_by").references(() => users.id),
        waivedReason: text("waived_reason"),
        notes: text("notes"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanIdx: index("loan_fee_loan_idx").on(table.loanId),
          typeIdx: index("loan_fee_type_idx").on(table.feeType),
          dueDateIdx: index("loan_fee_due_date_idx").on(table.dueDate)
        };
      }
    );
    insurancePolicies = pgTable(
      "insurance_policies",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").references(() => loans.id),
        propertyId: integer("property_id").references(() => properties.id).notNull(),
        policyType: text("policy_type").notNull(),
        // 'hazard', 'flood', 'earthquake', 'wind', 'liability'
        insuranceCompany: text("insurance_company").notNull(),
        policyNumber: text("policy_number").notNull(),
        effectiveDate: date("effective_date").notNull(),
        expirationDate: date("expiration_date").notNull(),
        coverageAmount: decimal("coverage_amount", {
          precision: 12,
          scale: 2
        }).notNull(),
        deductible: decimal("deductible", { precision: 10, scale: 2 }),
        annualPremium: decimal("annual_premium", {
          precision: 10,
          scale: 2
        }).notNull(),
        agentName: text("agent_name"),
        agentPhone: text("agent_phone"),
        agentEmail: text("agent_email"),
        isEscrowPaid: boolean("is_escrow_paid").default(false),
        isActive: boolean("is_active").default(true),
        lastVerifiedDate: date("last_verified_date"),
        notes: text("notes"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanIdx: index("insurance_loan_idx").on(table.loanId),
          propertyIdx: index("insurance_property_idx").on(table.propertyId),
          policyNumberIdx: index("insurance_policy_number_idx").on(
            table.policyNumber
          ),
          expirationIdx: index("insurance_expiration_idx").on(table.expirationDate)
        };
      }
    );
    notifications = pgTable(
      "notifications",
      {
        id: serial("id").primaryKey(),
        userId: integer("user_id").references(() => users.id).notNull(),
        type: notificationTypeEnum("type").notNull(),
        priority: priorityEnum("priority").default("medium").notNull(),
        title: text("title").notNull(),
        message: text("message").notNull(),
        relatedEntityType: text("related_entity_type"),
        relatedEntityId: integer("related_entity_id"),
        actionUrl: text("action_url"),
        isRead: boolean("is_read").default(false).notNull(),
        readAt: timestamp("read_at"),
        isArchived: boolean("is_archived").default(false),
        archivedAt: timestamp("archived_at"),
        scheduledFor: timestamp("scheduled_for"),
        sentAt: timestamp("sent_at"),
        emailSent: boolean("email_sent").default(false),
        smsSent: boolean("sms_sent").default(false),
        metadata: jsonb("metadata"),
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (table) => {
        return {
          userIdx: index("notification_user_idx").on(table.userId),
          readIdx: index("notification_is_read_idx").on(table.isRead),
          typeIdx: index("notification_type_idx").on(table.type),
          createdAtIdx: index("notification_created_idx").on(table.createdAt)
        };
      }
    );
    tasks = pgTable(
      "tasks",
      {
        id: serial("id").primaryKey(),
        title: text("title").notNull(),
        description: text("description"),
        taskType: text("task_type").notNull(),
        // 'review', 'approval', 'processing', 'verification'
        priority: priorityEnum("priority").default("medium"),
        status: text("status").notNull(),
        // 'pending', 'in_progress', 'completed', 'cancelled'
        // References
        loanId: integer("loan_id").references(() => loans.id),
        relatedEntityType: text("related_entity_type"),
        relatedEntityId: integer("related_entity_id"),
        // Assignment
        assignedTo: integer("assigned_to").references(() => users.id),
        assignedBy: integer("assigned_by").references(() => users.id),
        assignedDate: timestamp("assigned_date"),
        // Dates
        dueDate: timestamp("due_date"),
        startedDate: timestamp("started_date"),
        completedDate: timestamp("completed_date"),
        // Additional
        notes: text("notes"),
        metadata: jsonb("metadata"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          assignedToIdx: index("task_assigned_to_idx").on(table.assignedTo),
          statusIdx: index("task_status_idx").on(table.status),
          dueDateIdx: index("task_due_date_idx").on(table.dueDate),
          loanIdx: index("task_loan_idx").on(table.loanId)
        };
      }
    );
    systemSettings = pgTable(
      "system_settings",
      {
        id: serial("id").primaryKey(),
        category: text("category").notNull(),
        key: text("key").notNull(),
        value: jsonb("value").notNull(),
        description: text("description"),
        isEditable: boolean("is_editable").default(true),
        updatedBy: integer("updated_by").references(() => users.id),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          categoryKeyIdx: uniqueIndex("settings_category_key_idx").on(
            table.category,
            table.key
          )
        };
      }
    );
    noticeTemplates = pgTable(
      "notice_templates",
      {
        id: serial("id").primaryKey(),
        category: text("category").notNull(),
        // 'late', 'insurance', 'nsf', 'payoff', 'hud', 'arm', 'other'
        subcategory: text("subcategory"),
        // 'balloon', 'beneficiary', 'reinstate', 'gtm', etc.
        name: text("name").notNull(),
        description: text("description"),
        filename: text("filename"),
        fileUrl: text("file_url"),
        fileSize: integer("file_size"),
        mimeType: text("mime_type"),
        isActive: boolean("is_active").default(true),
        uploadedBy: integer("uploaded_by").references(() => users.id),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          categoryIdx: index("notice_template_category_idx").on(table.category),
          categorySubcategoryIdx: index("notice_template_cat_subcat_idx").on(
            table.category,
            table.subcategory
          )
        };
      }
    );
    noticeSettings = pgTable(
      "notice_settings",
      {
        id: serial("id").primaryKey(),
        category: text("category").notNull(),
        // 'late', 'nsf', 'payoff', etc.
        settingKey: text("setting_key").notNull(),
        settingValue: jsonb("setting_value").notNull(),
        description: text("description"),
        updatedBy: integer("updated_by").references(() => users.id),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          categoryKeyIdx: uniqueIndex("notice_settings_category_key_idx").on(
            table.category,
            table.settingKey
          )
        };
      }
    );
    usersRelations = relations(users, ({ many }) => ({
      loansAsLender: many(loans),
      loansAsServicer: many(loans),
      documentsUploaded: many(documents),
      notifications: many(notifications),
      tasks: many(tasks)
    }));
    loansRelations = relations(loans, ({ one, many }) => ({
      property: one(properties, {
        fields: [loans.propertyId],
        references: [properties.id]
      }),
      lender: one(users, {
        fields: [loans.lenderId],
        references: [users.id]
      }),
      servicer: one(users, {
        fields: [loans.servicerId],
        references: [users.id]
      }),
      investor: one(users, {
        fields: [loans.investorId],
        references: [users.id]
      }),
      borrowers: many(loanBorrowers),
      guarantors: many(guarantors),
      payments: many(payments),
      paymentSchedule: many(paymentSchedule),
      documents: many(documents),
      escrowAccount: one(escrowAccounts2),
      servicingInstructions: many(servicingInstructions),
      collectionActivities: many(collectionActivities),
      legalProceedings: many(legalProceedings),
      insurancePolicies: many(insurancePolicies),
      tasks: many(tasks)
    }));
    userStatusEnum = pgEnum("user_status", [
      "invited",
      "active",
      "locked",
      "suspended",
      "disabled"
    ]);
    permissionLevelEnum = pgEnum("permission_level", [
      "none",
      "read",
      "write",
      "admin"
    ]);
    loginOutcomeEnum = pgEnum("login_outcome", [
      "succeeded",
      "failed",
      "locked"
    ]);
    roles = pgTable("roles", {
      id: uuid("id").defaultRandom().primaryKey(),
      name: text("name").notNull().unique(),
      description: text("description"),
      createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull(),
      updatedAt: timestamp("updated_at", { withTimezone: true }).defaultNow().notNull()
    });
    userRoles = pgTable(
      "user_roles",
      {
        userId: integer("user_id").notNull().references(() => users.id, { onDelete: "cascade" }),
        roleId: uuid("role_id").notNull().references(() => roles.id, { onDelete: "cascade" }),
        assignedAt: timestamp("assigned_at", { withTimezone: true }).defaultNow(),
        assignedBy: integer("assigned_by").references(() => users.id)
      },
      (table) => {
        return {
          userIdx: index("idx_user_roles_user_id").on(table.userId),
          roleIdx: index("idx_user_roles_role_id").on(table.roleId),
          pk: primaryKey({ columns: [table.userId, table.roleId] })
        };
      }
    );
    permissions = pgTable(
      "permissions",
      {
        id: uuid("id").defaultRandom().primaryKey(),
        resource: text("resource").notNull(),
        level: permissionLevelEnum("level").notNull(),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (table) => {
        return {
          uniqueResourceLevel: uniqueIndex("unique_resource_level").on(
            table.resource,
            table.level
          )
        };
      }
    );
    rolePermissions = pgTable(
      "role_permissions",
      {
        roleId: uuid("role_id").notNull().references(() => roles.id, { onDelete: "cascade" }),
        permissionId: uuid("permission_id").notNull().references(() => permissions.id, { onDelete: "cascade" }),
        scope: jsonb("scope"),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (table) => {
        return {
          roleIdx: index("idx_role_permissions_role_id").on(table.roleId),
          pk: primaryKey({ columns: [table.roleId, table.permissionId] })
        };
      }
    );
    userIpAllowlist = pgTable(
      "user_ip_allowlist",
      {
        id: uuid("id").defaultRandom().primaryKey(),
        userId: integer("user_id").notNull().references(() => users.id, { onDelete: "cascade" }),
        ipAddress: text("ip_address").notNull(),
        description: text("description"),
        isActive: boolean("is_active").default(true),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow(),
        expiresAt: timestamp("expires_at", { withTimezone: true }),
        lastUsedAt: timestamp("last_used_at", { withTimezone: true }),
        useCount: integer("use_count").default(0),
        cidr: text("cidr"),
        label: text("label")
      },
      (table) => {
        return {
          activeIdx: index("idx_user_ip_allowlist_user_id").on(table.userId)
        };
      }
    );
    authEvents = pgTable(
      "auth_events",
      {
        id: uuid("id").defaultRandom().primaryKey(),
        occurredAt: timestamp("occurred_at", { withTimezone: true }).defaultNow().notNull(),
        actorUserId: integer("actor_user_id").references(() => users.id),
        targetUserId: integer("target_user_id").references(() => users.id),
        eventType: text("event_type").notNull(),
        ip: text("ip"),
        // Using text for inet type
        userAgent: text("user_agent"),
        details: jsonb("details").notNull().default({}),
        eventKey: text("event_key").unique()
      },
      (table) => {
        return {
          occurredAtIdx: index("idx_auth_events_occurred_at").on(table.occurredAt),
          actorIdx: index("idx_auth_events_actor_user_id").on(table.actorUserId),
          targetIdx: index("idx_auth_events_target_user_id").on(table.targetUserId),
          eventTypeIdx: index("idx_auth_events_event_type").on(table.eventType)
        };
      }
    );
    loginAttempts = pgTable(
      "login_attempts",
      {
        id: uuid("id").defaultRandom().primaryKey(),
        userId: integer("user_id").references(() => users.id),
        emailAttempted: text("email_attempted"),
        attemptedAt: timestamp("attempted_at", { withTimezone: true }).defaultNow().notNull(),
        ip: text("ip"),
        // Using text for inet type
        userAgent: text("user_agent"),
        outcome: loginOutcomeEnum("outcome").notNull(),
        reason: text("reason")
      },
      (table) => {
        return {
          userIdx: index("idx_login_attempts_user_id").on(table.userId),
          attemptedAtIdx: index("idx_login_attempts_attempted_at").on(
            table.attemptedAt
          ),
          ipIdx: index("idx_login_attempts_ip").on(table.ip)
        };
      }
    );
    passwordResetTokens = pgTable(
      "password_reset_tokens",
      {
        id: uuid("id").defaultRandom().primaryKey(),
        userId: integer("user_id").notNull().references(() => users.id, { onDelete: "cascade" }),
        tokenHash: text("token_hash").notNull(),
        expiresAt: timestamp("expires_at", { withTimezone: true }).notNull(),
        usedAt: timestamp("used_at", { withTimezone: true }),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (table) => {
        return {
          uniqueUserToken: uniqueIndex("unique_user_token").on(
            table.userId,
            table.tokenHash
          ),
          userIdx: index("idx_password_reset_tokens_user_id").on(table.userId),
          expiresIdx: index("idx_password_reset_tokens_expires_at").on(
            table.expiresAt
          )
        };
      }
    );
    sessions = pgTable(
      "sessions",
      {
        id: uuid("id").defaultRandom().primaryKey(),
        userId: integer("user_id").notNull().references(() => users.id, { onDelete: "cascade" }),
        sid: varchar("sid", { length: 255 }).unique(),
        // Express session ID
        sess: json("sess").notNull(),
        // Session data
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull(),
        lastSeenAt: timestamp("last_seen_at", { withTimezone: true }).defaultNow().notNull(),
        ip: text("ip"),
        // Using text for inet type
        userAgent: text("user_agent"),
        revokedAt: timestamp("revoked_at", { withTimezone: true }),
        revokeReason: text("revoke_reason"),
        expire: timestamp("expire", { precision: 6 }).notNull()
        // For express-session compatibility
      },
      (table) => {
        return {
          userIdx: index("idx_sessions_user_id").on(table.userId),
          lastSeenIdx: index("idx_sessions_last_seen_at").on(table.lastSeenAt),
          sidIdx: uniqueIndex("idx_sessions_sid").on(table.sid),
          expireIdx: index("idx_sessions_expire").on(table.expire)
        };
      }
    );
    crmNotes = pgTable(
      "crm_notes",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").notNull().references(() => loans.id, { onDelete: "cascade" }),
        userId: integer("user_id").notNull().references(() => users.id),
        content: text("content").notNull(),
        isPrivate: boolean("is_private").default(false),
        mentionedUsers: jsonb("mentioned_users").default([]),
        attachments: jsonb("attachments").default([]),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanIdx: index("crm_notes_loan_idx").on(table.loanId),
          userIdx: index("crm_notes_user_idx").on(table.userId),
          createdAtIdx: index("crm_notes_created_at_idx").on(table.createdAt)
        };
      }
    );
    crmTasks = pgTable(
      "crm_tasks",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").notNull().references(() => loans.id, { onDelete: "cascade" }),
        createdBy: integer("created_by").notNull().references(() => users.id),
        assignedTo: integer("assigned_to").references(() => users.id),
        title: text("title").notNull(),
        description: text("description"),
        status: text("status").notNull().default("pending"),
        // pending, in_progress, completed, cancelled
        priority: text("priority").default("medium"),
        // low, medium, high, urgent
        dueDate: timestamp("due_date"),
        completedAt: timestamp("completed_at"),
        tags: jsonb("tags").default([]),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanIdx: index("crm_tasks_loan_idx").on(table.loanId),
          assignedToIdx: index("crm_tasks_assigned_to_idx").on(table.assignedTo),
          statusIdx: index("crm_tasks_status_idx").on(table.status),
          dueDateIdx: index("crm_tasks_due_date_idx").on(table.dueDate)
        };
      }
    );
    crmAppointments = pgTable(
      "crm_appointments",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").notNull().references(() => loans.id, { onDelete: "cascade" }),
        createdBy: integer("created_by").notNull().references(() => users.id),
        title: text("title").notNull(),
        description: text("description"),
        location: text("location"),
        startTime: timestamp("start_time").notNull(),
        endTime: timestamp("end_time").notNull(),
        attendees: jsonb("attendees").default([]),
        reminderMinutes: integer("reminder_minutes").default(15),
        status: text("status").default("scheduled"),
        // scheduled, completed, cancelled, rescheduled
        meetingLink: text("meeting_link"),
        notes: text("notes"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanIdx: index("crm_appointments_loan_idx").on(table.loanId),
          startTimeIdx: index("crm_appointments_start_time_idx").on(
            table.startTime
          ),
          statusIdx: index("crm_appointments_status_idx").on(table.status)
        };
      }
    );
    crmCalls = pgTable(
      "crm_calls",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").notNull().references(() => loans.id, { onDelete: "cascade" }),
        userId: integer("user_id").notNull().references(() => users.id),
        contactName: text("contact_name").notNull(),
        contactPhone: text("contact_phone").notNull(),
        direction: text("direction").notNull(),
        // inbound, outbound
        status: text("status").notNull(),
        // completed, missed, voicemail, scheduled
        duration: integer("duration"),
        // in seconds
        outcome: text("outcome"),
        notes: text("notes"),
        scheduledFor: timestamp("scheduled_for"),
        completedAt: timestamp("completed_at"),
        recordingUrl: text("recording_url"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanIdx: index("crm_calls_loan_idx").on(table.loanId),
          userIdx: index("crm_calls_user_idx").on(table.userId),
          statusIdx: index("crm_calls_status_idx").on(table.status),
          scheduledForIdx: index("crm_calls_scheduled_for_idx").on(
            table.scheduledFor
          )
        };
      }
    );
    crmActivity = pgTable(
      "crm_activity",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").notNull().references(() => loans.id, { onDelete: "cascade" }),
        userId: integer("user_id").notNull().references(() => users.id),
        activityType: text("activity_type").notNull(),
        // note, task, call, appointment, email, document, status_change
        activityData: jsonb("activity_data").notNull(),
        relatedId: integer("related_id"),
        // ID of related record (note_id, task_id, etc.)
        isSystem: boolean("is_system").default(false),
        // System-generated vs user action
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanIdx: index("crm_activity_loan_idx").on(table.loanId),
          userIdx: index("crm_activity_user_idx").on(table.userId),
          typeIdx: index("crm_activity_type_idx").on(table.activityType),
          createdAtIdx: index("crm_activity_created_at_idx").on(table.createdAt)
        };
      }
    );
    crmCollaborators = pgTable(
      "crm_collaborators",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").notNull().references(() => loans.id, { onDelete: "cascade" }),
        userId: integer("user_id").notNull().references(() => users.id),
        role: text("role").notNull(),
        // viewer, editor, manager
        permissions: jsonb("permissions").default({}),
        addedBy: integer("added_by").notNull().references(() => users.id),
        addedAt: timestamp("added_at").defaultNow().notNull(),
        lastActivityAt: timestamp("last_activity_at")
      },
      (table) => {
        return {
          loanUserIdx: uniqueIndex("crm_collaborators_loan_user_idx").on(
            table.loanId,
            table.userId
          ),
          loanIdx: index("crm_collaborators_loan_idx").on(table.loanId),
          userIdx: index("crm_collaborators_user_idx").on(table.userId)
        };
      }
    );
    crmDeals = pgTable(
      "crm_deals",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").notNull().references(() => loans.id, { onDelete: "cascade" }),
        title: text("title").notNull(),
        value: decimal("value", { precision: 12, scale: 2 }),
        stage: text("stage").notNull(),
        // prospecting, qualification, proposal, negotiation, closed_won, closed_lost
        probability: integer("probability").default(0),
        // 0-100
        expectedCloseDate: date("expected_close_date"),
        actualCloseDate: date("actual_close_date"),
        lostReason: text("lost_reason"),
        notes: text("notes"),
        createdBy: integer("created_by").notNull().references(() => users.id),
        assignedTo: integer("assigned_to").references(() => users.id),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => {
        return {
          loanIdx: index("crm_deals_loan_idx").on(table.loanId),
          stageIdx: index("crm_deals_stage_idx").on(table.stage),
          assignedToIdx: index("crm_deals_assigned_to_idx").on(table.assignedTo)
        };
      }
    );
    insertUserSchema = createInsertSchema(users).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertBorrowerEntitySchema = createInsertSchema(
      borrowerEntities
    ).omit({ id: true, createdAt: true, updatedAt: true });
    insertPropertySchema = createInsertSchema(properties).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertRoleSchema = createInsertSchema(roles).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertUserRoleSchema = createInsertSchema(userRoles).omit({
      assignedAt: true
    });
    insertPermissionSchema = createInsertSchema(permissions).omit({
      id: true,
      createdAt: true
    });
    insertRolePermissionSchema = createInsertSchema(
      rolePermissions
    ).omit({ createdAt: true });
    insertUserIpAllowlistSchema = createInsertSchema(
      userIpAllowlist
    ).omit({ id: true, createdAt: true, updatedAt: true });
    insertAuthEventSchema = createInsertSchema(authEvents).omit({
      id: true,
      occurredAt: true
    });
    insertLoginAttemptSchema = createInsertSchema(loginAttempts).omit({
      id: true,
      attemptedAt: true
    });
    insertPasswordResetTokenSchema = createInsertSchema(
      passwordResetTokens
    ).omit({ id: true, createdAt: true });
    insertSessionSchema = createInsertSchema(sessions).omit({
      id: true,
      createdAt: true,
      lastSeenAt: true
    });
    insertLoanSchema = createInsertSchema(loans).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertLoanBorrowerSchema = createInsertSchema(loanBorrowers).omit({
      id: true,
      createdAt: true
    });
    insertGuarantorSchema = createInsertSchema(guarantors).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertInvestorSchema = createInsertSchema(investors).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertPaymentScheduleSchema = createInsertSchema(
      paymentSchedule
    ).omit({ id: true, createdAt: true });
    insertPaymentSchema = createInsertSchema(payments).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertEscrowAccountSchema = createInsertSchema(
      escrowAccounts2
    ).omit({ id: true, createdAt: true, updatedAt: true });
    insertEscrowDisbursementSchema = createInsertSchema(
      escrowDisbursements2
    ).omit({ id: true, createdAt: true, updatedAt: true }).extend({
      paymentMethod: z.enum(["check", "ach", "wire"])
    });
    insertEscrowDisbursementPaymentSchema = createInsertSchema(
      escrowDisbursementPayments
    ).omit({ id: true, createdAt: true });
    insertEscrowTransactionSchema = createInsertSchema(
      escrowTransactions
    ).omit({ id: true, createdAt: true });
    insertPayeeSchema = createInsertSchema(payees).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertDocumentSchema = createInsertSchema(documents).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertDocumentTemplateSchema = createInsertSchema(
      documentTemplates
    ).omit({ id: true, createdAt: true, updatedAt: true });
    insertDocumentTemplateSystemSchema = createInsertSchema(
      documentTemplate
    ).omit({ createdAt: true, retiredAt: true });
    insertServicingInstructionSchema = createInsertSchema(
      servicingInstructions
    ).omit({ id: true, createdAt: true, updatedAt: true });
    insertCollectionActivitySchema = createInsertSchema(
      collectionActivities
    ).omit({ id: true, createdAt: true });
    insertLegalProceedingSchema = createInsertSchema(
      legalProceedings
    ).omit({ id: true, createdAt: true, updatedAt: true });
    insertFeeTemplateSchema = createInsertSchema(feeTemplates).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertLoanFeeSchema = createInsertSchema(loanFees).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertLoanLedgerSchema = createInsertSchema(loanLedger).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertInsurancePolicySchema = createInsertSchema(
      insurancePolicies
    ).omit({ id: true, createdAt: true, updatedAt: true });
    insertNotificationSchema = createInsertSchema(notifications).omit({
      id: true,
      createdAt: true
    });
    insertTaskSchema = createInsertSchema(tasks).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertSystemSettingSchema = createInsertSchema(
      systemSettings
    ).omit({ id: true, createdAt: true, updatedAt: true });
    escrowPayments = escrowTransactions;
    insertEscrowPaymentSchema = insertEscrowTransactionSchema;
    servicingRuns = pgTable("servicing_runs", {
      id: serial("id").primaryKey(),
      runId: text("run_id").notNull().unique(),
      valuationDate: date("valuation_date").notNull(),
      startTime: timestamp("start_time").notNull().defaultNow(),
      endTime: timestamp("end_time"),
      status: text("status", {
        enum: ["pending", "running", "completed", "failed", "cancelled"]
      }).notNull().default("pending"),
      loansProcessed: integer("loans_processed").notNull().default(0),
      totalLoans: integer("total_loans").notNull().default(0),
      eventsCreated: integer("events_created").notNull().default(0),
      exceptionsCreated: integer("exceptions_created").notNull().default(0),
      totalDisbursedBeneficiary: decimal("total_disbursed_beneficiary", {
        precision: 12,
        scale: 2
      }).default("0.00"),
      totalDisbursedInvestors: decimal("total_disbursed_investors", {
        precision: 12,
        scale: 2
      }).default("0.00"),
      reconciliationStatus: text("reconciliation_status", {
        enum: ["pending", "balanced", "imbalanced"]
      }).default("pending"),
      inputHash: text("input_hash"),
      errors: text("errors").array(),
      dryRun: boolean("dry_run").notNull().default(false),
      loanIds: text("loan_ids").array(),
      createdBy: integer("created_by").references(() => users.id),
      createdAt: timestamp("created_at").notNull().defaultNow(),
      updatedAt: timestamp("updated_at").notNull().defaultNow()
    });
    servicingEvents = pgTable(
      "servicing_events",
      {
        id: serial("id").primaryKey(),
        runId: text("run_id").notNull().references(() => servicingRuns.runId),
        eventKey: text("event_key").notNull(),
        eventType: text("event_type").notNull(),
        // interest_accrual, assess_due, late_fee, post_payment, distribute_investors, etc.
        loanId: integer("loan_id").references(() => loans.id),
        timestamp: timestamp("timestamp").notNull().defaultNow(),
        valuationDate: date("valuation_date").notNull(),
        amount: decimal("amount", { precision: 12, scale: 2 }),
        principal: decimal("principal", { precision: 12, scale: 2 }),
        interest: decimal("interest", { precision: 12, scale: 2 }),
        escrow: decimal("escrow", { precision: 12, scale: 2 }),
        fees: decimal("fees", { precision: 12, scale: 2 }),
        details: jsonb("details").notNull().default("{}"),
        status: text("status", { enum: ["success", "failed", "pending"] }).notNull().default("pending"),
        errorMessage: text("error_message"),
        createdAt: timestamp("created_at").notNull().defaultNow()
      },
      (table) => ({
        uniqueEventKey: uniqueIndex("unique_event_key").on(
          table.valuationDate,
          table.eventKey
        ),
        loanIdIdx: index("servicing_events_loan_id_idx").on(table.loanId),
        runIdIdx: index("servicing_events_run_id_idx").on(table.runId),
        eventTypeIdx: index("servicing_events_type_idx").on(table.eventType)
      })
    );
    servicingExceptions = pgTable(
      "servicing_exceptions",
      {
        id: serial("id").primaryKey(),
        runId: text("run_id").references(() => servicingRuns.runId),
        loanId: integer("loan_id").references(() => loans.id),
        severity: text("severity", {
          enum: ["low", "medium", "high", "critical"]
        }).notNull(),
        type: text("type").notNull(),
        // insufficient_escrow, missing_payment, data_anomaly, etc.
        message: text("message").notNull(),
        suggestedAction: text("suggested_action"),
        dueDate: date("due_date"),
        status: text("status", { enum: ["open", "resolved", "escalated"] }).notNull().default("open"),
        resolvedBy: integer("resolved_by").references(() => users.id),
        resolvedAt: timestamp("resolved_at"),
        resolutionNotes: text("resolution_notes"),
        metadata: jsonb("metadata").default("{}"),
        createdAt: timestamp("created_at").notNull().defaultNow(),
        updatedAt: timestamp("updated_at").notNull().defaultNow()
      },
      (table) => ({
        loanIdIdx: index("servicing_exceptions_loan_id_idx").on(table.loanId),
        statusIdx: index("servicing_exceptions_status_idx").on(table.status),
        severityIdx: index("servicing_exceptions_severity_idx").on(table.severity)
      })
    );
    paymentsInbox = pgTable(
      "payments_inbox",
      {
        id: serial("id").primaryKey(),
        referenceNumber: text("reference_number").unique(),
        valueDate: date("value_date").notNull(),
        amount: decimal("amount", { precision: 12, scale: 2 }).notNull(),
        borrowerId: integer("borrower_id").references(() => borrowerEntities.id),
        loanId: integer("loan_id").references(() => loans.id),
        matchedBy: text("matched_by"),
        // loan_id_memo, borrower_id, reference_number, etc.
        matchConfidence: decimal("match_confidence", { precision: 3, scale: 2 }),
        // 0.00 to 1.00
        status: text("status", {
          enum: ["unmatched", "matched", "processed", "suspense", "rejected"]
        }).notNull().default("unmatched"),
        processedAt: timestamp("processed_at"),
        processedByRunId: text("processed_by_run_id").references(
          () => servicingRuns.runId
        ),
        metadata: jsonb("metadata").default("{}"),
        createdAt: timestamp("created_at").notNull().defaultNow()
      },
      (table) => ({
        loanIdIdx: index("payments_inbox_loan_id_idx").on(table.loanId),
        statusIdx: index("payments_inbox_status_idx").on(table.status),
        valueDateIdx: index("payments_inbox_value_date_idx").on(table.valueDate)
      })
    );
    interestAccruals = pgTable(
      "interest_accruals",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").notNull().references(() => loans.id),
        accrualDate: date("accrual_date").notNull(),
        fromDate: date("from_date").notNull(),
        toDate: date("to_date").notNull(),
        dayCount: integer("day_count").notNull(),
        dayCountConvention: text("day_count_convention").notNull(),
        // ACT/365, 30/360, etc.
        interestRate: decimal("interest_rate", {
          precision: 8,
          scale: 4
        }).notNull(),
        principalBalance: decimal("principal_balance", {
          precision: 12,
          scale: 2
        }).notNull(),
        dailyRate: decimal("daily_rate", { precision: 12, scale: 10 }).notNull(),
        accruedAmount: decimal("accrued_amount", {
          precision: 12,
          scale: 2
        }).notNull(),
        runId: text("run_id").references(() => servicingRuns.runId),
        createdAt: timestamp("created_at").notNull().defaultNow()
      },
      (table) => ({
        uniqueAccrual: uniqueIndex("unique_accrual").on(
          table.loanId,
          table.accrualDate
        ),
        loanIdIdx: index("interest_accruals_loan_id_idx").on(table.loanId)
      })
    );
    investorDistributions = pgTable(
      "investor_distributions",
      {
        id: serial("id").primaryKey(),
        runId: text("run_id").notNull().references(() => servicingRuns.runId),
        loanId: integer("loan_id").notNull().references(() => loans.id),
        investorId: integer("investor_id").notNull().references(() => investors.id),
        distributionDate: date("distribution_date").notNull(),
        ownershipPercentage: decimal("ownership_percentage", {
          precision: 8,
          scale: 6
        }).notNull(),
        grossAmount: decimal("gross_amount", { precision: 12, scale: 2 }).notNull(),
        principalAmount: decimal("principal_amount", {
          precision: 12,
          scale: 2
        }).notNull(),
        interestAmount: decimal("interest_amount", {
          precision: 12,
          scale: 2
        }).notNull(),
        feesAmount: decimal("fees_amount", { precision: 12, scale: 2 }).notNull(),
        netAmount: decimal("net_amount", { precision: 12, scale: 2 }).notNull(),
        roundingAdjustment: decimal("rounding_adjustment", {
          precision: 6,
          scale: 4
        }).default("0.00"),
        status: text("status", { enum: ["pending", "processed", "paid", "failed"] }).notNull().default("pending"),
        paidAt: timestamp("paid_at"),
        metadata: jsonb("metadata").default("{}"),
        createdAt: timestamp("created_at").notNull().defaultNow()
      },
      (table) => ({
        loanInvestorIdx: index("investor_distributions_loan_investor_idx").on(
          table.loanId,
          table.investorId
        ),
        runIdIdx: index("investor_distributions_run_id_idx").on(table.runId)
      })
    );
    escrowAdvances = pgTable(
      "escrow_advances",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").notNull().references(() => loans.id),
        escrowAccountId: integer("escrow_account_id").references(
          () => escrowAccounts2.id
        ),
        advanceDate: date("advance_date").notNull(),
        amount: decimal("amount", { precision: 12, scale: 2 }).notNull(),
        reason: text("reason").notNull(),
        repaymentMonths: integer("repayment_months").notNull().default(12),
        monthlyRepayment: decimal("monthly_repayment", {
          precision: 12,
          scale: 2
        }).notNull(),
        outstandingBalance: decimal("outstanding_balance", {
          precision: 12,
          scale: 2
        }).notNull(),
        status: text("status", { enum: ["active", "paid", "written_off"] }).notNull().default("active"),
        paidOffDate: date("paid_off_date"),
        runId: text("run_id").references(() => servicingRuns.runId),
        createdAt: timestamp("created_at").notNull().defaultNow(),
        updatedAt: timestamp("updated_at").notNull().defaultNow()
      },
      (table) => ({
        loanIdIdx: index("escrow_advances_loan_id_idx").on(table.loanId),
        statusIdx: index("escrow_advances_status_idx").on(table.status)
      })
    );
    userMfaFactors = pgTable(
      "user_mfa_factors",
      {
        id: serial("id").primaryKey(),
        userId: integer("user_id").notNull().references(() => users.id, { onDelete: "cascade" }),
        factorType: text("factor_type", {
          enum: ["totp", "sms", "email"]
        }).notNull(),
        factorName: text("factor_name").notNull(),
        // e.g., "iPhone Authenticator"
        // TOTP specific fields
        totpSecret: text("totp_secret"),
        // Encrypted at rest
        totpIssuer: text("totp_issuer").default("LoanServe Pro"),
        totpAlgorithm: text("totp_algorithm").default("SHA1"),
        totpDigits: integer("totp_digits").default(6),
        totpPeriod: integer("totp_period").default(30),
        // Time step in seconds
        // SMS/Email specific fields
        phoneNumber: text("phone_number"),
        emailAddress: text("email_address"),
        // Verification status
        verified: boolean("verified").default(false).notNull(),
        verifiedAt: timestamp("verified_at"),
        lastUsedAt: timestamp("last_used_at"),
        // Device trust
        trustedDevices: jsonb("trusted_devices").default("[]"),
        // Array of trusted device fingerprints
        // Metadata
        enrolledAt: timestamp("enrolled_at").notNull().defaultNow(),
        enrolledIp: text("enrolled_ip"),
        enrolledUserAgent: text("enrolled_user_agent"),
        isActive: boolean("is_active").default(true).notNull(),
        metadata: jsonb("metadata").default("{}")
      },
      (table) => ({
        userIdIdx: index("user_mfa_factors_user_id_idx").on(table.userId),
        factorTypeIdx: index("user_mfa_factors_factor_type_idx").on(
          table.factorType
        ),
        activeIdx: index("user_mfa_factors_active_idx").on(table.isActive)
      })
    );
    mfaBackupCodes = pgTable(
      "mfa_backup_codes",
      {
        id: serial("id").primaryKey(),
        userId: integer("user_id").notNull().references(() => users.id, { onDelete: "cascade" }),
        codeHash: text("code_hash").notNull(),
        // Hashed backup code
        usedAt: timestamp("used_at"),
        usedIp: text("used_ip"),
        createdAt: timestamp("created_at").notNull().defaultNow(),
        expiresAt: timestamp("expires_at")
      },
      (table) => ({
        userIdIdx: index("mfa_backup_codes_user_id_idx").on(table.userId),
        codeHashIdx: uniqueIndex("mfa_backup_codes_code_hash_idx").on(
          table.codeHash
        )
      })
    );
    mfaChallenges = pgTable(
      "mfa_challenges",
      {
        id: serial("id").primaryKey(),
        challengeId: text("challenge_id").notNull().unique(),
        // UUID for challenge
        userId: integer("user_id").notNull().references(() => users.id),
        sessionId: text("session_id"),
        // Session that initiated the challenge
        factorId: integer("factor_id").references(() => userMfaFactors.id),
        challengeType: text("challenge_type", {
          enum: ["login", "step_up", "enrollment"]
        }).notNull(),
        // Challenge details
        action: text("action"),
        // What action requires MFA (e.g., 'transfer_funds', 'change_password')
        requiredFactors: integer("required_factors").default(1),
        // Number of factors required
        completedFactors: integer("completed_factors").default(0),
        // Rate limiting
        attempts: integer("attempts").default(0),
        maxAttempts: integer("max_attempts").default(5),
        lastAttemptAt: timestamp("last_attempt_at"),
        lockedUntil: timestamp("locked_until"),
        // Status
        status: text("status", {
          enum: ["pending", "verified", "failed", "expired"]
        }).notNull().default("pending"),
        verifiedAt: timestamp("verified_at"),
        // Metadata
        ip: text("ip"),
        userAgent: text("user_agent"),
        deviceFingerprint: text("device_fingerprint"),
        metadata: jsonb("metadata").default("{}"),
        createdAt: timestamp("created_at").notNull().defaultNow(),
        expiresAt: timestamp("expires_at").notNull()
        // Challenge expiry (usually 5-10 minutes)
      },
      (table) => ({
        challengeIdIdx: uniqueIndex("mfa_challenges_challenge_id_idx").on(
          table.challengeId
        ),
        userIdIdx: index("mfa_challenges_user_id_idx").on(table.userId),
        statusIdx: index("mfa_challenges_status_idx").on(table.status),
        expiresAtIdx: index("mfa_challenges_expires_at_idx").on(table.expiresAt)
      })
    );
    mfaAuditLog = pgTable(
      "mfa_audit_log",
      {
        id: serial("id").primaryKey(),
        userId: integer("user_id").notNull().references(() => users.id),
        factorId: integer("factor_id").references(() => userMfaFactors.id),
        challengeId: text("challenge_id").references(
          () => mfaChallenges.challengeId
        ),
        eventType: text("event_type").notNull(),
        // enrolled, verified, failed, disabled, backup_used, etc.
        eventDetails: jsonb("event_details").default("{}"),
        ip: text("ip"),
        userAgent: text("user_agent"),
        deviceFingerprint: text("device_fingerprint"),
        success: boolean("success").notNull(),
        failureReason: text("failure_reason"),
        createdAt: timestamp("created_at").notNull().defaultNow()
      },
      (table) => ({
        userIdIdx: index("mfa_audit_log_user_id_idx").on(table.userId),
        eventTypeIdx: index("mfa_audit_log_event_type_idx").on(table.eventType),
        createdAtIdx: index("mfa_audit_log_created_at_idx").on(table.createdAt)
      })
    );
    insertServicingRunSchema = createInsertSchema(servicingRuns).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertServicingEventSchema = createInsertSchema(
      servicingEvents
    ).omit({
      id: true,
      createdAt: true
    });
    insertServicingExceptionSchema = createInsertSchema(
      servicingExceptions
    ).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertPaymentInboxSchema = createInsertSchema(paymentsInbox).omit({
      id: true,
      createdAt: true
    });
    insertInterestAccrualSchema = createInsertSchema(
      interestAccruals
    ).omit({
      id: true,
      createdAt: true
    });
    insertInvestorDistributionSchema = createInsertSchema(
      investorDistributions
    ).omit({
      id: true,
      createdAt: true
    });
    insertEscrowAdvanceSchema = createInsertSchema(
      escrowAdvances
    ).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertUserMfaFactorSchema = createInsertSchema(
      userMfaFactors
    ).omit({
      id: true,
      enrolledAt: true
    });
    insertMfaBackupCodeSchema = createInsertSchema(
      mfaBackupCodes
    ).omit({
      id: true,
      createdAt: true
    });
    insertMfaChallengeSchema = createInsertSchema(mfaChallenges).omit({
      id: true,
      createdAt: true
    });
    insertMfaAuditLogSchema = createInsertSchema(mfaAuditLog).omit({
      id: true,
      createdAt: true
    });
    emailTemplateFolders = pgTable("email_template_folders", {
      id: serial("id").primaryKey(),
      name: varchar("name", { length: 255 }).notNull(),
      parentId: integer("parent_id").references(() => emailTemplateFolders.id),
      createdBy: integer("created_by").references(() => users.id),
      createdAt: timestamp("created_at").defaultNow(),
      updatedAt: timestamp("updated_at").defaultNow()
    });
    insertEmailTemplateFolderSchema = createInsertSchema(
      emailTemplateFolders
    ).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    emailTemplates = pgTable("email_templates", {
      id: serial("id").primaryKey(),
      folderId: integer("folder_id").references(() => emailTemplateFolders.id),
      name: varchar("name", { length: 255 }).notNull(),
      templateKey: varchar("template_key", { length: 100 }).unique(),
      // Unique key for template identification
      subject: text("subject"),
      body: text("body"),
      format: varchar("format", { length: 20 }).default("markdown"),
      // 'markdown', 'html', 'text'
      flags: jsonb("flags"),
      // Store template flags like include_fdCPA_if_applicable
      trigger: jsonb("trigger"),
      // Store trigger conditions
      tokens: jsonb("tokens"),
      // Available merge fields for this template
      isShared: boolean("is_shared").default(false),
      isActive: boolean("is_active").default(true),
      createdBy: integer("created_by").references(() => users.id),
      createdAt: timestamp("created_at").defaultNow(),
      updatedAt: timestamp("updated_at").defaultNow()
    });
    insertEmailTemplateSchema = createInsertSchema(
      emailTemplates
    ).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    idMappings = pgTable(
      "id_mappings",
      {
        uuid: varchar("uuid", { length: 36 }).primaryKey().default(sql2`gen_random_uuid()`),
        entityType: varchar("entity_type", { length: 50 }).notNull(),
        // 'loan', 'payment', 'user', etc.
        serialId: integer("serial_id").notNull(),
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (t) => ({
        uniqueMapping: unique().on(t.entityType, t.serialId),
        serialIdx: index().on(t.serialId)
      })
    );
    paymentIngestions = pgTable(
      "payment_ingestions",
      {
        id: varchar("id", { length: 36 }).primaryKey().default(sql2`gen_random_uuid()`),
        idempotencyKey: text("idempotency_key").notNull().unique(),
        channel: text("channel").notNull(),
        // ach|wire|realtime|check|card|paypal|venmo|book
        sourceReference: text("source_reference"),
        // provider transfer id or file id
        rawPayloadHash: text("raw_payload_hash").notNull(),
        // sha256 hex of raw body
        artifactUri: text("artifact_uri").array().notNull().default(sql2`'{}'`),
        artifactHash: text("artifact_hash").array().notNull().default(sql2`'{}'`),
        receivedAt: timestamp("received_at", { withTimezone: true }).notNull().defaultNow(),
        normalizedEnvelope: jsonb("normalized_envelope").notNull(),
        status: text("status", {
          enum: ["received", "normalized", "published"]
        }).notNull()
      },
      (t) => ({
        channelReceivedIdx: index().on(t.channel, t.receivedAt)
      })
    );
    paymentArtifacts = pgTable(
      "payment_artifacts",
      {
        id: varchar("id", { length: 36 }).primaryKey().default(sql2`gen_random_uuid()`),
        ingestionId: varchar("ingestion_id", { length: 36 }).notNull().references(() => paymentIngestions.id, { onDelete: "cascade" }),
        type: text("type").notNull(),
        // check_image_front|check_image_back|ach_return_pdf|wire_receipt|psp_receipt
        uri: text("uri").notNull(),
        sha256: text("sha256").notNull(),
        sizeBytes: bigint("size_bytes", { mode: "number" }),
        mime: text("mime"),
        sourceMetadata: jsonb("source_metadata")
      },
      (t) => ({
        ingestionTypeIdx: index().on(t.ingestionId, t.type)
      })
    );
    paymentEvents = pgTable(
      "payment_events",
      {
        id: varchar("id", { length: 36 }).primaryKey().default(sql2`gen_random_uuid()`),
        paymentId: varchar("payment_id", { length: 36 }).references(
          () => payments.id
        ),
        // UUID reference
        ingestionId: varchar("ingestion_id", { length: 36 }),
        // nullable for internal-only events
        type: text("type").notNull(),
        // payment.ingested|payment.validated|payment.posted|payment.reversed.nsf|...
        eventTime: timestamp("event_time", { withTimezone: true }).notNull().defaultNow(),
        actorType: text("actor_type").notNull(),
        // Check constraint in SQL: 'system'|'human'|'ai'
        actorId: text("actor_id"),
        correlationId: varchar("correlation_id", { length: 36 }).notNull(),
        data: jsonb("data").notNull(),
        prevEventHash: text("prev_event_hash"),
        eventHash: text("event_hash").notNull()
      },
      (t) => ({
        paymentEventTimeIdx: index().on(t.paymentId, t.eventTime),
        correlationIdx: index().on(t.correlationId)
      })
    );
    ledgerEntries = pgTable(
      "ledger_entries",
      {
        id: varchar("id", { length: 36 }).primaryKey().default(sql2`gen_random_uuid()`),
        paymentId: varchar("payment_id", { length: 36 }).notNull().references(() => payments.id, { onDelete: "cascade" }),
        entryDate: date("entry_date").notNull(),
        accountType: text("account_type").notNull(),
        // asset, liability, revenue, expense
        accountCode: text("account_code").notNull(),
        // specific account identifier
        debitAmount: decimal("debit_amount", { precision: 18, scale: 2 }).notNull().default("0"),
        creditAmount: decimal("credit_amount", { precision: 18, scale: 2 }).notNull().default("0"),
        description: text("description").notNull(),
        correlationId: varchar("correlation_id", { length: 36 }).notNull(),
        metadata: jsonb("metadata"),
        createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow(),
        updatedAt: timestamp("updated_at", { withTimezone: true }).notNull().defaultNow()
      },
      (t) => ({
        paymentIdx: index().on(t.paymentId),
        accountIdx: index().on(t.accountCode, t.entryDate),
        correlationIdx: index().on(t.correlationId)
      })
    );
    inbox = pgTable(
      "inbox",
      {
        id: serial("id").primaryKey(),
        consumer: text("consumer").notNull(),
        messageId: text("message_id").notNull(),
        resultHash: text("result_hash").notNull(),
        processedAt: timestamp("processed_at", { withTimezone: true }).notNull().defaultNow()
      },
      (t) => ({
        // Unique constraint to prevent duplicate processing
        consumerMessageIdx: uniqueIndex().on(t.consumer, t.messageId),
        // Index for cleanup of old messages
        processedAtIdx: index().on(t.processedAt)
      })
    );
    outbox = pgTable(
      "outbox",
      {
        id: serial("id").primaryKey(),
        aggregateType: text("aggregate_type").notNull(),
        aggregateId: text("aggregate_id").notNull(),
        schema: text("schema").notNull(),
        routingKey: text("routing_key").notNull(),
        payload: jsonb("payload").notNull(),
        headers: jsonb("headers"),
        createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow(),
        publishedAt: timestamp("published_at", { withTimezone: true }),
        attemptCount: integer("attempt_count").notNull().default(0),
        lastError: text("last_error"),
        nextRetryAt: timestamp("next_retry_at", { withTimezone: true })
      },
      (t) => ({
        // Index for polling unpublished messages
        publishedIdx: index().on(t.publishedAt, t.createdAt),
        // Index for retry mechanism
        retryIdx: index().on(t.publishedAt, t.nextRetryAt),
        // Index for aggregate queries
        aggregateIdx: index().on(t.aggregateType, t.aggregateId)
      })
    );
    outboxMessages = pgTable(
      "outbox_messages",
      {
        id: varchar("id", { length: 36 }).primaryKey().default(sql2`gen_random_uuid()`),
        aggregateType: text("aggregate_type").notNull(),
        // payments, crm
        aggregateId: varchar("aggregate_id", { length: 36 }).notNull(),
        // payment_id, loan_id
        eventType: text("event_type").notNull(),
        // payment.posted, crm.email.requested.v1
        payload: jsonb("payload").notNull(),
        createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow(),
        publishedAt: timestamp("published_at", { withTimezone: true }),
        attemptCount: integer("attempt_count").notNull().default(0),
        lastError: text("last_error"),
        nextRetryAt: timestamp("next_retry_at", { withTimezone: true }),
        // For exponential backoff
        correlationId: varchar("correlation_id", { length: 36 })
      },
      (t) => ({
        // Index for efficient polling (unpublished messages first, ordered by creation time)
        publishedCreatedIdx: index().on(t.publishedAt, t.createdAt),
        // Index for retry mechanism
        retryIdx: index().on(t.publishedAt, t.nextRetryAt, t.attemptCount)
      })
    );
    reconciliations = pgTable(
      "reconciliations",
      {
        id: varchar("id", { length: 36 }).primaryKey().default(sql2`gen_random_uuid()`),
        channel: text("channel").notNull(),
        periodStart: date("period_start").notNull(),
        periodEnd: date("period_end").notNull(),
        bankTotal: decimal("bank_total", { precision: 18, scale: 2 }).notNull().default("0"),
        sorTotal: decimal("sor_total", { precision: 18, scale: 2 }).notNull().default("0"),
        variance: decimal("variance", { precision: 18, scale: 2 }).notNull().default("0"),
        status: text("status").notNull(),
        // CHECK constraint in SQL: 'open'|'balanced'|'variance'
        details: jsonb("details")
      },
      (t) => ({
        // Unique index on channel and period
        channelPeriodIdx: uniqueIndex().on(t.channel, t.periodStart, t.periodEnd)
      })
    );
    exceptionCases = pgTable(
      "exception_cases",
      {
        id: varchar("id", { length: 36 }).primaryKey().default(sql2`gen_random_uuid()`),
        ingestionId: varchar("ingestion_id", { length: 36 }).references(
          () => paymentIngestions.id
        ),
        paymentId: integer("payment_id").references(() => payments.id),
        category: text("category").notNull(),
        // ach_return|nsf|wire_recall|duplicate|dispute|reconcile_variance
        subcategory: text("subcategory"),
        severity: text("severity").notNull(),
        // CHECK: 'low'|'medium'|'high'|'critical'
        state: text("state").notNull(),
        // CHECK: 'open'|'pending'|'resolved'|'cancelled'
        assignedTo: text("assigned_to"),
        aiRecommendation: jsonb("ai_recommendation"),
        createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow(),
        resolvedAt: timestamp("resolved_at", { withTimezone: true })
      },
      (t) => ({
        // Index on state and severity for efficient filtering
        stateSeverityIdx: index().on(t.state, t.severity)
      })
    );
    generalLedgerEvents = pgTable(
      "general_ledger_events",
      {
        eventId: uuid("event_id").primaryKey().defaultRandom(),
        loanId: integer("loan_id").references(() => loans.id, { onDelete: "cascade" }).notNull(),
        eventType: text("event_type").notNull(),
        // payment, disbursement, fee, adjustment, reversal, accrual
        eventDate: date("event_date").notNull(),
        effectiveDate: date("effective_date").notNull(),
        correlationId: text("correlation_id"),
        // Link to external transaction
        description: text("description").notNull(),
        reversalOf: uuid("reversal_of").references(
          () => generalLedgerEvents.eventId
        ),
        metadata: jsonb("metadata"),
        // Additional context
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull(),
        createdBy: integer("created_by").references(() => users.id)
      },
      (t) => ({
        loanEventTypeIdx: index("gl_events_loan_type_idx").on(
          t.loanId,
          t.eventType
        ),
        eventDateIdx: index("gl_events_date_idx").on(t.eventDate),
        correlationIdx: index("gl_events_correlation_idx").on(t.correlationId)
      })
    );
    generalLedgerEntries = pgTable(
      "general_ledger_entries",
      {
        entryId: uuid("entry_id").primaryKey().defaultRandom(),
        eventId: uuid("event_id").references(() => generalLedgerEvents.eventId, { onDelete: "cascade" }).notNull(),
        accountCode: text("account_code").notNull(),
        // Chart of accounts code
        accountName: text("account_name").notNull(),
        // Human-readable account name
        debitMinor: bigint("debit_minor", { mode: "bigint" }).notNull().default(BigInt(0)),
        creditMinor: bigint("credit_minor", { mode: "bigint" }).notNull().default(BigInt(0)),
        currency: text("currency").notNull().default("USD"),
        memo: text("memo"),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (t) => ({
        eventIdx: index("gl_entries_event_idx").on(t.eventId),
        accountCodeIdx: index("gl_entries_account_idx").on(t.accountCode)
        // Ensure debit = credit for each event (enforced via trigger in DB)
      })
    );
    loanTerms = pgTable(
      "loan_terms",
      {
        loanTermsId: serial("loan_terms_id").primaryKey(),
        loanId: integer("loan_id").references(() => loans.id, { onDelete: "cascade" }).notNull(),
        effectiveFrom: date("effective_from").notNull(),
        effectiveTo: date("effective_to"),
        // null means open-ended
        interestType: text("interest_type").notNull(),
        // fixed, arm, io_fixed, etc.
        indexName: text("index_name"),
        // SOFR, Prime, etc.
        indexMarginBps: integer("index_margin_bps"),
        // Basis points over index
        nominalRateBps: integer("nominal_rate_bps").notNull(),
        // Current rate in basis points
        rateCapUpBps: integer("rate_cap_up_bps"),
        // Maximum rate increase
        rateCapDownBps: integer("rate_cap_down_bps"),
        // Maximum rate decrease
        compounding: text("compounding").notNull(),
        // none, monthly, daily
        dayCount: text("day_count").notNull(),
        // 30E/360, ACT/360, ACT/365
        firstPaymentDate: date("first_payment_date"),
        termMonths: integer("term_months"),
        interestOnlyMonths: integer("interest_only_months"),
        scheduledPaymentMinor: bigint("scheduled_payment_minor", {
          mode: "bigint"
        }),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (t) => ({
        loanEffectiveIdx: unique().on(t.loanId, t.effectiveFrom),
        effectiveFromIdx: index("loan_terms_loan_effective_idx").on(
          t.loanId,
          t.effectiveFrom
        )
      })
    );
    loanBalances = pgTable(
      "loan_balances",
      {
        loanId: integer("loan_id").primaryKey().references(() => loans.id, { onDelete: "cascade" }),
        principalMinor: bigint("principal_minor", { mode: "bigint" }).notNull().default(BigInt(0)),
        interestAccruedMinor: bigint("interest_accrued_minor", { mode: "bigint" }).notNull().default(BigInt(0)),
        escrowMinor: bigint("escrow_minor", { mode: "bigint" }).notNull().default(BigInt(0)),
        lateFeesMinor: bigint("late_fees_minor", { mode: "bigint" }).notNull().default(BigInt(0)),
        totalPaidMinor: bigint("total_paid_minor", { mode: "bigint" }).notNull().default(BigInt(0)),
        lastPaymentDate: date("last_payment_date"),
        lastPaymentMinor: bigint("last_payment_minor", { mode: "bigint" }),
        nextPaymentDue: date("next_payment_due"),
        delinquentDays: integer("delinquent_days").notNull().default(0),
        updatedAt: timestamp("updated_at", { withTimezone: true }).defaultNow().notNull()
      },
      (t) => ({
        nextDueIdx: index("loan_balances_next_due_idx").on(t.nextPaymentDue),
        delinquentIdx: index("loan_balances_delinquent_idx").on(t.delinquentDays)
      })
    );
    escrowForecasts = pgTable(
      "escrow_forecasts",
      {
        forecastId: serial("forecast_id").primaryKey(),
        loanId: integer("loan_id").references(() => loans.id, { onDelete: "cascade" }).notNull(),
        generatedAt: timestamp("generated_at", { withTimezone: true }).defaultNow().notNull(),
        asOfDate: date("as_of_date").notNull(),
        forecastMonths: integer("forecast_months").notNull().default(12),
        // Current state
        currentBalanceMinor: bigint("current_balance_minor", {
          mode: "bigint"
        }).notNull(),
        currentPaymentMinor: bigint("current_payment_minor", {
          mode: "bigint"
        }).notNull(),
        // Projected totals (annual)
        projectedDisbursementsMinor: bigint("projected_disbursements_minor", {
          mode: "bigint"
        }).notNull(),
        projectedCollectionsMinor: bigint("projected_collections_minor", {
          mode: "bigint"
        }).notNull(),
        projectedShortageMinor: bigint("projected_shortage_minor", {
          mode: "bigint"
        }).notNull().default(BigInt(0)),
        projectedSurplusMinor: bigint("projected_surplus_minor", { mode: "bigint" }).notNull().default(BigInt(0)),
        // Recommended adjustments
        recommendedPaymentMinor: bigint("recommended_payment_minor", {
          mode: "bigint"
        }).notNull(),
        cushionRequiredMinor: bigint("cushion_required_minor", {
          mode: "bigint"
        }).notNull(),
        // Detailed projections (JSONB array of monthly projections)
        monthlyProjections: jsonb("monthly_projections").notNull(),
        // Array of {month, disbursements, balance}
        // Analysis metadata
        analysisVersion: text("analysis_version").notNull().default("1.0"),
        assumptions: jsonb("assumptions"),
        // Rate assumptions, dates, etc.
        warnings: jsonb("warnings"),
        // Array of warning messages
        status: text("status").notNull().default("draft"),
        // draft, approved, superseded
        approvedBy: integer("approved_by").references(() => users.id),
        approvedAt: timestamp("approved_at", { withTimezone: true }),
        supersededBy: integer("superseded_by").references(
          () => escrowForecasts.forecastId
        ),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (t) => ({
        loanAsOfIdx: unique().on(t.loanId, t.asOfDate, t.status),
        statusIdx: index("escrow_forecasts_status_idx").on(t.status),
        generatedAtIdx: index("escrow_forecasts_generated_idx").on(t.generatedAt)
      })
    );
    insertIdMappingSchema = createInsertSchema(idMappings).omit({
      uuid: true,
      createdAt: true
    });
    insertPaymentIngestionSchema = createInsertSchema(
      paymentIngestions
    ).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertPaymentArtifactSchema = createInsertSchema(
      paymentArtifacts
    ).omit({
      id: true,
      createdAt: true
    });
    insertPaymentEventSchema = createInsertSchema(paymentEvents).omit({
      id: true,
      createdAt: true
    });
    insertLedgerEntrySchema = createInsertSchema(ledgerEntries).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertInboxSchema = createInsertSchema(inbox).omit({
      id: true,
      processedAt: true
    });
    insertOutboxSchema = createInsertSchema(outbox).omit({
      id: true,
      createdAt: true,
      publishedAt: true,
      attemptCount: true,
      lastError: true,
      nextRetryAt: true
    });
    insertOutboxMessageSchema = createInsertSchema(
      outboxMessages
    ).omit({
      id: true,
      createdAt: true
    });
    emailArtifacts = pgTable(
      "email_artifacts",
      {
        id: varchar("id", { length: 36 }).primaryKey(),
        // ULID
        correlationId: varchar("correlation_id", { length: 36 }).notNull(),
        loanId: integer("loan_id").references(() => loans.id),
        userId: integer("user_id").references(() => users.id),
        templateId: text("template_id"),
        // Email metadata
        subject: text("subject").notNull(),
        fromAddress: text("from_address").notNull(),
        toAddresses: text("to_addresses").array().notNull(),
        ccAddresses: text("cc_addresses").array().default([]),
        bccAddresses: text("bcc_addresses").array().default([]),
        // Content (immutable snapshot)
        htmlContent: text("html_content"),
        textContent: text("text_content"),
        htmlContentHash: text("html_content_hash"),
        // SHA-256
        textContentHash: text("text_content_hash"),
        // SHA-256
        variablesUsed: jsonb("variables_used").notNull(),
        // Attachments
        attachments: jsonb("attachments").default([]),
        // Sending details
        sentAt: timestamp("sent_at", { withTimezone: true }).notNull(),
        providerMessageId: text("provider_message_id"),
        deliveryStatus: text("delivery_status").notNull().default("queued"),
        // queued, sent, delivered, failed, bounced
        deliveryDetails: jsonb("delivery_details").default({}),
        // Classification
        emailCategory: text("email_category").notNull(),
        // transactional, marketing
        topic: text("topic").notNull(),
        // Compliance
        dncCheckPassed: boolean("dnc_check_passed").notNull(),
        dncCheckDetails: jsonb("dnc_check_details").default({}),
        // Audit metadata
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull(),
        updatedAt: timestamp("updated_at", { withTimezone: true }).defaultNow(),
        retentionExpiresAt: timestamp("retention_expires_at", { withTimezone: true }).notNull()
      },
      (t) => ({
        correlationIdx: index("email_artifacts_correlation_idx").on(t.correlationId),
        loanIdx: index("email_artifacts_loan_idx").on(t.loanId),
        sentAtIdx: index("email_artifacts_sent_at_idx").on(t.sentAt),
        categoryTopicIdx: index("email_artifacts_category_topic_idx").on(t.emailCategory, t.topic),
        retentionIdx: index("email_artifacts_retention_idx").on(t.retentionExpiresAt)
      })
    );
    insertReconciliationSchema = createInsertSchema(
      reconciliations
    ).omit({
      id: true,
      createdAt: true
    });
    insertExceptionCaseSchema = createInsertSchema(
      exceptionCases
    ).omit({
      id: true,
      createdAt: true
    });
    insertGeneralLedgerEventSchema = createInsertSchema(
      generalLedgerEvents
    ).omit({
      eventId: true,
      createdAt: true
    });
    insertGeneralLedgerEntrySchema = createInsertSchema(
      generalLedgerEntries
    ).omit({
      entryId: true,
      createdAt: true
    });
    insertLoanTermsSchema = createInsertSchema(loanTerms).omit({
      loanTermsId: true,
      createdAt: true
    });
    insertLoanBalancesSchema = createInsertSchema(loanBalances).omit({
      updatedAt: true
    });
    insertEscrowForecastSchema = createInsertSchema(
      escrowForecasts
    ).omit({
      forecastId: true,
      generatedAt: true,
      createdAt: true
    });
    bankAccounts = pgTable(
      "bank_accounts",
      {
        bankAcctId: uuid("bank_acct_id").primaryKey().defaultRandom(),
        name: text("name").notNull(),
        bankId: text("bank_id").notNull(),
        // Institution identifier
        accountNumberMask: text("account_number_mask").notNull(),
        // Last 4 digits
        accountNumberEncrypted: text("account_number_encrypted"),
        // Full encrypted account
        routingNumber: text("routing_number").notNull(),
        accountType: text("account_type").notNull(),
        // checking, savings, escrow
        currency: text("currency").notNull().default("USD"),
        glCashAccount: text("gl_cash_account").notNull(),
        // GL account code
        active: boolean("active").notNull().default(true),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull(),
        updatedAt: timestamp("updated_at", { withTimezone: true }).defaultNow().notNull()
      },
      (t) => ({
        activeIdx: index("bank_accounts_active_idx").on(t.active),
        glAccountIdx: index("bank_accounts_gl_idx").on(t.glCashAccount)
      })
    );
    bankTxn = pgTable(
      "bank_txn",
      {
        bankTxnId: uuid("bank_txn_id").primaryKey().defaultRandom(),
        bankAcctId: uuid("bank_acct_id").references(() => bankAccounts.bankAcctId).notNull(),
        stmtFileId: uuid("stmt_file_id"),
        transactionDate: date("transaction_date").notNull(),
        valueDate: date("value_date").notNull(),
        postDate: date("post_date"),
        amountMinor: bigint("amount_minor", { mode: "bigint" }).notNull(),
        // Positive for credits, negative for debits
        type: text("type").notNull(),
        // credit, debit
        description: text("description").notNull(),
        reference: text("reference"),
        checkNumber: text("check_number"),
        balanceMinor: bigint("balance_minor", { mode: "bigint" }),
        // Running balance after transaction
        status: text("status").notNull().default("unmatched"),
        // unmatched, matched, reconciled
        matchedAt: timestamp("matched_at", { withTimezone: true }),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (t) => ({
        bankAcctDateIdx: index("bank_txn_acct_date_idx").on(
          t.bankAcctId,
          t.transactionDate
        ),
        statusIdx: index("bank_txn_status_idx").on(t.status),
        referenceIdx: index("bank_txn_reference_idx").on(t.reference)
      })
    );
    bankStatementFiles = pgTable(
      "bank_statement_files",
      {
        stmtFileId: uuid("stmt_file_id").primaryKey().defaultRandom(),
        bankAcctId: uuid("bank_acct_id").references(() => bankAccounts.bankAcctId).notNull(),
        filename: text("filename").notNull(),
        format: text("format").notNull(),
        // bai2, mt940, csv, ofx
        fileHash: text("file_hash").notNull().unique(),
        // SHA256 for deduplication
        statementDate: date("statement_date").notNull(),
        startDate: date("start_date").notNull(),
        endDate: date("end_date").notNull(),
        openingBalanceMinor: bigint("opening_balance_minor", {
          mode: "bigint"
        }).notNull(),
        closingBalanceMinor: bigint("closing_balance_minor", {
          mode: "bigint"
        }).notNull(),
        transactionCount: integer("transaction_count").notNull(),
        status: text("status").notNull().default("pending"),
        // pending, processing, completed, failed
        processedAt: timestamp("processed_at", { withTimezone: true }),
        errors: jsonb("errors"),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (t) => ({
        hashIdx: unique().on(t.fileHash),
        bankAcctDateIdx: index("stmt_files_acct_date_idx").on(
          t.bankAcctId,
          t.statementDate
        )
      })
    );
    achBatch = pgTable(
      "ach_batch",
      {
        achBatchId: uuid("ach_batch_id").primaryKey().defaultRandom(),
        bankAcctId: uuid("bank_acct_id").references(() => bankAccounts.bankAcctId).notNull(),
        serviceClass: text("service_class").notNull(),
        // 200, 220, 225
        companyId: text("company_id").notNull(),
        companyName: text("company_name").notNull(),
        effectiveEntryDate: date("effective_entry_date").notNull(),
        totalEntries: integer("total_entries").notNull(),
        totalAmountMinor: bigint("total_amount_minor", {
          mode: "bigint"
        }).notNull(),
        status: text("status").notNull().default("pending"),
        // pending, submitted, settled, failed
        submittedAt: timestamp("submitted_at", { withTimezone: true }),
        settledAt: timestamp("settled_at", { withTimezone: true }),
        createdBy: integer("created_by").references(() => users.id),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (t) => ({
        statusIdx: index("ach_batch_status_idx").on(t.status),
        effectiveDateIdx: index("ach_batch_date_idx").on(t.effectiveEntryDate)
      })
    );
    achEntry = pgTable(
      "ach_entry",
      {
        achEntryId: uuid("ach_entry_id").primaryKey().defaultRandom(),
        achBatchId: uuid("ach_batch_id").references(() => achBatch.achBatchId).notNull(),
        loanId: integer("loan_id").references(() => loans.id),
        txnCode: text("txn_code").notNull(),
        // 22, 27, 32, 37
        rdfiRouting: text("rdfi_routing").notNull(),
        ddaAccountMask: text("dda_account_mask").notNull(),
        // Last 4 digits
        amountMinor: bigint("amount_minor", { mode: "bigint" }).notNull(),
        traceNumber: text("trace_number").notNull().unique(),
        individualName: text("individual_name").notNull(),
        addenda: text("addenda"),
        status: text("status").notNull().default("pending"),
        // pending, sent, settled, returned
        idempotencyKey: text("idempotency_key").unique(),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (t) => ({
        batchIdx: index("ach_entry_batch_idx").on(t.achBatchId),
        loanIdx: index("ach_entry_loan_idx").on(t.loanId),
        traceIdx: unique().on(t.traceNumber)
      })
    );
    achReturns = pgTable(
      "ach_returns",
      {
        achReturnId: uuid("ach_return_id").primaryKey().defaultRandom(),
        achEntryId: uuid("ach_entry_id").references(() => achEntry.achEntryId).notNull(),
        returnCode: text("return_code").notNull(),
        // R01, R02, etc.
        returnReason: text("return_reason").notNull(),
        returnDate: date("return_date").notNull(),
        amountMinor: bigint("amount_minor", { mode: "bigint" }).notNull(),
        traceNumber: text("trace_number").notNull(),
        processed: boolean("processed").notNull().default(false),
        processedAt: timestamp("processed_at", { withTimezone: true }),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (t) => ({
        entryIdx: index("ach_return_entry_idx").on(t.achEntryId),
        processedIdx: index("ach_return_processed_idx").on(t.processed)
      })
    );
    cashMatchCandidates = pgTable(
      "cash_match_candidates",
      {
        candidateId: uuid("candidate_id").primaryKey().defaultRandom(),
        bankTxnId: uuid("bank_txn_id").references(() => bankTxn.bankTxnId).notNull(),
        eventId: uuid("event_id").notNull(),
        // Reference to ledger event
        score: integer("score").notNull(),
        // Confidence score 0-100
        matchReason: text("match_reason").notNull(),
        amountVarianceMinor: bigint("amount_variance_minor", {
          mode: "bigint"
        }).notNull(),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (t) => ({
        bankTxnIdx: index("match_candidate_txn_idx").on(t.bankTxnId),
        scoreIdx: index("match_candidate_score_idx").on(t.score)
      })
    );
    reconExceptions = pgTable(
      "recon_exceptions",
      {
        exceptionId: uuid("exception_id").primaryKey().defaultRandom(),
        bankTxnId: uuid("bank_txn_id").references(() => bankTxn.bankTxnId),
        category: text("category").notNull(),
        // ach_return, nsf, wire_recall, duplicate, dispute
        subcategory: text("subcategory"),
        severity: text("severity").notNull(),
        // low, medium, high, critical
        state: text("state").notNull().default("open"),
        // open, pending, resolved, cancelled
        assignedTo: integer("assigned_to").references(() => users.id),
        aiRecommendation: jsonb("ai_recommendation"),
        resolvedAt: timestamp("resolved_at", { withTimezone: true }),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (t) => ({
        stateIdx: index("recon_exception_state_idx").on(t.state),
        severityIdx: index("recon_exception_severity_idx").on(t.severity)
      })
    );
    borrowerUsers = pgTable(
      "borrower_users",
      {
        id: serial("id").primaryKey(),
        borrowerEntityId: integer("borrower_entity_id").references(() => borrowerEntities.id).notNull(),
        email: text("email").notNull(),
        phone: text("phone"),
        mfaEnabled: boolean("mfa_enabled").default(false).notNull(),
        status: text("status").default("active").notNull(),
        // active, disabled
        lastLoginAt: timestamp("last_login_at"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (t) => ({
        emailIdx: index("borrower_users_email_idx").on(t.email),
        entityIdx: index("borrower_users_entity_idx").on(t.borrowerEntityId),
        uniqueEntityEmail: unique().on(t.borrowerEntityId, t.email)
      })
    );
    loanBorrowerLinks = pgTable(
      "loan_borrower_links",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").references(() => loans.id).notNull(),
        borrowerEntityId: integer("borrower_entity_id").references(() => borrowerEntities.id).notNull(),
        borrowerUserId: integer("borrower_user_id").references(
          () => borrowerUsers.id
        ),
        role: text("role").notNull(),
        // primary, co, authorized
        permissions: jsonb("permissions"),
        // view_only, make_payments, full_access
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (t) => ({
        loanIdx: index("loan_borrower_loan_idx").on(t.loanId),
        entityIdx: index("loan_borrower_entity_idx").on(t.borrowerEntityId),
        uniqueLoanBorrowerRole: unique().on(t.loanId, t.borrowerEntityId, t.role)
      })
    );
    borrowerPaymentMethods = pgTable(
      "borrower_payment_methods",
      {
        id: serial("id").primaryKey(),
        borrowerUserId: integer("borrower_user_id").references(() => borrowerUsers.id).notNull(),
        type: text("type").notNull(),
        // ach, card (ach only for Phase 1)
        processorToken: text("processor_token").notNull(),
        // Encrypted processor reference
        last4: text("last4"),
        bankName: text("bank_name"),
        accountType: text("account_type"),
        // checking, savings
        nameOnAccount: text("name_on_account"),
        status: text("status").default("active").notNull(),
        // active, deleted
        isDefault: boolean("is_default").default(false),
        verifiedAt: timestamp("verified_at"),
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (t) => ({
        userIdx: index("payment_methods_user_idx").on(t.borrowerUserId)
      })
    );
    borrowerNotices = pgTable(
      "borrower_notices",
      {
        id: serial("id").primaryKey(),
        loanId: integer("loan_id").references(() => loans.id).notNull(),
        borrowerUserId: integer("borrower_user_id").references(
          () => borrowerUsers.id
        ),
        type: text("type").notNull(),
        // past_due, payment_received, statement_ready, etc
        title: text("title").notNull(),
        message: text("message").notNull(),
        payload: jsonb("payload"),
        readAt: timestamp("read_at"),
        deliveryChannels: text("delivery_channels").array(),
        // portal, email, sms
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (t) => ({
        loanIdx: index("notices_loan_idx").on(t.loanId),
        userIdx: index("notices_user_idx").on(t.borrowerUserId),
        unreadIdx: index("notices_unread_idx").on(t.readAt)
      })
    );
    borrowerPreferences = pgTable(
      "borrower_preferences",
      {
        id: serial("id").primaryKey(),
        borrowerUserId: integer("borrower_user_id").references(() => borrowerUsers.id).notNull().unique(),
        statementDelivery: text("statement_delivery").default("paperless"),
        // paperless, mail
        paperlessConsent: boolean("paperless_consent").default(false),
        emailNotifications: boolean("email_notifications").default(true),
        smsNotifications: boolean("sms_notifications").default(false),
        language: text("language").default("en"),
        timezone: text("timezone").default("America/Phoenix"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (t) => ({
        userIdx: unique().on(t.borrowerUserId)
      })
    );
    insertBorrowerUserSchema = createInsertSchema(borrowerUsers).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertLoanBorrowerLinkSchema = createInsertSchema(
      loanBorrowerLinks
    ).omit({
      id: true,
      createdAt: true
    });
    insertBorrowerPaymentMethodSchema = createInsertSchema(
      borrowerPaymentMethods
    ).omit({
      id: true,
      createdAt: true
    });
    insertBorrowerNoticeSchema = createInsertSchema(
      borrowerNotices
    ).omit({
      id: true,
      createdAt: true
    });
    insertBorrowerPreferencesSchema = createInsertSchema(
      borrowerPreferences
    ).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertBankAccountSchema = createInsertSchema(bankAccounts).omit({
      bankAcctId: true,
      createdAt: true,
      updatedAt: true
    });
    insertBankTxnSchema = createInsertSchema(bankTxn).omit({
      bankTxnId: true,
      createdAt: true
    });
    insertBankStatementFileSchema = createInsertSchema(
      bankStatementFiles
    ).omit({
      stmtFileId: true,
      createdAt: true
    });
    insertAchBatchSchema = createInsertSchema(achBatch).omit({
      achBatchId: true,
      createdAt: true
    });
    insertAchEntrySchema = createInsertSchema(achEntry).omit({
      achEntryId: true,
      createdAt: true
    });
    insertAchReturnSchema = createInsertSchema(achReturns).omit({
      achReturnId: true,
      createdAt: true
    });
    insertCashMatchCandidateSchema = createInsertSchema(
      cashMatchCandidates
    ).omit({
      candidateId: true,
      createdAt: true
    });
    insertReconExceptionSchema = createInsertSchema(
      reconExceptions
    ).omit({
      exceptionId: true,
      createdAt: true
    });
    complianceAuditLog = pgTable("compliance_audit_log", {
      id: serial("id").primaryKey(),
      correlationId: uuid("correlation_id").notNull(),
      accountId: uuid("account_id"),
      actorType: text("actor_type").notNull(),
      // 'user','system','integration'
      actorId: text("actor_id"),
      eventType: text("event_type").notNull(),
      // 'CRUD.CREATE','FIN.POST','NOTICE.SENT', etc.
      eventTsUtc: timestamp("event_ts_utc", { withTimezone: true }).notNull().defaultNow(),
      resourceType: text("resource_type").notNull(),
      // 'loan','payment','notice','consent', ...
      resourceId: text("resource_id"),
      loanId: integer("loan_id"),
      // For loan-related events
      payloadJson: jsonb("payload_json").notNull(),
      // PII minimized
      payloadHash: text("payload_hash"),
      prevHash: text("prev_hash"),
      recordHash: text("record_hash"),
      ipAddr: text("ip_addr"),
      userAgent: text("user_agent"),
      geo: jsonb("geo"),
      createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow()
    }, (t) => ({
      correlationIdx: index("compliance_audit_correlation_idx").on(t.correlationId, t.eventTsUtc),
      accountIdx: index("compliance_audit_account_idx").on(t.accountId, t.eventTsUtc),
      eventIdx: index("compliance_audit_event_idx").on(t.eventType, t.eventTsUtc),
      resourceIdx: index("compliance_audit_resource_idx").on(t.resourceType, t.resourceId),
      loanIdx: index("compliance_audit_loan_idx").on(t.loanId, t.eventTsUtc)
    }));
    consentRecord = pgTable("consent_record", {
      id: uuid("id").primaryKey().defaultRandom(),
      subjectId: uuid("subject_id").notNull(),
      purpose: text("purpose").notNull(),
      // 'emarketing','esign','privacy', etc.
      scope: text("scope").notNull(),
      // 'loan:read','email:marketing', ...
      status: text("status").notNull(),
      // 'granted','revoked'
      channel: text("channel").notNull(),
      // 'web','email','sms','paper','ivr'
      version: text("version").notNull(),
      // doc/policy version or hash
      evidenceUri: text("evidence_uri"),
      // WORM link
      locale: text("locale").default("en-US"),
      tsGrantedUtc: timestamp("ts_granted_utc", { withTimezone: true }),
      tsRevokedUtc: timestamp("ts_revoked_utc", { withTimezone: true }),
      createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow(),
      updatedAt: timestamp("updated_at", { withTimezone: true }).notNull().defaultNow()
    }, (t) => ({
      subjectIdx: index("consent_subject_idx").on(t.subjectId, t.purpose)
    }));
    communicationPreference = pgTable("communication_preference", {
      id: uuid("id").primaryKey().defaultRandom(),
      subjectId: uuid("subject_id").notNull(),
      channel: text("channel").notNull(),
      // 'email','sms','phone','push','mail'
      topic: text("topic").notNull(),
      // 'billing','collections','marketing','privacy'
      allowed: boolean("allowed").notNull().default(true),
      frequency: text("frequency"),
      // 'immediate','daily','weekly','monthly'
      lastUpdatedBy: text("last_updated_by").notNull(),
      updatedAt: timestamp("updated_at", { withTimezone: true }).notNull().defaultNow()
    }, (t) => ({
      uniquePref: unique().on(t.subjectId, t.channel, t.topic)
    }));
    retentionPolicy = pgTable("retention_policy", {
      id: uuid("id").primaryKey().defaultRandom(),
      dataClass: text("data_class").notNull(),
      // 'PII.ID','FIN.TXN','DOC.APPRAISAL', ...
      jurisdiction: text("jurisdiction").notNull(),
      // 'US','EU','CA', ...
      minRetentionDays: integer("min_retention_days").notNull(),
      maxRetentionDays: integer("max_retention_days"),
      legalHoldAllowed: boolean("legal_hold_allowed").notNull().default(true),
      policyVersion: text("policy_version").notNull(),
      notes: text("notes"),
      createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow()
    }, (t) => ({
      uniqueRetPol: unique().on(t.dataClass, t.jurisdiction, t.policyVersion)
    }));
    legalHold = pgTable("legal_hold", {
      id: uuid("id").primaryKey().defaultRandom(),
      scopeType: text("scope_type").notNull(),
      // 'artifact','account','subject'
      scopeId: text("scope_id").notNull(),
      reason: text("reason").notNull(),
      imposedBy: text("imposed_by").notNull(),
      active: boolean("active").notNull().default(true),
      createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow(),
      releasedAt: timestamp("released_at", { withTimezone: true })
    }, (t) => ({
      scopeIdx: index("legal_hold_scope_idx").on(t.scopeType, t.scopeId)
    }));
    processTimer = pgTable("process_timer", {
      id: uuid("id").primaryKey().defaultRandom(),
      timerCode: text("timer_code").notNull(),
      // 'NOTICE.ADVERSE.ACTION','NOTICE.PRIVACY.ANNUAL', ...
      jurisdiction: text("jurisdiction").notNull(),
      windowHoursMin: integer("window_hours_min").notNull(),
      windowHoursMax: integer("window_hours_max").notNull(),
      graceHours: integer("grace_hours").default(0),
      version: text("version").notNull(),
      createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow()
    }, (t) => ({
      uniqueTimer: unique().on(t.timerCode, t.jurisdiction, t.version)
    }));
    deletionReceipt = pgTable("deletion_receipt", {
      id: uuid("id").primaryKey().defaultRandom(),
      subjectId: uuid("subject_id"),
      dataClass: text("data_class").notNull(),
      payloadSummary: jsonb("payload_summary").notNull(),
      deletedAtUtc: timestamp("deleted_at_utc", { withTimezone: true }).notNull().defaultNow(),
      evidenceUri: text("evidence_uri"),
      responsibleActor: text("responsible_actor").notNull(),
      recordHash: text("record_hash").notNull(),
      createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow()
    });
    noticeDeliveryLog = pgTable("notice_delivery_log", {
      id: uuid("id").primaryKey().defaultRandom(),
      accountId: uuid("account_id"),
      subjectId: uuid("subject_id"),
      noticeCode: text("notice_code").notNull(),
      // 'PRIVACY.ANNUAL','ESCROW.ANALYSIS', ...
      deliveryChannel: text("delivery_channel").notNull(),
      // 'email','mail','portal'
      deliveryStatus: text("delivery_status").notNull(),
      // 'queued','sent','failed','opened','returned'
      scheduledFor: timestamp("scheduled_for", { withTimezone: true }).notNull(),
      sentAt: timestamp("sent_at", { withTimezone: true }),
      failureReason: text("failure_reason"),
      correlationId: uuid("correlation_id").notNull(),
      createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow()
    }, (t) => ({
      accountIdx: index("notice_account_idx").on(t.accountId, t.noticeCode, t.scheduledFor)
    }));
    accountBalanceLedger = pgTable("account_balance_ledger", {
      id: serial("id").primaryKey(),
      accountId: uuid("account_id").notNull(),
      postingTsUtc: timestamp("posting_ts_utc", { withTimezone: true }).notNull(),
      amountCents: bigint("amount_cents", { mode: "bigint" }).notNull(),
      currency: text("currency").notNull().default("USD"),
      txnType: text("txn_type").notNull(),
      // 'debit','credit'
      description: text("description"),
      externalRef: text("external_ref"),
      correlationId: uuid("correlation_id").notNull()
    }, (t) => ({
      acctIdx: index("acct_ledger_idx").on(t.accountId, t.postingTsUtc)
    }));
    artifact = pgTable("artifact", {
      id: uuid("id").primaryKey().defaultRandom(),
      accountId: uuid("account_id"),
      subjectId: uuid("subject_id"),
      artifactCode: text("artifact_code").notNull(),
      // 'DISCLOSURE.TILA','APPRAISAL','PRIVACY.NOTICE'
      uri: text("uri").notNull(),
      // object store URL / DMS ID
      sha256: text("sha256").notNull(),
      createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow()
    });
    dataSubjectRequest = pgTable("data_subject_request", {
      id: uuid("id").primaryKey().defaultRandom(),
      subjectId: uuid("subject_id").notNull(),
      type: text("type").notNull(),
      // 'access','deletion','correction'
      status: text("status").notNull(),
      // 'received','in_progress','completed','rejected'
      submittedVia: text("submitted_via").notNull(),
      // 'portal','email','mail'
      openedAt: timestamp("opened_at", { withTimezone: true }).notNull().defaultNow(),
      dueAt: timestamp("due_at", { withTimezone: true }).notNull(),
      closedAt: timestamp("closed_at", { withTimezone: true }),
      detailsJson: jsonb("details_json"),
      caseRef: text("case_ref")
    }, (t) => ({
      subjectIdx: index("dsar_subject_idx").on(t.subjectId, t.status)
    }));
    insertComplianceAuditLogSchema = createInsertSchema(complianceAuditLog).omit({
      id: true,
      eventTsUtc: true,
      createdAt: true
    });
    insertConsentRecordSchema = createInsertSchema(consentRecord).omit({
      id: true,
      createdAt: true,
      updatedAt: true
    });
    insertCommunicationPreferenceSchema = createInsertSchema(communicationPreference).omit({
      id: true,
      updatedAt: true
    });
    insertRetentionPolicySchema = createInsertSchema(retentionPolicy).omit({
      id: true,
      createdAt: true
    });
    insertLegalHoldSchema = createInsertSchema(legalHold).omit({
      id: true,
      createdAt: true
    });
    insertProcessTimerSchema = createInsertSchema(processTimer).omit({
      id: true,
      createdAt: true
    });
    insertDeletionReceiptSchema = createInsertSchema(deletionReceipt).omit({
      id: true,
      deletedAtUtc: true,
      createdAt: true
    });
    insertNoticeDeliveryLogSchema = createInsertSchema(noticeDeliveryLog).omit({
      id: true,
      createdAt: true
    });
    insertAccountBalanceLedgerSchema = createInsertSchema(accountBalanceLedger).omit({
      id: true
    });
    insertArtifactSchema = createInsertSchema(artifact).omit({
      id: true,
      createdAt: true
    });
    insertDataSubjectRequestSchema = createInsertSchema(dataSubjectRequest).omit({
      id: true,
      openedAt: true
    });
    noticeStatusEnum = pgEnum("notice_status", [
      "scheduled",
      "sent",
      "canceled"
    ]);
    noticeSchedule = pgTable("notice_schedule", {
      noticeId: uuid("notice_id").primaryKey().defaultRandom(),
      loanId: integer("loan_id").references(() => loans.id, { onDelete: "cascade" }).notNull(),
      noticeTemplateId: uuid("notice_template_id").notNull(),
      // References notice_template_v2
      triggerCode: text("trigger_code").notNull(),
      params: jsonb("params").notNull().default("{}"),
      scheduledFor: timestamp("scheduled_for", { withTimezone: true }).notNull(),
      status: noticeStatusEnum("status").notNull().default("scheduled"),
      sentDocId: uuid("sent_doc_id"),
      // References document_artifact
      createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow()
    }, (table) => ({
      uniqueSchedule: unique().on(table.loanId, table.noticeTemplateId, table.scheduledFor)
    }));
    sagaStepHistory = pgTable("saga_step_history", {
      id: serial("id").primaryKey(),
      sagaId: uuid("saga_id").notNull(),
      // References saga_states
      stepName: varchar("step_name", { length: 100 }).notNull(),
      startedAt: timestamp("started_at", { withTimezone: true }).notNull().defaultNow(),
      completedAt: timestamp("completed_at", { withTimezone: true }),
      inputData: jsonb("input_data"),
      outputData: jsonb("output_data"),
      errorMessage: text("error_message"),
      idempotencyKey: varchar("idempotency_key", { length: 200 })
    }, (table) => ({
      uniqueSagaStep: unique().on(table.sagaId, table.stepName, table.idempotencyKey)
    }));
    remittanceExport = pgTable("remittance_export", {
      exportId: uuid("export_id").primaryKey().defaultRandom(),
      cycleId: uuid("cycle_id").notNull(),
      // References remittance_cycle
      format: text("format").notNull(),
      // 'csv' or 'xml'
      fileHash: varchar("file_hash", { length: 64 }).notNull(),
      bytes: text("bytes").notNull(),
      // BYTEA stored as text in Drizzle
      createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow()
    });
    insertNoticeScheduleSchema = createInsertSchema(noticeSchedule).omit({
      noticeId: true,
      createdAt: true
    });
    insertSagaStepHistorySchema = createInsertSchema(sagaStepHistory).omit({
      id: true,
      startedAt: true
    });
    insertRemittanceExportSchema = createInsertSchema(remittanceExport).omit({
      exportId: true,
      createdAt: true
    });
  }
});

// server/db.ts
var db_exports = {};
__export(db_exports, {
  db: () => db,
  pool: () => pool
});
import { Pool, neonConfig } from "@neondatabase/serverless";
import { drizzle } from "drizzle-orm/neon-serverless";
import ws from "ws";
var pool, db;
var init_db = __esm({
  "server/db.ts"() {
    "use strict";
    init_schema();
    neonConfig.webSocketConstructor = ws;
    if (!process.env.DATABASE_URL) {
      throw new Error(
        "DATABASE_URL must be set. Did you forget to provision a database?"
      );
    }
    pool = new Pool({ connectionString: process.env.DATABASE_URL });
    db = drizzle({ client: pool, schema: schema_exports });
  }
});

// server/auth/custom-session-store.ts
import { Store } from "express-session";
import { sql as sql3 } from "drizzle-orm";
var CustomSessionStore;
var init_custom_session_store = __esm({
  "server/auth/custom-session-store.ts"() {
    "use strict";
    init_db();
    CustomSessionStore = class extends Store {
      ttl;
      pruneSessionInterval;
      pruneTimer;
      constructor(options = {}) {
        super();
        this.ttl = options.ttl || 86400;
        this.pruneSessionInterval = options.pruneSessionInterval || 6e4;
        this.startPruning();
      }
      /**
       * Get session from database
       */
      async get(sid, callback2) {
        try {
          const result = await db.execute(sql3`
        SELECT * FROM sessions 
        WHERE sid = ${sid} 
        AND expire > NOW()
        AND revoked_at IS NULL
        LIMIT 1
      `);
          const session2 = result.rows?.[0];
          if (!session2) {
            return callback2(null, null);
          }
          await db.execute(sql3`
        UPDATE sessions 
        SET last_seen_at = NOW()
        WHERE sid = ${sid}
      `);
          const sessionData = typeof session2.sess === "string" ? JSON.parse(session2.sess) : session2.sess;
          callback2(null, sessionData);
        } catch (error) {
          console.error("Session get error:", error);
          callback2(error);
        }
      }
      /**
       * Set/update session in database
       */
      async set(sid, sessionData, callback2) {
        try {
          const expire = sessionData.cookie?.expires ? new Date(sessionData.cookie.expires) : new Date(Date.now() + this.ttl * 1e3);
          const userId = sessionData?.userId || sessionData?.passport?.user;
          const ip = sessionData?.ip || null;
          const userAgent = sessionData?.userAgent || null;
          if (userId) {
            await db.execute(sql3`
          INSERT INTO sessions (sid, user_id, sess, expire, ip, user_agent, created_at, last_seen_at)
          VALUES (
            ${sid},
            ${userId},
            ${JSON.stringify(sessionData)}::json,
            ${expire},
            ${ip},
            ${userAgent},
            NOW(),
            NOW()
          )
          ON CONFLICT (sid) 
          DO UPDATE SET 
            sess = ${JSON.stringify(sessionData)}::json,
            expire = ${expire},
            last_seen_at = NOW(),
            ip = COALESCE(sessions.ip, ${ip}),
            user_agent = COALESCE(sessions.user_agent, ${userAgent})
        `);
          } else {
            console.warn("Session without userId:", sid);
          }
          if (callback2) callback2();
        } catch (error) {
          console.error("Session set error:", error);
          if (callback2) callback2(error);
        }
      }
      /**
       * Destroy session (mark as revoked instead of deleting for audit trail)
       */
      async destroy(sid, callback2) {
        try {
          await db.execute(sql3`
        UPDATE sessions 
        SET revoked_at = NOW(),
            revoke_reason = 'User logout'
        WHERE sid = ${sid}
      `);
          if (callback2) callback2();
        } catch (error) {
          console.error("Session destroy error:", error);
          if (callback2) callback2(error);
        }
      }
      /**
       * Update session expiration time
       */
      async touch(sid, sessionData, callback2) {
        try {
          const expire = sessionData.cookie?.expires ? new Date(sessionData.cookie.expires) : new Date(Date.now() + this.ttl * 1e3);
          await db.execute(sql3`
        UPDATE sessions 
        SET expire = ${expire},
            last_seen_at = NOW()
        WHERE sid = ${sid}
      `);
          if (callback2) callback2();
        } catch (error) {
          console.error("Session touch error:", error);
          if (callback2) callback2(error);
        }
      }
      /**
       * Get all active sessions
       */
      async all(callback2) {
        try {
          const result = await db.execute(sql3`
        SELECT sid, sess FROM sessions 
        WHERE expire > NOW()
        AND revoked_at IS NULL
      `);
          const sessionMap = {};
          if (result.rows) {
            for (const session2 of result.rows) {
              sessionMap[session2.sid] = typeof session2.sess === "string" ? JSON.parse(session2.sess) : session2.sess;
            }
          }
          callback2(null, sessionMap);
        } catch (error) {
          console.error("Session all error:", error);
          callback2(error);
        }
      }
      /**
       * Clear all sessions (mark as revoked for audit)
       */
      async clear(callback2) {
        try {
          await db.execute(sql3`
        UPDATE sessions
        SET revoked_at = NOW(),
            revoke_reason = 'Admin clear all sessions'
        WHERE revoked_at IS NULL
      `);
          if (callback2) callback2();
        } catch (error) {
          console.error("Session clear error:", error);
          if (callback2) callback2(error);
        }
      }
      /**
       * Count active sessions
       */
      async length(callback2) {
        try {
          const result = await db.execute(sql3`
        SELECT COUNT(*) as count 
        FROM sessions 
        WHERE expire > NOW()
        AND revoked_at IS NULL
      `);
          const count3 = result.rows?.[0]?.count || 0;
          callback2(null, parseInt(count3));
        } catch (error) {
          console.error("Session length error:", error);
          callback2(error);
        }
      }
      /**
       * Start pruning expired sessions
       */
      startPruning() {
        this.pruneTimer = setInterval(async () => {
          try {
            await db.execute(sql3`
          UPDATE sessions 
          SET revoked_at = NOW(),
              revoke_reason = 'Session expired'
          WHERE expire < NOW()
          AND revoked_at IS NULL
        `);
          } catch (error) {
            console.error("Session pruning error:", error);
          }
        }, this.pruneSessionInterval);
      }
      /**
       * Stop pruning timer
       */
      stopPruning() {
        if (this.pruneTimer) {
          clearInterval(this.pruneTimer);
          this.pruneTimer = void 0;
        }
      }
    };
  }
});

// server/storage.ts
import { eq as eq3, desc, and as and2, or, count, sum, gte as gte2, inArray } from "drizzle-orm";
var DatabaseStorage, storage;
var init_storage = __esm({
  "server/storage.ts"() {
    "use strict";
    init_schema();
    init_db();
    init_custom_session_store();
    DatabaseStorage = class {
      sessionStore;
      constructor() {
        this.sessionStore = new CustomSessionStore({
          ttl: 86400,
          // 24 hours
          pruneSessionInterval: 6e4
          // 1 minute
        });
      }
      // User methods
      async getUser(id) {
        const [user] = await db.select().from(users).where(eq3(users.id, id));
        if (!user) return void 0;
        const userRolesList = await db.select({
          roleId: userRoles.roleId,
          roleName: roles.name
        }).from(userRoles).innerJoin(roles, eq3(userRoles.roleId, roles.id)).where(eq3(userRoles.userId, id));
        return {
          ...user,
          roles: userRolesList.map((r) => r.roleName)
        };
      }
      async getUserByUsername(username) {
        const [user] = await db.select().from(users).where(eq3(users.username, username));
        return user || void 0;
      }
      async getUserByEmail(email) {
        const [user] = await db.select().from(users).where(eq3(users.email, email));
        return user || void 0;
      }
      async createUser(insertUser) {
        const [user] = await db.insert(users).values(insertUser).returning();
        return user;
      }
      async updateUser(id, updateUser) {
        const [user] = await db.update(users).set({ ...updateUser, updatedAt: /* @__PURE__ */ new Date() }).where(eq3(users.id, id)).returning();
        return user;
      }
      // Borrower Entity methods
      async getBorrowerEntity(id) {
        const [entity] = await db.select().from(borrowerEntities).where(eq3(borrowerEntities.id, id));
        return entity || void 0;
      }
      async createBorrowerEntity(entity) {
        const [borrower] = await db.insert(borrowerEntities).values(entity).returning();
        return borrower;
      }
      async updateBorrowerEntity(id, entity) {
        const [borrower] = await db.update(borrowerEntities).set({ ...entity, updatedAt: /* @__PURE__ */ new Date() }).where(eq3(borrowerEntities.id, id)).returning();
        return borrower;
      }
      async getBorrowerEntities() {
        return await db.select().from(borrowerEntities).where(eq3(borrowerEntities.isActive, true));
      }
      // Property methods
      async getProperty(id) {
        const [property] = await db.select().from(properties).where(eq3(properties.id, id));
        return property || void 0;
      }
      async createProperty(property) {
        const [prop] = await db.insert(properties).values(property).returning();
        return prop;
      }
      async updateProperty(id, property) {
        const [prop] = await db.update(properties).set({ ...property, updatedAt: /* @__PURE__ */ new Date() }).where(eq3(properties.id, id)).returning();
        return prop;
      }
      async getProperties() {
        return await db.select().from(properties).orderBy(desc(properties.createdAt));
      }
      // Loan methods
      async getLoans(filters = {}) {
        let query = db.select().from(loans).leftJoin(properties, eq3(loans.propertyId, properties.id));
        const conditions = [];
        if (filters.lenderId) conditions.push(eq3(loans.lenderId, filters.lenderId));
        if (filters.servicerId) conditions.push(eq3(loans.servicerId, filters.servicerId));
        if (filters.investorId) conditions.push(eq3(loans.investorId, filters.investorId));
        if (filters.status) conditions.push(eq3(loans.status, filters.status));
        if (conditions.length > 0) {
          query = query.where(and2(...conditions));
        }
        query = query.orderBy(desc(loans.createdAt));
        if (filters.limit) {
          query = query.limit(filters.limit);
        }
        if (filters.offset) {
          query = query.offset(filters.offset);
        }
        const result = await query;
        return result.map((row) => ({
          ...row.loans,
          propertyAddress: row.properties?.address,
          propertyCity: row.properties?.city,
          propertyState: row.properties?.state,
          propertyZip: row.properties?.zipCode,
          propertyType: row.properties?.propertyType,
          propertyValue: row.properties?.purchasePrice || row.properties?.currentValue,
          property: row.properties
        }));
      }
      async getLoan(id) {
        const [result] = await db.select().from(loans).leftJoin(properties, eq3(loans.propertyId, properties.id)).where(eq3(loans.id, id));
        if (!result) return void 0;
        return {
          ...result.loans,
          // Include property fields at the loan level for easy access
          apn: result.properties?.apn,
          parcelNumber: result.properties?.apn,
          legalDescription: result.properties?.legalDescription,
          propertyAddress: result.properties?.address,
          propertyCity: result.properties?.city,
          propertyState: result.properties?.state,
          propertyZip: result.properties?.zipCode,
          propertyType: result.properties?.propertyType,
          propertyValue: result.properties?.purchasePrice || result.properties?.currentValue,
          property: result.properties
        };
      }
      async getLoanByNumber(loanNumber) {
        const [loan] = await db.select().from(loans).where(eq3(loans.loanNumber, loanNumber));
        return loan || void 0;
      }
      async createLoan(insertLoan) {
        console.log("=== STORAGE: createLoan called ===");
        console.log("Insert data received:", JSON.stringify(insertLoan, null, 2));
        try {
          console.log("Attempting to insert into database with transaction...");
          const result = await db.transaction(async (tx) => {
            const [loan] = await tx.insert(loans).values(insertLoan).returning();
            console.log("Loan inserted successfully:", loan);
            if (insertLoan.monthlyEscrow && parseFloat(insertLoan.monthlyEscrow) > 0) {
              await tx.insert(escrowAccounts2).values({
                loanId: loan.id,
                accountType: "standard",
                balance: "0.00",
                monthlyAmount: insertLoan.monthlyEscrow,
                status: "active",
                lastAnalysisDate: /* @__PURE__ */ new Date()
              });
              console.log("Escrow account created for loan:", loan.id);
            }
            await tx.insert(loanLedger).values({
              loanId: loan.id,
              transactionDate: /* @__PURE__ */ new Date(),
              transactionId: `ORIG-${loan.id}-${Date.now()}`,
              description: "Loan Origination",
              transactionType: "origination",
              category: "loan",
              creditAmount: loan.originalAmount,
              debitAmount: "0",
              runningBalance: loan.originalAmount,
              principalBalance: loan.originalAmount,
              interestBalance: "0",
              status: "posted",
              createdBy: null,
              notes: `Loan ${loan.loanNumber} originated`
            });
            console.log("Initial ledger entry created for loan:", loan.id);
            return loan;
          });
          return result;
        } catch (error) {
          console.error("=== DATABASE ERROR ===");
          console.error("Error in loan creation transaction:", error);
          console.error("Error message:", error.message);
          console.error("Error code:", error.code);
          console.error("Error detail:", error.detail);
          throw error;
        }
      }
      async updateLoan(id, updateLoan) {
        const cleanUpdateData = { ...updateLoan };
        Object.keys(cleanUpdateData).forEach((key) => {
          const value = cleanUpdateData[key];
          if (value === void 0) {
            delete cleanUpdateData[key];
          }
          if (value && typeof value === "string" && (key.includes("Date") || key === "createdAt" || key === "updatedAt")) {
            try {
              cleanUpdateData[key] = new Date(value);
            } catch (e) {
              delete cleanUpdateData[key];
            }
          }
        });
        delete cleanUpdateData.createdAt;
        delete cleanUpdateData.updatedAt;
        const [loan] = await db.update(loans).set(cleanUpdateData).where(eq3(loans.id, id)).returning();
        return loan;
      }
      async deleteLoan(id) {
        await db.transaction(async (tx) => {
          console.log(`Starting transaction to delete loan ${id}`);
          const docsDeleted = await tx.delete(documents).where(eq3(documents.loanId, id));
          console.log(`Deleted documents for loan ${id}`);
          await tx.delete(loanBorrowers).where(eq3(loanBorrowers.loanId, id));
          console.log(`Deleted loan borrowers for loan ${id}`);
          await tx.delete(investors).where(eq3(investors.loanId, id));
          console.log(`Deleted investors for loan ${id}`);
          await tx.delete(payments).where(eq3(payments.loanId, id));
          console.log(`Deleted payments for loan ${id}`);
          await tx.delete(paymentSchedule).where(eq3(paymentSchedule.loanId, id));
          console.log(`Deleted payment schedule for loan ${id}`);
          await tx.delete(escrowDisbursementPayments).where(
            inArray(
              escrowDisbursementPayments.disbursementId,
              tx.select({ id: escrowDisbursements2.id }).from(escrowDisbursements2).where(eq3(escrowDisbursements2.loanId, id))
            )
          );
          await tx.delete(escrowDisbursements2).where(eq3(escrowDisbursements2.loanId, id));
          console.log(`Deleted escrow disbursements for loan ${id}`);
          await tx.delete(escrowTransactions).where(eq3(escrowTransactions.loanId, id));
          await tx.delete(escrowAccounts2).where(eq3(escrowAccounts2.loanId, id));
          console.log(`Deleted escrow accounts for loan ${id}`);
          await tx.delete(loanLedger).where(eq3(loanLedger.loanId, id));
          console.log(`Deleted ledger entries for loan ${id}`);
          await tx.delete(loanFees).where(eq3(loanFees.loanId, id));
          console.log(`Deleted loan fees for loan ${id}`);
          await tx.delete(loans).where(eq3(loans.id, id));
          console.log(`Successfully deleted loan ${id} and all related records`);
        });
      }
      async getLoanMetrics(userId) {
        let conditions = [];
        if (userId) {
          conditions.push(or(
            eq3(loans.lenderId, userId),
            eq3(loans.servicerId, userId),
            eq3(loans.investorId, userId)
          ));
        }
        const whereClause = conditions.length > 0 ? and2(...conditions) : void 0;
        const [totalPortfolioResult] = await db.select({ total: sum(loans.principalBalance) }).from(loans).where(whereClause);
        const [activeLoansResult] = await db.select({ count: count() }).from(loans).where(and2(
          eq3(loans.status, "active"),
          whereClause
        ));
        const [delinquentResult] = await db.select({ count: count() }).from(loans).where(and2(
          eq3(loans.status, "delinquent"),
          whereClause
        ));
        const currentYear = (/* @__PURE__ */ new Date()).getFullYear();
        const yearStart = new Date(currentYear, 0, 1);
        const [collectionsResult] = await db.select({ total: sum(payments.totalReceived) }).from(payments).innerJoin(loans, eq3(payments.loanId, loans.id)).where(and2(
          gte2(payments.effectiveDate, yearStart.toISOString().split("T")[0]),
          whereClause
        ));
        return {
          totalPortfolio: totalPortfolioResult?.total || "0",
          activeLoans: Number(activeLoansResult?.count) || 0,
          delinquentLoans: Number(delinquentResult?.count) || 0,
          collectionsYTD: collectionsResult?.total || "0"
        };
      }
      // Loan Borrower methods
      async getLoanBorrowers(loanId) {
        return await db.select().from(loanBorrowers).where(eq3(loanBorrowers.loanId, loanId));
      }
      async createLoanBorrower(loanBorrower2) {
        const [lb] = await db.insert(loanBorrowers).values(loanBorrower2).returning();
        return lb;
      }
      async deleteLoanBorrower(id) {
        await db.delete(loanBorrowers).where(eq3(loanBorrowers.id, id));
      }
      // Investor methods
      async getInvestorsByLoan(loanId) {
        return await db.select().from(investors).where(eq3(investors.loanId, loanId));
      }
      async getInvestor(id) {
        const [investor] = await db.select().from(investors).where(eq3(investors.id, id));
        return investor || void 0;
      }
      async createInvestor(investor) {
        const [inv] = await db.insert(investors).values(investor).returning();
        return inv;
      }
      async updateInvestor(id, investor) {
        const cleanUpdateData = { ...investor };
        Object.keys(cleanUpdateData).forEach((key) => {
          const value = cleanUpdateData[key];
          if (value === void 0) {
            delete cleanUpdateData[key];
          }
          if (value && typeof value === "string" && (key.includes("Date") || key === "createdAt" || key === "updatedAt")) {
            try {
              cleanUpdateData[key] = new Date(value);
            } catch (e) {
              delete cleanUpdateData[key];
            }
          }
        });
        delete cleanUpdateData.createdAt;
        delete cleanUpdateData.updatedAt;
        const [inv] = await db.update(investors).set(cleanUpdateData).where(eq3(investors.id, id)).returning();
        return inv;
      }
      async deleteInvestor(id) {
        await db.delete(investors).where(eq3(investors.id, id));
      }
      // Payment methods
      async getPayments(loanId, limit) {
        let query = db.select().from(payments).where(eq3(payments.loanId, loanId)).orderBy(desc(payments.effectiveDate));
        if (limit) {
          query = query.limit(limit);
        }
        return await query;
      }
      async createPayment(insertPayment) {
        const [payment] = await db.insert(payments).values(insertPayment).returning();
        return payment;
      }
      async getPaymentHistory(loanId) {
        return await this.getPayments(loanId);
      }
      async updatePayment(id, updatePayment) {
        const [payment] = await db.update(payments).set({ ...updatePayment, updatedAt: /* @__PURE__ */ new Date() }).where(eq3(payments.id, id)).returning();
        return payment;
      }
      // Payment Schedule methods
      async getPaymentSchedule(loanId) {
        return await db.select().from(paymentSchedule).where(eq3(paymentSchedule.loanId, loanId)).orderBy(paymentSchedule.paymentNumber);
      }
      async createPaymentSchedule(schedule) {
        const [ps] = await db.insert(paymentSchedule).values(schedule).returning();
        return ps;
      }
      async generatePaymentSchedule(loanId) {
        return [];
      }
      // Escrow methods
      async getEscrowAccount(loanId) {
        const [account] = await db.select().from(escrowAccounts2).where(eq3(escrowAccounts2.loanId, loanId));
        return account || void 0;
      }
      async createEscrowAccount(insertAccount) {
        const [account] = await db.insert(escrowAccounts2).values(insertAccount).returning();
        return account;
      }
      async updateEscrowAccount(id, updateAccount) {
        const [account] = await db.update(escrowAccounts2).set({ ...updateAccount, updatedAt: /* @__PURE__ */ new Date() }).where(eq3(escrowAccounts2.id, id)).returning();
        return account;
      }
      async getEscrowTransactions(filters = {}) {
        let query = db.select().from(escrowTransactions);
        if (filters.escrowAccountId) {
          query = query.where(eq3(escrowTransactions.escrowAccountId, filters.escrowAccountId));
        }
        query = query.orderBy(desc(escrowTransactions.transactionDate));
        if (filters.limit) {
          query = query.limit(filters.limit);
        }
        return await query;
      }
      async createEscrowTransaction(transaction) {
        const [trans] = await db.insert(escrowTransactions).values(transaction).returning();
        return trans;
      }
      // Stub implementations - escrowItems table not implemented yet
      async getEscrowItems(escrowAccountId) {
        return [];
      }
      async createEscrowItem(item) {
        return { id: 0, ...item };
      }
      async getEscrowMetrics() {
        const [balanceResult] = await db.select({ total: sum(escrowAccounts2.currentBalance) }).from(escrowAccounts2).where(eq3(escrowAccounts2.isActive, true));
        const [pendingResult] = await db.select({ total: sum(escrowAccounts2.pendingDisbursements) }).from(escrowAccounts2).where(eq3(escrowAccounts2.isActive, true));
        const [shortageResult] = await db.select({ total: sum(escrowAccounts2.shortageAmount) }).from(escrowAccounts2).where(eq3(escrowAccounts2.isActive, true));
        const [surplusResult] = await db.select({ total: sum(escrowAccounts2.surplusAmount) }).from(escrowAccounts2).where(eq3(escrowAccounts2.isActive, true));
        return {
          totalBalance: balanceResult?.total || "0",
          pendingDisbursements: pendingResult?.total || "0",
          shortages: shortageResult?.total || "0",
          surpluses: surplusResult?.total || "0"
        };
      }
      // Document methods
      async getDocuments(filters = {}) {
        let query = db.select().from(documents);
        const conditions = [];
        if (filters.loanId) conditions.push(eq3(documents.loanId, filters.loanId));
        if (filters.borrowerId) conditions.push(eq3(documents.borrowerId, filters.borrowerId));
        if (filters.category) conditions.push(eq3(documents.category, filters.category));
        if (conditions.length > 0) {
          query = query.where(and2(...conditions));
        }
        query = query.orderBy(desc(documents.createdAt));
        return await query;
      }
      async createDocument(insertDocument) {
        const result = await db.insert(documents).values(insertDocument).returning();
        return result[0];
      }
      async getDocument(id) {
        const [document] = await db.select().from(documents).where(eq3(documents.id, id));
        return document || void 0;
      }
      async updateDocument(id, updateDocument) {
        const [document] = await db.update(documents).set({ ...updateDocument, updatedAt: /* @__PURE__ */ new Date() }).where(eq3(documents.id, id)).returning();
        return document;
      }
      async deleteDocument(id) {
        await db.delete(documents).where(eq3(documents.id, id));
      }
      // Notification methods
      async getNotifications(userId, limit) {
        let query = db.select().from(notifications).where(eq3(notifications.userId, userId)).orderBy(desc(notifications.createdAt));
        if (limit) {
          query = query.limit(limit);
        }
        return await query;
      }
      async createNotification(insertNotification) {
        const [notification] = await db.insert(notifications).values(insertNotification).returning();
        return notification;
      }
      async markNotificationAsRead(id) {
        await db.update(notifications).set({ isRead: true, readAt: /* @__PURE__ */ new Date() }).where(eq3(notifications.id, id));
      }
      async getUnreadNotificationCount(userId) {
        const [result] = await db.select({ count: count() }).from(notifications).where(and2(
          eq3(notifications.userId, userId),
          eq3(notifications.isRead, false)
        ));
        return Number(result?.count) || 0;
      }
      // Escrow Disbursement methods implementation
      async getEscrowDisbursements(loanId) {
        const disbursements = await db.select().from(escrowDisbursements2).where(eq3(escrowDisbursements2.loanId, loanId)).orderBy(desc(escrowDisbursements2.createdAt));
        return disbursements;
      }
      async getEscrowDisbursement(id) {
        const [disbursement2] = await db.select().from(escrowDisbursements2).where(eq3(escrowDisbursements2.id, id));
        return disbursement2 || void 0;
      }
      async createEscrowDisbursement(disbursement2) {
        const [newDisbursement] = await db.insert(escrowDisbursements2).values(disbursement2).returning();
        return newDisbursement;
      }
      async updateEscrowDisbursement(id, disbursement2) {
        const [updatedDisbursement] = await db.update(escrowDisbursements2).set(disbursement2).where(eq3(escrowDisbursements2.id, id)).returning();
        return updatedDisbursement;
      }
      async deleteEscrowDisbursement(id) {
        await db.delete(escrowDisbursements2).where(eq3(escrowDisbursements2.id, id));
      }
      async holdEscrowDisbursement(id, reason, requestedBy) {
        const [disbursement2] = await db.update(escrowDisbursements2).set({
          isOnHold: true,
          holdReason: reason,
          holdRequestedBy: requestedBy,
          holdDate: /* @__PURE__ */ new Date()
        }).where(eq3(escrowDisbursements2.id, id)).returning();
        return disbursement2;
      }
      async releaseEscrowDisbursement(id) {
        const [disbursement2] = await db.update(escrowDisbursements2).set({
          isOnHold: false,
          holdReason: null,
          holdRequestedBy: null,
          holdDate: null
        }).where(eq3(escrowDisbursements2.id, id)).returning();
        return disbursement2;
      }
      async getEscrowSummary(loanId) {
        const disbursements = await this.getEscrowDisbursements(loanId);
        const totalDisbursements = disbursements.length;
        const activeDisbursements = disbursements.filter((d) => !d.isOnHold && d.status === "active").length;
        const onHoldDisbursements = disbursements.filter((d) => d.isOnHold).length;
        const totalAnnualAmount = disbursements.reduce((sum3, d) => sum3 + parseFloat(d.annualAmount || "0"), 0).toFixed(2);
        return {
          summary: {
            totalDisbursements,
            activeDisbursements,
            onHoldDisbursements,
            totalAnnualAmount
          }
        };
      }
    };
    storage = new DatabaseStorage();
  }
});

// server/utils/audit-helper.ts
function getRealUserIP(req) {
  const xForwardedFor = req.headers["x-forwarded-for"];
  const xRealIP = req.headers["x-real-ip"];
  const xClientIP = req.headers["x-client-ip"];
  const cfConnectingIP = req.headers["cf-connecting-ip"];
  if (xForwardedFor) {
    const forwarded = Array.isArray(xForwardedFor) ? xForwardedFor[0] : xForwardedFor;
    const firstIP = forwarded.split(",")[0]?.trim();
    if (firstIP && !isPrivateIP(firstIP)) {
      return firstIP;
    }
  }
  if (xRealIP && typeof xRealIP === "string" && !isPrivateIP(xRealIP)) {
    return xRealIP;
  }
  if (xClientIP && typeof xClientIP === "string" && !isPrivateIP(xClientIP)) {
    return xClientIP;
  }
  if (cfConnectingIP && typeof cfConnectingIP === "string" && !isPrivateIP(cfConnectingIP)) {
    return cfConnectingIP;
  }
  return req.ip || req.socket?.remoteAddress || "unknown";
}
function isPrivateIP(ip) {
  const privateRanges = [
    /^10\./,
    // 10.0.0.0/8
    /^172\.(1[6-9]|2[0-9]|3[0-1])\./,
    // 172.16.0.0/12
    /^192\.168\./,
    // 192.168.0.0/16
    /^127\./,
    // 127.0.0.0/8 (localhost)
    /^169\.254\./,
    // 169.254.0.0/16 (link-local)
    /^::1$/,
    // IPv6 localhost
    /^fc00:/,
    // IPv6 unique local
    /^fe80:/
    // IPv6 link-local
  ];
  return privateRanges.some((range) => range.test(ip));
}
async function auditAndRun(client5, action, audit) {
  try {
    await client5.query("BEGIN");
    const res = await action();
    await audit(res);
    await client5.query("COMMIT");
    return res;
  } catch (e) {
    await client5.query("ROLLBACK");
    throw e;
  }
}
async function setRequestContext(client5, actorId, correlationId) {
  await client5.query("SELECT set_config($1, $2, true)", ["app.actor_id", actorId]);
  await client5.query("SELECT set_config($1, $2, true)", ["app.correlation_id", correlationId]);
}
async function createAuditEvent(client5, params) {
  try {
    const correlationId = await complianceAudit.logEvent({
      eventType: params.eventType,
      actorType: params.actorId && params.actorId !== "system" ? "user" : "system",
      actorId: params.actorId,
      resourceType: params.resourceType,
      resourceId: params.resourceId,
      loanId: params.loanId ? parseInt(params.loanId) : void 0,
      description: params.description || `${params.eventType} operation`,
      // Support both direct payload and structured field changes
      previousValues: params.payloadJson?.oldValues || params.payloadJson?.previousValues,
      newValues: params.payloadJson?.newValues || params.payloadJson,
      changedFields: params.payloadJson?.changedFields,
      // Capture request context for audit trail
      ipAddr: params.req ? getRealUserIP(params.req) : void 0,
      userAgent: params.req?.get?.("user-agent"),
      metadata: {
        correlationId: params.correlationId,
        // Preserve original payload for backward compatibility
        originalPayload: params.payloadJson
      }
    });
    console.log(`[Audit] Created audit event ${params.eventType} with correlation ID: ${correlationId}`);
  } catch (error) {
    console.error(`[Audit] Failed to create audit event ${params.eventType}:`, error);
  }
}
var init_audit_helper = __esm({
  "server/utils/audit-helper.ts"() {
    "use strict";
    init_auditService();
  }
});

// server/compliance/auditService.ts
var auditService_exports = {};
__export(auditService_exports, {
  COMPLIANCE_EVENTS: () => COMPLIANCE_EVENTS,
  complianceAudit: () => complianceAudit
});
import { createHash } from "crypto";
import { ulid } from "ulid";
var COMPLIANCE_EVENTS, ComplianceAuditService, complianceAudit;
var init_auditService = __esm({
  "server/compliance/auditService.ts"() {
    "use strict";
    init_db();
    init_schema();
    init_audit_helper();
    COMPLIANCE_EVENTS = {
      // Loan Lifecycle Events
      LOAN: {
        CREATED: "LOAN.CREATED",
        UPDATED: "LOAN.UPDATED",
        DELETED: "LOAN.DELETED",
        STATUS_CHANGED: "LOAN.STATUS_CHANGED",
        TERMS_MODIFIED: "LOAN.TERMS_MODIFIED",
        BENEFICIARY_UPDATED: "LOAN.BENEFICIARY_UPDATED",
        ESCROW_UPDATED: "LOAN.ESCROW_UPDATED",
        INSURANCE_UPDATED: "LOAN.INSURANCE_UPDATED"
      },
      // Payment Operations
      PAYMENT: {
        RECEIVED: "PAYMENT.RECEIVED",
        CREATED: "PAYMENT.CREATED",
        UPDATED: "PAYMENT.UPDATED",
        POSTED: "PAYMENT.POSTED",
        REVERSED: "PAYMENT.REVERSED",
        ALLOCATED: "PAYMENT.ALLOCATED",
        REJECTED: "PAYMENT.REJECTED",
        SCHEDULED: "PAYMENT.SCHEDULED",
        VIEWED: "PAYMENT.VIEWED"
      },
      // Fee Management
      FEE: {
        TEMPLATE_CREATED: "FEE.TEMPLATE_CREATED",
        TEMPLATE_UPDATED: "FEE.TEMPLATE_UPDATED",
        TEMPLATE_DELETED: "FEE.TEMPLATE_DELETED",
        APPLIED_TO_LOAN: "FEE.APPLIED_TO_LOAN",
        SCHEDULE_MODIFIED: "FEE.SCHEDULE_MODIFIED",
        ASSESSED: "FEE.ASSESSED",
        WAIVED: "FEE.WAIVED"
      },
      // Borrower Operations
      BORROWER: {
        CREATED: "BORROWER.CREATED",
        UPDATED: "BORROWER.UPDATED",
        DELETED: "BORROWER.DELETED",
        LINKED_TO_LOAN: "BORROWER.LINKED_TO_LOAN",
        UNLINKED_FROM_LOAN: "BORROWER.UNLINKED_FROM_LOAN"
      },
      // Property Operations
      PROPERTY: {
        CREATED: "PROPERTY.CREATED",
        UPDATED: "PROPERTY.UPDATED",
        DELETED: "PROPERTY.DELETED",
        VALUATION_UPDATED: "PROPERTY.VALUATION_UPDATED"
      },
      // Investor Operations
      INVESTOR: {
        CREATED: "INVESTOR.CREATED",
        UPDATED: "INVESTOR.UPDATED",
        FIELD_UPDATED: "INVESTOR.FIELD_UPDATED",
        DELETED: "INVESTOR.DELETED",
        OWNERSHIP_CHANGED: "INVESTOR.OWNERSHIP_CHANGED",
        DISTRIBUTION_PROCESSED: "INVESTOR.DISTRIBUTION_PROCESSED"
      },
      // Escrow Operations
      ESCROW: {
        ACCOUNT_CREATED: "ESCROW.ACCOUNT_CREATED",
        ACCOUNT_UPDATED: "ESCROW.ACCOUNT_UPDATED",
        DISBURSEMENT_CREATED: "ESCROW.DISBURSEMENT_CREATED",
        DISBURSEMENT_UPDATED: "ESCROW.DISBURSEMENT_UPDATED",
        DISBURSEMENT_DELETED: "ESCROW.DISBURSEMENT_DELETED",
        DISBURSEMENT_SCHEDULED: "ESCROW.DISBURSEMENT_SCHEDULED",
        DISBURSEMENT_COMPLETED: "ESCROW.DISBURSEMENT_COMPLETED",
        DISBURSEMENT_CANCELLED: "ESCROW.DISBURSEMENT_CANCELLED",
        DISBURSEMENT_HELD: "ESCROW.DISBURSEMENT_HELD",
        DISBURSEMENT_RELEASED: "ESCROW.DISBURSEMENT_RELEASED",
        PAYMENT_PROCESSED: "ESCROW.PAYMENT_PROCESSED",
        PAYMENT_FAILED: "ESCROW.PAYMENT_FAILED",
        ANALYSIS_PERFORMED: "ESCROW.ANALYSIS_PERFORMED",
        SHORTAGE_DETECTED: "ESCROW.SHORTAGE_DETECTED",
        SURPLUS_DETECTED: "ESCROW.SURPLUS_DETECTED",
        VIEWED: "ESCROW.VIEWED"
      },
      // Document Management
      DOCUMENT: {
        UPLOADED: "DOCUMENT.UPLOADED",
        ANALYZED: "DOCUMENT.ANALYZED",
        DELETED: "DOCUMENT.DELETED",
        ACCESSED: "DOCUMENT.ACCESSED",
        MOVED: "DOCUMENT.MOVED",
        RENAMED: "DOCUMENT.RENAMED",
        FOLDER_CREATED: "DOCUMENT.FOLDER_CREATED",
        FOLDER_DELETED: "DOCUMENT.FOLDER_DELETED"
      },
      // CRM Activities
      CRM: {
        NOTE_ADDED: "CRM.NOTE_ADDED",
        NOTE_UPDATED: "CRM.NOTE_UPDATED",
        NOTE_DELETED: "CRM.NOTE_DELETED",
        TASK_CREATED: "CRM.TASK_CREATED",
        TASK_UPDATED: "CRM.TASK_UPDATED",
        TASK_COMPLETED: "CRM.TASK_COMPLETED",
        CONTACT_UPDATED: "CRM.CONTACT_UPDATED",
        COMMUNICATION_SENT: "CRM.COMMUNICATION_SENT",
        APPOINTMENT_SCHEDULED: "CRM.APPOINTMENT_SCHEDULED",
        CALL_LOGGED: "CRM.CALL_LOGGED",
        EMAIL_REQUESTED: "CRM.EMAIL_REQUESTED",
        EMAIL_SENT: "CRM.EMAIL_SENT",
        EMAIL_FAILED: "CRM.EMAIL_FAILED",
        SMS_SENT: "CRM.SMS_SENT",
        TEXT_SENT: "CRM.TEXT_SENT",
        COLLABORATOR_ADDED: "CRM.COLLABORATOR_ADDED",
        DEAL_CREATED: "CRM.DEAL_CREATED"
      },
      // Accounting/Ledger Operations - Phase 9 Required
      ACCOUNTING: {
        LEDGER_EVENT_CREATED: "ACCOUNTING.LEDGER_EVENT_CREATED",
        LEDGER_ERROR: "ACCOUNTING.LEDGER_ERROR",
        BALANCE_CALCULATION: "ACCOUNTING.BALANCE_CALCULATION",
        DIRECT_UPDATE_BLOCKED: "ACCOUNTING.DIRECT_UPDATE_BLOCKED"
      },
      // User & Authentication
      AUTH: {
        LOGIN: "AUTH.LOGIN",
        LOGOUT: "AUTH.LOGOUT",
        PASSWORD_CHANGED: "AUTH.PASSWORD_CHANGED",
        ROLE_ASSIGNED: "AUTH.ROLE_ASSIGNED",
        PERMISSION_GRANTED: "AUTH.PERMISSION_GRANTED",
        ACCOUNT_LOCKED: "AUTH.ACCOUNT_LOCKED",
        ACCOUNT_UNLOCKED: "AUTH.ACCOUNT_UNLOCKED",
        SESSION_REVOKED: "AUTH.SESSION_REVOKED"
      },
      // System Operations
      SYSTEM: {
        BATCH_IMPORT: "SYSTEM.BATCH_IMPORT",
        BATCH_UPDATE: "SYSTEM.BATCH_UPDATE",
        REPORT_GENERATED: "SYSTEM.REPORT_GENERATED",
        DATA_EXPORT: "SYSTEM.DATA_EXPORT",
        CONFIGURATION_CHANGED: "SYSTEM.CONFIGURATION_CHANGED",
        SCHEDULED_JOB_RUN: "SYSTEM.SCHEDULED_JOB_RUN",
        INTEGRATION_SYNC: "SYSTEM.INTEGRATION_SYNC"
      },
      // Compliance Operations
      COMPLIANCE: {
        AUDIT_ACCESSED: "COMPLIANCE.AUDIT_ACCESSED",
        RETENTION_APPLIED: "COMPLIANCE.RETENTION_APPLIED",
        LEGAL_HOLD_CREATED: "COMPLIANCE.LEGAL_HOLD_CREATED",
        LEGAL_HOLD_RELEASED: "COMPLIANCE.LEGAL_HOLD_RELEASED",
        DATA_ANONYMIZED: "COMPLIANCE.DATA_ANONYMIZED",
        DATA_DELETED: "COMPLIANCE.DATA_DELETED",
        CONSENT_RECORDED: "COMPLIANCE.CONSENT_RECORDED",
        CONSENT_WITHDRAWN: "COMPLIANCE.CONSENT_WITHDRAWN"
      },
      // Communications and DNC Events
      COMMS: {
        PREFERENCES_ACCESSED: "COMMS.PREFERENCES_ACCESSED",
        DNC_ADDED: "COMMS.DNC_ADDED",
        BULK_PREFERENCES_UPDATED: "COMMS.BULK_PREFERENCES_UPDATED",
        COMPREHENSIVE_DNC_ADDED: "COMMS.COMPREHENSIVE_DNC_ADDED",
        DNC_VIOLATION_BLOCKED: "COMMS.DNC_VIOLATION_BLOCKED",
        TRANSACTIONAL_EMAIL_BLOCKED: "COMMS.TRANSACTIONAL_EMAIL_BLOCKED",
        MARKETING_EMAIL_BLOCKED: "COMMS.MARKETING_EMAIL_BLOCKED"
      }
    };
    ComplianceAuditService = class {
      /**
       * Generate SHA-256 hash
       */
      generateHash(data) {
        const hash = createHash("sha256");
        hash.update(JSON.stringify(data));
        return hash.digest("hex");
      }
      /**
       * Get the previous hash for chain continuity
       */
      async getPreviousHash() {
        const lastEntry = await db.select({ recordHash: complianceAuditLog.recordHash }).from(complianceAuditLog).orderBy(complianceAuditLog.createdAt).limit(1);
        return lastEntry.length > 0 ? lastEntry[0].recordHash : null;
      }
      /**
       * Generate correlation ID if not provided
       */
      generateCorrelationId() {
        return ulid();
      }
      /**
       * Extract changed fields between two objects
       */
      getChangedFields(previousValues, newValues) {
        if (!previousValues || !newValues) return [];
        const changedFields = [];
        const allKeys = /* @__PURE__ */ new Set([
          ...Object.keys(previousValues || {}),
          ...Object.keys(newValues || {})
        ]);
        for (const key of allKeys) {
          if (JSON.stringify(previousValues[key]) !== JSON.stringify(newValues[key])) {
            changedFields.push(key);
          }
        }
        return changedFields;
      }
      /**
       * Log an audit event with Phase 9 compliance features
       */
      async logEvent(data) {
        try {
          const correlationId = data.correlationId || this.generateCorrelationId();
          const changedFields = data.changedFields || this.getChangedFields(data.previousValues, data.newValues);
          const payloadJson = {
            previousValues: data.previousValues,
            newValues: data.newValues,
            changedFields,
            description: data.description,
            metadata: data.metadata || {},
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          };
          const payloadHash = this.generateHash(payloadJson);
          const prevHash = await this.getPreviousHash();
          const recordData = {
            correlationId,
            actorType: data.actorType,
            actorId: String(data.actorId || ""),
            eventType: data.eventType,
            resourceType: data.resourceType,
            resourceId: String(data.resourceId || ""),
            payloadHash,
            prevHash,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          };
          const recordHash = this.generateHash(recordData);
          await db.insert(complianceAuditLog).values({
            correlationId,
            accountId: data.sessionId || null,
            actorType: data.actorType,
            actorId: String(data.actorId || ""),
            eventType: data.eventType,
            eventTsUtc: /* @__PURE__ */ new Date(),
            resourceType: data.resourceType,
            resourceId: String(data.resourceId || ""),
            loanId: data.loanId || null,
            // Include loan ID for loan-related events
            payloadHash,
            payloadJson,
            prevHash,
            recordHash,
            ipAddr: data.ipAddr,
            userAgent: data.userAgent,
            geo: null
          });
        } catch (error) {
          console.error("[ComplianceAudit] Failed to log event:", error);
        }
      }
      /**
       * Simplified method for common audit scenarios
       */
      async logChange(eventType, resourceType, resourceId, previousValues, newValues, userId, req) {
        await this.logEvent({
          actorType: userId ? "user" : "system",
          actorId: userId,
          eventType,
          resourceType,
          resourceId,
          previousValues,
          newValues,
          ipAddr: req ? getRealUserIP(req) : void 0,
          userAgent: req?.headers?.["user-agent"],
          sessionId: req?.sessionID
        });
      }
      /**
       * Log a simple action without value changes
       */
      async logAction(eventType, resourceType, resourceId, description, userId, req, metadata) {
        await this.logEvent({
          actorType: userId ? "user" : "system",
          actorId: userId,
          eventType,
          resourceType,
          resourceId,
          description,
          metadata,
          ipAddr: req ? getRealUserIP(req) : void 0,
          userAgent: req?.headers?.["user-agent"],
          sessionId: req?.sessionID
        });
      }
      /**
       * Log system events
       */
      async logSystemEvent(eventType, description, metadata) {
        await this.logEvent({
          actorType: "system",
          eventType,
          resourceType: "system",
          description,
          metadata
        });
      }
    };
    complianceAudit = new ComplianceAuditService();
  }
});

// server/auth/ip-allowlist-service.ts
var ip_allowlist_service_exports = {};
__export(ip_allowlist_service_exports, {
  addIpToAllowlist: () => addIpToAllowlist,
  bulkUpdateIpAllowlist: () => bulkUpdateIpAllowlist,
  checkIpAllowlist: () => checkIpAllowlist,
  getUserIpAllowlist: () => getUserIpAllowlist,
  logIpDecision: () => logIpDecision,
  removeIpFromAllowlist: () => removeIpFromAllowlist,
  updateIpAllowlistEntry: () => updateIpAllowlistEntry
});
import { eq as eq6, and as and5, sql as sql6 } from "drizzle-orm";
import * as net from "net";
function normalizeIp(ip) {
  if (ip.startsWith("::ffff:")) {
    return ip.substring(7);
  }
  if (ip === "::1") {
    return "127.0.0.1";
  }
  return ip;
}
async function checkIpAllowlist(userId, ip) {
  try {
    const normalizedIp = normalizeIp(ip);
    const allowlistEntries = await db.select({
      id: userIpAllowlist.id,
      cidr: userIpAllowlist.cidr,
      label: userIpAllowlist.label,
      isActive: userIpAllowlist.isActive,
      expiresAt: userIpAllowlist.expiresAt
    }).from(userIpAllowlist).where(and5(
      eq6(userIpAllowlist.userId, userId),
      eq6(userIpAllowlist.isActive, true)
    ));
    if (allowlistEntries.length === 0) {
      return {
        allowed: true,
        hasAllowlist: false,
        reason: "No IP allowlist configured"
      };
    }
    const matchResult = await db.execute(
      sql6`
        SELECT id, cidr, label, begins_at, expires_at 
        FROM user_ip_allowlist 
        WHERE user_id = ${userId} 
          AND is_active = true 
          AND inet '${sql6.raw(normalizedIp)}' <<= cidr
          AND (begins_at IS NULL OR begins_at <= NOW())
          AND (expires_at IS NULL OR expires_at > NOW())
        LIMIT 1
      `
    );
    if (matchResult.rows && matchResult.rows.length > 0) {
      const matched = matchResult.rows[0];
      return {
        allowed: true,
        hasAllowlist: true,
        matchedEntry: {
          id: matched.id,
          cidr: matched.cidr,
          label: matched.label
        },
        reason: `IP matches allowlist entry: ${matched.label || matched.cidr}`
      };
    }
    return {
      allowed: true,
      hasAllowlist: true,
      matchedEntry: null,
      reason: `IP ${normalizedIp} not in trusted list (access allowed)`
    };
  } catch (error) {
    console.error("IP allowlist check error:", error);
    return {
      allowed: true,
      hasAllowlist: false,
      reason: "IP allowlist check failed (access allowed)"
    };
  }
}
async function logIpDecision(userId, ip, allowed, reason, matchedEntry) {
  try {
    await db.insert(authEvents).values({
      targetUserId: userId,
      eventType: allowed ? "permission_granted" : "permission_denied",
      ip,
      details: {
        normalizedIp: normalizeIp(ip),
        allowed,
        reason,
        matchedEntry: matchedEntry || null,
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      },
      eventKey: `ip-check-${userId}-${Date.now()}`
    });
  } catch (error) {
    console.error("Failed to log IP decision:", error);
  }
}
async function addIpToAllowlist(userId, cidr, label, actorUserId, expiresAt, beginsAt) {
  try {
    if (!cidr.includes("/")) {
      const isV6 = net.isIPv6(cidr);
      cidr = cidr + (isV6 ? "/128" : "/32");
    }
    const existing = await db.select().from(userIpAllowlist).where(and5(
      eq6(userIpAllowlist.userId, userId),
      eq6(userIpAllowlist.cidr, cidr)
    )).limit(1);
    if (existing.length > 0) {
      return {
        success: false,
        error: "This IP address is already in the allowlist"
      };
    }
    const ipAddress = cidr.split("/")[0];
    const [result] = await db.insert(userIpAllowlist).values({
      userId,
      ipAddress,
      // Required field - the actual IP address
      cidr,
      // Optional field - the CIDR notation with subnet
      label: label || `IP allowlist entry for ${cidr}`,
      // Set label field (required)
      description: label || `IP allowlist entry for ${cidr}`,
      // Also set description for compatibility
      isActive: true,
      beginsAt: beginsAt ? new Date(beginsAt) : /* @__PURE__ */ new Date(),
      // Start date (defaults to now)
      expiresAt: expiresAt ? new Date(expiresAt) : null
    }).returning({ id: userIpAllowlist.id });
    await db.insert(authEvents).values({
      actorUserId: actorUserId || userId,
      targetUserId: userId,
      eventType: "ip_allow_added",
      // Using the correct valid event type
      details: {
        cidr,
        label,
        entryId: result.id,
        expiresAt: expiresAt ? new Date(expiresAt).toISOString() : null
      },
      eventKey: `ip-add-${userId}-${Date.now()}`
    });
    return { success: true, id: result.id };
  } catch (error) {
    console.error("Add IP to allowlist error:", error);
    return {
      success: false,
      error: error.message || "Failed to add IP to allowlist"
    };
  }
}
async function removeIpFromAllowlist(entryId, actorUserId) {
  try {
    const [entry] = await db.select({
      userId: userIpAllowlist.userId,
      cidr: userIpAllowlist.cidr,
      label: userIpAllowlist.label
    }).from(userIpAllowlist).where(eq6(userIpAllowlist.id, entryId)).limit(1);
    if (!entry) {
      return { success: false, error: "Entry not found" };
    }
    await db.delete(userIpAllowlist).where(eq6(userIpAllowlist.id, entryId));
    await db.insert(authEvents).values({
      actorUserId: actorUserId || entry.userId,
      targetUserId: entry.userId,
      eventType: "ip_allow_removed",
      // Using the correct valid event type
      details: {
        cidr: entry.cidr,
        label: entry.label,
        entryId
      },
      eventKey: `ip-remove-${entry.userId}-${Date.now()}`
    });
    return { success: true };
  } catch (error) {
    console.error("Remove IP from allowlist error:", error);
    return {
      success: false,
      error: error.message || "Failed to remove IP from allowlist"
    };
  }
}
async function updateIpAllowlistEntry(entryId, updates, actorUserId) {
  try {
    const [entry] = await db.select({
      userId: userIpAllowlist.userId,
      cidr: userIpAllowlist.cidr,
      label: userIpAllowlist.label,
      isActive: userIpAllowlist.isActive
    }).from(userIpAllowlist).where(eq6(userIpAllowlist.id, entryId)).limit(1);
    if (!entry) {
      return { success: false, error: "Entry not found" };
    }
    if (updates.cidr && !updates.cidr.includes("/")) {
      const isV6 = net.isIPv6(updates.cidr);
      updates.cidr = updates.cidr + (isV6 ? "/128" : "/32");
    }
    const updateData = { ...updates };
    if (updates.cidr) {
      updateData.ipAddress = updates.cidr.split("/")[0];
      updateData.cidr = updates.cidr;
    }
    if (updates.label) {
      updateData.description = updates.label;
    }
    await db.update(userIpAllowlist).set(updateData).where(eq6(userIpAllowlist.id, entryId));
    await db.insert(authEvents).values({
      actorUserId: actorUserId || entry.userId,
      targetUserId: entry.userId,
      eventType: "settings_changed",
      // Using a valid event type for updates
      details: {
        action: "ip_allowlist_updated",
        entryId,
        previousValues: {
          cidr: entry.cidr,
          label: entry.label,
          isActive: entry.isActive
        },
        newValues: updates
      },
      eventKey: `ip-update-${entry.userId}-${Date.now()}`
    });
    return { success: true };
  } catch (error) {
    console.error("Update IP allowlist error:", error);
    return {
      success: false,
      error: error.message || "Failed to update IP allowlist entry"
    };
  }
}
async function getUserIpAllowlist(userId, includeInactive = false) {
  try {
    let query = db.select({
      id: userIpAllowlist.id,
      cidr: userIpAllowlist.cidr,
      label: userIpAllowlist.label,
      isActive: userIpAllowlist.isActive,
      createdAt: userIpAllowlist.createdAt,
      updatedAt: userIpAllowlist.updatedAt
    }).from(userIpAllowlist).where(eq6(userIpAllowlist.userId, userId));
    if (!includeInactive) {
      query = query.where(and5(
        eq6(userIpAllowlist.userId, userId),
        eq6(userIpAllowlist.isActive, true)
      ));
    }
    return await query;
  } catch (error) {
    console.error("Get user IP allowlist error:", error);
    return [];
  }
}
async function bulkUpdateIpAllowlist(userId, entries, actorUserId) {
  try {
    await db.delete(userIpAllowlist).where(eq6(userIpAllowlist.userId, userId));
    if (entries.length > 0) {
      const newEntries = entries.map((entry) => {
        const cidr = entry.cidr.includes("/") ? entry.cidr : net.isIPv6(entry.cidr) ? entry.cidr + "/128" : entry.cidr + "/32";
        const ipAddress = cidr.split("/")[0];
        return {
          userId,
          ipAddress,
          // Required field
          cidr,
          // Optional field
          description: entry.label || `IP allowlist entry`,
          isActive: entry.isActive !== false
        };
      });
      await db.insert(userIpAllowlist).values(newEntries);
    }
    await db.insert(authEvents).values({
      actorUserId: actorUserId || userId,
      targetUserId: userId,
      eventType: "ip_allowlist_bulk_updated",
      details: {
        entriesCount: entries.length,
        entries: entries.map((e) => ({ cidr: e.cidr, label: e.label }))
      },
      eventKey: `ip-bulk-${userId}-${Date.now()}`
    });
    return { success: true };
  } catch (error) {
    console.error("Bulk update IP allowlist error:", error);
    return {
      success: false,
      error: error.message || "Failed to bulk update IP allowlist"
    };
  }
}
var init_ip_allowlist_service = __esm({
  "server/auth/ip-allowlist-service.ts"() {
    "use strict";
    init_db();
    init_schema();
  }
});

// server/auth/auth-service.ts
var auth_service_exports = {};
__export(auth_service_exports, {
  RateLimiter: () => RateLimiter,
  activateAccountWithToken: () => activateAccountWithToken,
  addPasswordToHistory: () => addPasswordToHistory,
  checkPasswordResetToken: () => checkPasswordResetToken,
  createInvitationToken: () => createInvitationToken,
  createPasswordResetToken: () => createPasswordResetToken,
  emailRateLimiter: () => emailRateLimiter,
  generateSecureToken: () => generateSecureToken,
  hashPassword: () => hashPassword2,
  hashToken: () => hashToken,
  ipRateLimiter: () => ipRateLimiter,
  login: () => login,
  logout: () => logout,
  recordLoginAttempt: () => recordLoginAttempt,
  resetPasswordWithToken: () => resetPasswordWithToken,
  revokeAllUserSessions: () => revokeAllUserSessions,
  validatePassword: () => validatePassword,
  validatePasswordResetToken: () => validatePasswordResetToken,
  validateSession: () => validateSession,
  verifyPassword: () => verifyPassword
});
import argon22 from "argon2";
import crypto3 from "crypto";
import { eq as eq7, and as and6, gte as gte3, sql as sql7, desc as desc4 } from "drizzle-orm";
import { neon } from "@neondatabase/serverless";
async function hashPassword2(password) {
  return argon22.hash(password, ARGON2_CONFIG);
}
async function verifyPassword(password, hash) {
  try {
    return await argon22.verify(hash, password);
  } catch (error) {
    console.error("Password verification error:", error);
    return false;
  }
}
async function getPasswordPolicy() {
  try {
    const settings = await db.select().from(systemSettings).where(eq7(systemSettings.key, "PASSWORD_POLICY"));
    if (settings.length > 0 && settings[0].value) {
      const policy = JSON.parse(settings[0].value);
      return { ...DEFAULT_PASSWORD_POLICY, ...policy };
    }
  } catch (error) {
    console.error("Error fetching password policy:", error);
  }
  return DEFAULT_PASSWORD_POLICY;
}
async function checkPasswordHistory(userId, password, historyCount) {
  if (historyCount <= 0) return false;
  try {
    const history = await dbSql`
      SELECT password_hash 
      FROM password_history 
      WHERE user_id = ${userId}
      ORDER BY created_at DESC
      LIMIT ${historyCount}
    `;
    for (const record of history) {
      const matches = await argon22.verify(record.password_hash, password, ARGON2_CONFIG);
      if (matches) {
        return true;
      }
    }
  } catch (error) {
    console.error("Error checking password history:", error);
  }
  return false;
}
async function addPasswordToHistory(userId, passwordHash) {
  try {
    await dbSql`
      INSERT INTO password_history (user_id, password_hash)
      VALUES (${userId}, ${passwordHash})
      ON CONFLICT (user_id, password_hash) DO NOTHING
    `;
    const policy = await getPasswordPolicy();
    const maxHistory = policy.passwordHistoryCount || 5;
    await dbSql`
      DELETE FROM password_history
      WHERE user_id = ${userId}
      AND created_at < (
        SELECT created_at
        FROM password_history
        WHERE user_id = ${userId}
        ORDER BY created_at DESC
        LIMIT 1 OFFSET ${maxHistory}
      )
    `;
  } catch (error) {
    console.error("Error adding password to history:", error);
  }
}
async function validatePassword(password, userId, policy) {
  const errors = [];
  if (!policy) {
    policy = await getPasswordPolicy();
  }
  if (password.length < policy.minLength) {
    errors.push(`Password must be at least ${policy.minLength} characters long`);
  }
  if (policy.requireUppercase && !/[A-Z]/.test(password)) {
    errors.push("Password must contain at least one uppercase letter");
  }
  if (policy.requireLowercase && !/[a-z]/.test(password)) {
    errors.push("Password must contain at least one lowercase letter");
  }
  if (policy.requireNumbers && !/\d/.test(password)) {
    errors.push("Password must contain at least one number");
  }
  if (policy.requireSpecialChars && !/[!@#$%^&*()_+\-=\[\]{};':"\\|,.<>\/?]/.test(password)) {
    errors.push("Password must contain at least one special character");
  }
  if (policy.rejectCommonPasswords) {
    const commonPatterns = [
      password.toLowerCase() === "password",
      /^password\d+$/.test(password.toLowerCase()),
      /^\d{6,8}$/.test(password),
      /^[a-z]{6,8}$/.test(password.toLowerCase()),
      /^qwerty/i.test(password),
      /^admin/i.test(password),
      /^letmein/i.test(password),
      /^welcome/i.test(password),
      /^123456/i.test(password)
    ];
    if (commonPatterns.some((pattern) => pattern === true)) {
      errors.push("Password is too common. Please choose a more unique password");
    }
  }
  if (userId && policy.preventPasswordReuse && policy.passwordHistoryCount && policy.passwordHistoryCount > 0) {
    const isInHistory = await checkPasswordHistory(userId, password, policy.passwordHistoryCount);
    if (isInHistory) {
      errors.push(`Password has been used recently. Please choose a different password`);
    }
  }
  return {
    valid: errors.length === 0,
    errors
  };
}
async function getLockoutSettings() {
  const settings = await db.select().from(systemSettings).where(sql7`key IN ('LOCKOUT_THRESHOLD', 'LOCKOUT_WINDOW_MINUTES', 'LOCKOUT_AUTO_UNLOCK_MINUTES')`);
  const settingsMap = settings.reduce((acc, s) => {
    acc[s.key] = s.value;
    return acc;
  }, {});
  return {
    threshold: settingsMap.LOCKOUT_THRESHOLD || 5,
    windowMinutes: settingsMap.LOCKOUT_WINDOW_MINUTES || 15,
    autoUnlockMinutes: settingsMap.LOCKOUT_AUTO_UNLOCK_MINUTES || 30
  };
}
async function isAccountLocked(userId) {
  const [user] = await db.select({
    isActive: users.isActive,
    lockedUntil: users.lockedUntil,
    failedLoginAttempts: users.failedLoginAttempts
  }).from(users).where(eq7(users.id, userId)).limit(1);
  if (!user) {
    return { locked: false };
  }
  const isLocked = user.lockedUntil && new Date(user.lockedUntil) > /* @__PURE__ */ new Date();
  if (isLocked) {
    const settings = await getLockoutSettings();
    if (settings.autoUnlockMinutes) {
      const lockEvent = await db.select().from(authEvents).where(and6(
        eq7(authEvents.targetUserId, userId),
        eq7(authEvents.eventType, "account_locked")
      )).orderBy(desc4(authEvents.occurredAt)).limit(1);
      if (lockEvent.length > 0) {
        const lockTime = new Date(lockEvent[0].occurredAt);
        const unlockTime = new Date(lockTime.getTime() + settings.autoUnlockMinutes * 6e4);
        if (/* @__PURE__ */ new Date() >= unlockTime) {
          await unlockAccount(userId, "auto_unlock");
          return { locked: false };
        }
      }
    }
    return { locked: true, reason: "Account is locked due to too many failed login attempts" };
  }
  if (!user.isActive) {
    return { locked: true, reason: "Account is disabled" };
  }
  return { locked: false };
}
async function recordLoginAttempt(emailOrUsername, success, ip, userAgent) {
  const userQuery = emailOrUsername.includes("@") ? eq7(users.email, emailOrUsername) : eq7(users.username, emailOrUsername);
  const [user] = await db.select().from(users).where(userQuery).limit(1);
  const userId = user?.id;
  const isLocked = user?.lockedUntil && new Date(user.lockedUntil) > /* @__PURE__ */ new Date();
  const outcome = success ? "succeeded" : isLocked ? "locked" : "failed";
  await db.insert(loginAttempts).values({
    userId,
    emailAttempted: user?.email || emailOrUsername,
    ip,
    userAgent,
    outcome,
    reason: !success ? "Invalid credentials" : null
  });
  if (!user || success) {
    return { shouldLock: false, userId };
  }
  const settings = await getLockoutSettings();
  const windowStart = new Date(Date.now() - settings.windowMinutes * 6e4);
  const recentFailures = await db.select({
    count: sql7`COUNT(*)`
  }).from(loginAttempts).where(and6(
    eq7(loginAttempts.userId, userId),
    eq7(loginAttempts.outcome, "failed"),
    gte3(loginAttempts.attemptedAt, windowStart)
  ));
  const failureCount = Number(recentFailures[0]?.count || 0);
  await db.update(users).set({
    failedLoginAttempts: failureCount,
    updatedAt: /* @__PURE__ */ new Date()
  }).where(eq7(users.id, userId));
  const shouldLock = failureCount >= settings.threshold;
  if (shouldLock && (!user.lockedUntil || new Date(user.lockedUntil) < /* @__PURE__ */ new Date())) {
    await lockAccount(userId, "threshold_exceeded");
  }
  return { shouldLock, userId };
}
async function lockAccount(userId, reason) {
  const lockDuration = 30;
  await db.update(users).set({
    lockedUntil: new Date(Date.now() + lockDuration * 6e4),
    updatedAt: /* @__PURE__ */ new Date()
  }).where(eq7(users.id, userId));
  await db.insert(authEvents).values({
    targetUserId: userId,
    eventType: "account_locked",
    details: { reason },
    eventKey: `lock-${userId}-${Date.now()}`
  });
}
async function unlockAccount(userId, reason) {
  await db.update(users).set({
    lockedUntil: null,
    failedLoginAttempts: 0,
    updatedAt: /* @__PURE__ */ new Date()
  }).where(eq7(users.id, userId));
  await db.insert(authEvents).values({
    targetUserId: userId,
    eventType: "account_unlocked",
    details: { reason },
    eventKey: `unlock-${userId}-${Date.now()}`
  });
}
async function login(emailOrUsername, password, ip, userAgent) {
  try {
    const userQuery = emailOrUsername.includes("@") ? eq7(users.email, emailOrUsername) : eq7(users.username, emailOrUsername);
    const [user] = await db.select().from(users).where(userQuery).limit(1);
    if (!user) {
      await recordLoginAttempt(emailOrUsername, false, ip, userAgent);
      return { success: false, error: "Invalid credentials" };
    }
    const lockStatus = await isAccountLocked(user.id);
    if (lockStatus.locked) {
      await db.insert(loginAttempts).values({
        userId: user.id,
        emailAttempted: user.email,
        ip,
        userAgent,
        outcome: "locked",
        reason: lockStatus.reason
      });
      return { success: false, error: lockStatus.reason || "Account is locked" };
    }
    const passwordValid = await verifyPassword(password, user.password);
    if (!passwordValid) {
      const { shouldLock } = await recordLoginAttempt(user.email, false, ip, userAgent);
      if (shouldLock) {
        return { success: false, error: "Account has been locked due to too many failed attempts" };
      }
      return { success: false, error: "Invalid credentials" };
    }
    const { checkIpAllowlist: checkIpAllowlist2, logIpDecision: logIpDecision2 } = await Promise.resolve().then(() => (init_ip_allowlist_service(), ip_allowlist_service_exports));
    const ipCheck = await checkIpAllowlist2(user.id, ip);
    await logIpDecision2(user.id, ip, ipCheck.allowed, ipCheck.reason || "", ipCheck.matchedEntry);
    await db.update(users).set({
      failedLoginAttempts: 0,
      lastLogin: /* @__PURE__ */ new Date(),
      updatedAt: /* @__PURE__ */ new Date()
    }).where(eq7(users.id, user.id));
    await recordLoginAttempt(user.email, true, ip, userAgent);
    const sessionSid = `sess:${crypto3.randomUUID()}`;
    const expireTime = new Date(Date.now() + 864e5);
    await db.execute(sql7`
      INSERT INTO sessions (sid, sess, expire)
      VALUES (
        ${sessionSid},
        ${JSON.stringify({
      cookie: {
        originalMaxAge: 864e5,
        // 24 hours
        expires: expireTime.toISOString(),
        httpOnly: true,
        path: "/"
      },
      userId: user.id,
      passport: { user: user.id }
    })}::json,
        ${expireTime}
      )
    `);
    await db.insert(authEvents).values({
      actorUserId: user.id,
      eventType: "login_succeeded",
      ip,
      userAgent,
      details: {
        email: user.email,
        username: user.username,
        ipAllowlistMatch: ipCheck.matchedEntry || null,
        hasAllowlist: ipCheck.hasAllowlist
      },
      eventKey: `login-${user.id}-${Date.now()}`
    });
    const { password: _, ...userWithoutPassword } = user;
    return {
      success: true,
      user: userWithoutPassword,
      sessionId: sessionSid
    };
  } catch (error) {
    console.error("Login error:", error);
    return { success: false, error: "An error occurred during login" };
  }
}
async function logout(sessionId, userId) {
  await db.execute(sql7`
    DELETE FROM sessions 
    WHERE sid = ${sessionId}
  `);
  await db.insert(authEvents).values({
    actorUserId: userId,
    eventType: "session_revoked",
    details: { sessionId, reason: "user_logout" },
    eventKey: `logout-${userId}-${Date.now()}`
  });
}
async function validateSession(sessionId) {
  const result = await db.execute(sql7`
    SELECT sess, expire 
    FROM sessions 
    WHERE sid = ${sessionId}
    AND expire > NOW()
    LIMIT 1
  `);
  if (!result.rows || result.rows.length === 0) {
    return { valid: false };
  }
  const session2 = result.rows[0];
  const sessionData = typeof session2.sess === "string" ? JSON.parse(session2.sess) : session2.sess;
  return { valid: true, userId: sessionData.userId };
}
async function revokeAllUserSessions(userId, reason) {
  await db.execute(sql7`
    DELETE FROM sessions 
    WHERE sess::text LIKE '%"userId":${userId}%'
  `);
  await db.insert(authEvents).values({
    targetUserId: userId,
    eventType: "session_revoked",
    details: { reason, scope: "all_sessions" },
    eventKey: `revoke-all-${userId}-${Date.now()}`
  });
}
async function generateSecureToken() {
  const buffer = crypto3.randomBytes(32);
  return buffer.toString("base64url");
}
async function hashToken(token) {
  const hash = crypto3.createHash("sha256");
  hash.update(token);
  return hash.digest("hex");
}
async function createPasswordResetToken(email) {
  try {
    const [user] = await db.select({
      id: users.id,
      email: users.email,
      isActive: users.isActive
    }).from(users).where(eq7(users.email, email)).limit(1);
    if (!user || !user.isActive) {
      return { success: true };
    }
    const token = await generateSecureToken();
    const hashedToken = await hashToken(token);
    const expiresAt = new Date(Date.now() + 60 * 60 * 1e3);
    await db.insert(passwordResetTokens).values({
      userId: user.id,
      tokenHash: hashedToken,
      expiresAt
    });
    await db.insert(authEvents).values({
      targetUserId: user.id,
      eventType: "password_reset_requested",
      details: { email },
      eventKey: `reset-request-${user.id}-${Date.now()}`
    });
    return { success: true, token };
  } catch (error) {
    console.error("Password reset token error:", error);
    return { success: true };
  }
}
async function checkPasswordResetToken(token) {
  try {
    const hashedToken = await hashToken(token);
    const [resetToken] = await db.select({
      id: passwordResetTokens.id,
      userId: passwordResetTokens.userId,
      expiresAt: passwordResetTokens.expiresAt,
      usedAt: passwordResetTokens.usedAt
    }).from(passwordResetTokens).where(and6(
      eq7(passwordResetTokens.tokenHash, hashedToken),
      sql7`used_at IS NULL`,
      gte3(passwordResetTokens.expiresAt, /* @__PURE__ */ new Date())
    )).limit(1);
    if (!resetToken) {
      return { valid: false, error: "Invalid or expired token" };
    }
    return { valid: true, userId: resetToken.userId };
  } catch (error) {
    console.error("Token check error:", error);
    return { valid: false, error: "Token check failed" };
  }
}
async function validatePasswordResetToken(token) {
  try {
    const hashedToken = await hashToken(token);
    const [resetToken] = await db.select({
      id: passwordResetTokens.id,
      userId: passwordResetTokens.userId,
      expiresAt: passwordResetTokens.expiresAt,
      usedAt: passwordResetTokens.usedAt
    }).from(passwordResetTokens).where(and6(
      eq7(passwordResetTokens.tokenHash, hashedToken),
      sql7`used_at IS NULL`,
      gte3(passwordResetTokens.expiresAt, /* @__PURE__ */ new Date())
    )).limit(1);
    if (!resetToken) {
      return { valid: false, error: "Invalid or expired token" };
    }
    await db.update(passwordResetTokens).set({
      usedAt: /* @__PURE__ */ new Date()
    }).where(eq7(passwordResetTokens.id, resetToken.id));
    return { valid: true, userId: resetToken.userId };
  } catch (error) {
    console.error("Token validation error:", error);
    return { valid: false, error: "Token validation failed" };
  }
}
async function resetPasswordWithToken(token, newPassword) {
  try {
    const tokenValidation = await validatePasswordResetToken(token);
    if (!tokenValidation.valid || !tokenValidation.userId) {
      return { success: false, error: tokenValidation.error || "Invalid token" };
    }
    const passwordValidation = await validatePassword(newPassword, tokenValidation.userId);
    if (!passwordValidation.valid) {
      return {
        success: false,
        error: "Password does not meet requirements",
        errors: passwordValidation.errors
      };
    }
    const hashedPassword = await hashPassword2(newPassword);
    await db.update(users).set({
      password: hashedPassword,
      failedLoginAttempts: 0,
      // Reset failed attempts
      updatedAt: /* @__PURE__ */ new Date()
    }).where(eq7(users.id, tokenValidation.userId));
    await addPasswordToHistory(tokenValidation.userId, hashedPassword);
    await revokeAllUserSessions(tokenValidation.userId, "password_reset");
    await db.insert(authEvents).values({
      targetUserId: tokenValidation.userId,
      eventType: "password_reset_completed",
      details: { method: "reset_token" },
      eventKey: `reset-complete-${tokenValidation.userId}-${Date.now()}`
    });
    return { success: true };
  } catch (error) {
    console.error("Password reset error:", error);
    return { success: false, error: "Password reset failed" };
  }
}
async function createInvitationToken(email, roleIdOrName, invitedBy) {
  try {
    const [existingUser] = await db.select({
      id: users.id
    }).from(users).where(eq7(users.email, email)).limit(1);
    if (existingUser) {
      return { success: false, error: "User already exists" };
    }
    const token = crypto3.randomBytes(32).toString("hex");
    const hashedToken = crypto3.createHash("sha256").update(token).digest("hex");
    const expiresAt = new Date(Date.now() + 7 * 24 * 60 * 60 * 1e3);
    const [newUser] = await db.insert(users).values({
      username: email.split("@")[0] + "_" + Date.now(),
      // Temporary username
      email,
      password: await argon22.hash(crypto3.randomBytes(32).toString("hex")),
      // Random hashed password
      role: "lender",
      // Default enum role (required by DB constraint, but RBAC will be used for actual permissions)
      emailVerified: false,
      isActive: true,
      // Active but not verified
      firstName: "",
      lastName: ""
    }).returning({ id: users.id });
    if (roleIdOrName) {
      const isUuid = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i.test(roleIdOrName);
      if (isUuid) {
        await db.insert(userRoles).values({
          userId: newUser.id,
          roleId: roleIdOrName
        });
      } else {
        const [role] = await db.select({ id: roles.id }).from(roles).where(eq7(roles.name, roleIdOrName)).limit(1);
        if (role) {
          await db.insert(userRoles).values({
            userId: newUser.id,
            roleId: role.id
          });
        }
      }
    }
    await db.insert(passwordResetTokens).values({
      userId: newUser.id,
      tokenHash: hashedToken,
      expiresAt
    });
    await db.insert(authEvents).values({
      actorUserId: invitedBy,
      targetUserId: newUser.id,
      eventType: "user_created",
      details: { email, role: roleIdOrName, invited: true },
      ip: null,
      userAgent: null
    });
    const invitationUrl = `/reset-password?token=${token}`;
    return { success: true, token, invitationUrl };
  } catch (error) {
    console.error("Invitation token error:", error);
    return { success: false, error: "Failed to create invitation" };
  }
}
async function activateAccountWithToken(token, username, password, firstName, lastName) {
  try {
    const tokenValidation = await validatePasswordResetToken(token);
    if (!tokenValidation.valid || !tokenValidation.userId) {
      return { success: false, error: tokenValidation.error || "Invalid token" };
    }
    const result = await db.execute(
      sql7`SELECT * FROM users WHERE id = ${tokenValidation.userId} AND status = 'invited' LIMIT 1`
    );
    const invitedUser = result.rows?.[0];
    if (!invitedUser) {
      return { success: false, error: "Invalid invitation" };
    }
    const passwordValidation = validatePassword(password);
    if (!passwordValidation.valid) {
      return {
        success: false,
        error: "Password does not meet requirements",
        errors: passwordValidation.errors
      };
    }
    const hashedPassword = await hashPassword2(password);
    await db.execute(
      sql7`UPDATE users 
          SET username = ${username},
              password = ${hashedPassword},
              first_name = ${firstName},
              last_name = ${lastName},
              status = 'active',
              password_updated_at = ${/* @__PURE__ */ new Date()},
              updated_at = ${/* @__PURE__ */ new Date()},
              is_active = true
          WHERE id = ${tokenValidation.userId}`
    );
    await db.insert(authEvents).values({
      actorUserId: tokenValidation.userId,
      targetUserId: tokenValidation.userId,
      eventType: "user_updated",
      details: { method: "invitation", action: "account_activated" },
      eventKey: `activate-${tokenValidation.userId}-${Date.now()}`,
      ip: null,
      userAgent: null
    });
    const [activatedUser] = await db.select({
      id: users.id,
      username: users.username,
      email: users.email,
      firstName: users.firstName,
      lastName: users.lastName
      // role field removed - using RBAC system
    }).from(users).where(eq7(users.id, tokenValidation.userId)).limit(1);
    return { success: true, user: activatedUser };
  } catch (error) {
    console.error("Account activation error:", error);
    return { success: false, error: "Account activation failed" };
  }
}
var databaseUrl, dbSql, ARGON2_CONFIG, DEFAULT_PASSWORD_POLICY, RateLimiter, ipRateLimiter, emailRateLimiter, cleanupIntervalId;
var init_auth_service = __esm({
  "server/auth/auth-service.ts"() {
    "use strict";
    init_db();
    init_schema();
    databaseUrl = process.env.DATABASE_URL || "";
    dbSql = neon(databaseUrl);
    ARGON2_CONFIG = {
      type: argon22.argon2id,
      memoryCost: 65536,
      // 64 MB
      timeCost: 3,
      parallelism: 4,
      hashLength: 32
    };
    DEFAULT_PASSWORD_POLICY = {
      minLength: 4,
      requireUppercase: false,
      requireLowercase: false,
      requireNumbers: false,
      requireSpecialChars: false,
      rejectCommonPasswords: false,
      preventPasswordReuse: false,
      passwordHistoryCount: 5
    };
    RateLimiter = class {
      // Maximum number of buckets to prevent unbounded growth
      constructor(maxTokens, refillRate, windowMs) {
        this.maxTokens = maxTokens;
        this.refillRate = refillRate;
        this.windowMs = windowMs;
      }
      buckets = /* @__PURE__ */ new Map();
      lastCleanup = Date.now();
      cleanupInterval = 3e4;
      // Run cleanup every 30 seconds
      maxBuckets = 1e4;
      async checkLimit(key) {
        const now = Date.now();
        if (now - this.lastCleanup > this.cleanupInterval || this.buckets.size > this.maxBuckets) {
          this.cleanup();
        }
        let bucket = this.buckets.get(key);
        if (!bucket) {
          bucket = { tokens: this.maxTokens, lastRefill: now };
          this.buckets.set(key, bucket);
        }
        const timePassed = now - bucket.lastRefill;
        const tokensToAdd = Math.floor(timePassed / 1e3 * this.refillRate);
        bucket.tokens = Math.min(this.maxTokens, bucket.tokens + tokensToAdd);
        bucket.lastRefill = now;
        if (bucket.tokens > 0) {
          bucket.tokens--;
          return { allowed: true };
        }
        const tokensNeeded = 1;
        const timeToWait = tokensNeeded / this.refillRate * 1e3;
        return {
          allowed: false,
          retryAfter: Math.ceil(timeToWait / 1e3)
          // in seconds
        };
      }
      // Clean up old buckets periodically
      cleanup() {
        const now = Date.now();
        const expiry = this.windowMs * 2;
        let removed = 0;
        const entries = Array.from(this.buckets.entries());
        for (const [key, bucket] of entries) {
          if (now - bucket.lastRefill > expiry) {
            this.buckets.delete(key);
            removed++;
          }
        }
        if (this.buckets.size > this.maxBuckets) {
          const sortedEntries = entries.sort((a, b) => a[1].lastRefill - b[1].lastRefill).slice(0, this.buckets.size - this.maxBuckets);
          for (const [key] of sortedEntries) {
            this.buckets.delete(key);
            removed++;
          }
        }
        this.lastCleanup = now;
        if (removed > 0) {
          console.log(`[RateLimiter] Cleaned up ${removed} old buckets, ${this.buckets.size} remaining`);
        }
      }
      // Get current bucket count for monitoring
      getBucketCount() {
        return this.buckets.size;
      }
    };
    ipRateLimiter = new RateLimiter(10, 0.17, 6e4);
    emailRateLimiter = new RateLimiter(5, 0.017, 3e5);
    cleanupIntervalId = null;
    if (!cleanupIntervalId) {
      cleanupIntervalId = setInterval(() => {
        ipRateLimiter.cleanup();
        emailRateLimiter.cleanup();
        if (Math.random() < 0.1) {
          console.log(`[RateLimiter] IP buckets: ${ipRateLimiter.getBucketCount()}, Email buckets: ${emailRateLimiter.getBucketCount()}`);
        }
      }, 6e4);
    }
    process.on("SIGINT", () => {
      if (cleanupIntervalId) {
        clearInterval(cleanupIntervalId);
        cleanupIntervalId = null;
      }
      process.exit(0);
    });
    process.on("SIGTERM", () => {
      if (cleanupIntervalId) {
        clearInterval(cleanupIntervalId);
        cleanupIntervalId = null;
      }
      process.exit(0);
    });
  }
});

// server/utils/response-utils.ts
function sendSuccess(res, data, message, statusCode = 200) {
  const response = {
    success: true
  };
  if (data !== void 0) {
    response.data = data;
  }
  if (message) {
    response.message = message;
  }
  return res.status(statusCode).json(response);
}
function sendError(res, error, statusCode = 500, code, details) {
  const response = {
    success: false,
    error
  };
  if (code) {
    response.code = code;
  }
  if (details) {
    response.details = details;
  }
  return res.status(statusCode).json(response);
}
var ErrorResponses;
var init_response_utils = __esm({
  "server/utils/response-utils.ts"() {
    "use strict";
    ErrorResponses = {
      unauthorized: (res, message = "Authentication required") => sendError(res, message, 401, "UNAUTHORIZED"),
      forbidden: (res, message = "Access denied") => sendError(res, message, 403, "FORBIDDEN"),
      notFound: (res, resource = "Resource") => sendError(res, `${resource} not found`, 404, "NOT_FOUND"),
      badRequest: (res, message, details) => sendError(res, message, 400, "BAD_REQUEST", details),
      internalError: (res, message = "An error occurred", error) => {
        console.error("Internal server error:", error);
        return sendError(res, message, 500, "INTERNAL_ERROR");
      },
      conflict: (res, message) => sendError(res, message, 409, "CONFLICT"),
      tooManyRequests: (res, message = "Too many requests", retryAfter) => sendError(res, message, 429, "RATE_LIMIT", { retryAfter })
    };
  }
});

// server/auth/email-service.ts
var email_service_exports = {};
__export(email_service_exports, {
  getGenericResponseTemplate: () => getGenericResponseTemplate,
  getInvitationTemplate: () => getInvitationTemplate,
  getPasswordResetTemplate: () => getPasswordResetTemplate,
  sendEmail: () => sendEmail,
  sendGenericResponseEmail: () => sendGenericResponseEmail,
  sendInvitationEmail: () => sendInvitationEmail,
  sendPasswordResetEmail: () => sendPasswordResetEmail
});
import sgMail2 from "@sendgrid/mail";
function getPasswordResetTemplate(resetUrl) {
  const subject = "Password Reset Request - LoanServe Pro";
  const html = `
    <!DOCTYPE html>
    <html>
    <head>
      <meta charset="utf-8">
      <style>
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif; line-height: 1.6; color: #333; }
        .container { max-width: 600px; margin: 0 auto; padding: 20px; }
        .header { background: #2563eb; color: white; padding: 20px; text-align: center; border-radius: 8px 8px 0 0; }
        .content { background: #f9fafb; padding: 30px; border: 1px solid #e5e7eb; border-radius: 0 0 8px 8px; }
        .button { display: inline-block; padding: 12px 24px; background: #2563eb; color: white; text-decoration: none; border-radius: 6px; margin: 20px 0; }
        .warning { background: #fef2f2; border: 1px solid #fecaca; padding: 12px; border-radius: 6px; margin: 20px 0; }
        .footer { margin-top: 30px; padding-top: 20px; border-top: 1px solid #e5e7eb; font-size: 0.875rem; color: #6b7280; }
      </style>
    </head>
    <body>
      <div class="container">
        <div class="header">
          <h1>Password Reset Request</h1>
        </div>
        <div class="content">
          <p>We received a request to reset the password for your LoanServe Pro account.</p>
          
          <p>If you made this request, click the button below to reset your password:</p>
          
          <div style="text-align: center;">
            <a href="${resetUrl}" class="button">Reset Password</a>
          </div>
          
          <p style="font-size: 0.875rem; color: #6b7280;">
            Or copy and paste this link in your browser:<br>
            <code style="background: #f3f4f6; padding: 4px; border-radius: 4px; word-break: break-all;">${resetUrl}</code>
          </p>
          
          <div class="warning">
            <strong>\u26A0\uFE0F Important:</strong>
            <ul style="margin: 8px 0;">
              <li>This link will expire in 1 hour</li>
              <li>The link can only be used once</li>
              <li>All your active sessions will be terminated after resetting your password</li>
            </ul>
          </div>
          
          <p>If you did not request a password reset, please ignore this email. Your password will remain unchanged.</p>
          
          <div class="footer">
            <p>This is an automated message from LoanServe Pro. Please do not reply to this email.</p>
            <p>For security reasons, we never include your account details in emails.</p>
          </div>
        </div>
      </div>
    </body>
    </html>
  `;
  const text2 = `
Password Reset Request - LoanServe Pro

We received a request to reset the password for your LoanServe Pro account.

If you made this request, visit the following link to reset your password:
${resetUrl}

Important:
- This link will expire in 1 hour
- The link can only be used once
- All your active sessions will be terminated after resetting your password

If you did not request a password reset, please ignore this email. Your password will remain unchanged.

This is an automated message from LoanServe Pro. Please do not reply to this email.
For security reasons, we never include your account details in emails.
  `;
  return { subject, html, text: text2 };
}
function getInvitationTemplate(inviteUrl, role, expiresInDays = 7) {
  const subject = "Invitation to Join LoanServe Pro";
  const roleDisplay = {
    admin: "Administrator",
    lender: "Lender",
    borrower: "Borrower",
    investor: "Investor",
    title: "Title Officer",
    legal: "Legal Professional",
    regulator: "Regulator"
  }[role] || role;
  const html = `
    <!DOCTYPE html>
    <html>
    <head>
      <meta charset="utf-8">
      <style>
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif; line-height: 1.6; color: #333; }
        .container { max-width: 600px; margin: 0 auto; padding: 20px; }
        .header { background: #10b981; color: white; padding: 20px; text-align: center; border-radius: 8px 8px 0 0; }
        .content { background: #f9fafb; padding: 30px; border: 1px solid #e5e7eb; border-radius: 0 0 8px 8px; }
        .button { display: inline-block; padding: 12px 24px; background: #10b981; color: white; text-decoration: none; border-radius: 6px; margin: 20px 0; }
        .role-badge { display: inline-block; padding: 6px 12px; background: #dbeafe; color: #1e40af; border-radius: 4px; font-weight: 600; }
        .info-box { background: #f0f9ff; border: 1px solid #bfdbfe; padding: 16px; border-radius: 6px; margin: 20px 0; }
        .footer { margin-top: 30px; padding-top: 20px; border-top: 1px solid #e5e7eb; font-size: 0.875rem; color: #6b7280; }
      </style>
    </head>
    <body>
      <div class="container">
        <div class="header">
          <h1>Welcome to LoanServe Pro</h1>
        </div>
        <div class="content">
          <p>You've been invited to join LoanServe Pro as a <span class="role-badge">${roleDisplay}</span></p>
          
          <p>LoanServe Pro is a comprehensive mortgage loan servicing platform that helps manage the complete loan lifecycle.</p>
          
          <div class="info-box">
            <h3 style="margin-top: 0;">What you'll be able to do:</h3>
            <ul style="margin: 8px 0;">
              ${role === "admin" ? "<li>Full system administration and user management</li>" : ""}
              ${role === "lender" ? "<li>Manage loan portfolios and track performance</li>" : ""}
              ${role === "borrower" ? "<li>View your loans and make payments</li>" : ""}
              ${role === "investor" ? "<li>Monitor your investment positions and returns</li>" : ""}
              ${role === "title" ? "<li>Handle title and escrow documentation</li>" : ""}
              ${role === "legal" ? "<li>Access legal documents and compliance reports</li>" : ""}
              ${role === "regulator" ? "<li>Review compliance and audit information</li>" : ""}
              <li>Access secure document management</li>
              <li>Track real-time updates and notifications</li>
            </ul>
          </div>
          
          <p>To get started, click the button below to activate your account:</p>
          
          <div style="text-align: center;">
            <a href="${inviteUrl}" class="button">Activate Account</a>
          </div>
          
          <p style="font-size: 0.875rem; color: #6b7280;">
            Or copy and paste this link in your browser:<br>
            <code style="background: #f3f4f6; padding: 4px; border-radius: 4px; word-break: break-all;">${inviteUrl}</code>
          </p>
          
          <div style="background: #fef3c7; border: 1px solid #fcd34d; padding: 12px; border-radius: 6px; margin: 20px 0;">
            <strong>\u{1F4C5} Note:</strong> This invitation will expire in ${expiresInDays} days.
          </div>
          
          <div class="footer">
            <p>This invitation was sent from LoanServe Pro. If you believe you received this email in error, you can safely ignore it.</p>
            <p>Need help? Contact your system administrator.</p>
          </div>
        </div>
      </div>
    </body>
    </html>
  `;
  const text2 = `
Welcome to LoanServe Pro

You've been invited to join LoanServe Pro as a ${roleDisplay}.

LoanServe Pro is a comprehensive mortgage loan servicing platform that helps manage the complete loan lifecycle.

To get started, visit the following link to activate your account:
${inviteUrl}

Note: This invitation will expire in ${expiresInDays} days.

This invitation was sent from LoanServe Pro. If you believe you received this email in error, you can safely ignore it.

Need help? Contact your system administrator.
  `;
  return { subject, html, text: text2 };
}
function getGenericResponseTemplate() {
  const subject = "Request Received - LoanServe Pro";
  const html = `
    <!DOCTYPE html>
    <html>
    <head>
      <meta charset="utf-8">
      <style>
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif; line-height: 1.6; color: #333; }
        .container { max-width: 600px; margin: 0 auto; padding: 20px; }
        .header { background: #6b7280; color: white; padding: 20px; text-align: center; border-radius: 8px 8px 0 0; }
        .content { background: #f9fafb; padding: 30px; border: 1px solid #e5e7eb; border-radius: 0 0 8px 8px; }
        .footer { margin-top: 30px; padding-top: 20px; border-top: 1px solid #e5e7eb; font-size: 0.875rem; color: #6b7280; }
      </style>
    </head>
    <body>
      <div class="container">
        <div class="header">
          <h1>Request Received</h1>
        </div>
        <div class="content">
          <p>We have received your request.</p>
          
          <p>If an account exists with the provided email address, you will receive further instructions shortly.</p>
          
          <p>Please check your email inbox (and spam folder) for any messages from LoanServe Pro.</p>
          
          <div class="footer">
            <p>This is an automated message from LoanServe Pro. Please do not reply to this email.</p>
            <p>For security reasons, we cannot confirm whether an account exists with the provided email address.</p>
          </div>
        </div>
      </div>
    </body>
    </html>
  `;
  const text2 = `
Request Received - LoanServe Pro

We have received your request.

If an account exists with the provided email address, you will receive further instructions shortly.

Please check your email inbox (and spam folder) for any messages from LoanServe Pro.

This is an automated message from LoanServe Pro. Please do not reply to this email.
For security reasons, we cannot confirm whether an account exists with the provided email address.
  `;
  return { subject, html, text: text2 };
}
async function sendEmail(to, template, actorUserId) {
  try {
    console.log(`[EMAIL] Sending to ${to}: ${template.subject}`);
    if (!process.env.SENDGRID_API_KEY || !process.env.SENDGRID_FROM_EMAIL) {
      console.warn("[EMAIL] SendGrid not configured, logging email instead");
      console.log("--- EMAIL CONTENT ---");
      console.log("To:", to);
      console.log("Subject:", template.subject);
      console.log("Text:", template.text.substring(0, 200) + "...");
      console.log("--- END EMAIL ---");
      return true;
    }
    const fromEmail = process.env.SENDGRID_FROM_EMAIL.trim();
    console.log(`[EMAIL DEBUG] Raw FROM email: "${process.env.SENDGRID_FROM_EMAIL}"`);
    console.log(`[EMAIL DEBUG] Trimmed FROM email: "${fromEmail}"`);
    console.log(`[EMAIL DEBUG] FROM email length: ${fromEmail.length}`);
    const cleanFromEmail = fromEmail.replace(/\s+/g, "");
    const msg = {
      to: to.trim(),
      from: cleanFromEmail,
      subject: template.subject,
      text: template.text,
      html: template.html
    };
    console.log(`[EMAIL DEBUG] Cleaned FROM email: "${cleanFromEmail}"`);
    try {
      const [response] = await sgMail2.send(msg);
      console.log(`[EMAIL] \u2705 Successfully sent email to ${to}`);
      console.log(`[EMAIL] SendGrid Response Status: ${response.statusCode}`);
      console.log(`[EMAIL] Message ID: ${response.headers["x-message-id"]}`);
    } catch (sendError9) {
      console.error("[EMAIL] \u274C SendGrid error:", sendError9?.response?.body || sendError9);
      if (process.env.NODE_ENV === "development") {
        console.log("--- EMAIL CONTENT (SendGrid failed) ---");
        console.log("To:", to);
        console.log("From:", process.env.SENDGRID_FROM_EMAIL);
        console.log("Subject:", template.subject);
        console.log("Text:", template.text.substring(0, 200) + "...");
        console.log("--- END EMAIL ---");
      }
      console.warn("[EMAIL] Email send failed but continuing");
    }
    return true;
  } catch (error) {
    console.error("Email send error:", error);
    return false;
  }
}
function getBaseUrl() {
  const baseUrl = process.env.BASE_URL || process.env.REPLIT_DEV_DOMAIN ? `https://${process.env.REPLIT_DEV_DOMAIN}` : "https://mortgage-servicing-serinova1.replit.app";
  console.log(`[EMAIL] Determined base URL: ${baseUrl}`);
  return baseUrl;
}
async function sendPasswordResetEmail(email, token) {
  const baseUrl = getBaseUrl();
  const resetUrl = `${baseUrl}/reset-password?token=${encodeURIComponent(token)}`;
  const template = getPasswordResetTemplate(resetUrl);
  return sendEmail(email, template);
}
async function sendInvitationEmail(email, token, role, invitedBy) {
  const baseUrl = getBaseUrl();
  const inviteUrl = `${baseUrl}/activate?token=${encodeURIComponent(token)}`;
  console.log(`[EMAIL] Using base URL: ${baseUrl}`);
  const template = getInvitationTemplate(inviteUrl, role);
  return sendEmail(email, template, invitedBy);
}
async function sendGenericResponseEmail(email) {
  const template = getGenericResponseTemplate();
  return sendEmail(email, template);
}
var init_email_service = __esm({
  "server/auth/email-service.ts"() {
    "use strict";
    if (process.env.SENDGRID_API_KEY) {
      sgMail2.setApiKey(process.env.SENDGRID_API_KEY);
    }
  }
});

// server/auth/policy-engine.ts
import { eq as eq9, sql as sql8 } from "drizzle-orm";
async function resolveUserPermissions(userId) {
  const user = await db.select({
    id: users.id,
    username: users.username,
    email: users.email
  }).from(users).where(eq9(users.id, userId)).limit(1);
  if (!user.length) {
    throw new Error(`User ${userId} not found`);
  }
  const userRolesData = await db.select({
    roleId: userRoles.roleId,
    roleName: roles.name
  }).from(userRoles).innerJoin(roles, eq9(userRoles.roleId, roles.id)).where(eq9(userRoles.userId, userId));
  const roleNames = userRolesData.map((r) => r.roleName);
  const roleIds = userRolesData.map((r) => r.roleId);
  let userPermissions = [];
  const hasAdminRole = roleNames.includes("admin");
  if (hasAdminRole) {
    userPermissions = [
      "Users",
      "Loans",
      "Payments",
      "Escrow",
      "Investor Positions",
      "Reports",
      "Settings",
      "Audit Logs"
    ].map((resource) => ({
      resource,
      level: "admin",
      scope: null
    }));
  } else {
    if (roleIds.length > 0) {
      const perms = await db.execute(sql8`
        WITH merged_permissions AS (
          SELECT 
            p.resource,
            -- Get the highest permission level using CASE for ordering
            MAX(CASE 
              WHEN p.level = 'admin' THEN 3
              WHEN p.level = 'write' THEN 2
              WHEN p.level = 'read' THEN 1
              ELSE 0
            END) as level_rank,
            -- Get the actual level name for the highest permission
            CASE MAX(CASE 
              WHEN p.level = 'admin' THEN 3
              WHEN p.level = 'write' THEN 2
              WHEN p.level = 'read' THEN 1
              ELSE 0
            END)
              WHEN 3 THEN 'admin'
              WHEN 2 THEN 'write'
              WHEN 1 THEN 'read'
              ELSE 'none'
            END as level,
            -- Aggregate all scopes into a JSON array, then merge them
            COALESCE(
              jsonb_agg(rp.scope) FILTER (WHERE rp.scope IS NOT NULL),
              '[]'::jsonb
            ) as scopes
          FROM role_permissions rp
          INNER JOIN permissions p ON rp.permission_id = p.id
          WHERE rp.role_id = ANY(${roleIds}::uuid[])
          GROUP BY p.resource
        )
        SELECT 
          resource,
          level,
          -- Merge all scope objects into one
          CASE 
            WHEN scopes = '[]'::jsonb THEN NULL
            ELSE (
              SELECT jsonb_object_agg(key, value)
              FROM (
                SELECT DISTINCT ON (key) key, kv.value
                FROM jsonb_array_elements(scopes) AS elem
                CROSS JOIN LATERAL jsonb_each(elem) AS kv(key, value)
                ORDER BY key, kv.value DESC
              ) AS merged
            )
          END as scope
        FROM merged_permissions
        ORDER BY resource
      `);
      userPermissions = perms.rows || [];
    }
  }
  const mergedPermissions = userPermissions.map((perm) => ({
    resource: perm.resource,
    level: perm.level,
    scope: perm.scope
  }));
  return {
    userId: user[0].id,
    username: user[0].username,
    email: user[0].email,
    roles: roleNames,
    permissions: mergedPermissions,
    isAdmin: roleNames.includes("admin")
  };
}
function hasPermission(policy, resource, requiredLevel) {
  if (policy.isAdmin) return true;
  const permission = policy.permissions.find((p) => p.resource === resource);
  if (!permission) return false;
  const userLevel = permissionHierarchy[permission.level];
  const required = permissionHierarchy[requiredLevel];
  return userLevel >= required;
}
function hasRowLevelRestrictions(policy, resource) {
  const permission = policy.permissions.find((p) => p.resource === resource);
  if (!permission?.scope?.own_records_only) {
    return { restricted: false };
  }
  return {
    restricted: true,
    scope: permission.scope
  };
}
function buildRowLevelFilter(policy, resource, tableName) {
  const restriction = hasRowLevelRestrictions(policy, resource);
  if (!restriction.restricted) {
    return null;
  }
  if (policy.roles.includes("borrower")) {
    if (tableName === "loans") {
      return { borrowerId: policy.userId };
    }
    if (tableName === "payments") {
      return { borrowerId: policy.userId };
    }
  }
  if (policy.roles.includes("investor")) {
    if (tableName === "investor_positions") {
      return { investorId: policy.userId };
    }
    if (tableName === "investor_distributions") {
      return { investorId: policy.userId };
    }
  }
  return null;
}
async function logPermissionCheck(userId, resource, action, allowed, details = {}) {
  try {
    await db.insert(authEvents).values({
      actorUserId: userId,
      eventType: allowed ? "permission_granted" : "permission_denied",
      details: {
        resource,
        action,
        allowed,
        ...details
      },
      eventKey: `${userId}-${resource}-${action}-${Date.now()}`
    });
  } catch (error) {
    console.error("Failed to log permission check:", error);
  }
}
function getResourceForRoute(route) {
  for (const [resource, config] of Object.entries(ResourceRegistry)) {
    if (config.routes.some((r) => route.startsWith(r))) {
      return resource;
    }
  }
  return null;
}
async function getCachedUserPolicy(userId) {
  const cached = policyCache.get(userId);
  if (cached && Date.now() - cached.timestamp < CACHE_TTL) {
    return cached.policy;
  }
  const policy = await resolveUserPermissions(userId);
  policyCache.set(userId, { policy, timestamp: Date.now() });
  return policy;
}
var ResourceRegistry, PermissionLevel, permissionHierarchy, PIIMasker, policyCache, CACHE_TTL;
var init_policy_engine = __esm({
  "server/auth/policy-engine.ts"() {
    "use strict";
    init_db();
    init_schema();
    ResourceRegistry = {
      "Users and Roles": {
        routes: ["/api/admin/users", "/api/admin/roles"],
        tables: ["users", "roles", "user_roles"]
      },
      "Loans": {
        routes: ["/api/loans"],
        tables: ["loans", "loan_fees", "loan_ledger"]
      },
      "Payments and Allocations": {
        routes: ["/api/payments"],
        tables: ["payments", "payment_allocations"]
      },
      "Escrow and Disbursements": {
        routes: ["/api/escrow"],
        tables: ["escrow_accounts", "escrow_transactions", "escrow_disbursements"]
      },
      "Investor Positions and Distributions": {
        routes: ["/api/investors"],
        tables: ["investor_positions", "investor_distributions"]
      },
      "Reports": {
        routes: ["/api/reports"],
        tables: []
      },
      "Settings": {
        routes: ["/api/settings"],
        tables: ["system_settings"]
      },
      "Audit Logs": {
        routes: ["/api/audit"],
        tables: ["audit_logs", "auth_events"]
      }
    };
    PermissionLevel = /* @__PURE__ */ ((PermissionLevel2) => {
      PermissionLevel2["None"] = "none";
      PermissionLevel2["Read"] = "read";
      PermissionLevel2["Write"] = "write";
      PermissionLevel2["Admin"] = "admin";
      return PermissionLevel2;
    })(PermissionLevel || {});
    permissionHierarchy = {
      ["none" /* None */]: 0,
      ["read" /* Read */]: 1,
      ["write" /* Write */]: 2,
      ["admin" /* Admin */]: 3
    };
    PIIMasker = {
      /**
       * Mask email address - show first letter and domain only
       */
      maskEmail(email) {
        if (!email || !email.includes("@")) return email;
        const [local, domain] = email.split("@");
        return `${local[0]}***@${domain}`;
      },
      /**
       * Mask phone number - show area code only
       */
      maskPhone(phone) {
        if (!phone) return phone;
        const cleaned = phone.replace(/\D/g, "");
        if (cleaned.length < 10) return "***-***-****";
        return `${cleaned.substring(0, 3)}-***-****`;
      },
      /**
       * Mask SSN - show last 4 digits only
       */
      maskSSN(ssn) {
        if (!ssn) return ssn;
        const cleaned = ssn.replace(/\D/g, "");
        if (cleaned.length !== 9) return "***-**-****";
        return `***-**-${cleaned.substring(5)}`;
      },
      /**
       * Mask address - show city and state only
       */
      maskAddress(address) {
        if (!address) return address;
        return {
          ...address,
          address: "***",
          address_2: "***",
          zip_code: address.zip_code ? address.zip_code.substring(0, 3) + "**" : null
        };
      },
      /**
       * Apply PII masking to an object based on policy
       */
      applyMasking(data, policy, resource) {
        const permission = policy.permissions.find((p) => p.resource === resource);
        if (!permission?.scope?.pii_masked) {
          return data;
        }
        const masked = JSON.parse(JSON.stringify(data));
        if (masked.email) masked.email = this.maskEmail(masked.email);
        if (masked.phone) masked.phone = this.maskPhone(masked.phone);
        if (masked.mobile_phone) masked.mobile_phone = this.maskPhone(masked.mobile_phone);
        if (masked.ssn) masked.ssn = this.maskSSN(masked.ssn);
        if (masked.date_of_birth) masked.date_of_birth = null;
        if (masked.address || masked.city || masked.state) {
          masked.address = masked.address ? "***" : null;
          masked.address_2 = masked.address_2 ? "***" : null;
          masked.zip_code = masked.zip_code ? masked.zip_code.substring(0, 3) + "**" : null;
        }
        if (masked.bank_account_number) masked.bank_account_number = "****" + masked.bank_account_number.slice(-4);
        if (masked.routing_number) masked.routing_number = "****" + masked.routing_number.slice(-4);
        return masked;
      },
      /**
       * Apply masking to an array of objects
       */
      applyMaskingToArray(data, policy, resource) {
        return data.map((item) => this.applyMasking(item, policy, resource));
      }
    };
    policyCache = /* @__PURE__ */ new Map();
    CACHE_TTL = 5 * 60 * 1e3;
  }
});

// server/auth/middleware.ts
async function loadUserPolicy(req, res, next) {
  try {
    if (!req.path.startsWith("/api")) {
      return next();
    }
    const userId = req.user?.id || req.session?.passport?.user || req.session?.userId;
    if (!userId) {
      return next();
    }
    const { db: db2 } = await Promise.resolve().then(() => (init_db(), db_exports));
    const { users: users2, userRoles: userRoles2, roles: roles2 } = await Promise.resolve().then(() => (init_schema(), schema_exports));
    const { eq: eq38 } = await import("drizzle-orm");
    const [user] = await db2.select().from(users2).where(eq38(users2.id, userId)).limit(1);
    if (user) {
      const userRolesList = await db2.select({
        roleName: roles2.name
      }).from(userRoles2).innerJoin(roles2, eq38(userRoles2.roleId, roles2.id)).where(eq38(userRoles2.userId, userId));
      const roleNames = userRolesList.map((r) => r.roleName);
      req.user = {
        ...user,
        roleNames,
        role: roleNames.includes("borrower") ? "borrower" : roleNames.includes("admin") ? "admin" : roleNames[0] || "user"
      };
      if (roleNames.includes("borrower")) {
        return next();
      }
      const policy = await getCachedUserPolicy(userId);
      req.userPolicy = policy;
    }
    next();
  } catch (error) {
    console.error("Failed to load user policy:", error);
    console.error("Session data:", {
      hasUser: !!req.user,
      hasSession: !!req.session,
      sessionData: req.session ? Object.keys(req.session) : [],
      userId: req.user?.id || req.session?.passport?.user || req.session?.userId
    });
    res.status(500).json({
      error: "Failed to load user permissions",
      code: "POLICY_LOAD_ERROR"
    });
  }
}
function requireAuth2(req, res, next) {
  if (!req.userPolicy) {
    res.status(401).json({
      error: "Authentication required",
      code: "AUTH_REQUIRED"
    });
    return;
  }
  next();
}
function requirePermission(resource, level) {
  return async (req, res, next) => {
    try {
      if (!req.userPolicy) {
        res.status(401).json({
          error: "Authentication required",
          code: "AUTH_REQUIRED"
        });
        return;
      }
      const allowed = hasPermission(req.userPolicy, resource, level);
      await logPermissionCheck(
        req.userPolicy.userId,
        resource,
        level,
        allowed,
        {
          method: req.method,
          path: req.path,
          ip: req.ip
        }
      );
      if (!allowed) {
        res.status(403).json({
          error: "Insufficient permissions",
          code: "PERMISSION_DENIED",
          required: { resource, level }
        });
        return;
      }
      const filter = buildRowLevelFilter(req.userPolicy, resource, getTableFromRoute(req.path));
      if (filter) {
        req.rowLevelFilter = filter;
      }
      next();
    } catch (error) {
      console.error("Permission check failed:", error);
      res.status(500).json({
        error: "Authorization check failed",
        code: "AUTH_CHECK_FAILED"
      });
    }
  };
}
function applyPIIMasking() {
  return (req, res, next) => {
    if (!req.userPolicy) {
      return next();
    }
    if (!req.userPolicy.roles.includes("regulator")) {
      return next();
    }
    const originalJson = res.json.bind(res);
    res.json = function(data) {
      const resource = getResourceForRoute(req.path);
      if (resource && data) {
        if (Array.isArray(data)) {
          data = PIIMasker.applyMaskingToArray(data, req.userPolicy, resource);
        } else if (typeof data === "object") {
          data = PIIMasker.applyMasking(data, req.userPolicy, resource);
        }
      }
      return originalJson(data);
    };
    next();
  };
}
function requireRole(...roles2) {
  return (req, res, next) => {
    if (!req.userPolicy) {
      res.status(401).json({
        error: "Authentication required",
        code: "AUTH_REQUIRED"
      });
      return;
    }
    const hasRole2 = roles2.some((role) => req.userPolicy.roles.includes(role));
    if (!hasRole2) {
      res.status(403).json({
        error: "Required role not found",
        code: "ROLE_REQUIRED",
        required: roles2
      });
      return;
    }
    next();
  };
}
async function requireBorrower(req, res, next) {
  try {
    if (!req.user) {
      res.status(401).json({
        error: "Authentication required",
        code: "AUTH_REQUIRED"
      });
      return;
    }
    const hasBorrowerRole = req.user.roleNames?.includes("borrower") || req.user.role === "borrower";
    if (!hasBorrowerRole) {
      res.status(403).json({
        error: "Borrower access required",
        code: "BORROWER_REQUIRED"
      });
      return;
    }
    const { db: db2 } = await Promise.resolve().then(() => (init_db(), db_exports));
    const { borrowerUsers: borrowerUsers2 } = await Promise.resolve().then(() => (init_schema(), schema_exports));
    const { eq: eq38 } = await import("drizzle-orm");
    const [borrowerUser] = await db2.select().from(borrowerUsers2).where(eq38(borrowerUsers2.email, req.user.email)).limit(1);
    if (!borrowerUser) {
      res.status(403).json({
        error: "Borrower profile not found",
        code: "BORROWER_PROFILE_NOT_FOUND"
      });
      return;
    }
    req.user.borrowerUserId = borrowerUser.id;
    req.user.borrowerEntityId = borrowerUser.borrowerEntityId;
    await db2.update(borrowerUsers2).set({ lastLoginAt: /* @__PURE__ */ new Date() }).where(eq38(borrowerUsers2.id, borrowerUser.id));
    next();
  } catch (error) {
    console.error("Borrower auth middleware error:", error);
    res.status(500).json({
      error: "Authentication check failed",
      code: "AUTH_CHECK_FAILED"
    });
  }
}
function getTableFromRoute(path11) {
  const parts = path11.split("/").filter((p) => p);
  if (parts.length >= 2) {
    return parts[1];
  }
  return "";
}
var init_middleware = __esm({
  "server/auth/middleware.ts"() {
    "use strict";
    init_policy_engine();
  }
});

// server/utils/api-helpers.ts
import { z as z3 } from "zod";
import { drizzle as drizzle2 } from "drizzle-orm/neon-serverless";
function sendError4(res, status, message, code, details) {
  const response = { error: message };
  if (code) response.code = code;
  if (details) response.details = details;
  console.error(`[API Error] ${status}: ${message}`, details || "");
  return res.status(status).json(response);
}
function sendSuccess3(res, data, message, status = 200) {
  const response = { success: true };
  if (data !== void 0) response.data = data;
  if (message) response.message = message;
  return res.status(status).json(response);
}
function asyncHandler(fn) {
  return async (req, res, next) => {
    try {
      await fn(req, res, next);
    } catch (error) {
      console.error("[AsyncHandler] Uncaught error:", error);
      if (!res.headersSent) {
        const message = error instanceof Error ? error.message : "Internal server error";
        sendError4(res, 500, message, "INTERNAL_ERROR", error);
      }
    }
  };
}
var init_api_helpers = __esm({
  "server/utils/api-helpers.ts"() {
    "use strict";
  }
});

// server/utils/logger.ts
function createLogger(service) {
  return new Logger(service);
}
var Logger, loggers;
var init_logger = __esm({
  "server/utils/logger.ts"() {
    "use strict";
    Logger = class {
      service;
      context = {};
      constructor(service) {
        this.service = service;
      }
      setContext(context) {
        this.context = { ...this.context, ...context };
      }
      clearContext() {
        this.context = {};
      }
      formatMessage(level, message, data) {
        const timestamp2 = (/* @__PURE__ */ new Date()).toISOString();
        const contextStr = Object.keys(this.context).length > 0 ? ` [${Object.entries(this.context).map(([k, v]) => `${k}:${v}`).join(" ")}]` : "";
        const prefix = `[${this.service}]${contextStr}`;
        if (data !== void 0) {
          if (typeof data === "object") {
            return `${prefix} ${message}`;
          } else {
            return `${prefix} ${message}: ${data}`;
          }
        }
        return `${prefix} ${message}`;
      }
      log(level, message, data) {
        const formattedMessage = this.formatMessage(level, message, data);
        switch (level) {
          case "error" /* ERROR */:
            if (data && typeof data === "object") {
              console.error(formattedMessage, data);
            } else {
              console.error(formattedMessage);
            }
            break;
          case "warn" /* WARN */:
            if (data && typeof data === "object") {
              console.warn(formattedMessage, data);
            } else {
              console.warn(formattedMessage);
            }
            break;
          case "debug" /* DEBUG */:
            if (process.env.DEBUG === "true") {
              if (data && typeof data === "object") {
                console.log(formattedMessage, data);
              } else {
                console.log(formattedMessage);
              }
            }
            break;
          case "info" /* INFO */:
          default:
            if (data && typeof data === "object") {
              console.log(formattedMessage, data);
            } else {
              console.log(formattedMessage);
            }
            break;
        }
      }
      error(message, error) {
        if (error instanceof Error) {
          this.log("error" /* ERROR */, message, {
            name: error.name,
            message: error.message,
            stack: error.stack
          });
        } else {
          this.log("error" /* ERROR */, message, error);
        }
      }
      warn(message, data) {
        this.log("warn" /* WARN */, message, data);
      }
      info(message, data) {
        this.log("info" /* INFO */, message, data);
      }
      debug(message, data) {
        this.log("debug" /* DEBUG */, message, data);
      }
      // Request-specific logging
      logRequest(req, message, data) {
        const requestContext = {
          method: req.method,
          path: req.path,
          ip: req.ip,
          userId: req.user?.id || "anonymous"
        };
        const prevContext = this.context;
        this.setContext(requestContext);
        this.info(message, data);
        this.context = prevContext;
      }
      // Performance logging
      startTimer(label) {
        const start = Date.now();
        return () => {
          const duration = Date.now() - start;
          this.info(`${label} completed`, { durationMs: duration });
        };
      }
      // Structured error logging
      logError(error, context) {
        const errorData = {
          context,
          name: error?.name || "UnknownError",
          message: error?.message || "Unknown error occurred",
          stack: error?.stack,
          code: error?.code,
          ...this.context
        };
        this.error(`Error in ${context || "unknown context"}`, errorData);
      }
      // Batch operation logging
      logBatch(operation, total, processed, failed) {
        const successRate = total > 0 ? ((processed - (failed || 0)) / total * 100).toFixed(2) : "0";
        this.info(`Batch ${operation} completed`, {
          total,
          processed,
          failed: failed || 0,
          successRate: `${successRate}%`
        });
      }
      // Database operation logging
      logQuery(query, params, duration) {
        if (process.env.LOG_SQL === "true") {
          this.debug("SQL Query", {
            query: query.substring(0, 500),
            // Truncate long queries
            params: params?.slice(0, 10),
            // Limit param logging
            duration: duration ? `${duration}ms` : void 0
          });
        }
      }
    };
    loggers = {
      auth: createLogger("Auth"),
      payment: createLogger("Payment"),
      escrow: createLogger("Escrow"),
      remittance: createLogger("Remittance"),
      reconciliation: createLogger("Reconciliation"),
      api: createLogger("API"),
      db: createLogger("Database"),
      rabbit: createLogger("RabbitMQ"),
      scheduler: createLogger("Scheduler"),
      document: createLogger("Document"),
      crm: createLogger("CRM"),
      cash: createLogger("CashManagement"),
      dlq: createLogger("DLQ"),
      queue: createLogger("QueueMonitor")
    };
  }
});

// server/compliance/hashChain.ts
import { createHash as createHash3 } from "crypto";
import { desc as desc8, eq as eq15 } from "drizzle-orm";
var HashChainService, hashChainService;
var init_hashChain = __esm({
  "server/compliance/hashChain.ts"() {
    "use strict";
    init_db();
    init_schema();
    HashChainService = class {
      /**
       * Generate SHA-256 hash of an object
       */
      generateHash(data) {
        const hash = createHash3("sha256");
        hash.update(JSON.stringify(data));
        return hash.digest("hex");
      }
      /**
       * Get the hash of the previous audit log entry
       */
      async getPreviousHash() {
        const lastEntry = await db.select({ recordHash: complianceAuditLog.recordHash }).from(complianceAuditLog).orderBy(desc8(complianceAuditLog.id)).limit(1);
        return lastEntry.length > 0 ? lastEntry[0].recordHash : null;
      }
      /**
       * Create a new audit log entry with hash chain
       */
      async createAuditEntry(data) {
        const prevHash = await this.getPreviousHash();
        const payloadHash = this.generateHash(data.payloadJson);
        const recordData = {
          correlationId: data.correlationId,
          actorType: data.actorType,
          actorId: data.actorId,
          eventType: data.eventType,
          resourceType: data.resourceType,
          resourceId: data.resourceId,
          payloadHash,
          prevHash,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        };
        const recordHash = this.generateHash(recordData);
        await db.insert(complianceAuditLog).values({
          correlationId: data.correlationId,
          accountId: data.accountId,
          actorType: data.actorType,
          actorId: data.actorId,
          eventType: data.eventType,
          resourceType: data.resourceType,
          resourceId: data.resourceId,
          payloadJson: data.payloadJson,
          payloadHash,
          prevHash,
          recordHash,
          ipAddr: data.ipAddr,
          userAgent: data.userAgent,
          geo: data.geo
        });
      }
      /**
       * Verify the integrity of the hash chain
       */
      async verifyChainIntegrity(startId, endId) {
        const query = db.select().from(complianceAuditLog).orderBy(complianceAuditLog.id);
        const entries = await query;
        const brokenLinks = [];
        for (let i = 1; i < entries.length; i++) {
          const current = entries[i];
          const previous = entries[i - 1];
          if (current.prevHash !== previous.recordHash) {
            brokenLinks.push({
              id: current.id,
              expected: previous.recordHash || "",
              actual: current.prevHash || ""
            });
          }
        }
        return {
          isValid: brokenLinks.length === 0,
          brokenLinks
        };
      }
      /**
       * Generate audit pack for a specific time range
       */
      async generateAuditPack(startDate, endDate) {
        const entries = await db.select().from(complianceAuditLog).where(
          eq15(complianceAuditLog.eventTsUtc, startDate)
          // This would need proper date range query
        ).orderBy(complianceAuditLog.id);
        const startHash = entries.length > 0 ? entries[0].prevHash : null;
        const endHash = entries.length > 0 ? entries[entries.length - 1].recordHash : null;
        let chainValid = true;
        for (let i = 1; i < entries.length; i++) {
          if (entries[i].prevHash !== entries[i - 1].recordHash) {
            chainValid = false;
            break;
          }
        }
        const checksum = this.generateHash({
          startDate: startDate.toISOString(),
          endDate: endDate.toISOString(),
          entryCount: entries.length,
          startHash,
          endHash,
          entries: entries.map((e) => e.recordHash)
        });
        return {
          entries,
          chainValid,
          startHash,
          endHash,
          checksum
        };
      }
    };
    hashChainService = new HashChainService();
  }
});

// server/compliance/consentManagement.ts
import { eq as eq16, and as and13, or as or6 } from "drizzle-orm";
import { v4 as uuidv42 } from "uuid";
var ConsentManagementService, consentManagementService;
var init_consentManagement = __esm({
  "server/compliance/consentManagement.ts"() {
    "use strict";
    init_db();
    init_schema();
    init_hashChain();
    ConsentManagementService = class {
      /**
       * Record user consent
       */
      async recordConsent(data) {
        const correlationId = uuidv42();
        const existing = await db.select().from(consentRecord).where(
          and13(
            eq16(consentRecord.subjectId, data.subjectId),
            eq16(consentRecord.purpose, data.purpose)
          )
        ).limit(1);
        if (existing.length > 0) {
          await db.update(consentRecord).set({
            status: "granted",
            scope: data.scope,
            channel: data.channel,
            version: data.version,
            evidenceUri: data.evidenceUri,
            locale: data.locale || "en-US",
            tsGrantedUtc: /* @__PURE__ */ new Date(),
            updatedAt: /* @__PURE__ */ new Date()
          }).where(eq16(consentRecord.id, existing[0].id));
        } else {
          await db.insert(consentRecord).values({
            subjectId: data.subjectId,
            purpose: data.purpose,
            scope: data.scope,
            status: "granted",
            channel: data.channel,
            version: data.version,
            evidenceUri: data.evidenceUri,
            locale: data.locale || "en-US",
            tsGrantedUtc: /* @__PURE__ */ new Date()
          });
        }
        await hashChainService.createAuditEntry({
          correlationId,
          actorType: "user",
          actorId: data.subjectId,
          eventType: "CONSENT.GRANTED",
          resourceType: "consent",
          resourceId: data.subjectId,
          payloadJson: {
            purpose: data.purpose,
            scope: data.scope,
            version: data.version
          }
        });
      }
      /**
       * Revoke user consent
       */
      async revokeConsent(subjectId, purpose) {
        const correlationId = uuidv42();
        await db.update(consentRecord).set({
          status: "revoked",
          tsRevokedUtc: /* @__PURE__ */ new Date(),
          updatedAt: /* @__PURE__ */ new Date()
        }).where(
          and13(
            eq16(consentRecord.subjectId, subjectId),
            eq16(consentRecord.purpose, purpose)
          )
        );
        await hashChainService.createAuditEntry({
          correlationId,
          actorType: "user",
          actorId: subjectId,
          eventType: "CONSENT.REVOKED",
          resourceType: "consent",
          resourceId: subjectId,
          payloadJson: {
            purpose,
            revokedAt: (/* @__PURE__ */ new Date()).toISOString()
          }
        });
      }
      /**
       * Check if user has given consent for a purpose
       */
      async hasConsent(subjectId, purpose) {
        const consent = await db.select().from(consentRecord).where(
          and13(
            eq16(consentRecord.subjectId, subjectId),
            eq16(consentRecord.purpose, purpose),
            eq16(consentRecord.status, "granted")
          )
        ).limit(1);
        return consent.length > 0;
      }
      /**
       * Get all consents for a subject
       */
      async getSubjectConsents(subjectId) {
        return await db.select().from(consentRecord).where(eq16(consentRecord.subjectId, subjectId));
      }
      /**
       * Update communication preferences
       */
      async updateCommunicationPreference(data) {
        const correlationId = uuidv42();
        const existing = await db.select().from(communicationPreference).where(
          and13(
            eq16(communicationPreference.subjectId, data.subjectId),
            eq16(communicationPreference.channel, data.channel),
            eq16(communicationPreference.topic, data.topic)
          )
        ).limit(1);
        if (existing.length > 0) {
          await db.update(communicationPreference).set({
            allowed: data.allowed,
            frequency: data.frequency,
            lastUpdatedBy: data.updatedBy,
            updatedAt: /* @__PURE__ */ new Date()
          }).where(eq16(communicationPreference.id, existing[0].id));
        } else {
          await db.insert(communicationPreference).values({
            subjectId: data.subjectId,
            channel: data.channel,
            topic: data.topic,
            allowed: data.allowed,
            frequency: data.frequency,
            lastUpdatedBy: data.updatedBy
          });
        }
        await hashChainService.createAuditEntry({
          correlationId,
          actorType: "user",
          actorId: data.updatedBy,
          eventType: "PREFERENCE.UPDATED",
          resourceType: "communication_preference",
          resourceId: data.subjectId,
          payloadJson: data
        });
      }
      /**
       * Check if communication is allowed
       */
      async isCommunicationAllowed(subjectId, channel, topic) {
        const preference = await db.select().from(communicationPreference).where(
          and13(
            eq16(communicationPreference.subjectId, subjectId),
            eq16(communicationPreference.channel, channel),
            eq16(communicationPreference.topic, topic)
          )
        ).limit(1);
        return preference.length === 0 || preference[0].allowed;
      }
      /**
       * Create a DSAR (Data Subject Access Request)
       */
      async createDSAR(data) {
        const correlationId = uuidv42();
        const caseRef = `DSAR-${Date.now()}`;
        const dueDate = /* @__PURE__ */ new Date();
        dueDate.setDate(dueDate.getDate() + 30);
        const result = await db.insert(dataSubjectRequest).values({
          subjectId: data.subjectId,
          type: data.type,
          status: "received",
          submittedVia: data.submittedVia,
          dueAt: dueDate,
          detailsJson: data.detailsJson,
          caseRef
        }).returning();
        await hashChainService.createAuditEntry({
          correlationId,
          actorType: "user",
          actorId: data.subjectId,
          eventType: "DSAR.CREATED",
          resourceType: "dsar",
          resourceId: result[0].id,
          payloadJson: {
            type: data.type,
            caseRef,
            dueDate: dueDate.toISOString()
          }
        });
        return result[0].id;
      }
      /**
       * Update DSAR status
       */
      async updateDSARStatus(dsarId, status, updatedBy) {
        const correlationId = uuidv42();
        const updateData = { status };
        if (status === "completed" || status === "rejected") {
          updateData.closedAt = /* @__PURE__ */ new Date();
        }
        await db.update(dataSubjectRequest).set(updateData).where(eq16(dataSubjectRequest.id, dsarId));
        await hashChainService.createAuditEntry({
          correlationId,
          actorType: "user",
          actorId: updatedBy,
          eventType: "DSAR.STATUS_UPDATED",
          resourceType: "dsar",
          resourceId: dsarId,
          payloadJson: {
            status,
            updatedBy,
            updatedAt: (/* @__PURE__ */ new Date()).toISOString()
          }
        });
      }
      /**
       * Get pending DSARs
       */
      async getPendingDSARs() {
        return await db.select().from(dataSubjectRequest).where(
          or6(
            eq16(dataSubjectRequest.status, "received"),
            eq16(dataSubjectRequest.status, "in_progress")
          )
        );
      }
    };
    consentManagementService = new ConsentManagementService();
  }
});

// server/observability/prometheus-metrics.ts
import client from "prom-client";
var register, mqPublishTotal, mqConsumeTotal;
var init_prometheus_metrics = __esm({
  "server/observability/prometheus-metrics.ts"() {
    "use strict";
    register = new client.Registry();
    client.collectDefaultMetrics({ register });
    mqPublishTotal = new client.Counter({
      name: "mq_publish_total",
      help: "Messages published",
      labelNames: ["exchange", "routing_key"]
    });
    mqConsumeTotal = new client.Counter({
      name: "mq_consume_total",
      help: "Messages consumed",
      labelNames: ["queue"]
    });
    register.registerMetric(mqPublishTotal);
    register.registerMetric(mqConsumeTotal);
  }
});

// server/services/rabbitmq-unified.ts
var rabbitmq_unified_exports = {};
__export(rabbitmq_unified_exports, {
  RabbitMQClient: () => RabbitMQClient,
  publishJSON: () => publishJSON,
  rabbitmqClient: () => rabbitmqClient
});
import amqplib from "amqplib";
import os from "os";
async function publishJSON(exchange, routingKey, payload, options) {
  await rabbitmqClient.publishJSON(exchange, routingKey, payload, options);
}
var RabbitMQClient, rabbitmqClient;
var init_rabbitmq_unified = __esm({
  "server/services/rabbitmq-unified.ts"() {
    "use strict";
    init_prometheus_metrics();
    RabbitMQClient = class _RabbitMQClient {
      static _instance = null;
      conn = null;
      publisherChannel = null;
      consumerChannels = /* @__PURE__ */ new Map();
      reconnecting = false;
      reconnectAttempts = 0;
      maxReconnectAttempts;
      heartbeat;
      url;
      // Connection tracking metrics
      connectionStartTime = 0;
      totalReconnects = 0;
      isBlocked = false;
      constructor() {
        this.url = process.env.CLOUDAMQP_URL || "";
        this.heartbeat = Number(process.env.RABBITMQ_HEARTBEAT || "30");
        this.maxReconnectAttempts = Number(process.env.RABBITMQ_MAX_RECONNECT_ATTEMPTS || "8");
        if (!this.url) {
          throw new Error("CLOUDAMQP_URL environment variable must be defined");
        }
      }
      /**
       * Returns the singleton client instance.
       */
      static getInstance() {
        if (!this._instance) {
          this._instance = new _RabbitMQClient();
          this._instance.connect().catch((err) => {
            console.error("[RabbitMQ] Initial connection failed:", err);
          });
        }
        return this._instance;
      }
      /**
       * Lazily connect to the broker. If already connected, resolves immediately.
       */
      async connect() {
        if (this.conn) return;
        const connectionName = `${process.env.SERVICE_NAME || "loanserve"}@${os.hostname()}#${process.pid}`;
        const conn = await amqplib.connect(this.url + `?heartbeat=${this.heartbeat}`, {
          clientProperties: {
            connection_name: connectionName
          }
        });
        conn.on("error", (err) => {
          console.error("[RabbitMQ] connection error:", err);
        });
        conn.on("close", () => {
          console.warn("[RabbitMQ] connection closed");
          this.conn = null;
          this.publisherChannel = null;
          this.consumerChannels.clear();
          if (!this.reconnecting) {
            this.scheduleReconnect();
          }
        });
        conn.on("blocked", (reason) => {
          console.warn("[RabbitMQ] connection blocked:", reason);
          this.isBlocked = true;
        });
        conn.on("unblocked", () => {
          console.log("[RabbitMQ] connection unblocked");
          this.isBlocked = false;
        });
        this.conn = conn;
        this.connectionStartTime = Date.now();
        console.log(`[RabbitMQ] Connected as ${connectionName}`);
      }
      /**
       * Schedules a reconnection attempt with exponential backoff.
       */
      scheduleReconnect() {
        if (this.reconnecting) return;
        this.reconnecting = true;
        const attemptReconnect = async () => {
          try {
            await this.connect();
            this.reconnecting = false;
            this.reconnectAttempts = 0;
            console.log("[RabbitMQ] Reconnection successful");
          } catch (err) {
            this.reconnectAttempts++;
            if (this.reconnectAttempts >= this.maxReconnectAttempts) {
              console.error(`[RabbitMQ] max reconnect attempts (${this.maxReconnectAttempts}) reached; giving up`);
              this.reconnecting = false;
              return;
            }
            const delay = Math.min(1e3 * Math.pow(1.5, this.reconnectAttempts), 6e4);
            console.warn(`[RabbitMQ] reconnect attempt ${this.reconnectAttempts} failed; retrying in ${delay}ms`);
            setTimeout(attemptReconnect, delay);
          }
        };
        setTimeout(attemptReconnect, 0);
      }
      /**
       * Lazily create or return the confirm channel used for publishing.
       */
      async getPublisherChannel() {
        if (this.publisherChannel) return this.publisherChannel;
        await this.connect();
        const channel = await this.conn.createConfirmChannel();
        channel.on("error", (err) => {
          console.error("[RabbitMQ] publisher channel error:", err);
          this.publisherChannel = null;
        });
        channel.on("close", () => {
          console.warn("[RabbitMQ] publisher channel closed");
          this.publisherChannel = null;
        });
        this.publisherChannel = channel;
        return channel;
      }
      /**
       * Publish a message to an exchange with routing key.
       * Waits for publisher confirm or rejects on error.
       */
      async publish(exchange, routingKey, content, options) {
        const ch = await this.getPublisherChannel();
        try {
          mqPublishTotal.inc({ exchange, routing_key: routingKey });
        } catch (error) {
          console.warn("[RabbitMQ] Failed to increment publish metric:", error);
        }
        await new Promise((resolve, reject) => {
          ch.publish(
            exchange,
            routingKey,
            content,
            {
              persistent: true,
              mandatory: true,
              ...options
            },
            (err) => err ? reject(err) : resolve()
          );
        });
      }
      /**
       * Publish JSON payload to an exchange with routing key.
       */
      async publishJSON(exchange, routingKey, payload, options) {
        const buffer = Buffer.from(JSON.stringify(payload));
        await this.publish(exchange, routingKey, buffer, {
          contentType: "application/json",
          ...options
        });
      }
      /**
       * Lazily create or return a channel for a consumer.
       * Each consumerTag gets its own channel with prefetch.
       */
      async getConsumerChannel(consumerTag, prefetch) {
        const existing = this.consumerChannels.get(consumerTag);
        if (existing) return existing;
        await this.connect();
        const ch = await this.conn.createChannel();
        const pCount = prefetch ?? Number(process.env.RABBITMQ_PREFETCH || "10");
        await ch.prefetch(pCount);
        ch.on("error", (err) => {
          console.error(`[RabbitMQ] consumer channel (${consumerTag}) error:`, err);
          this.consumerChannels.delete(consumerTag);
        });
        ch.on("close", () => {
          console.warn(`[RabbitMQ] consumer channel (${consumerTag}) closed`);
          this.consumerChannels.delete(consumerTag);
        });
        this.consumerChannels.set(consumerTag, ch);
        return ch;
      }
      /**
       * Start consuming messages from a queue.
       *
       * The handler is called with the raw ConsumeMessage and the parsed JSON body.
       * It should return a Promise; if it throws, the message is nacked without requeue.
       */
      async consume(queue, handler, opts) {
        const tag = opts?.consumerTag ?? queue;
        const ch = await this.getConsumerChannel(tag, opts?.prefetch);
        const { consumerTag } = await ch.consume(
          queue,
          async (msg) => {
            if (!msg) return;
            try {
              mqConsumeTotal.inc({ queue });
            } catch (error) {
              console.warn("[RabbitMQ] Failed to increment consume metric:", error);
            }
            try {
              const body = JSON.parse(msg.content.toString());
              await handler(body, msg, ch);
              if (!opts?.noAck) ch.ack(msg);
            } catch (err) {
              console.error(`[RabbitMQ] error handling message on ${queue}:`, err);
              ch.nack(msg, false, false);
            }
          },
          {
            noAck: opts?.noAck ?? false,
            exclusive: opts?.exclusive ?? false,
            consumerTag: tag
          }
        );
        return consumerTag;
      }
      /**
       * Cancel an active consumer by tag.
       */
      async cancelConsumer(tag) {
        const ch = this.consumerChannels.get(tag);
        if (ch) {
          try {
            await ch.cancel(tag);
            await ch.close();
          } catch (err) {
            console.error(`[RabbitMQ] error cancelling consumer (${tag}):`, err);
          }
          this.consumerChannels.delete(tag);
        }
      }
      /**
       * Create an admin channel for one-off operations like queue management.
       */
      async withAdminChannel(operation) {
        await this.connect();
        const ch = await this.conn.createChannel();
        try {
          return await operation(ch);
        } finally {
          await ch.close();
        }
      }
      /**
       * Get connection statistics.
       */
      getConnectionStats() {
        return {
          connected: !!this.conn,
          publisherChannelActive: !!this.publisherChannel,
          consumerChannels: this.consumerChannels.size,
          reconnecting: this.reconnecting,
          reconnectAttempts: this.reconnectAttempts
        };
      }
      /**
       * Get connection information for monitoring/debugging.
       */
      async getConnectionInfo() {
        if (!this.conn && !this.reconnecting) {
          try {
            await this.connect();
          } catch (error) {
            console.error("[RabbitMQ] Connection attempt failed during monitoring check:", error);
          }
        }
        return {
          connected: !!this.conn,
          reconnectAttempts: this.reconnectAttempts,
          totalReconnects: this.totalReconnects,
          publisherConnected: !!this.publisherChannel,
          consumerConnected: this.consumerChannels.size > 0,
          activeConsumers: this.consumerChannels.size,
          uptime: this.connectionStartTime ? Date.now() - this.connectionStartTime : 0,
          isBlocked: this.isBlocked
        };
      }
      /**
       * Get queue statistics for monitoring
       */
      async getQueueStats(queueName) {
        try {
          await this.connect();
          const ch = await this.conn.createChannel();
          try {
            const queueInfo = await ch.checkQueue(queueName);
            return {
              queue: queueName,
              messageCount: queueInfo.messageCount,
              consumerCount: queueInfo.consumerCount
            };
          } finally {
            try {
              await ch.close();
            } catch (closeError) {
              console.error("[RabbitMQ] Error closing stats channel:", closeError);
            }
          }
        } catch (error) {
          console.error(`[RabbitMQ] Failed to get queue stats for ${queueName}:`, error);
          return null;
        }
      }
      /**
       * Get DLQ channel for Dead Letter Queue operations
       */
      async getDLQChannel() {
        try {
          await this.connect();
          return await this.conn.createChannel();
        } catch (error) {
          console.error("[RabbitMQ] Failed to create DLQ channel:", error);
          return null;
        }
      }
      /**
       * Gracefully close channels and connection.
       */
      async shutdown() {
        console.log("[RabbitMQ] Starting graceful shutdown...");
        for (const [tag, ch] of this.consumerChannels) {
          try {
            await ch.close();
          } catch (err) {
            console.error(`[RabbitMQ] Error closing consumer channel ${tag}:`, err);
          }
        }
        this.consumerChannels.clear();
        if (this.publisherChannel) {
          try {
            await this.publisherChannel.close();
          } catch (err) {
            console.error("[RabbitMQ] Error closing publisher channel:", err);
          }
          this.publisherChannel = null;
        }
        if (this.conn) {
          try {
            await this.conn.close();
          } catch (err) {
            console.error("[RabbitMQ] Error closing connection:", err);
          }
          this.conn = null;
        }
        console.log("[RabbitMQ] Graceful shutdown complete");
      }
    };
    rabbitmqClient = RabbitMQClient.getInstance();
    ["SIGINT", "SIGTERM"].forEach((sig) => {
      process.on(sig, async () => {
        try {
          await rabbitmqClient.shutdown();
        } finally {
          process.exit(0);
        }
      });
    });
  }
});

// server/middleware/safe-logger.ts
function maskSensitive(obj) {
  if (obj == null || typeof obj !== "object") return obj;
  const clone = Array.isArray(obj) ? [] : {};
  for (const [k, v] of Object.entries(obj)) {
    if ([
      "account_number",
      "routing_number",
      "account_number_masked",
      "routing_number_masked",
      "ssn",
      "token",
      "password",
      "secret",
      "apiKey",
      "api_key",
      "authorization",
      "cookie",
      "session"
    ].includes(k.toLowerCase())) {
      clone[k] = "***";
    } else if (typeof v === "object") {
      clone[k] = maskSensitive(v);
    } else {
      clone[k] = v;
    }
  }
  return clone;
}
var init_safe_logger = __esm({
  "server/middleware/safe-logger.ts"() {
    "use strict";
  }
});

// server/payments/types.ts
function maskAccountNumber(accountNumber) {
  if (accountNumber.length < 4) return accountNumber;
  const visibleDigits = accountNumber.slice(-4);
  const maskedLength = Math.max(4, accountNumber.length - 4);
  return "*".repeat(maskedLength) + visibleDigits;
}
function maskRoutingNumber(routingNumber) {
  if (routingNumber.length !== 9) return routingNumber;
  return "*****" + routingNumber.slice(-4);
}
function generateTraceNumber() {
  const timestamp2 = Date.now().toString();
  const random = Math.random().toString(36).substring(2, 6);
  return `ACH${timestamp2}${random}`.toUpperCase();
}
var init_types = __esm({
  "server/payments/types.ts"() {
    "use strict";
  }
});

// src/qc/businessDays.ts
import dayjs from "dayjs";
import utc from "dayjs/plugin/utc";
import tz from "dayjs/plugin/timezone";
function loadHolidays() {
  const file = process.env.QC_TRID_BUSINESS_DAYS_FILE;
  if (!file) {
    const year = (/* @__PURE__ */ new Date()).getFullYear();
    [year, year + 1].forEach((y) => {
      FIXED.add(`${y}-01-01`);
      FIXED.add(`${y}-07-04`);
      FIXED.add(`${y}-12-25`);
    });
    return;
  }
  try {
    const fs11 = __require("fs");
    const arr = JSON.parse(fs11.readFileSync(file, "utf-8"));
    arr.forEach((d) => FIXED.add(dayjs.tz(d, Z).format("YYYY-MM-DD")));
  } catch {
  }
}
function isBusinessDay(d) {
  const local = d.tz(Z);
  const dow = local.day();
  if (dow === 0 || dow === 6) return false;
  if (FIXED.has(local.format("YYYY-MM-DD"))) return false;
  return true;
}
function diffBusinessDays(aISO, bISO) {
  let a = dayjs.tz(aISO, Z);
  let b = dayjs.tz(bISO, Z);
  if (b.isBefore(a)) [a, b] = [b, a];
  let d = a;
  let count3 = 0;
  while (d.isBefore(b, "day")) {
    d = d.add(1, "day");
    if (isBusinessDay(d)) count3++;
  }
  return count3;
}
var Z, FIXED;
var init_businessDays = __esm({
  "src/qc/businessDays.ts"() {
    "use strict";
    dayjs.extend(utc);
    dayjs.extend(tz);
    Z = process.env.QC_BUSINESS_TZ || "America/New_York";
    FIXED = /* @__PURE__ */ new Set();
    loadHolidays();
  }
});

// src/qc/rules/deterministic.ts
function num(x) {
  if (x == null) return null;
  if (typeof x === "number") return x;
  const n = Number(String(x).replace(/[^\d.]/g, ""));
  return isFinite(n) ? n : null;
}
function QC001(ctx) {
  const note = num(ctx.datapoints.NoteAmount?.value);
  const cd = num(ctx.datapoints.TotalLoanAmount?.value);
  if (note == null || cd == null) return { ok: true };
  const ok = Math.abs(note - cd) < 0.01;
  return ok ? { ok: true } : {
    ok: false,
    message: `QC001: NoteAmount $${note} != CD TotalLoanAmount $${cd}`,
    evidence_doc_id: ctx.datapoints.TotalLoanAmount?.evidence_doc_id,
    evidence_page: ctx.datapoints.TotalLoanAmount?.evidence_page
  };
}
function QC002(ctx, params) {
  const note = num(ctx.datapoints.InterestRate?.value);
  const cd = num(ctx.datapoints.InterestRate?.value);
  if (note == null || cd == null) return { ok: true };
  const tol = params?.tolerance ?? 0.125;
  const ok = Math.abs(note - cd) <= tol + 1e-9;
  return ok ? { ok: true } : {
    ok: false,
    message: `QC002: Rate difference ${Math.abs(note - cd).toFixed(3)} > ${tol}%`,
    evidence_doc_id: ctx.datapoints.InterestRate?.evidence_doc_id,
    evidence_page: ctx.datapoints.InterestRate?.evidence_page
  };
}
function QC003(ctx, params) {
  const first = ctx.datapoints.FirstPaymentDate?.value;
  const noteDate = ctx.datapoints.NoteDate?.value || ctx.datapoints.MaturityDate?.value;
  if (!first || !noteDate) return { ok: true };
  const allow = params?.maxDays ?? 62;
  const diff = diffBusinessDays(String(noteDate), String(first));
  const ok = diff <= allow;
  return ok ? { ok: true } : {
    ok: false,
    message: `QC003: FirstPaymentDate is ${diff} business days after NoteDate (max ${allow})`,
    evidence_doc_id: ctx.datapoints.FirstPaymentDate?.evidence_doc_id,
    evidence_page: ctx.datapoints.FirstPaymentDate?.evidence_page
  };
}
function QC004(ctx) {
  const term = Number(ctx.datapoints.AmortTermMonths?.value);
  const first = ctx.datapoints.FirstPaymentDate?.value;
  const maturity = ctx.datapoints.MaturityDate?.value;
  if (!term || !first || !maturity) return { ok: true };
  const a = new Date(String(first));
  const b = new Date(String(maturity));
  const months = (b.getFullYear() - a.getFullYear()) * 12 + (b.getMonth() - a.getMonth());
  const ok = Math.abs(months - term) <= 1;
  return ok ? { ok: true } : {
    ok: false,
    message: `QC004: Term months ${term} != calendar months ${months}`,
    evidence_doc_id: ctx.datapoints.MaturityDate?.evidence_doc_id,
    evidence_page: ctx.datapoints.MaturityDate?.evidence_page
  };
}
function QC013(ctx, params) {
  const req = params?.required ?? false;
  if (!req) return { ok: true };
  const carrier = ctx.datapoints.HomeownersInsCarrier?.value;
  const policy = ctx.datapoints.HOIPolicyNumber?.value;
  if (carrier && policy) return { ok: true };
  return {
    ok: false,
    message: "QC013: HOI required by program but missing carrier/policy",
    evidence_doc_id: ctx.datapoints.HomeownersInsCarrier?.evidence_doc_id || ctx.datapoints.HOIPolicyNumber?.evidence_doc_id,
    evidence_page: ctx.datapoints.HomeownersInsCarrier?.evidence_page || ctx.datapoints.HOIPolicyNumber?.evidence_page
  };
}
function QC017(ctx) {
  const ssr = String(ctx.datapoints.UCDPSSRStatus?.value || "").toUpperCase();
  if (!ssr) return { ok: true };
  const ok = /ACCEPT|SUBMISSION SUCCESS|SUCCESS/.test(ssr);
  return ok ? { ok: true } : {
    ok: false,
    message: `QC017: SSR status '${ssr}' not acceptable`,
    evidence_doc_id: ctx.datapoints.UCDPSSRStatus?.evidence_doc_id,
    evidence_page: ctx.datapoints.UCDPSSRStatus?.evidence_page
  };
}
function QC020(ctx, params) {
  const appDate = ctx.datapoints.TRID_ApplicationDate?.value || ctx.datapoints.ApplicationDate?.value;
  const leDate = ctx.datapoints.TRID_LEDate?.value;
  if (!appDate || !leDate) return { ok: true };
  const max = params?.maxDays ?? 3;
  const diff = diffBusinessDays(String(appDate), String(leDate));
  const ok = diff <= max;
  return ok ? { ok: true } : {
    ok: false,
    message: `QC020: LE issued ${diff} business days after app (max ${max})`,
    evidence_doc_id: ctx.datapoints.TRID_LEDate?.evidence_doc_id,
    evidence_page: ctx.datapoints.TRID_LEDate?.evidence_page
  };
}
function QC021(ctx, params) {
  const cdDate = ctx.datapoints.TRID_CDDate?.value;
  const noteDate = ctx.datapoints.NoteDate?.value;
  if (!cdDate || !noteDate) return { ok: true };
  const min = params?.minDays ?? 3;
  const diff = diffBusinessDays(String(cdDate), String(noteDate));
  const ok = diff >= min;
  return ok ? { ok: true } : {
    ok: false,
    message: `QC021: CD only ${diff} business days before NoteDate (min ${min})`,
    evidence_doc_id: ctx.datapoints.TRID_CDDate?.evidence_doc_id,
    evidence_page: ctx.datapoints.TRID_CDDate?.evidence_page
  };
}
function QC043(ctx, params) {
  const approved = !!params?.approved;
  const edited = ctx.datapoints.WireEditedAfterApproval?.value === true;
  if (!approved) return { ok: true };
  return edited ? {
    ok: false,
    message: "QC043: Wire instructions edited after approval (forbidden)",
    evidence_doc_id: ctx.datapoints.WireEditedAfterApproval?.evidence_doc_id,
    evidence_page: ctx.datapoints.WireEditedAfterApproval?.evidence_page
  } : { ok: true };
}
function QC050(ctx) {
  const cert = ctx.datapoints.QCCertificateId?.value;
  return cert ? { ok: true } : {
    ok: false,
    message: "QC050: QC Certificate missing",
    evidence_doc_id: ctx.datapoints.QCCertificateId?.evidence_doc_id,
    evidence_page: ctx.datapoints.QCCertificateId?.evidence_page
  };
}
var init_deterministic = __esm({
  "src/qc/rules/deterministic.ts"() {
    "use strict";
    init_businessDays();
  }
});

// src/qc/engine.ts
async function runQcForLoan(tenantId, loanId) {
  console.log(`[QcEngine] Running QC for loan ${loanId} (tenant: ${tenantId})`);
  try {
    const dp = {
      NoteAmount: { value: 35e4, confidence: 1, evidence_doc_id: "doc-123", evidence_page: 1 },
      TotalLoanAmount: { value: 35e4, confidence: 1, evidence_doc_id: "doc-123", evidence_page: 1 },
      InterestRate: { value: 4.25, confidence: 1, evidence_doc_id: "doc-123", evidence_page: 1 },
      FirstPaymentDate: { value: "2025-10-01", confidence: 1, evidence_doc_id: "doc-123", evidence_page: 1 },
      NoteDate: { value: "2025-09-01", confidence: 1, evidence_doc_id: "doc-123", evidence_page: 1 },
      AmortTermMonths: { value: 360, confidence: 1, evidence_doc_id: "doc-123", evidence_page: 1 },
      MaturityDate: { value: "2055-09-01", confidence: 1, evidence_doc_id: "doc-123", evidence_page: 1 },
      HomeownersInsCarrier: { value: "State Farm", confidence: 1, evidence_doc_id: "doc-124", evidence_page: 1 },
      HOIPolicyNumber: { value: "POL-123456", confidence: 1, evidence_doc_id: "doc-124", evidence_page: 1 },
      ProgramCode: { value: "FNMA", confidence: 1, evidence_doc_id: "doc-123", evidence_page: 1 }
    };
    const rules = [
      { id: "rule-001", code: "QC001", name: "Note Amount Match", severity: "high", params: {} },
      { id: "rule-002", code: "QC002", name: "Interest Rate Tolerance", severity: "medium", params: { tolerance: 0.125 } },
      { id: "rule-003", code: "QC003", name: "Payment Date Alignment", severity: "medium", params: { maxDays: 62 } },
      { id: "rule-004", code: "QC004", name: "Maturity Term Match", severity: "medium", params: {} },
      { id: "rule-013", code: "QC013", name: "HOI Required", severity: "high", params: { required: true } }
    ];
    const program = dp.ProgramCode?.value || process.env.PROGRAM || "FNMA";
    console.log(`[QcEngine] Using program: ${program}`);
    const reqMap = {
      "HomeownersInsCarrier": { required: true, params: {} },
      "HOIPolicyNumber": { required: true, params: {} }
    };
    const defects = [];
    for (const r of rules) {
      const code = r.code;
      const fn = REGISTRY[code];
      if (!fn) {
        console.warn(`[QcEngine] Rule ${code} not found in registry`);
        continue;
      }
      let params = r.params || {};
      if (code === "QC013") {
        const hoiReq = reqMap["HomeownersInsCarrier"]?.required && reqMap["HOIPolicyNumber"]?.required;
        params = { ...params, required: !!hoiReq };
      }
      try {
        const res = fn({ loanId, datapoints: dp, program }, params);
        if (!res.ok) {
          defects.push({
            rule_id: r.id,
            message: res.message || `${code} failed`,
            evidence_doc_id: res.evidence_doc_id,
            evidence_page: res.evidence_page
          });
          console.log(`[QcEngine] Rule ${code} failed: ${res.message}`);
        } else {
          console.log(`[QcEngine] Rule ${code} passed`);
        }
      } catch (error) {
        console.error(`[QcEngine] Error executing rule ${code}:`, error);
        defects.push({
          rule_id: r.id,
          message: `${code} execution error: ${error.message}`
        });
      }
    }
    console.log(`[QcEngine] Completed QC for loan ${loanId}: ${rules.length} rules, ${defects.length} defects`);
    return {
      total_rules: rules.length,
      defects: defects.length,
      defects_detail: defects,
      program
    };
  } catch (error) {
    console.error(`[QcEngine] Failed to run QC for loan ${loanId}:`, error);
    throw error;
  }
}
var REGISTRY;
var init_engine = __esm({
  "src/qc/engine.ts"() {
    "use strict";
    init_deterministic();
    REGISTRY = {
      QC001,
      QC002,
      QC003,
      QC004,
      QC013,
      QC017,
      QC020,
      QC021,
      QC043,
      QC050
    };
  }
});

// src/monitoring/metrics.ts
import client2 from "prom-client";
var pipelineStageStarted, pipelineStageCompleted, pipelineStageDuration, extractConfidence, hitlConflicts, qcDefectsOpen, qcDefectResolution, dnpPrevented, rmqQueueDepth, rmqQueueDlqDepth, exportSuccess, exportFailure, httpRequestDuration;
var init_metrics = __esm({
  "src/monitoring/metrics.ts"() {
    "use strict";
    if ((process.env.METRICS_ENABLED || "true") === "true") {
      client2.collectDefaultMetrics({ prefix: "loanserve_node_" });
    }
    pipelineStageStarted = new client2.Counter({
      name: "loanserve_stage_started_total",
      help: "Pipeline stages started",
      labelNames: ["stage"]
      // import, split, ocr, extract, qc, export, notify
    });
    pipelineStageCompleted = new client2.Counter({
      name: "loanserve_stage_completed_total",
      help: "Pipeline stages completed",
      labelNames: ["stage"]
    });
    pipelineStageDuration = new client2.Histogram({
      name: "loanserve_stage_duration_seconds",
      help: "Stage duration seconds (e2e per loan/stage)",
      labelNames: ["stage"],
      buckets: [1, 3, 5, 10, 30, 60, 120, 300, 900, 1800]
    });
    extractConfidence = new client2.Histogram({
      name: "loanserve_extract_confidence",
      help: "Distribution of extraction confidences",
      labelNames: ["key", "source"],
      // InterestRate|NoteAmount... + deterministic|ai_doc|payload|vendor
      buckets: [0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 1]
    });
    hitlConflicts = new client2.Counter({
      name: "loanserve_hitl_conflicts_total",
      help: "Count of conflicts requiring HITL",
      labelNames: ["key"]
    });
    qcDefectsOpen = new client2.Gauge({
      name: "loanserve_qc_defects_open",
      help: "Open QC defects",
      labelNames: ["rule_code", "severity"]
      // QC001..; Low|Medium|High|Critical
    });
    qcDefectResolution = new client2.Histogram({
      name: "loanserve_qc_defect_resolution_seconds",
      help: "Time to resolve QC defects",
      labelNames: ["rule_code", "severity"],
      buckets: [600, 1800, 3600, 14400, 28800, 86400, 172800]
      // 10m..2d
    });
    dnpPrevented = new client2.Counter({
      name: "loanserve_dnp_prevented_total",
      help: "Count of notifications suppressed by Do-Not-Ping",
      labelNames: ["template_code"]
    });
    rmqQueueDepth = new client2.Gauge({
      name: "loanserve_rmq_queue_depth",
      help: "RabbitMQ queue message count",
      labelNames: ["queue"]
    });
    rmqQueueDlqDepth = new client2.Gauge({
      name: "loanserve_rmq_dlq_depth",
      help: "RabbitMQ DLQ message count",
      labelNames: ["queue"]
    });
    exportSuccess = new client2.Counter({
      name: "loanserve_export_success_total",
      help: "Successful exports",
      labelNames: ["template"]
      // fannie|freddie|custom
    });
    exportFailure = new client2.Counter({
      name: "loanserve_export_failure_total",
      help: "Failed exports",
      labelNames: ["template"]
    });
    httpRequestDuration = new client2.Histogram({
      name: "loanserve_http_request_duration_seconds",
      help: "HTTP request duration",
      labelNames: ["method", "route", "code"],
      buckets: [0.03, 0.05, 0.1, 0.2, 0.5, 1, 2, 5]
    });
  }
});

// src/monitoring/stage.ts
function stageStart(loanId, stage) {
  const key = `${loanId}:${stage}`;
  pipelineStageStarted.labels(stage).inc();
  stageStartCache.set(key, Date.now());
}
function stageComplete(loanId, stage) {
  const key = `${loanId}:${stage}`;
  pipelineStageCompleted.labels(stage).inc();
  const t0 = stageStartCache.get(key);
  if (t0) {
    const secs = (Date.now() - t0) / 1e3;
    pipelineStageDuration.labels(stage).observe(secs);
    stageStartCache.delete(key);
  }
}
var stageStartCache;
var init_stage = __esm({
  "src/monitoring/stage.ts"() {
    "use strict";
    init_metrics();
    stageStartCache = /* @__PURE__ */ new Map();
  }
});

// src/workers/QcWorker.ts
var QcWorker_exports = {};
__export(QcWorker_exports, {
  QcWorker: () => QcWorker,
  qcWorker: () => qcWorker,
  startQcWorker: () => startQcWorker
});
async function startQcWorker() {
  return await qcWorker.start();
}
var QcWorker, qcWorker;
var init_QcWorker = __esm({
  "src/workers/QcWorker.ts"() {
    "use strict";
    init_engine();
    init_stage();
    init_metrics();
    QcWorker = class {
      isRunning = false;
      /**
       * Initialize and start the QC worker
       */
      async start() {
        console.log("[QcWorker] Starting QC worker...");
        this.isRunning = true;
        console.log("[QcWorker] QC worker started successfully");
      }
      /**
       * Stop the QC worker
       */
      async stop() {
        console.log("[QcWorker] Stopping QC worker...");
        this.isRunning = false;
        console.log("[QcWorker] QC worker stopped");
      }
      /**
       * Run QC for a specific loan
       */
      async processLoan(tenantId, loanId) {
        if (!this.isRunning) {
          throw new Error("QC worker is not running");
        }
        try {
          console.log(`[QcWorker] Processing QC for loan ${loanId} (tenant: ${tenantId})`);
          stageStart(loanId, "qc");
          const results = await runQcForLoan(tenantId, loanId);
          if (results.defects && Array.isArray(results.defects)) {
            for (const defect of results.defects) {
              qcDefectsOpen.labels(defect.rule_code || "UNKNOWN", defect.severity || "Medium").inc();
            }
          }
          stageComplete(loanId, "qc");
          console.log(`[QcWorker] QC completed for loan ${loanId}:`, {
            total_rules: results.total_rules,
            defects: results.defects,
            program: results.program
          });
          return results;
        } catch (error) {
          console.error(`[QcWorker] Failed to process QC for loan ${loanId}:`, error);
          throw error;
        }
      }
      /**
       * Get worker status
       */
      getStatus() {
        return {
          isRunning: this.isRunning,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
    };
    qcWorker = new QcWorker();
  }
});

// src/exports/mapperUtil.ts
import fs5 from "fs";
import yaml from "js-yaml";
import { create } from "xmlbuilder2";
function loadMapperConfig(p = "config/mappers.v2025-09-03.yaml") {
  return yaml.load(fs5.readFileSync(p, "utf-8"));
}
function toBool(v) {
  if (v === true || v === "true" || v === "1" || v === 1) return "true";
  return "false";
}
function lineageComment(key, ev) {
  const parts = [`canonical:${key}`];
  if (ev?.evidence_doc_id) parts.push(`doc:${ev.evidence_doc_id}`);
  if (ev?.evidence_page != null) parts.push(`page:${ev.evidence_page}`);
  if (ev?.evidence_text_hash) parts.push(`hash:${ev.evidence_text_hash}`);
  return `LINEAGE ${parts.join(" | ")}`;
}
function buildXml(root, sections, data, evidence) {
  const doc = create({ version: "1.0", encoding: "UTF-8" }).ele(root.name);
  if (root.ns) doc.att("xmlns", root.ns);
  for (const [section, fields] of Object.entries(sections)) {
    const node = doc.ele(section);
    for (const [key, path11] of Object.entries(fields)) {
      const val = data[key];
      if (val == null) continue;
      node.com(lineageComment(key, evidence[key]));
      const leaf = path11.split("/").pop();
      node.ele(leaf).txt(String(val));
    }
  }
  return doc.end({ prettyPrint: true });
}
var init_mapperUtil = __esm({
  "src/exports/mapperUtil.ts"() {
    "use strict";
  }
});

// src/exports/engine.ts
import { createHash as createHash6 } from "crypto";
async function generateExport(opts) {
  const cfg = loadMapperConfig();
  const tpl = cfg.templates[opts.template];
  if (!tpl) throw new Error(`Unknown template: ${opts.template}`);
  const req = tpl.required || [];
  const missing = req.filter((k) => opts.canonical[k] == null || opts.canonical[k] === "");
  if (missing.length) throw new Error(`Missing required keys: ${missing.join(", ")}`);
  let bytes, mime, filename;
  if (tpl.format === "xml") {
    const data = { ...opts.canonical };
    if (data.EscrowRequired != null) data.EscrowRequired = toBool(data.EscrowRequired);
    const xml = buildXml(tpl.root, tpl.sections, data, opts.evidence);
    bytes = Buffer.from(xml, "utf-8");
    mime = "application/xml";
    filename = `${opts.template.toUpperCase()}_${opts.loanId}.xml`;
  } else if (tpl.format === "csv") {
    const header = tpl.csv.header;
    const map = tpl.csv.mapping;
    const row = header.map((h) => {
      const key = map[h] || h;
      const v = opts.canonical[key];
      return v == null ? "" : String(v);
    });
    const csv = header.join(",") + "\n" + row.map(escapeCsv).join(",") + "\n";
    bytes = Buffer.from(csv, "utf-8");
    mime = "text/csv";
    filename = `CUSTOM_${opts.loanId}.csv`;
  } else {
    throw new Error(`Unsupported format: ${tpl.format}`);
  }
  const sha256 = createHash6("sha256").update(bytes).digest("hex");
  return { bytes, sha256, mime, filename };
}
function escapeCsv(s) {
  if (/[,"\n]/.test(s)) return `"${s.replace(/"/g, '""')}"`;
  return s;
}
async function saveExport(tenantId, loanId, filename, bytes) {
  const mockUri = `s3://loanserve-exports/${tenantId}/loans/${loanId}/exports/${filename}`;
  console.log(`[Export] Mock save to ${mockUri} (${bytes.length} bytes)`);
  return mockUri;
}
var init_engine2 = __esm({
  "src/exports/engine.ts"() {
    "use strict";
    init_mapperUtil();
  }
});

// src/repo/exports.ts
async function createExport(tenantId, loanId, template, requestedBy) {
  const exportsVersion = process.env.EXPORTS_VERSION || "v2025.09.03";
  const mockExport = {
    id: crypto.randomUUID(),
    tenant_id: tenantId,
    loan_id: loanId,
    template,
    status: "queued",
    file_uri: null,
    file_sha256: null,
    errors: [],
    lineage: {},
    mapper_version: exportsVersion,
    created_at: /* @__PURE__ */ new Date(),
    started_at: null,
    completed_at: null,
    requested_by: requestedBy || null
  };
  console.log(`[ExportRepo] Created export ${mockExport.id} for loan ${loanId} template ${template}`);
  return mockExport;
}
async function markExportRunning(id, tenantId) {
  console.log(`[ExportRepo] Marking export ${id} as running`);
}
async function markExportResult(id, tenantId, status, file_uri, file_sha256, errors) {
  console.log(`[ExportRepo] Marking export ${id} as ${status}`, {
    file_uri,
    file_sha256,
    errors
  });
}
async function getExport(id, tenantId) {
  console.log(`[ExportRepo] Getting export ${id} for tenant ${tenantId}`);
  return {
    id,
    tenant_id: tenantId,
    status: "succeeded",
    file_uri: `s3://loanserve-exports/${tenantId}/loans/test-loan/exports/FANNIE_test-loan.xml`,
    file_sha256: "abc123def456",
    template: "fannie",
    created_at: /* @__PURE__ */ new Date(),
    completed_at: /* @__PURE__ */ new Date()
  };
}
async function loadCanonicalWithEvidence(tenantId, loanId) {
  console.log(`[ExportRepo] Loading canonical with evidence for loan ${loanId}`);
  const canonical = {
    NoteAmount: 35e4,
    InterestRate: 4.25,
    AmortTermMonths: 360,
    FirstPaymentDate: "2025-10-01",
    MaturityDate: "2055-09-01",
    BorrowerFullName: "John Q. Public",
    PropertyStreet: "123 Main Street",
    PropertyCity: "Phoenix",
    PropertyState: "AZ",
    PropertyZip: "85032",
    EscrowRequired: true,
    LoanNumber: `LN-${loanId}`,
    LenderLoanId: `LEND-${loanId}`,
    InvestorLoanId: `INV-${loanId}`
  };
  const evidence = {};
  Object.keys(canonical).forEach((key) => {
    evidence[key] = {
      evidence_doc_id: "doc-123",
      evidence_page: 1,
      evidence_text_hash: "hash-abc123"
    };
  });
  return { canonical, evidence };
}
var init_exports = __esm({
  "src/repo/exports.ts"() {
    "use strict";
  }
});

// src/workers/ExportWorker.ts
var ExportWorker_exports = {};
__export(ExportWorker_exports, {
  ExportWorker: () => ExportWorker,
  exportWorker: () => exportWorker,
  startExportWorker: () => startExportWorker
});
async function startExportWorker() {
  return await exportWorker.start();
}
var ExportWorker, exportWorker;
var init_ExportWorker = __esm({
  "src/workers/ExportWorker.ts"() {
    "use strict";
    init_engine2();
    init_exports();
    init_stage();
    init_metrics();
    ExportWorker = class {
      isRunning = false;
      /**
       * Initialize and start the export worker
       */
      async start() {
        console.log("[ExportWorker] Starting export worker...");
        this.isRunning = true;
        console.log("[ExportWorker] Export worker started successfully");
      }
      /**
       * Stop the export worker
       */
      async stop() {
        console.log("[ExportWorker] Stopping export worker...");
        this.isRunning = false;
        console.log("[ExportWorker] Export worker stopped");
      }
      /**
       * Process an export request
       */
      async processExportRequest(opts) {
        if (!this.isRunning) {
          throw new Error("Export worker is not running");
        }
        const { tenantId, loanId, template, requestedBy } = opts;
        try {
          console.log(`[ExportWorker] Processing export request for loan ${loanId}, template ${template}`);
          stageStart(loanId, "export");
          const exportRecord = await createExport(tenantId, loanId, template, requestedBy);
          const exportId = exportRecord.id;
          await markExportRunning(exportId, tenantId);
          const { canonical, evidence } = await loadCanonicalWithEvidence(tenantId, loanId);
          const mapperVersion = process.env.EXPORTS_VERSION || "v2025.09.03";
          const exportResult = await generateExport({
            tenantId,
            loanId,
            template,
            canonical,
            evidence,
            mapperVersion
          });
          const fileUri = await saveExport(tenantId, loanId, exportResult.filename, exportResult.bytes);
          await markExportResult(exportId, tenantId, "succeeded", fileUri, exportResult.sha256, []);
          await this.emitWebhook(tenantId, exportId, fileUri, exportResult.sha256, template);
          exportSuccess.labels(template).inc();
          stageComplete(loanId, "export");
          console.log(`[ExportWorker] Export completed for loan ${loanId}:`, {
            exportId,
            template,
            fileUri,
            sha256: exportResult.sha256
          });
          return {
            exportId,
            status: "succeeded",
            fileUri,
            sha256: exportResult.sha256,
            filename: exportResult.filename
          };
        } catch (error) {
          console.error(`[ExportWorker] Export failed for loan ${loanId}:`, error);
          exportFailure.labels(template).inc();
          const exportId = `export-${Date.now()}`;
          await markExportResult(exportId, tenantId, "failed", void 0, void 0, [{ message: error.message }]);
          throw error;
        }
      }
      /**
       * Emit webhook notifications (simplified)
       */
      async emitWebhook(tenantId, exportId, uri, sha256, template) {
        try {
          console.log(`[ExportWorker] Would emit webhook for export ${exportId}, template ${template}`);
          const webhookPayload = {
            export_id: exportId,
            template,
            file_uri: uri,
            sha256,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          };
          console.log("[ExportWorker] Webhook payload:", webhookPayload);
        } catch (error) {
          console.error("[ExportWorker] Webhook emission failed:", error);
        }
      }
      /**
       * Get worker status
       */
      getStatus() {
        return {
          isRunning: this.isRunning,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
    };
    exportWorker = new ExportWorker();
  }
});

// src/notifications/template.ts
var template_exports = {};
__export(template_exports, {
  registerTemplateHelpers: () => registerTemplateHelpers,
  renderTemplate: () => renderTemplate
});
import Handlebars from "handlebars";
function renderTemplate(subject, body, params) {
  try {
    const renderedSubject = subject ? Handlebars.compile(subject, { noEscape: true })(params) : null;
    const renderedBody = Handlebars.compile(body, { noEscape: false })(params);
    return {
      subject: renderedSubject,
      body: renderedBody
    };
  } catch (error) {
    throw new Error(`Template rendering failed: ${error.message}`);
  }
}
function registerTemplateHelpers() {
  Handlebars.registerHelper("currency", function(amount) {
    return new Intl.NumberFormat("en-US", {
      style: "currency",
      currency: "USD"
    }).format(amount);
  });
  Handlebars.registerHelper("date", function(date2, format2) {
    const d = new Date(date2);
    if (format2 === "short") {
      return d.toLocaleDateString();
    }
    return d.toLocaleDateString("en-US", {
      year: "numeric",
      month: "long",
      day: "numeric"
    });
  });
  Handlebars.registerHelper("ifEquals", function(arg1, arg2, options) {
    return arg1 == arg2 ? options.fn(this) : options.inverse(this);
  });
}
var init_template = __esm({
  "src/notifications/template.ts"() {
    "use strict";
    registerTemplateHelpers();
  }
});

// src/notifications/providers/email.ts
import nodemailer from "nodemailer";
function getTransporter() {
  if (cachedTransporter) return cachedTransporter;
  const smtpConfig = {
    host: process.env.SMTP_HOST,
    port: Number(process.env.SMTP_PORT || "587"),
    secure: false,
    // Use TLS
    auth: {
      user: process.env.SMTP_USER,
      pass: process.env.SMTP_PASS
    }
  };
  if (!smtpConfig.host || !smtpConfig.auth.user || !smtpConfig.auth.pass) {
    throw new Error("SMTP configuration incomplete. Check SMTP_HOST, SMTP_USER, SMTP_PASS");
  }
  cachedTransporter = nodemailer.createTransport(smtpConfig);
  return cachedTransporter;
}
async function sendEmail2(to, subject, htmlOrText) {
  try {
    const transport = getTransporter();
    const from = `"${process.env.NOTIFY_FROM_NAME || "LoanServe"}" <${process.env.NOTIFY_FROM_EMAIL}>`;
    if (!process.env.NOTIFY_FROM_EMAIL) {
      return { ok: false, error: "NOTIFY_FROM_EMAIL not configured" };
    }
    const mailOptions = {
      from,
      to,
      subject,
      text: htmlOrText,
      html: convertToHtml(htmlOrText)
    };
    console.log(`[EmailProvider] Sending email to ${to}: ${subject}`);
    const info = await transport.sendMail(mailOptions);
    console.log(`[EmailProvider] Email sent successfully. MessageId: ${info.messageId}`);
    return {
      ok: true,
      providerId: info.messageId
    };
  } catch (error) {
    console.error(`[EmailProvider] Email send failed:`, error);
    return {
      ok: false,
      error: `Email send failed: ${error.message}`
    };
  }
}
function convertToHtml(text2) {
  return text2.replace(/\n/g, "<br/>");
}
var cachedTransporter;
var init_email = __esm({
  "src/notifications/providers/email.ts"() {
    "use strict";
    cachedTransporter = null;
  }
});

// src/notifications/providers/sms.ts
import twilio2 from "twilio";
function getTwilioClient() {
  if (twilioClient) return twilioClient;
  const accountSid = process.env.TWILIO_ACCOUNT_SID;
  const authToken = process.env.TWILIO_AUTH_TOKEN;
  if (!accountSid || !authToken) {
    throw new Error("Twilio credentials not configured. Check TWILIO_ACCOUNT_SID and TWILIO_AUTH_TOKEN");
  }
  twilioClient = twilio2(accountSid, authToken);
  return twilioClient;
}
async function sendSms(to, body) {
  try {
    const client5 = getTwilioClient();
    const from = process.env.NOTIFY_SMS_FROM;
    if (!from) {
      return { ok: false, error: "NOTIFY_SMS_FROM not configured" };
    }
    if (!isValidPhoneNumber(to)) {
      return { ok: false, error: `Invalid phone number format: ${to}` };
    }
    if (body.length > 1600) {
      return { ok: false, error: "SMS message too long (max 1600 characters)" };
    }
    console.log(`[SmsProvider] Sending SMS to ${to}`);
    const message = await client5.messages.create({
      from,
      to,
      body
    });
    console.log(`[SmsProvider] SMS sent successfully. SID: ${message.sid}`);
    return {
      ok: true,
      sid: message.sid
    };
  } catch (error) {
    console.error(`[SmsProvider] SMS send failed:`, error);
    return {
      ok: false,
      error: `SMS send failed: ${error.message}`
    };
  }
}
function isValidPhoneNumber(phone) {
  const cleaned = phone.replace(/[^\d+]/g, "");
  const phoneRegex = /^\+?[1-9]\d{9,14}$/;
  return phoneRegex.test(cleaned);
}
var twilioClient;
var init_sms = __esm({
  "src/notifications/providers/sms.ts"() {
    "use strict";
    twilioClient = null;
  }
});

// src/notifications/providers/webhook.ts
import { createHmac as createHmac2 } from "crypto";
async function sendWebhook(url, payload, secret) {
  try {
    if (!isValidUrl(url)) {
      return { ok: false, error: `Invalid webhook URL: ${url}` };
    }
    const body = JSON.stringify(payload);
    const headers = {
      "Content-Type": "application/json",
      "User-Agent": "LoanServe-Notifications/1.0"
    };
    if (secret) {
      const signature = generateHmacSignature(body, secret);
      headers["X-LoanServe-Notify-Signature"] = signature;
    }
    const timeoutMs = Number(process.env.NOTIFY_WEBHOOK_TIMEOUT_MS || "10000");
    console.log(`[WebhookProvider] Sending webhook to ${url}`);
    const response = await fetch(url, {
      method: "POST",
      headers,
      body,
      signal: AbortSignal.timeout(timeoutMs)
    });
    if (!response.ok) {
      const errorText = await response.text().catch(() => "Unknown error");
      console.error(`[WebhookProvider] Webhook failed: ${response.status} ${errorText}`);
      return {
        ok: false,
        status: response.status,
        error: `Webhook failed: ${response.status} ${errorText}`
      };
    }
    console.log(`[WebhookProvider] Webhook sent successfully: ${response.status}`);
    return {
      ok: true,
      status: response.status
    };
  } catch (error) {
    console.error(`[WebhookProvider] Webhook send failed:`, error);
    if (error.name === "AbortError") {
      return { ok: false, error: "Webhook timeout" };
    }
    return {
      ok: false,
      error: `Webhook send failed: ${error.message}`
    };
  }
}
function generateHmacSignature(body, secret) {
  if (!secret) return "";
  return createHmac2("sha256", secret).update(body).digest("hex");
}
function isValidUrl(url) {
  try {
    const parsedUrl = new URL(url);
    return parsedUrl.protocol === "http:" || parsedUrl.protocol === "https:";
  } catch {
    return false;
  }
}
var init_webhook = __esm({
  "src/notifications/providers/webhook.ts"() {
    "use strict";
  }
});

// src/logging/redact.ts
function redactUuid(u) {
  if (!u) return "unknown";
  return u.replace(/[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-([0-9a-f]{12})/i, "********-****-****-****-$1");
}
var init_redact = __esm({
  "src/logging/redact.ts"() {
    "use strict";
  }
});

// src/db/withTenantClient.ts
import { z as z9 } from "zod";
async function withTenantClient(tenantId, fn) {
  if (!tenantId) throw new Error("Tenant ID is required for database operations");
  const normalizedTenantId = tenantIdSchema.parse(tenantId);
  const client5 = await pool.connect();
  try {
    await client5.query("BEGIN");
    try {
      await client5.query(`SET LOCAL app.tenant_id = '${normalizedTenantId}'`);
    } catch (error) {
      console.warn("[DB] Neon serverless does not support SET LOCAL, using alternative approach");
    }
    console.debug("[DB] Tenant context set for session", {
      tenantId: redactUuid(normalizedTenantId),
      originalTenantId: tenantId !== normalizedTenantId ? tenantId : void 0,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
    const result = await fn(client5);
    await client5.query("COMMIT");
    return result;
  } catch (error) {
    try {
      await client5.query("ROLLBACK");
    } catch {
    }
    console.error("[DB] Database operation failed with tenant context", {
      tenantId: redactUuid(tenantId),
      error: error instanceof Error ? error.message : String(error)
    });
    throw error;
  } finally {
    client5.release();
  }
}
var NIL, DEFAULT_TENANT, tenantIdSchema;
var init_withTenantClient = __esm({
  "src/db/withTenantClient.ts"() {
    "use strict";
    init_db();
    init_redact();
    NIL = "00000000-0000-0000-0000-000000000000";
    DEFAULT_TENANT = process.env.DEFAULT_TENANT_ID ?? NIL;
    tenantIdSchema = z9.string().transform((v) => v === "default" || !v ? DEFAULT_TENANT : v).refine(
      (v) => /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i.test(v),
      "Invalid UUID format"
    );
  }
});

// src/notifications/guard.ts
async function canSatisfyFromDocsOrVendors(tenantId, loanId, keys, minConfidence = Number(process.env.AI_ACCEPT_CONFIDENCE || "0.80")) {
  return withTenantClient(tenantId, async (client5) => {
    const result = await client5.query(
      `SELECT key, value, confidence, autofilled_from 
       FROM loan_datapoints 
       WHERE loan_id = $1 AND key = ANY($2)`,
      [loanId, keys]
    );
    const dataMap = {};
    result.rows.forEach((row) => {
      dataMap[row.key] = row;
    });
    const missingKeys = [];
    const satisfied = keys.every((key) => {
      const datapoint = dataMap[key];
      if (!datapoint || !datapoint.value) {
        missingKeys.push(key);
        return false;
      }
      const acceptableSources = ["payload", "document", "vendor"];
      const sourceOk = acceptableSources.includes(datapoint.autofilled_from);
      const confidence = datapoint.confidence ?? 1;
      const confidenceOk = confidence >= minConfidence;
      if (!sourceOk || !confidenceOk) {
        missingKeys.push(key);
        return false;
      }
      return true;
    });
    if (satisfied) {
      console.log(`[DoNotPingGuard] All required keys satisfied for loan ${loanId}: ${keys.join(", ")}`);
      return {
        satisfied: true,
        evidence: dataMap
      };
    }
    console.log(`[DoNotPingGuard] Missing required data for loan ${loanId}: ${missingKeys.join(", ")}`);
    return {
      satisfied: false,
      missingKeys
    };
  });
}
function getRequiredKeysForTemplate(templateCode) {
  const requiredKeysByTemplate = {
    // Borrower HOI request - check if we already have insurance info
    "BORR_HOI_REQUEST": [
      "HomeownersInsCarrier",
      "HOIPolicyNumber",
      "HOIEffectiveDate",
      "HOIExpirationDate"
    ],
    // Escrow flood determination - check if we have flood info
    "ESC_ADDENDUM_MISSING_FLOOD": [
      "FloodZone",
      "FloodInsRequired",
      "DeterminationIdentifier"
    ],
    // Property value verification - check if we have appraisal
    "BORR_APPRAISAL_REQUEST": [
      "AppraisalDate",
      "AppraisedValue",
      "AppraisalFormType"
    ],
    // Income verification - check if we have income docs
    "BORR_INCOME_REQUEST": [
      "BorrowerIncome",
      "IncomeSource",
      "EmploymentStatus"
    ]
  };
  return requiredKeysByTemplate[templateCode] || [];
}
async function shouldSuppressNotification(tenantId, loanId, templateCode) {
  const requiredKeys = getRequiredKeysForTemplate(templateCode);
  if (requiredKeys.length === 0) {
    return { suppress: false };
  }
  try {
    const result = await canSatisfyFromDocsOrVendors(tenantId, loanId, requiredKeys);
    if (result.satisfied) {
      return {
        suppress: true,
        reason: `Do-Not-Ping: Required data already available: ${requiredKeys.join(", ")}`
      };
    }
    return { suppress: false };
  } catch (error) {
    console.error(`[DoNotPingGuard] Error checking suppression for ${templateCode}:`, error);
    return { suppress: false };
  }
}
var init_guard = __esm({
  "src/notifications/guard.ts"() {
    "use strict";
    init_withTenantClient();
  }
});

// src/notifications/service.ts
async function requestNotification(request) {
  return withTenantClient(request.tenantId, async (client5) => {
    if (request.idempotencyKey) {
      const existing = await client5.query(
        "SELECT 1 FROM idempotency_keys WHERE idempotency_key = $1",
        [request.idempotencyKey]
      );
      if (existing.rowCount && existing.rowCount > 0) {
        console.log(`[NotificationService] Duplicate request ignored: ${request.idempotencyKey}`);
        return null;
      }
      await client5.query(
        "INSERT INTO idempotency_keys (idempotency_key) VALUES ($1)",
        [request.idempotencyKey]
      );
    }
    if (request.loanId) {
      const today = (/* @__PURE__ */ new Date()).toISOString().slice(0, 10);
      const rateLimit = Number(process.env.NOTIFY_RATE_LIMIT_PER_LOAN_PER_TEMPLATE_PER_DAY || "5");
      await client5.query(`
        INSERT INTO notification_counters (tenant_id, loan_id, template_code, day, count)
        VALUES ($1, $2, $3, $4, 1)
        ON CONFLICT (tenant_id, loan_id, template_code, day) 
        DO UPDATE SET count = notification_counters.count + 1
      `, [request.tenantId, request.loanId, request.templateCode, today]);
      const counter = await client5.query(
        "SELECT count FROM notification_counters WHERE tenant_id = $1 AND loan_id = $2 AND template_code = $3 AND day = $4",
        [request.tenantId, request.loanId, request.templateCode, today]
      );
      if ((counter.rows[0]?.count || 0) > rateLimit) {
        throw new Error(`Rate limit exceeded for template ${request.templateCode}: ${rateLimit}/day`);
      }
    }
    const templateResult = await client5.query(`
      SELECT * FROM notification_templates 
      WHERE code = $1 AND locale = $2 AND channel = $3 AND active = true 
      ORDER BY created_at DESC LIMIT 1
    `, [request.templateCode, request.locale || "en-US", request.channel]);
    if (!templateResult.rowCount) {
      throw new Error(`Template not found: ${request.templateCode}/${request.channel}/${request.locale || "en-US"}`);
    }
    const template = templateResult.rows[0];
    if (request.loanId) {
      const suppressCheck = await shouldSuppressNotification(
        request.tenantId,
        request.loanId,
        request.templateCode
      );
      if (suppressCheck.suppress) {
        const notificationResult2 = await client5.query(`
          INSERT INTO notifications (
            tenant_id, loan_id, template_code, locale, channel, 
            to_party, to_address, params, status, reason, 
            template_version, idempotency_key, created_by
          ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13)
          RETURNING id
        `, [
          request.tenantId,
          request.loanId,
          request.templateCode,
          request.locale || "en-US",
          request.channel,
          request.toParty,
          request.toAddress,
          JSON.stringify(request.params || {}),
          "suppressed",
          suppressCheck.reason,
          template.version,
          request.idempotencyKey,
          request.createdBy
        ]);
        const notificationId2 = notificationResult2.rows[0].id;
        await client5.query(
          "INSERT INTO notification_events (notification_id, event, meta) VALUES ($1, $2, $3)",
          [notificationId2, "suppressed", JSON.stringify({ reason: suppressCheck.reason })]
        );
        console.log(`[NotificationService] Notification suppressed: ${suppressCheck.reason}`);
        return {
          id: notificationId2,
          status: "suppressed",
          reason: suppressCheck.reason
        };
      }
    }
    const notificationResult = await client5.query(`
      INSERT INTO notifications (
        tenant_id, loan_id, template_code, locale, channel, 
        to_party, to_address, params, status, 
        template_version, idempotency_key, created_by
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12)
      RETURNING id
    `, [
      request.tenantId,
      request.loanId,
      request.templateCode,
      request.locale || "en-US",
      request.channel,
      request.toParty,
      request.toAddress,
      JSON.stringify(request.params || {}),
      "queued",
      template.version,
      request.idempotencyKey,
      request.createdBy
    ]);
    const notificationId = notificationResult.rows[0].id;
    await client5.query(
      "INSERT INTO notification_events (notification_id, event, meta) VALUES ($1, $2, $3)",
      [notificationId, "requested", JSON.stringify({ template_code: request.templateCode })]
    );
    const processResult = await processNotification(notificationId, template, request);
    return {
      id: notificationId,
      status: processResult.status,
      reason: processResult.reason
    };
  });
}
async function processNotification(notificationId, template, request) {
  try {
    return await withTenantClient(request.tenantId, async (client5) => {
      const rendered = renderTemplate(template.subject, template.body, request.params || {});
      await client5.query(
        "UPDATE notifications SET status = $1 WHERE id = $2",
        ["rendered", notificationId]
      );
      await client5.query(
        "INSERT INTO notification_events (notification_id, event, meta) VALUES ($1, $2, $3)",
        [notificationId, "rendered", JSON.stringify({ subject: rendered.subject })]
      );
      let sendResult;
      switch (request.channel) {
        case "email":
          if (!rendered.subject) {
            throw new Error("Email requires subject");
          }
          sendResult = await sendEmail2(request.toAddress, rendered.subject, rendered.body);
          break;
        case "sms":
          sendResult = await sendSms(request.toAddress, rendered.body);
          break;
        case "webhook":
          const payload = JSON.parse(rendered.body);
          sendResult = await sendWebhook(request.toAddress, payload);
          break;
        default:
          throw new Error(`Unsupported channel: ${request.channel}`);
      }
      const finalStatus = sendResult.ok ? "sent" : "failed";
      const sentAt = sendResult.ok ? /* @__PURE__ */ new Date() : null;
      await client5.query(
        "UPDATE notifications SET status = $1, reason = $2, sent_at = $3 WHERE id = $4",
        [finalStatus, sendResult.error || null, sentAt, notificationId]
      );
      await client5.query(
        "INSERT INTO notification_events (notification_id, event, meta) VALUES ($1, $2, $3)",
        [notificationId, finalStatus, JSON.stringify({
          provider_id: sendResult.providerId || sendResult.sid,
          error: sendResult.error
        })]
      );
      console.log(`[NotificationService] Notification ${notificationId} ${finalStatus}`);
      return {
        status: finalStatus,
        reason: sendResult.error
      };
    });
  } catch (error) {
    console.error(`[NotificationService] Processing failed for ${notificationId}:`, error);
    try {
      await withTenantClient(request.tenantId, async (client5) => {
        await client5.query(
          "UPDATE notifications SET status = $1, reason = $2 WHERE id = $3",
          ["failed", error.message, notificationId]
        );
        await client5.query(
          "INSERT INTO notification_events (notification_id, event, meta) VALUES ($1, $2, $3)",
          [notificationId, "failed", JSON.stringify({ error: error.message })]
        );
      });
    } catch (updateError) {
      console.error(`[NotificationService] Failed to update error status for ${notificationId}:`, updateError);
    }
    return {
      status: "failed",
      reason: error.message
    };
  }
}
var init_service = __esm({
  "src/notifications/service.ts"() {
    "use strict";
    init_template();
    init_email();
    init_sms();
    init_webhook();
    init_guard();
    init_withTenantClient();
  }
});

// src/workers/NotificationWorker.ts
var NotificationWorker_exports = {};
__export(NotificationWorker_exports, {
  NotificationWorker: () => NotificationWorker,
  getNotificationWorker: () => getNotificationWorker,
  startNotificationWorker: () => startNotificationWorker
});
async function startNotificationWorker() {
  if (!notificationWorker) {
    notificationWorker = new NotificationWorker();
    await notificationWorker.start();
  }
  return notificationWorker;
}
function getNotificationWorker() {
  return notificationWorker;
}
var NotificationWorker, notificationWorker;
var init_NotificationWorker = __esm({
  "src/workers/NotificationWorker.ts"() {
    "use strict";
    init_service();
    init_stage();
    init_metrics();
    NotificationWorker = class {
      isRunning = false;
      /**
       * Initialize and start the notification worker
       */
      async start() {
        console.log("[NotificationWorker] Starting notification worker...");
        this.isRunning = true;
        console.log("[NotificationWorker] Notification worker started successfully");
      }
      /**
       * Stop the notification worker
       */
      async stop() {
        console.log("[NotificationWorker] Stopping notification worker...");
        this.isRunning = false;
        console.log("[NotificationWorker] Notification worker stopped");
      }
      /**
       * Process a single notification request
       */
      async processNotificationRequest(request) {
        if (!this.isRunning) {
          throw new Error("Notification worker is not running");
        }
        try {
          console.log(`[NotificationWorker] Processing notification: ${request.templateCode} -> ${request.toAddress}`);
          stageStart(request.loanId || "unknown", "notify");
          const result = await requestNotification(request);
          if (result) {
            console.log(`[NotificationWorker] Notification ${result.id} ${result.status}`);
            if (result.status === "suppressed" && result.reason === "DoNotPingPolicy") {
              dnpPrevented.labels(request.templateCode).inc();
            }
            if (result.reason) {
              console.log(`[NotificationWorker] Reason: ${result.reason}`);
            }
            stageComplete(request.loanId || "unknown", "notify");
          } else {
            console.log(`[NotificationWorker] Notification skipped (duplicate)`);
            stageComplete(request.loanId || "unknown", "notify");
          }
        } catch (error) {
          console.error(`[NotificationWorker] Failed to process notification:`, error);
          throw error;
        }
      }
      /**
       * Process multiple notification requests in batch
       */
      async processBatch(requests) {
        if (!this.isRunning) {
          throw new Error("Notification worker is not running");
        }
        console.log(`[NotificationWorker] Processing batch of ${requests.length} notifications`);
        const results = await Promise.allSettled(
          requests.map((request) => this.processNotificationRequest(request))
        );
        const succeeded = results.filter((r) => r.status === "fulfilled").length;
        const failed = results.filter((r) => r.status === "rejected").length;
        console.log(`[NotificationWorker] Batch complete: ${succeeded} succeeded, ${failed} failed`);
      }
      /**
       * Get worker status
       */
      getStatus() {
        return {
          isRunning: this.isRunning,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
    };
    notificationWorker = null;
  }
});

// src/services/S3Service.ts
import {
  S3Client,
  PutObjectCommand,
  GetObjectCommand,
  DeleteObjectCommand,
  HeadObjectCommand,
  ListObjectsV2Command,
  CreateBucketCommand,
  HeadBucketCommand,
  DeleteObjectsCommand
} from "@aws-sdk/client-s3";
import { Upload } from "@aws-sdk/lib-storage";
import { fromEnv, fromIni, fromInstanceMetadata } from "@aws-sdk/credential-providers";
import { createHash as createHash7 } from "crypto";
var S3Service;
var init_S3Service = __esm({
  "src/services/S3Service.ts"() {
    "use strict";
    S3Service = class {
      client;
      bucket;
      region;
      /**
       * Hash S3 key for secure logging - prevents PII exposure
       */
      hashKey(key) {
        return createHash7("sha256").update(key).digest("hex").substring(0, 16);
      }
      /**
       * Create safe log representation of S3 key
       */
      safelog(key) {
        const hash = this.hashKey(key);
        const extension = key.split(".").pop();
        return `key_${hash}${extension ? `.${extension}` : ""}`;
      }
      constructor(config) {
        this.region = config?.region || process.env.AWS_REGION || "us-east-1";
        this.bucket = config?.bucket || process.env.AWS_S3_BUCKET || process.env.AI_PIPELINE_BUCKET || "";
        if (!this.bucket) {
          throw new Error("S3 bucket not configured. Set AWS_S3_BUCKET or AI_PIPELINE_BUCKET environment variable.");
        }
        this.client = new S3Client({
          region: this.region,
          credentials: this.createCredentialsProvider(config)
        });
        console.log(`[S3Service] Initialized for bucket: ${this.bucket}, region: ${this.region}`);
      }
      /**
       * Create AWS credentials provider with fallback chain
       */
      createCredentialsProvider(config) {
        if (config?.accessKeyId && config?.secretAccessKey) {
          return {
            accessKeyId: config.accessKeyId,
            secretAccessKey: config.secretAccessKey
          };
        }
        try {
          if (process.env.AWS_ACCESS_KEY_ID && process.env.AWS_SECRET_ACCESS_KEY) {
            return fromEnv();
          }
          return fromIni();
        } catch (error) {
          console.warn("[S3Service] Using instance metadata credentials");
          return fromInstanceMetadata();
        }
      }
      /**
       * Ensure bucket exists, create if necessary
       */
      async ensureBucket() {
        try {
          await this.client.send(new HeadBucketCommand({ Bucket: this.bucket }));
          console.log(`[S3Service] Bucket ${this.bucket} exists`);
        } catch (error) {
          if (error.name === "NotFound") {
            console.log(`[S3Service] Creating bucket ${this.bucket}`);
            const createParams = { Bucket: this.bucket };
            if (this.region !== "us-east-1") {
              createParams.CreateBucketConfiguration = {
                LocationConstraint: this.region
              };
            }
            await this.client.send(new CreateBucketCommand(createParams));
            console.log(`[S3Service] Bucket ${this.bucket} created successfully`);
          } else {
            throw new Error(`Failed to verify bucket: ${error.message}`);
          }
        }
      }
      /**
       * Upload file to S3
       */
      async uploadFile(key, data, contentType, metadata) {
        try {
          const uploadParams = {
            Bucket: this.bucket,
            Key: key,
            Body: data,
            ContentType: contentType || "application/octet-stream",
            Metadata: metadata
          };
          let result;
          if (Buffer.isBuffer(data) && data.length > 5 * 1024 * 1024) {
            const upload6 = new Upload({
              client: this.client,
              params: uploadParams
            });
            result = await upload6.done();
          } else {
            result = await this.client.send(new PutObjectCommand(uploadParams));
          }
          const location = `s3://${this.bucket}/${key}`;
          console.log(`[S3Service] Uploaded ${this.safelog(key)} to bucket ${this.bucket}`);
          return {
            key,
            bucket: this.bucket,
            location,
            etag: result.ETag || ""
          };
        } catch (error) {
          console.error(`[S3Service] Upload failed for ${this.safelog(key)}:`, error.message);
          throw new Error(`S3 upload failed: ${error.message}`);
        }
      }
      /**
       * Download file from S3
       */
      async downloadFile(key) {
        try {
          const command = new GetObjectCommand({
            Bucket: this.bucket,
            Key: key
          });
          const response = await this.client.send(command);
          if (!response.Body) {
            throw new Error("No data received from S3");
          }
          const chunks = [];
          const stream = response.Body;
          return new Promise((resolve, reject) => {
            stream.on("data", (chunk) => chunks.push(chunk));
            stream.on("end", () => resolve(Buffer.concat(chunks)));
            stream.on("error", reject);
          });
        } catch (error) {
          console.error(`[S3Service] Download failed for ${this.safelog(key)}:`, error.message);
          if (error.name === "NoSuchKey") {
            throw new Error(`File not found in storage`);
          }
          throw new Error(`S3 download failed: ${error.message}`);
        }
      }
      /**
       * Download file as stream
       */
      async downloadStream(key) {
        try {
          const command = new GetObjectCommand({
            Bucket: this.bucket,
            Key: key
          });
          const response = await this.client.send(command);
          if (!response.Body) {
            throw new Error("No data received from S3");
          }
          return response.Body;
        } catch (error) {
          console.error(`[S3Service] Stream download failed for ${this.safelog(key)}:`, error.message);
          throw new Error(`S3 stream download failed: ${error.message}`);
        }
      }
      /**
       * Check if file exists
       */
      async fileExists(key) {
        try {
          await this.client.send(new HeadObjectCommand({
            Bucket: this.bucket,
            Key: key
          }));
          return true;
        } catch (error) {
          if (error.name === "NotFound") {
            return false;
          }
          throw new Error(`S3 head object failed: ${error.message}`);
        }
      }
      /**
       * Get file metadata
       */
      async getFileMetadata(key) {
        try {
          const response = await this.client.send(new HeadObjectCommand({
            Bucket: this.bucket,
            Key: key
          }));
          return {
            key,
            size: response.ContentLength || 0,
            lastModified: response.LastModified || /* @__PURE__ */ new Date(),
            etag: response.ETag || ""
          };
        } catch (error) {
          if (error.name === "NotFound") {
            throw new Error(`File not found: ${key}`);
          }
          throw new Error(`S3 metadata failed: ${error.message}`);
        }
      }
      /**
       * Delete file from S3
       */
      async deleteFile(key) {
        try {
          await this.client.send(new DeleteObjectCommand({
            Bucket: this.bucket,
            Key: key
          }));
          console.log(`[S3Service] Deleted ${this.safelog(key)}`);
        } catch (error) {
          console.error(`[S3Service] Delete failed for ${this.safelog(key)}:`, error.message);
          throw new Error(`S3 delete failed: ${error.message}`);
        }
      }
      /**
       * Delete multiple files
       */
      async deleteFiles(keys) {
        if (keys.length === 0) return;
        try {
          const deleteParams = {
            Bucket: this.bucket,
            Delete: {
              Objects: keys.map((key) => ({ Key: key }))
            }
          };
          await this.client.send(new DeleteObjectsCommand(deleteParams));
          console.log(`[S3Service] Deleted ${keys.length} files`);
        } catch (error) {
          console.error(`[S3Service] Batch delete failed:`, error);
          throw new Error(`S3 batch delete failed: ${error.message}`);
        }
      }
      /**
       * List files with prefix
       */
      async listFiles(prefix, maxKeys) {
        try {
          const command = new ListObjectsV2Command({
            Bucket: this.bucket,
            Prefix: prefix,
            MaxKeys: maxKeys || 1e3
          });
          const response = await this.client.send(command);
          return (response.Contents || []).map((obj) => ({
            key: obj.Key || "",
            size: obj.Size || 0,
            lastModified: obj.LastModified || /* @__PURE__ */ new Date(),
            etag: obj.ETag || ""
          }));
        } catch (error) {
          const safePrefix = prefix ? this.hashKey(prefix).substring(0, 8) : "none";
          console.error(`[S3Service] List failed for prefix ${safePrefix}:`, error.message);
          throw new Error(`S3 list failed: ${error.message}`);
        }
      }
      /**
       * Delete all files with prefix (for cleanup)
       */
      async deletePrefix(prefix) {
        try {
          const objects = await this.listFiles(prefix);
          if (objects.length === 0) {
            const safePrefix2 = this.hashKey(prefix).substring(0, 8);
            console.log(`[S3Service] No files found with prefix: ${safePrefix2}`);
            return;
          }
          const keys = objects.map((obj) => obj.key);
          await this.deleteFiles(keys);
          const safePrefix = this.hashKey(prefix).substring(0, 8);
          console.log(`[S3Service] Deleted ${keys.length} files with prefix: ${safePrefix}`);
        } catch (error) {
          const safePrefix = this.hashKey(prefix).substring(0, 8);
          console.error(`[S3Service] Delete prefix failed for ${safePrefix}:`, error.message);
          throw new Error(`S3 delete prefix failed: ${error.message}`);
        }
      }
      /**
       * Get S3 URL for a key
       */
      getS3Url(key) {
        return `s3://${this.bucket}/${key}`;
      }
      /**
       * Get HTTP URL for a key (if bucket allows public access)
       */
      getHttpUrl(key) {
        return `https://${this.bucket}.s3.${this.region}.amazonaws.com/${key}`;
      }
      /**
       * Test S3 connectivity
       */
      async testConnection() {
        try {
          await this.ensureBucket();
          const testKey = "test-connection.txt";
          const testData = Buffer.from("S3 connection test");
          await this.uploadFile(testKey, testData, "text/plain");
          const downloaded = await this.downloadFile(testKey);
          await this.deleteFile(testKey);
          const success = downloaded.equals(testData);
          console.log(`[S3Service] Connection test: ${success ? "PASSED" : "FAILED"}`);
          return success;
        } catch (error) {
          console.error(`[S3Service] Connection test failed:`, error);
          return false;
        }
      }
      /**
       * Get service configuration
       */
      getConfig() {
        return {
          bucket: this.bucket,
          region: this.region
        };
      }
    };
  }
});

// src/utils/storage.ts
import { createHash as createHash8 } from "crypto";
async function putBytes(bucket, key, data) {
  const storage4 = new AIPipelineStorageManager();
  await storage4.s3Service.ensureBucket();
  const uploadResult = await storage4.s3Service.uploadFile(key, Buffer.from(data), "application/pdf", {
    "generated-by": "finalization-engine",
    "timestamp": (/* @__PURE__ */ new Date()).toISOString()
  });
  return uploadResult.location;
}
var AIPipelineStorageManager;
var init_storage2 = __esm({
  "src/utils/storage.ts"() {
    "use strict";
    init_S3Service();
    AIPipelineStorageManager = class {
      s3Service;
      s3Prefix;
      constructor() {
        this.s3Service = new S3Service();
        this.s3Prefix = process.env.AI_PIPELINE_PREFIX || "ai-servicing";
      }
      /**
       * Save uploaded file to storage
       * Structure: s3://$BUCKET/$PREFIX/{tenantId}/loans/{loanId}/uploads/{fileNameOrUuid}
       */
      async saveUpload(file, tenantId, loanId, originalFilename) {
        const fileBuffer = Buffer.isBuffer(file) ? file : file.buffer;
        const filename = originalFilename || file.originalname || "uploaded-file";
        const size = fileBuffer.length;
        const mime = file.mimetype || "application/octet-stream";
        const sha256 = createHash8("sha256").update(fileBuffer).digest("hex");
        const storageKey = `${this.s3Prefix}/${tenantId}/loans/${loanId}/uploads/${sha256}_${filename}`;
        try {
          await this.s3Service.ensureBucket();
          const uploadResult = await this.s3Service.uploadFile(storageKey, fileBuffer, mime, {
            "filename": filename,
            "tenant-id": tenantId,
            "loan-id": loanId,
            "sha256": sha256
          });
          console.log(`[Storage] Uploaded file to ${uploadResult.location}`);
          return {
            uri: uploadResult.location,
            sha256,
            filename,
            size,
            mime
          };
        } catch (error) {
          throw new Error(`Failed to upload file: ${error instanceof Error ? error.message : String(error)}`);
        }
      }
      /**
       * Save document chunk from PDF splitting
       * Structure: s3://$BUCKET/$PREFIX/{tenantId}/loans/{loanId}/chunks/{docId}/page-{n}.pdf
       */
      async saveChunk(tenantId, loanId, docId, pageNumber, chunkData) {
        const sha256 = createHash8("sha256").update(chunkData).digest("hex");
        const storageKey = `${this.s3Prefix}/${tenantId}/loans/${loanId}/chunks/${docId}/page-${pageNumber}.pdf`;
        try {
          await this.s3Service.ensureBucket();
          await this.s3Service.uploadFile(storageKey, chunkData, "application/pdf", {
            "doc-id": docId,
            "page-number": pageNumber.toString(),
            "tenant-id": tenantId,
            "loan-id": loanId
          });
          console.log(`[Storage] Saved chunk to ${this.s3Service.getS3Url(storageKey)}`);
          return {
            docId,
            pageNumber,
            chunkData,
            sha256
          };
        } catch (error) {
          throw new Error(`Failed to save chunk: ${error instanceof Error ? error.message : String(error)}`);
        }
      }
      /**
       * Save OCR results from Textract
       * Structure: s3://$BUCKET/$PREFIX/{tenantId}/loans/{loanId}/ocr/{docId}/page-{n}.json
       */
      async saveOCRResult(tenantId, loanId, docId, pageNumber, textractBlocks) {
        const ocrResult = {
          docId,
          pageNumber,
          textractBlocks,
          confidence: this.calculateOverallConfidence(textractBlocks),
          timestamp: /* @__PURE__ */ new Date()
        };
        const storageKey = `${this.s3Prefix}/${tenantId}/loans/${loanId}/ocr/${docId}/page-${pageNumber}.json`;
        try {
          await this.s3Service.ensureBucket();
          const jsonData = JSON.stringify(ocrResult, null, 2);
          await this.s3Service.uploadFile(storageKey, Buffer.from(jsonData), "application/json", {
            "doc-id": docId,
            "page-number": pageNumber.toString(),
            "tenant-id": tenantId,
            "loan-id": loanId,
            "confidence": ocrResult.confidence.toString()
          });
          console.log(`[Storage] Saved OCR result to ${this.s3Service.getS3Url(storageKey)}`);
          return ocrResult;
        } catch (error) {
          throw new Error(`Failed to save OCR result: ${error instanceof Error ? error.message : String(error)}`);
        }
      }
      /**
       * Save reflowed text for evidence tracking
       * Structure: s3://$BUCKET/$PREFIX/{tenantId}/loans/{loanId}/text/{docId}.txt
       */
      async saveReflowedText(tenantId, loanId, docId, reflowedText) {
        const storageKey = `${this.s3Prefix}/${tenantId}/loans/${loanId}/text/${docId}.txt`;
        try {
          await this.s3Service.ensureBucket();
          await this.s3Service.uploadFile(storageKey, Buffer.from(reflowedText), "text/plain", {
            "doc-id": docId,
            "tenant-id": tenantId,
            "loan-id": loanId
          });
          console.log(`[Storage] Saved reflowed text to ${this.s3Service.getS3Url(storageKey)}`);
          return this.s3Service.getS3Url(storageKey);
        } catch (error) {
          throw new Error(`Failed to save reflowed text: ${error instanceof Error ? error.message : String(error)}`);
        }
      }
      /**
       * Save evidence snippet for lineage tracking
       * Structure: s3://$BUCKET/$PREFIX/{tenantId}/loans/{loanId}/evidence/{docId}/page-{n}.txt
       */
      async saveEvidenceSnippet(tenantId, loanId, evidence) {
        const storageKey = `${this.s3Prefix}/${tenantId}/loans/${loanId}/evidence/${evidence.docId}/page-${evidence.pageNumber}.txt`;
        try {
          await this.s3Service.ensureBucket();
          const evidenceData = {
            text: evidence.text,
            boundingBox: evidence.boundingBox,
            textHash: evidence.textHash,
            timestamp: /* @__PURE__ */ new Date()
          };
          const jsonData = JSON.stringify(evidenceData, null, 2);
          await this.s3Service.uploadFile(storageKey, Buffer.from(jsonData), "application/json", {
            "doc-id": evidence.docId,
            "page-number": evidence.pageNumber.toString(),
            "tenant-id": tenantId,
            "loan-id": loanId,
            "text-hash": evidence.textHash
          });
          console.log(`[Storage] Saved evidence snippet to ${this.s3Service.getS3Url(storageKey)}`);
          return this.s3Service.getS3Url(storageKey);
        } catch (error) {
          throw new Error(`Failed to save evidence snippet: ${error instanceof Error ? error.message : String(error)}`);
        }
      }
      /**
       * Get reflowed text for evidence retrieval
       */
      async getText(tenantId, loanId, docId) {
        const storageKey = `${this.s3Prefix}/${tenantId}/loans/${loanId}/text/${docId}.txt`;
        try {
          console.log(`[Storage] Retrieving text from ${storageKey}`);
          const textBuffer = await this.s3Service.downloadFile(storageKey);
          return textBuffer.toString("utf-8");
        } catch (error) {
          throw new Error(`Failed to retrieve text: ${error instanceof Error ? error.message : String(error)}`);
        }
      }
      /**
       * Get document chunk
       */
      async getChunk(tenantId, loanId, docId, pageNumber) {
        const storageKey = `${this.s3Prefix}/${tenantId}/loans/${loanId}/chunks/${docId}/page-${pageNumber}.pdf`;
        try {
          console.log(`[Storage] Retrieving chunk from ${storageKey}`);
          return await this.s3Service.downloadFile(storageKey);
        } catch (error) {
          throw new Error(`Failed to retrieve chunk: ${error instanceof Error ? error.message : String(error)}`);
        }
      }
      /**
       * Get OCR result
       */
      async getOCRResult(tenantId, loanId, docId, pageNumber) {
        const storageKey = `${this.s3Prefix}/${tenantId}/loans/${loanId}/ocr/${docId}/page-${pageNumber}.json`;
        try {
          console.log(`[Storage] Retrieving OCR result from ${storageKey}`);
          const jsonBuffer = await this.s3Service.downloadFile(storageKey);
          return JSON.parse(jsonBuffer.toString("utf-8"));
        } catch (error) {
          if (error.message.includes("not found")) {
            return null;
          }
          console.warn(`OCR result not found for ${storageKey}: ${error}`);
          return null;
        }
      }
      /**
       * Save export for investor delivery
       * Structure: s3://$BUCKET/$PREFIX/{tenantId}/loans/{loanId}/exports/{exportId}/...
       */
      async saveExport(tenantId, loanId, exportId, filename, data, mime = "application/octet-stream") {
        const storageKey = `${this.s3Prefix}/${tenantId}/loans/${loanId}/exports/${exportId}/${filename}`;
        try {
          await this.s3Service.ensureBucket();
          const uploadResult = await this.s3Service.uploadFile(storageKey, data, mime, {
            "export-id": exportId,
            "tenant-id": tenantId,
            "loan-id": loanId,
            "filename": filename
          });
          console.log(`[Storage] Saved export to ${uploadResult.location}`);
          return uploadResult.location;
        } catch (error) {
          throw new Error(`Failed to save export: ${error instanceof Error ? error.message : String(error)}`);
        }
      }
      /**
       * Verify file integrity using SHA-256
       */
      async verifyFileIntegrity(tenantId, loanId, docId, expectedSha256) {
        try {
          const uploadPrefix = `${this.s3Prefix}/${tenantId}/loans/${loanId}/uploads/${expectedSha256}_`;
          const files = await this.s3Service.listFiles(uploadPrefix, 1);
          if (files.length === 0) {
            return false;
          }
          const fileBuffer = await this.s3Service.downloadFile(files[0].key);
          const actualSha256 = createHash8("sha256").update(fileBuffer).digest("hex");
          return actualSha256 === expectedSha256;
        } catch (error) {
          console.error(`File integrity verification failed: ${error}`);
          return false;
        }
      }
      /**
       * Clean up temporary files for a loan
       */
      async cleanupLoanFiles(tenantId, loanId) {
        const prefixToClean = `${this.s3Prefix}/${tenantId}/loans/${loanId}/`;
        try {
          console.log(`[Storage] Cleaning up files for loan ${loanId}`);
          await this.s3Service.deletePrefix(prefixToClean);
        } catch (error) {
          console.error(`Failed to cleanup loan files: ${error}`);
          throw error;
        }
      }
      /**
       * Calculate overall confidence from Textract blocks
       */
      calculateOverallConfidence(textractBlocks) {
        if (!textractBlocks || textractBlocks.length === 0) {
          return 0;
        }
        const confidences = textractBlocks.filter((block) => block.Confidence !== void 0).map((block) => block.Confidence);
        if (confidences.length === 0) {
          return 0;
        }
        return confidences.reduce((sum3, conf) => sum3 + conf, 0) / confidences.length / 100;
      }
      /**
       * Generate storage path for document
       */
      getDocumentPath(tenantId, loanId, docId, type) {
        return `${this.s3Prefix}/${tenantId}/loans/${loanId}/${type}/${docId}`;
      }
      /**
       * Test S3 connectivity
       */
      async testConnection() {
        try {
          return await this.s3Service.testConnection();
        } catch (error) {
          console.error("[Storage] Connection test failed:", error);
          return false;
        }
      }
      /**
       * Get S3 service configuration
       */
      getS3Config() {
        return this.s3Service.getConfig();
      }
    };
  }
});

// server/utils/enhanced-health-monitor.ts
import { sql as sql15 } from "drizzle-orm";
var EnhancedHealthMonitor, healthMonitor;
var init_enhanced_health_monitor = __esm({
  "server/utils/enhanced-health-monitor.ts"() {
    "use strict";
    init_db();
    EnhancedHealthMonitor = class {
      startTime;
      checkHistory = /* @__PURE__ */ new Map();
      constructor() {
        this.startTime = Date.now();
      }
      /**
       * Comprehensive database health check
       */
      async checkDatabase() {
        const start = Date.now();
        try {
          await db.execute(sql15`SELECT 1 as test`);
          const complexQuery = sql15`
        SELECT 
          COUNT(*) as total_loans,
          COALESCE(SUM(principal_balance), 0) as total_balance,
          COUNT(DISTINCT borrower_id) as unique_borrowers
        FROM loans 
        WHERE id IS NOT NULL
        LIMIT 1
      `;
          const result = await db.execute(complexQuery);
          const responseTime = Date.now() - start;
          const status = responseTime > 1e3 ? "degraded" : "healthy";
          return {
            name: "database",
            status,
            responseTime,
            details: {
              ...result[0],
              connectionPool: "active",
              queryComplexity: "advanced"
            },
            timestamp: Date.now()
          };
        } catch (error) {
          return {
            name: "database",
            status: "unhealthy",
            responseTime: Date.now() - start,
            error: error.message,
            details: {
              errorType: error.code || "UNKNOWN",
              connectionPool: "failed"
            },
            timestamp: Date.now()
          };
        }
      }
      /**
       * RabbitMQ connectivity check with graceful degradation
       */
      async checkRabbitMQ() {
        const start = Date.now();
        try {
          if (!process.env.CLOUDAMQP_URL) {
            return {
              name: "rabbitmq",
              status: "degraded",
              responseTime: Date.now() - start,
              details: {
                configured: false,
                reason: "CLOUDAMQP_URL not configured"
              },
              timestamp: Date.now()
            };
          }
          try {
            const { rabbitmqClient: rabbitmqClient2 } = await Promise.resolve().then(() => (init_rabbitmq_unified(), rabbitmq_unified_exports));
            const connectionInfo = await rabbitmqClient2.getConnectionInfo();
            return {
              name: "rabbitmq",
              status: connectionInfo.connected ? "healthy" : "degraded",
              responseTime: Date.now() - start,
              details: {
                connected: connectionInfo.connected,
                configured: true,
                uptime: connectionInfo.uptime || 0
              },
              timestamp: Date.now()
            };
          } catch (clientError) {
            return {
              name: "rabbitmq",
              status: "degraded",
              responseTime: Date.now() - start,
              details: {
                configured: true,
                clientError: clientError.message,
                fallbackMode: true
              },
              timestamp: Date.now()
            };
          }
        } catch (error) {
          return {
            name: "rabbitmq",
            status: "unhealthy",
            responseTime: Date.now() - start,
            error: error.message,
            timestamp: Date.now()
          };
        }
      }
      /**
       * File system health check
       */
      async checkFileSystem() {
        const start = Date.now();
        try {
          const fs11 = await import("fs/promises");
          const path11 = await import("path");
          const uploadsDir = "server/uploads";
          const tempDir = "/tmp";
          await fs11.access(uploadsDir);
          const testFile = path11.join(uploadsDir, `health-check-${Date.now()}.tmp`);
          await fs11.writeFile(testFile, "health check test");
          await fs11.unlink(testFile);
          return {
            name: "filesystem",
            status: "healthy",
            responseTime: Date.now() - start,
            details: {
              uploadsDirectory: "accessible",
              writePermissions: "ok",
              tempDirectory: "accessible"
            },
            timestamp: Date.now()
          };
        } catch (error) {
          return {
            name: "filesystem",
            status: "unhealthy",
            responseTime: Date.now() - start,
            error: error.message,
            details: {
              uploadsDirectory: "failed",
              writePermissions: "failed"
            },
            timestamp: Date.now()
          };
        }
      }
      /**
       * Environment configuration health check
       */
      async checkEnvironment() {
        const start = Date.now();
        try {
          const requiredEnvVars = [
            "DATABASE_URL",
            "NODE_ENV"
          ];
          const optionalEnvVars = [
            "CLOUDAMQP_URL",
            "XAI_API_KEY",
            "COLUMN_WEBHOOK_SECRET"
          ];
          const missingRequired = requiredEnvVars.filter((env) => !process.env[env]);
          const missingOptional = optionalEnvVars.filter((env) => !process.env[env]);
          const status = missingRequired.length > 0 ? "unhealthy" : missingOptional.length > 0 ? "degraded" : "healthy";
          return {
            name: "environment",
            status,
            responseTime: Date.now() - start,
            details: {
              nodeEnv: process.env.NODE_ENV,
              requiredVars: {
                configured: requiredEnvVars.length - missingRequired.length,
                missing: missingRequired
              },
              optionalVars: {
                configured: optionalEnvVars.length - missingOptional.length,
                missing: missingOptional
              },
              features: {
                payments: !!process.env.COLUMN_WEBHOOK_SECRET,
                ai: !!process.env.XAI_API_KEY,
                messaging: !!process.env.CLOUDAMQP_URL
              }
            },
            timestamp: Date.now()
          };
        } catch (error) {
          return {
            name: "environment",
            status: "unhealthy",
            responseTime: Date.now() - start,
            error: error.message,
            timestamp: Date.now()
          };
        }
      }
      /**
       * Memory and process health check
       */
      async checkSystem() {
        const start = Date.now();
        try {
          const memUsage = process.memoryUsage();
          const uptime = process.uptime();
          const memUsageMB = {
            rss: Math.round(memUsage.rss / 1024 / 1024),
            heapTotal: Math.round(memUsage.heapTotal / 1024 / 1024),
            heapUsed: Math.round(memUsage.heapUsed / 1024 / 1024),
            external: Math.round(memUsage.external / 1024 / 1024)
          };
          const heapUtilization = memUsageMB.heapUsed / memUsageMB.heapTotal;
          const status = heapUtilization > 0.9 ? "degraded" : "healthy";
          return {
            name: "system",
            status,
            responseTime: Date.now() - start,
            details: {
              memory: memUsageMB,
              uptime: Math.round(uptime),
              heapUtilization: Math.round(heapUtilization * 100),
              nodeVersion: process.version,
              platform: process.platform,
              architecture: process.arch
            },
            timestamp: Date.now()
          };
        } catch (error) {
          return {
            name: "system",
            status: "unhealthy",
            responseTime: Date.now() - start,
            error: error.message,
            timestamp: Date.now()
          };
        }
      }
      /**
       * Run all health checks
       */
      async runAllChecks() {
        const checks = await Promise.all([
          this.checkDatabase(),
          this.checkRabbitMQ(),
          this.checkFileSystem(),
          this.checkEnvironment(),
          this.checkSystem()
        ]);
        checks.forEach((check) => {
          if (!this.checkHistory.has(check.name)) {
            this.checkHistory.set(check.name, []);
          }
          const history = this.checkHistory.get(check.name);
          history.push(check);
          if (history.length > 10) {
            history.shift();
          }
        });
        const summary = {
          healthy: checks.filter((c) => c.status === "healthy").length,
          degraded: checks.filter((c) => c.status === "degraded").length,
          unhealthy: checks.filter((c) => c.status === "unhealthy").length,
          totalChecks: checks.length
        };
        const overall = summary.unhealthy > 0 ? "unhealthy" : summary.degraded > 0 ? "degraded" : "healthy";
        return {
          overall,
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          uptime: Date.now() - this.startTime,
          checks,
          summary
        };
      }
      /**
       * Get health check history for trending
       */
      getCheckHistory(checkName) {
        if (checkName) {
          const history = this.checkHistory.get(checkName);
          return history ? /* @__PURE__ */ new Map([[checkName, history]]) : /* @__PURE__ */ new Map();
        }
        return new Map(this.checkHistory);
      }
      /**
       * Get average response times for each check
       */
      getPerformanceMetrics() {
        const metrics2 = {};
        for (const [checkName, history] of this.checkHistory) {
          if (history.length === 0) continue;
          const responseTimes = history.map((h) => h.responseTime);
          metrics2[checkName] = {
            avg: Math.round(responseTimes.reduce((a, b) => a + b, 0) / responseTimes.length),
            min: Math.min(...responseTimes),
            max: Math.max(...responseTimes),
            count: responseTimes.length
          };
        }
        return metrics2;
      }
      /**
       * Check if system is ready to receive traffic
       */
      async isReady() {
        const dbCheck = await this.checkDatabase();
        const envCheck = await this.checkEnvironment();
        if (dbCheck.status === "unhealthy") {
          return { ready: false, reason: "Database unavailable" };
        }
        if (envCheck.status === "unhealthy") {
          return { ready: false, reason: "Critical environment variables missing" };
        }
        return { ready: true };
      }
      /**
       * Simple liveness check
       */
      isAlive() {
        return true;
      }
    };
    healthMonitor = new EnhancedHealthMonitor();
  }
});

// server/routes/health.ts
var health_exports = {};
__export(health_exports, {
  default: () => health_default
});
import { Router as Router24 } from "express";
var router18, health_default;
var init_health = __esm({
  "server/routes/health.ts"() {
    "use strict";
    init_enhanced_health_monitor();
    router18 = Router24();
    router18.get("/", async (req, res) => {
      try {
        const health = await healthMonitor.runAllChecks();
        const httpStatus = health.overall === "healthy" ? 200 : health.overall === "degraded" ? 206 : 503;
        res.status(httpStatus).json(health);
      } catch (error) {
        console.error("Health check failed:", error);
        res.status(503).json({
          overall: "unhealthy",
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          error: "Health check system failure",
          details: error.message
        });
      }
    });
    router18.get("/live", (req, res) => {
      const isAlive = healthMonitor.isAlive();
      res.status(200).json({
        status: "live",
        alive: isAlive,
        timestamp: (/* @__PURE__ */ new Date()).toISOString(),
        uptime: process.uptime()
      });
    });
    router18.get("/metrics", async (req, res) => {
      try {
        const metrics2 = healthMonitor.getPerformanceMetrics();
        const history = healthMonitor.getCheckHistory();
        res.status(200).json({
          performance: metrics2,
          historyCount: Object.fromEntries(
            Array.from(history.entries()).map(([name, checks]) => [name, checks.length])
          ),
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        res.status(500).json({
          error: "Failed to get health metrics",
          details: error.message
        });
      }
    });
    router18.get("/history/:checkName?", (req, res) => {
      try {
        const { checkName } = req.params;
        const history = healthMonitor.getCheckHistory(checkName);
        const result = Object.fromEntries(history.entries());
        res.status(200).json({
          history: result,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        res.status(500).json({
          error: "Failed to get health history",
          details: error.message
        });
      }
    });
    router18.get("/ready", async (req, res) => {
      try {
        const readiness = await healthMonitor.isReady();
        if (readiness.ready) {
          res.status(200).json({
            status: "ready",
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          });
        } else {
          res.status(503).json({
            status: "not_ready",
            reason: readiness.reason,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          });
        }
      } catch (error) {
        res.status(503).json({
          status: "not_ready",
          reason: "Readiness check failed",
          error: error.message,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      }
    });
    health_default = router18;
  }
});

// packages/shared/messaging/envelope.ts
function createCanonicalEnvelope(data, schema, options) {
  const now = (/* @__PURE__ */ new Date()).toISOString();
  const messageId = options.id || generateMessageId();
  return {
    id: messageId,
    message_id: messageId,
    correlation_id: options.correlation_id || generateCorrelationId(),
    idempotency_key: options.idempotency_key || generateIdempotencyKey(data, schema),
    schema,
    version: "v1",
    occurred_at: now,
    published_at: now,
    producer: options.producer,
    trace_id: options.trace_id,
    user_id: options.user_id,
    tenant_id: options.tenant_id,
    priority: options.priority,
    ttl: options.ttl,
    retry_count: 0,
    data
  };
}
function generateMessageId() {
  return `msg_${Date.now()}_${Math.random().toString(36).substring(2, 8)}`;
}
function generateCorrelationId() {
  return `corr_${Date.now()}_${Math.random().toString(36).substring(2, 8)}`;
}
function generateIdempotencyKey(data, schema) {
  const crypto22 = __require("crypto");
  const content = JSON.stringify({ data, schema, timestamp: Date.now() });
  return crypto22.createHash("sha256").update(content).digest("hex").substring(0, 32);
}
var init_envelope = __esm({
  "packages/shared/messaging/envelope.ts"() {
    "use strict";
  }
});

// server/services/payments/column-webhook.ts
import crypto6 from "crypto";
var ColumnWebhookService, columnWebhookService;
var init_column_webhook = __esm({
  "server/services/payments/column-webhook.ts"() {
    "use strict";
    init_envelope();
    ColumnWebhookService = class {
      secret;
      constructor() {
        this.secret = process.env.COLUMN_WEBHOOK_SECRET || "";
        if (!this.secret) {
          console.warn("[ColumnWebhook] COLUMN_WEBHOOK_SECRET not configured - webhook verification disabled");
        }
      }
      /**
       * Verify webhook signature using raw HMAC verification
       */
      verifySignature(rawBody, signature, timestamp2) {
        if (!this.secret) {
          console.warn("[ColumnWebhook] Webhook verification skipped - no secret configured");
          return true;
        }
        try {
          const [algorithm, providedHash] = signature.split("=");
          if (algorithm !== "sha256") {
            return false;
          }
          const payload = timestamp2 + rawBody.toString("utf8");
          const expectedHash = crypto6.createHmac("sha256", this.secret).update(payload, "utf8").digest("hex");
          return crypto6.timingSafeEqual(
            Buffer.from(providedHash, "hex"),
            Buffer.from(expectedHash, "hex")
          );
        } catch (error) {
          console.error("[ColumnWebhook] Signature verification error:", error);
          return false;
        }
      }
      /**
       * Process webhook event with idempotency protection
       */
      async processWebhook(rawBody, signature, timestamp2, correlationId) {
        if (!this.verifySignature(rawBody, signature, timestamp2)) {
          throw new Error("Invalid webhook signature");
        }
        const webhookTime = parseInt(timestamp2);
        const currentTime = Date.now();
        if (Math.abs(currentTime - webhookTime) > 3e5) {
          throw new Error("Webhook timestamp expired");
        }
        const event = JSON.parse(rawBody.toString("utf8"));
        const normalizedEvent = this.normalizeColumnEvent(event);
        const envelope = createCanonicalEnvelope(
          normalizedEvent,
          `column.webhook.${event.type}.v1`,
          {
            idempotency_key: event.id,
            // Use Column's event ID for idempotency
            correlation_id: correlationId || `column-${event.id}`,
            producer: {
              service: "column-webhook-handler",
              instance: process.env.HOSTNAME || "unknown",
              version: "1.0.0"
            },
            trace_id: correlationId
          }
        );
        const rabbitmq2 = getEnhancedRabbitMQService();
        await rabbitmq2.publish(envelope, {
          exchange: "payments.topic",
          routingKey: `payment.webhook.column.${event.type}`,
          persistent: true,
          headers: {
            "x-idempotency-key": event.id,
            "x-event-type": event.type,
            "x-source": "column"
          }
        });
        console.log(`[ColumnWebhook] Processed event ${event.id} of type ${event.type}`);
      }
      /**
       * Normalize Column event to standard payment event format
       */
      normalizeColumnEvent(event) {
        const baseEvent = {
          external_id: event.id,
          event_type: event.type,
          occurred_at: event.occurred_at,
          source: "column",
          resource: event.resource
        };
        switch (event.type) {
          case "payment.settled":
            return {
              ...baseEvent,
              payment_data: {
                amount_cents: event.resource?.amount || 0,
                currency: event.resource?.currency || "USD",
                status: "settled",
                reference: event.resource?.reference_id,
                account_id: event.resource?.account_id
              }
            };
          case "payment.failed":
            return {
              ...baseEvent,
              payment_data: {
                amount_cents: event.resource?.amount || 0,
                currency: event.resource?.currency || "USD",
                status: "failed",
                failure_reason: event.resource?.failure_reason,
                reference: event.resource?.reference_id
              }
            };
          case "transfer.completed":
            return {
              ...baseEvent,
              transfer_data: {
                amount_cents: event.resource?.amount || 0,
                currency: event.resource?.currency || "USD",
                status: "completed",
                from_account: event.resource?.from_account_id,
                to_account: event.resource?.to_account_id,
                reference: event.resource?.reference_id
              }
            };
          default:
            return baseEvent;
        }
      }
    };
    columnWebhookService = new ColumnWebhookService();
  }
});

// server/routes/webhook-column.ts
var webhook_column_exports = {};
__export(webhook_column_exports, {
  default: () => webhook_column_default
});
import express2 from "express";
import crypto7 from "crypto";
var router19, webhook_column_default;
var init_webhook_column = __esm({
  "server/routes/webhook-column.ts"() {
    "use strict";
    init_column_webhook();
    router19 = express2.Router();
    router19.post("/webhook/column", express2.raw({ type: "application/json" }), async (req, res) => {
      try {
        const signature = req.header("X-Signature") || "";
        const timestamp2 = req.header("X-Timestamp") || "";
        const correlationId = req.correlationId || crypto7.randomUUID();
        if (!signature || !timestamp2) {
          return res.status(401).json({ error: "Missing signature or timestamp headers" });
        }
        await columnWebhookService.processWebhook(
          req.body,
          signature,
          timestamp2,
          correlationId
        );
        res.status(200).json({ received: true });
      } catch (error) {
        console.error("[ColumnWebhook] Processing error:", error);
        res.status(200).json({
          received: true,
          error: "Processing error logged"
        });
      }
    });
    webhook_column_default = router19;
  }
});

// src/messaging/envelope-helpers.ts
var envelope_helpers_exports = {};
__export(envelope_helpers_exports, {
  createDateKey: () => createDateKey,
  createEnvelope: () => createEnvelope,
  createEtlIdempotencyKey: () => createEtlIdempotencyKey,
  createRoutingKey: () => createRoutingKey,
  validateMessage: () => validateMessage
});
import { randomUUID as randomUUID9 } from "crypto";
function normalizeTenantId(tenantId) {
  if (!tenantId || tenantId === "default") {
    return process.env.DEFAULT_TENANT_ID ?? NIL2;
  }
  return tenantId;
}
function createEnvelope(params) {
  const msgId = params.messageId ?? randomUUID9();
  return {
    messageId: msgId,
    // Explicit messageId for consumer compatibility
    tenantId: normalizeTenantId(params.tenantId),
    correlationId: params.correlationId ?? msgId,
    causationId: params.causationId,
    idempotencyKey: params.idempotencyKey || randomUUID9(),
    actor: params.actor,
    occurredAt: (/* @__PURE__ */ new Date()).toISOString(),
    schemaVersion: 1,
    payload: params.payload
  };
}
function createRoutingKey(tenantId, action) {
  return `tenant.${tenantId}.${action}`;
}
function createEtlIdempotencyKey(tenantId, jobType, timeWindow) {
  return `etl:${tenantId}:${jobType}:${timeWindow}`;
}
function createDateKey(date2) {
  const d = date2 || /* @__PURE__ */ new Date();
  return d.toISOString().split("T")[0];
}
function validateMessage(envelope, schema) {
  if (!envelope || typeof envelope !== "object") {
    throw new Error("Invalid envelope: must be an object");
  }
  if (!envelope.payload) {
    throw new Error("Invalid envelope: missing payload");
  }
  const result = schema.safeParse(envelope.payload);
  if (!result.success) {
    throw new Error(`Invalid payload: ${result.error.message}`);
  }
  return result.data;
}
var NIL2;
var init_envelope_helpers = __esm({
  "src/messaging/envelope-helpers.ts"() {
    "use strict";
    NIL2 = "00000000-0000-0000-0000-000000000000";
  }
});

// src/queues/topology.ts
var topology_exports = {};
__export(topology_exports, {
  Exchanges: () => Exchanges,
  Queues: () => Queues,
  ROUTING_KEYS: () => ROUTING_KEYS,
  declareTopology: () => declareTopology,
  dlq: () => dlq,
  retry: () => retry
});
function retry(queue, suffix) {
  return `${queue}.retry.${suffix}`;
}
function dlq(queue) {
  return `${queue}.dlq`;
}
async function declareTopology(ch) {
  await ch.assertExchange(Exchanges.Commands, "topic", { durable: true });
  await ch.assertExchange(Exchanges.Events, "topic", { durable: true });
  await ch.assertExchange(Exchanges.Schedules, "topic", { durable: true });
  await ch.assertExchange(Exchanges.Dlq, "fanout", { durable: true });
  const withDlq = (q) => ({
    durable: true,
    arguments: {
      "x-dead-letter-exchange": Exchanges.Dlq,
      "x-queue-type": "quorum"
      // crash-safe
    }
  });
  const modernQueues = [
    Queues.LoanCreate,
    Queues.LoanUpdate,
    Queues.PaymentProcess,
    Queues.PaymentAllocate,
    Queues.EscrowDisburse,
    Queues.DocumentProcess,
    Queues.LoanFinalizeCompleted,
    Queues.LoanBoardRequest,
    Queues.EtlSchedule,
    Queues.EtlJob,
    Queues.MaintenanceSchedule,
    Queues.StatusUpdate,
    Queues.Dlq
  ];
  for (const queue of modernQueues) {
    await ch.assertQueue(queue, withDlq(queue));
  }
  await ch.bindQueue(Queues.LoanCreate, Exchanges.Commands, "tenant.*.loan.create");
  await ch.bindQueue(Queues.LoanUpdate, Exchanges.Commands, "tenant.*.loan.update");
  await ch.bindQueue(Queues.PaymentProcess, Exchanges.Commands, "tenant.*.payment.process");
  await ch.bindQueue(Queues.PaymentAllocate, Exchanges.Commands, "tenant.*.payment.allocate");
  await ch.bindQueue(Queues.EscrowDisburse, Exchanges.Commands, "tenant.*.escrow.disburse");
  await ch.bindQueue(Queues.DocumentProcess, Exchanges.Commands, "tenant.*.document.process");
  await ch.bindQueue(Queues.LoanFinalizeCompleted, Exchanges.Events, "tenant.*.loan.finalize.completed");
  await ch.bindQueue(Queues.LoanBoardRequest, Exchanges.Commands, "tenant.*.loan.board.request");
  await ch.bindQueue(Queues.EtlSchedule, Exchanges.Schedules, "tenant.*.etl.schedule");
  await ch.bindQueue(Queues.EtlJob, Exchanges.Commands, "tenant.*.etl.job");
  await ch.bindQueue(Queues.MaintenanceSchedule, Exchanges.Schedules, "tenant.*.maintenance.schedule");
  await ch.bindQueue(Queues.StatusUpdate, Exchanges.Events, "tenant.*.status.#");
  await ch.bindQueue(Queues.Dlq, Exchanges.Dlq, "");
}
var Exchanges, Queues, ROUTING_KEYS;
var init_topology = __esm({
  "src/queues/topology.ts"() {
    "use strict";
    Exchanges = {
      COMMANDS: "commands",
      // direct exchange for commands
      EVENTS: "loan.events",
      // topic exchange for emitted events
      // New modernized exchanges (additive, no breaking changes)
      Commands: "ls.commands",
      // topic exchange for tenant-aware commands
      Events: "ls.events",
      // topic exchange for tenant-aware events  
      Schedules: "ls.schedules",
      // topic exchange for scheduled jobs
      Dlq: "ls.dlq"
      // fanout exchange for dead letter handling
    };
    Queues = {
      // Existing queues (preserved for backwards compatibility)
      Import: "import.command",
      Ocr: "ocr.command",
      Datapoint: "datapoint.command",
      Conflict: "conflict.command",
      Disbursement: "disbursement.command",
      Escrow: "escrow.command",
      Ucdp: "ucdp.command",
      Flood: "flood.command",
      Hoi: "hoi.command",
      Title: "title.command",
      // New versioned command queues (scoped)
      LoanCreate: "loan.create.v1",
      LoanUpdate: "loan.update.v1",
      PaymentProcess: "payment.process.v1",
      PaymentAllocate: "payment.allocate.v1",
      EscrowDisburse: "escrow.disburse.v1",
      DocumentProcess: "document.process.v1",
      // Boarding and finalization queues (Legacy)
      LoanFinalizeCompleted: "loan.finalize.completed.q",
      LoanBoardRequest: "loan.board.request.q",
      // ETL orchestration
      EtlSchedule: "etl.schedule.v1",
      EtlJob: "etl.job.v1",
      // Maintenance tasks (replaces node-cron)
      MaintenanceSchedule: "maintenance.schedule.v1",
      // Events / status
      StatusUpdate: "status.update.v1",
      // Dead-letter
      Dlq: "ls.dlq.v1"
    };
    ROUTING_KEYS = {
      // Payment processing
      PAYMENT_PROCESS: Queues.PaymentProcess,
      PAYMENT_ALLOCATE: Queues.PaymentAllocate,
      // Loan operations  
      LOAN_CREATE: Queues.LoanCreate,
      LOAN_UPDATE: Queues.LoanUpdate,
      // Escrow operations
      ESCROW_DISBURSE: Queues.EscrowDisburse,
      // Document processing
      DOCUMENT_PROCESS: Queues.DocumentProcess,
      // ETL operations
      ETL_SCHEDULE: Queues.EtlSchedule,
      ETL_JOB: Queues.EtlJob,
      // Status updates
      STATUS_UPDATE: Queues.StatusUpdate
    };
  }
});

// server/routes/payment-async.ts
var payment_async_exports = {};
__export(payment_async_exports, {
  AsyncPaymentSubmissionSchema: () => AsyncPaymentSubmissionSchema,
  default: () => payment_async_default,
  setPublishFunction: () => setPublishFunction
});
import { Router as Router25 } from "express";
import { z as z10 } from "zod";
import { ulid as ulid3 } from "ulid";
function setPublishFunction(publishFn) {
  globalPublishFunction = publishFn;
}
var router20, AsyncPaymentSubmissionSchema, globalPublishFunction, payment_async_default;
var init_payment_async = __esm({
  "server/routes/payment-async.ts"() {
    "use strict";
    init_middleware();
    init_policy_engine();
    init_response_utils();
    init_safe_logger();
    init_types();
    init_envelope_helpers();
    init_topology();
    router20 = Router25();
    AsyncPaymentSubmissionSchema = z10.object({
      loan_id: z10.number(),
      amount: z10.number().positive(),
      source: z10.enum(["ach", "wire", "check", "card", "cash"]),
      // ACH fields
      routing_number: z10.string().optional(),
      account_number: z10.string().optional(),
      account_type: z10.enum(["checking", "savings"]).optional(),
      sec_code: z10.enum(["PPD", "CCD", "WEB", "TEL"]).optional(),
      // Wire fields
      wire_ref: z10.string().optional(),
      sender_ref: z10.string().optional(),
      // Check fields
      check_number: z10.string().optional(),
      payer_account: z10.string().optional(),
      payer_bank: z10.string().optional(),
      issue_date: z10.string().optional(),
      // Card fields
      card_last_four: z10.string().optional(),
      card_type: z10.string().optional(),
      auth_code: z10.string().optional(),
      // Common fields
      external_ref: z10.string().optional(),
      processor_ref: z10.string().optional()
    });
    globalPublishFunction = null;
    router20.post("/payments/async", requireAuth2, async (req, res) => {
      try {
        console.log("[API] Async payment submission received", {
          body: maskSensitive(req.body),
          user: req.user.id,
          ip: req.ip
        });
        if (!globalPublishFunction) {
          console.error("[Payment Route] Queue publisher not initialized");
          return res.status(503).json({
            error: "Payment processing service unavailable",
            message: "Queue system not initialized"
          });
        }
        if (!await hasPermission(req.user.id, "payments", "write", { userId: req.user.id })) {
          return res.status(403).json({ error: "Insufficient permissions" });
        }
        const data = AsyncPaymentSubmissionSchema.parse(req.body);
        const paymentId = ulid3();
        const correlationId = ulid3();
        const amountCents = Math.round(data.amount * 100);
        let paymentMessage = {
          payment_id: paymentId,
          loan_id: data.loan_id,
          source: data.source,
          amount_cents: amountCents,
          currency: "USD",
          external_ref: data.external_ref,
          processor_ref: data.processor_ref,
          submitted_by: req.user.id,
          submitted_at: (/* @__PURE__ */ new Date()).toISOString()
        };
        switch (data.source) {
          case "ach":
            if (!data.routing_number || !data.account_number) {
              return res.status(400).json({ error: "ACH payments require routing and account numbers" });
            }
            paymentMessage = {
              ...paymentMessage,
              account_number_masked: maskAccountNumber(data.account_number),
              routing_number_masked: maskRoutingNumber(data.routing_number),
              account_type: data.account_type || "checking",
              sec_code: data.sec_code || "PPD",
              trace_number: generateTraceNumber()
            };
            break;
          case "wire":
            if (!data.wire_ref) {
              return res.status(400).json({ error: "Wire payments require a wire reference" });
            }
            paymentMessage = {
              ...paymentMessage,
              wire_ref: data.wire_ref,
              sender_ref: data.sender_ref
            };
            break;
          case "check":
            paymentMessage = {
              ...paymentMessage,
              check_number: data.check_number,
              payer_account: data.payer_account,
              payer_bank: data.payer_bank,
              issue_date: data.issue_date
            };
            break;
          case "card":
            paymentMessage = {
              ...paymentMessage,
              card_last_four: data.card_last_four,
              card_type: data.card_type,
              auth_code: data.auth_code
            };
            break;
          case "cash":
            break;
        }
        const envelope = createEnvelope({
          tenantId: "default",
          correlationId,
          actor: { userId: req.user.id.toString() },
          payload: paymentMessage
        });
        const routingKey = "tenant.default.payment.process";
        await globalPublishFunction(Exchanges.Commands, routingKey, envelope);
        console.log(`[Payment Route] Payment queued for async processing:`, {
          paymentId,
          correlationId,
          loanId: data.loan_id,
          amount: data.amount,
          source: data.source
        });
        return sendSuccess(res, {
          payment_id: paymentId,
          correlation_id: correlationId,
          status: "queued",
          message: "Payment queued for processing",
          estimated_processing_time: "2-5 minutes",
          loan_id: data.loan_id,
          amount: data.amount,
          source: data.source,
          submitted_at: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Payment Route] Error submitting async payment:", error);
        if (error instanceof z10.ZodError) {
          return res.status(400).json({
            error: "Validation error",
            details: error.errors
          });
        }
        return sendError(res, ErrorResponses.INTERNAL_ERROR, {
          message: "Failed to submit payment for processing",
          error: process.env.NODE_ENV === "development" ? error.message : void 0
        });
      }
    });
    router20.get("/payments/:id/status", requireAuth2, async (req, res) => {
      try {
        const paymentId = req.params.id;
        res.json({
          payment_id: paymentId,
          status: "processing",
          message: "Payment processing status lookup not yet implemented",
          last_updated: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Payment Route] Error getting payment status:", error);
        return sendError(res, ErrorResponses.INTERNAL_ERROR);
      }
    });
    payment_async_default = router20;
  }
});

// src/queues/monitoring/queue-monitor.ts
var queue_monitor_exports = {};
__export(queue_monitor_exports, {
  QueueMonitor: () => QueueMonitor,
  globalQueueMonitor: () => globalQueueMonitor
});
var QueueMonitor, globalQueueMonitor;
var init_queue_monitor = __esm({
  "src/queues/monitoring/queue-monitor.ts"() {
    "use strict";
    init_topology();
    QueueMonitor = class {
      connection = null;
      channel = null;
      monitoringInterval = null;
      currentHealth = {
        status: "critical",
        queues: [],
        totalMessages: 0,
        totalConsumers: 0,
        connectionStatus: "disconnected",
        lastUpdated: (/* @__PURE__ */ new Date()).toISOString(),
        issues: ["Not initialized"]
      };
      /**
       * Initialize queue monitoring
       */
      async initialize(connection2) {
        this.connection = connection2;
        this.channel = await connection2.createChannel();
        console.log("[Queue Monitor] Initializing comprehensive queue monitoring...");
        this.startPeriodicMonitoring();
        await this.updateHealth();
        console.log("[Queue Monitor] \u2705 Queue monitoring initialized");
      }
      /**
       * Start periodic health monitoring
       */
      startPeriodicMonitoring() {
        if (this.monitoringInterval) {
          clearInterval(this.monitoringInterval);
        }
        this.monitoringInterval = setInterval(async () => {
          try {
            await this.updateHealth();
          } catch (error) {
            console.error("[Queue Monitor] Error during periodic health check:", error);
            this.currentHealth.status = "critical";
            this.currentHealth.issues = [`Monitoring error: ${error.message}`];
            this.currentHealth.lastUpdated = (/* @__PURE__ */ new Date()).toISOString();
          }
        }, 3e4);
      }
      /**
       * Update comprehensive health status
       */
      async updateHealth() {
        if (!this.channel) {
          this.currentHealth = {
            status: "critical",
            queues: [],
            totalMessages: 0,
            totalConsumers: 0,
            connectionStatus: "disconnected",
            lastUpdated: (/* @__PURE__ */ new Date()).toISOString(),
            issues: ["Channel not available"]
          };
          return;
        }
        try {
          const issues = [];
          const queueStats = [];
          let totalMessages = 0;
          let totalConsumers = 0;
          const modernQueues = [
            Queues.LoanCreate,
            Queues.LoanUpdate,
            Queues.PaymentProcess,
            Queues.PaymentAllocate,
            Queues.EscrowDisburse,
            Queues.DocumentProcess,
            Queues.EtlSchedule,
            Queues.EtlJob,
            Queues.StatusUpdate
          ];
          for (const queueName of modernQueues) {
            try {
              const queueInfo = await this.channel.checkQueue(queueName);
              const stats = {
                name: queueName,
                messageCount: queueInfo.messageCount,
                consumerCount: queueInfo.consumerCount,
                state: this.getQueueState(queueInfo.messageCount, queueInfo.consumerCount)
              };
              queueStats.push(stats);
              totalMessages += queueInfo.messageCount;
              totalConsumers += queueInfo.consumerCount;
              if (queueInfo.messageCount > 100) {
                issues.push(`Queue ${queueName} has high message backlog: ${queueInfo.messageCount}`);
              }
              if (queueInfo.consumerCount === 0 && queueInfo.messageCount > 0) {
                issues.push(`Queue ${queueName} has messages but no consumers`);
              }
            } catch (error) {
              issues.push(`Failed to check queue ${queueName}: ${error.message}`);
            }
          }
          let status = "healthy";
          if (issues.length > 0) {
            const criticalIssues = issues.filter(
              (issue) => issue.includes("no consumers") || issue.includes("Failed to check")
            );
            if (criticalIssues.length > 0) {
              status = "critical";
            } else {
              status = "warning";
            }
          }
          this.currentHealth = {
            status,
            queues: queueStats,
            totalMessages,
            totalConsumers,
            connectionStatus: "connected",
            lastUpdated: (/* @__PURE__ */ new Date()).toISOString(),
            issues
          };
          if (status !== "healthy") {
            console.log(`[Queue Monitor] Health Status: ${status.toUpperCase()}`, {
              totalMessages,
              totalConsumers,
              issueCount: issues.length,
              issues: issues.slice(0, 3)
              // Log first 3 issues
            });
          }
        } catch (error) {
          console.error("[Queue Monitor] Error updating health status:", error);
          this.currentHealth = {
            status: "critical",
            queues: [],
            totalMessages: 0,
            totalConsumers: 0,
            connectionStatus: "error",
            lastUpdated: (/* @__PURE__ */ new Date()).toISOString(),
            issues: [`Health check failed: ${error.message}`]
          };
        }
      }
      /**
       * Determine queue state based on activity
       */
      getQueueState(messageCount, consumerCount) {
        if (messageCount > 0 && consumerCount > 0) {
          return "flow";
        } else if (consumerCount > 0) {
          return "running";
        } else {
          return "idle";
        }
      }
      /**
       * Get current health status
       */
      getHealth() {
        return { ...this.currentHealth };
      }
      /**
       * Get detailed queue metrics
       */
      async getDetailedMetrics() {
        await this.updateHealth();
        return {
          queues: this.currentHealth.queues,
          processing_rates: {},
          error_rates: {},
          avg_processing_time: {}
        };
      }
      /**
       * Force health check update
       */
      async refreshHealth() {
        await this.updateHealth();
        return this.getHealth();
      }
      /**
       * Stop monitoring
       */
      stop() {
        if (this.monitoringInterval) {
          clearInterval(this.monitoringInterval);
          this.monitoringInterval = null;
        }
        if (this.channel) {
          this.channel.close().catch(
            (err) => console.error("[Queue Monitor] Error closing channel:", err)
          );
        }
        console.log("[Queue Monitor] Monitoring stopped");
      }
    };
    globalQueueMonitor = new QueueMonitor();
  }
});

// server/routes/queue-health.ts
var queue_health_exports = {};
__export(queue_health_exports, {
  default: () => queue_health_default
});
import { Router as Router26 } from "express";
var router21, queue_health_default;
var init_queue_health = __esm({
  "server/routes/queue-health.ts"() {
    "use strict";
    init_middleware();
    init_queue_monitor();
    router21 = Router26();
    router21.get("/queue-health", requireAuth2, async (req, res) => {
      try {
        const health = globalQueueMonitor.getHealth();
        res.json({
          success: true,
          data: health,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Queue Health API] Error getting health status:", error);
        res.status(500).json({
          success: false,
          error: "Failed to retrieve queue health status",
          message: error.message
        });
      }
    });
    router21.get("/queue-health/detailed", requireAuth2, async (req, res) => {
      try {
        const metrics2 = await globalQueueMonitor.getDetailedMetrics();
        res.json({
          success: true,
          data: metrics2,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Queue Health API] Error getting detailed metrics:", error);
        res.status(500).json({
          success: false,
          error: "Failed to retrieve detailed queue metrics",
          message: error.message
        });
      }
    });
    router21.post("/queue-health/refresh", requireAuth2, async (req, res) => {
      try {
        const health = await globalQueueMonitor.refreshHealth();
        res.json({
          success: true,
          data: health,
          message: "Queue health metrics refreshed successfully",
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Queue Health API] Error refreshing health status:", error);
        res.status(500).json({
          success: false,
          error: "Failed to refresh queue health metrics",
          message: error.message
        });
      }
    });
    router21.get("/queue-health/status", async (req, res) => {
      try {
        const health = globalQueueMonitor.getHealth();
        res.status(health.status === "healthy" ? 200 : health.status === "warning" ? 200 : 503).json({
          status: health.status,
          message: health.status === "healthy" ? "All queue systems operating normally" : `Queue system issues detected: ${health.issues.length} issues`,
          queues_active: health.totalConsumers > 0,
          messages_pending: health.totalMessages,
          last_check: health.lastUpdated
        });
      } catch (error) {
        console.error("[Queue Health API] Error in status check:", error);
        res.status(503).json({
          status: "critical",
          message: "Queue monitoring system unavailable",
          error: error.message
        });
      }
    });
    queue_health_default = router21;
  }
});

// server/routes/microservice-api.ts
var microservice_api_exports = {};
__export(microservice_api_exports, {
  default: () => microservice_api_default
});
import { Router as Router27 } from "express";
import { ulid as ulid4 } from "ulid";
import { z as z11 } from "zod";
var router22, MICROSERVICES, CreatePaymentSchema, CreateDisbursementSchema, microservice_api_default;
var init_microservice_api = __esm({
  "server/routes/microservice-api.ts"() {
    "use strict";
    init_middleware();
    router22 = Router27();
    MICROSERVICES = [
      {
        name: "payment-service",
        version: "1.0.0",
        capabilities: ["payment.processing", "payment.allocation", "payment.validation"],
        endpoints: ["/api/v3/payments", "/api/v3/payments/allocate"],
        health_status: "healthy",
        last_check: (/* @__PURE__ */ new Date()).toISOString()
      },
      {
        name: "document-service",
        version: "1.0.0",
        capabilities: ["document.upload", "document.ocr", "document.ai_analysis"],
        endpoints: ["/api/v3/documents/upload", "/api/v3/documents/process"],
        health_status: "healthy",
        last_check: (/* @__PURE__ */ new Date()).toISOString()
      },
      {
        name: "escrow-service",
        version: "1.0.0",
        capabilities: ["escrow.disbursement", "escrow.analysis", "escrow.balance_management"],
        endpoints: ["/api/v3/escrow/disbursements", "/api/v3/escrow/analysis"],
        health_status: "healthy",
        last_check: (/* @__PURE__ */ new Date()).toISOString()
      },
      {
        name: "loan-service",
        version: "1.0.0",
        capabilities: ["loan.management", "loan.lifecycle", "loan.reporting"],
        endpoints: ["/api/v3/loans", "/api/v3/loans/metrics"],
        health_status: "healthy",
        last_check: (/* @__PURE__ */ new Date()).toISOString()
      }
    ];
    router22.get("/v3/gateway/health", requireAuth2, (req, res) => {
      const totalServices = MICROSERVICES.length;
      const healthyServices = MICROSERVICES.filter((s) => s.health_status === "healthy").length;
      const degradedServices = MICROSERVICES.filter((s) => s.health_status === "degraded").length;
      const unhealthyServices = MICROSERVICES.filter((s) => s.health_status === "unhealthy").length;
      res.json({
        status: "healthy",
        gateway: {
          name: "api-gateway",
          version: "1.0.0",
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          uptime_seconds: Math.floor(process.uptime())
        },
        services: {
          total: totalServices,
          healthy: healthyServices,
          degraded: degradedServices,
          unhealthy: unhealthyServices,
          discovery_enabled: true,
          load_balancing: "round_robin"
        },
        microservices: MICROSERVICES.map((service) => ({
          service_name: service.name,
          version: service.version,
          status: service.health_status,
          capabilities: service.capabilities,
          endpoints: service.endpoints,
          last_health_check: service.last_check
        }))
      });
    });
    router22.get("/v3/gateway/services", requireAuth2, (req, res) => {
      const { capability, service_name, status } = req.query;
      let filteredServices = [...MICROSERVICES];
      if (capability) {
        filteredServices = filteredServices.filter(
          (service) => service.capabilities.includes(capability)
        );
      }
      if (service_name) {
        filteredServices = filteredServices.filter(
          (service) => service.name === service_name
        );
      }
      if (status) {
        filteredServices = filteredServices.filter(
          (service) => service.health_status === status
        );
      }
      res.json({
        success: true,
        services: filteredServices,
        total: filteredServices.length,
        filters_applied: {
          capability: capability || null,
          service_name: service_name || null,
          status: status || null
        }
      });
    });
    CreatePaymentSchema = z11.object({
      loan_id: z11.number(),
      payment_method: z11.enum(["ach", "wire", "check", "card", "manual"]),
      amount_cents: z11.number().positive(),
      payment_date: z11.string(),
      reference_number: z11.string().optional(),
      notes: z11.string().optional()
    });
    router22.post("/v3/payments/async", requireAuth2, async (req, res) => {
      try {
        const paymentData = CreatePaymentSchema.parse(req.body);
        const paymentId = ulid4();
        const correlationId = ulid4();
        const { createEnvelope: createEnvelope2 } = await Promise.resolve().then(() => (init_envelope_helpers(), envelope_helpers_exports));
        const { Exchanges: Exchanges3 } = await Promise.resolve().then(() => (init_topology(), topology_exports));
        const paymentMessage = {
          payment_id: paymentId,
          loan_id: paymentData.loan_id,
          source: paymentData.payment_method,
          amount_cents: paymentData.amount_cents,
          payment_date: paymentData.payment_date,
          reference_number: paymentData.reference_number,
          notes: paymentData.notes,
          processing_options: {
            validate_loan: true,
            check_balances: true,
            apply_waterfall: true,
            update_escrow: true
          }
        };
        const envelope = createEnvelope2({
          tenantId: "default",
          correlationId,
          payload: paymentMessage
        });
        console.log("[Payment Microservice] Payment processed:", {
          paymentId,
          correlationId,
          loanId: paymentData.loan_id,
          amount: paymentData.amount_cents
        });
        console.log("[Payment Microservice] Payment queued for processing:", {
          paymentId,
          correlationId,
          loanId: paymentData.loan_id,
          amount: paymentData.amount_cents
        });
        res.status(202).json({
          success: true,
          service: "payment-service",
          payment_id: paymentId,
          correlation_id: correlationId,
          status: "queued",
          message: "Payment submitted to payment processing queue",
          endpoints: {
            status: `/api/v3/payments/${paymentId}/status`,
            service_health: "/api/v3/gateway/services?service_name=payment-service"
          }
        });
      } catch (error) {
        console.error("[Payment Microservice] Error:", error);
        res.status(400).json({
          success: false,
          service: "payment-service",
          error: error instanceof Error ? error.message : "Unknown error",
          service_status: "degraded"
        });
      }
    });
    router22.post("/v3/documents/upload", requireAuth2, async (req, res) => {
      try {
        const { loan_id, processing_type = "full", file_path, file_name, mime_type, file_size } = req.body;
        if (!loan_id || !file_path || !file_name) {
          return res.status(400).json({
            success: false,
            service: "document-service",
            error: "loan_id, file_path, and file_name are required"
          });
        }
        const documentId = ulid4();
        const correlationId = ulid4();
        const { createEnvelope: createEnvelope2 } = await Promise.resolve().then(() => (init_envelope_helpers(), envelope_helpers_exports));
        const { Exchanges: Exchanges3 } = await Promise.resolve().then(() => (init_topology(), topology_exports));
        const documentMessage = {
          document_id: documentId,
          loan_id: parseInt(loan_id),
          file_path,
          file_name,
          mime_type: mime_type || "application/pdf",
          file_size: file_size || 0,
          processing_type,
          uploaded_by: req.user?.id,
          ocr_language: "en",
          extract_tables: processing_type === "full",
          analyze_content: ["ai_analysis", "full"].includes(processing_type),
          classify_document: ["classification", "full"].includes(processing_type),
          extract_datapoints: processing_type === "full"
        };
        const docEnvelope = createEnvelope2({
          tenantId: "default",
          correlationId,
          payload: documentMessage
        });
        console.log("[Document Microservice] Document processed:", {
          documentId,
          correlationId,
          loanId: loan_id,
          processingType: processing_type
        });
        console.log("[Document Microservice] Document queued for processing:", {
          documentId,
          correlationId,
          loanId: loan_id,
          processingType: processing_type
        });
        res.status(202).json({
          success: true,
          service: "document-service",
          document_id: documentId,
          correlation_id: correlationId,
          status: "queued",
          processing_type,
          message: "Document submitted to document processing queue",
          endpoints: {
            status: `/api/v3/documents/${documentId}/status`,
            service_health: "/api/v3/gateway/services?service_name=document-service"
          }
        });
      } catch (error) {
        console.error("[Document Microservice] Error:", error);
        res.status(400).json({
          success: false,
          service: "document-service",
          error: error instanceof Error ? error.message : "Unknown error"
        });
      }
    });
    CreateDisbursementSchema = z11.object({
      loan_id: z11.number(),
      disbursement_type: z11.enum(["property_tax", "homeowners_insurance", "flood_insurance", "pmi", "hoa_fee", "other"]),
      payee_name: z11.string(),
      amount_cents: z11.number().positive(),
      due_date: z11.string()
    });
    router22.post("/v3/escrow/disbursements", requireAuth2, async (req, res) => {
      try {
        const disbursementData = CreateDisbursementSchema.parse(req.body);
        const disbursementId = ulid4();
        const correlationId = ulid4();
        const { createEnvelope: createEnvelope2 } = await Promise.resolve().then(() => (init_envelope_helpers(), envelope_helpers_exports));
        const { Exchanges: Exchanges3 } = await Promise.resolve().then(() => (init_topology(), topology_exports));
        const disbursementMessage = {
          disbursement_id: disbursementId,
          loan_id: disbursementData.loan_id,
          disbursement_type: disbursementData.disbursement_type,
          payee_name: disbursementData.payee_name,
          amount_cents: disbursementData.amount_cents,
          due_date: disbursementData.due_date,
          created_by: req.user?.id,
          processing_options: {
            validate_balance: true,
            check_approval: true,
            generate_check: true,
            update_escrow: true
          }
        };
        const envelope = createEnvelope2({
          tenantId: "default",
          correlationId,
          payload: disbursementMessage
        });
        const escrowEnvelope = createEnvelope2({
          tenantId: "default",
          correlationId,
          payload: disbursementMessage
        });
        console.log("[Escrow Microservice] Disbursement processed:", {
          disbursementId,
          correlationId,
          loanId: disbursementData.loan_id,
          payeeName: disbursementData.payee_name,
          amount: disbursementData.amount_cents
        });
        console.log("[Escrow Microservice] Disbursement queued for processing:", {
          disbursementId,
          correlationId,
          loanId: disbursementData.loan_id,
          payeeName: disbursementData.payee_name,
          amount: disbursementData.amount_cents
        });
        res.status(202).json({
          success: true,
          service: "escrow-service",
          disbursement_id: disbursementId,
          correlation_id: correlationId,
          status: "queued",
          disbursement_type: disbursementData.disbursement_type,
          payee_name: disbursementData.payee_name,
          amount_cents: disbursementData.amount_cents,
          message: "Disbursement submitted to escrow processing queue",
          endpoints: {
            status: `/api/v3/escrow/disbursements/${disbursementId}/status`,
            service_health: "/api/v3/gateway/services?service_name=escrow-service"
          }
        });
      } catch (error) {
        console.error("[Escrow Microservice] Error:", error);
        res.status(400).json({
          success: false,
          service: "escrow-service",
          error: error instanceof Error ? error.message : "Unknown error"
        });
      }
    });
    router22.get("/v3/gateway/load-balancer", requireAuth2, (req, res) => {
      const routes = [
        {
          path: "/api/v3/payments/*",
          service: "payment-service",
          healthy_instances: 1,
          load_balancing: "round_robin",
          circuit_breaker: "closed"
        },
        {
          path: "/api/v3/documents/*",
          service: "document-service",
          healthy_instances: 1,
          load_balancing: "round_robin",
          circuit_breaker: "closed"
        },
        {
          path: "/api/v3/escrow/*",
          service: "escrow-service",
          healthy_instances: 1,
          load_balancing: "round_robin",
          circuit_breaker: "closed"
        }
      ];
      res.json({
        success: true,
        gateway_version: "1.0.0",
        load_balancing_strategy: "round_robin",
        circuit_breaker_enabled: true,
        request_timeout_ms: 3e4,
        routes,
        total_routes: routes.length,
        total_healthy_instances: routes.reduce((sum3, route) => sum3 + route.healthy_instances, 0)
      });
    });
    microservice_api_default = router22;
  }
});

// server/services/column-api-client.ts
import axios2 from "axios";
import crypto8 from "crypto";
var COLUMN_API_BASE, COLUMN_API_KEY, COLUMN_API_SECRET, COLUMN_WEBHOOK_SECRET, ColumnAPIClient, columnClient;
var init_column_api_client = __esm({
  "server/services/column-api-client.ts"() {
    "use strict";
    COLUMN_API_BASE = process.env.COLUMN_API_BASE || "https://api.column.com";
    COLUMN_API_KEY = process.env.COLUMN_API_KEY || "";
    COLUMN_API_SECRET = process.env.COLUMN_API_SECRET || "";
    COLUMN_WEBHOOK_SECRET = process.env.COLUMN_WEBHOOK_SECRET || "";
    ColumnAPIClient = class {
      client;
      apiKey;
      apiSecret;
      webhookSecret;
      constructor() {
        this.apiKey = COLUMN_API_KEY;
        this.apiSecret = COLUMN_API_SECRET;
        this.webhookSecret = COLUMN_WEBHOOK_SECRET;
        if (!this.apiKey || !this.apiSecret) {
          console.warn("[Column] API credentials not configured");
        }
        this.client = axios2.create({
          baseURL: COLUMN_API_BASE,
          headers: {
            "Content-Type": "application/json",
            "X-API-Key": this.apiKey
          },
          timeout: 3e4
        });
        this.client.interceptors.request.use(
          (config) => {
            const timestamp2 = Date.now().toString();
            const payload = config.data ? JSON.stringify(config.data) : "";
            const signature = this.generateSignature(timestamp2, payload);
            config.headers["X-Timestamp"] = timestamp2;
            config.headers["X-Signature"] = signature;
            return config;
          },
          (error) => Promise.reject(error)
        );
        this.client.interceptors.response.use(
          (response) => response,
          async (error) => {
            const { response } = error;
            if (response) {
              console.error(`[Column] API Error ${response.status}:`, response.data);
              if (response.status === 401) {
                console.error("[Column] Authentication failed - check API credentials");
              } else if (response.status === 429) {
                console.error("[Column] Rate limited - implement retry logic");
              }
            } else {
              console.error("[Column] Network error:", error.message);
            }
            return Promise.reject(error);
          }
        );
      }
      /**
       * Generate HMAC signature for request authentication
       */
      generateSignature(timestamp2, payload) {
        const message = `${timestamp2}.${payload}`;
        return crypto8.createHmac("sha256", this.apiSecret).update(message).digest("hex");
      }
      /**
       * Verify webhook signature
       */
      verifyWebhookSignature(payload, signature, timestamp2) {
        const expectedSignature = crypto8.createHmac("sha256", this.webhookSecret).update(`${timestamp2}.${payload}`).digest("hex");
        const sig1 = Buffer.from(signature || "");
        const sig2 = Buffer.from(expectedSignature);
        if (sig1.length !== sig2.length) {
          return false;
        }
        return crypto8.timingSafeEqual(sig1, sig2);
      }
      /**
       * Create a new bank account
       */
      async createAccount(params) {
        console.log("[Column] Creating account:", params.holder_name);
        const response = await this.client.post("/v1/accounts", params);
        return response.data;
      }
      /**
       * Get account details
       */
      async getAccount(accountId) {
        const response = await this.client.get(`/v1/accounts/${accountId}`);
        return response.data;
      }
      /**
       * List all accounts
       */
      async listAccounts(params) {
        const response = await this.client.get("/v1/accounts", { params });
        return response.data.accounts || [];
      }
      /**
       * Get account balance
       */
      async getBalance(accountId) {
        const account = await this.getAccount(accountId);
        return account.balance;
      }
      /**
       * Create a transfer (ACH, wire, or book)
       */
      async createTransfer(params) {
        console.log(`[Column] Creating ${params.type} transfer:`, params.reference_id);
        if (params.type === "book") {
          if (!params.source_account_id || !params.destination_account_id) {
            throw new Error("Book transfers require source and destination account IDs");
          }
        } else {
          if (params.direction === "debit" && !params.source_account_id) {
            throw new Error("Debit transfers require source account ID");
          }
          if (params.direction === "credit" && !params.destination_account_id && !params.external_account) {
            throw new Error("Credit transfers require destination account or external account");
          }
        }
        const response = await this.client.post("/v1/transfers", params);
        return response.data;
      }
      /**
       * Get transfer details
       */
      async getTransfer(transferId) {
        const response = await this.client.get(`/v1/transfers/${transferId}`);
        return response.data;
      }
      /**
       * List transfers
       */
      async listTransfers(params) {
        const response = await this.client.get("/v1/transfers", { params });
        return response.data.transfers || [];
      }
      /**
       * Cancel a pending transfer
       */
      async cancelTransfer(transferId) {
        console.log(`[Column] Cancelling transfer: ${transferId}`);
        const response = await this.client.post(`/v1/transfers/${transferId}/cancel`);
        return response.data;
      }
      /**
       * Get transaction history
       */
      async getTransactions(params) {
        const response = await this.client.get("/v1/transactions", { params });
        return response.data.transactions || [];
      }
      /**
       * Create a payment link for customer payment collection
       */
      async createPaymentLink(params) {
        console.log("[Column] Creating payment link:", params.reference_id);
        const response = await this.client.post("/v1/payment_links", params);
        return response.data;
      }
      /**
       * Validate account and routing numbers
       */
      async validateAccount(params) {
        try {
          const response = await this.client.post("/v1/validate/account", params);
          return response.data;
        } catch (error) {
          console.error("[Column] Account validation failed:", error);
          return { valid: false };
        }
      }
      /**
       * Get webhook events
       */
      async getWebhookEvents(params) {
        const response = await this.client.get("/v1/webhook_events", { params });
        return response.data.events || [];
      }
      /**
       * Retry a webhook event
       */
      async retryWebhookEvent(eventId) {
        await this.client.post(`/v1/webhook_events/${eventId}/retry`);
      }
      /**
       * Health check
       */
      async healthCheck() {
        try {
          const response = await this.client.get("/v1/health");
          return response.data;
        } catch (error) {
          return {
            status: "down",
            services: {}
          };
        }
      }
    };
    columnClient = new ColumnAPIClient();
  }
});

// server/services/column-bank-service.ts
import { eq as eq24, and as and20, isNotNull } from "drizzle-orm";
import crypto9 from "crypto";
import { randomUUID as randomUUID10 } from "crypto";
var ColumnBankService, columnBankService;
var init_column_bank_service = __esm({
  "server/services/column-bank-service.ts"() {
    "use strict";
    init_db();
    init_schema();
    init_column_api_client();
    ColumnBankService = class {
      masterAccountId;
      escrowAccountId;
      operatingAccountId;
      constructor() {
        this.masterAccountId = process.env.COLUMN_MASTER_ACCOUNT_ID;
        this.escrowAccountId = process.env.COLUMN_ESCROW_ACCOUNT_ID;
        this.operatingAccountId = process.env.COLUMN_OPERATING_ACCOUNT_ID;
      }
      /**
       * Initialize Column accounts
       */
      async initializeAccounts() {
        console.log("[ColumnBank] Initializing accounts");
        if (!this.masterAccountId) {
          const masterAccount = await columnClient.createAccount({
            type: "checking",
            holder_name: "LoanServe Pro Master",
            holder_type: "business",
            metadata: {
              account_type: "master",
              created_at: (/* @__PURE__ */ new Date()).toISOString()
            }
          });
          this.masterAccountId = masterAccount.id;
          console.log(`[ColumnBank] Created master account: ${this.masterAccountId}`);
        }
        if (!this.escrowAccountId) {
          const escrowAccount = await columnClient.createAccount({
            type: "checking",
            holder_name: "LoanServe Pro Escrow",
            holder_type: "business",
            metadata: {
              account_type: "escrow",
              created_at: (/* @__PURE__ */ new Date()).toISOString()
            }
          });
          this.escrowAccountId = escrowAccount.id;
          console.log(`[ColumnBank] Created escrow account: ${this.escrowAccountId}`);
        }
        if (!this.operatingAccountId) {
          const operatingAccount = await columnClient.createAccount({
            type: "checking",
            holder_name: "LoanServe Pro Operating",
            holder_type: "business",
            metadata: {
              account_type: "operating",
              created_at: (/* @__PURE__ */ new Date()).toISOString()
            }
          });
          this.operatingAccountId = operatingAccount.id;
          console.log(`[ColumnBank] Created operating account: ${this.operatingAccountId}`);
        }
        console.log("[ColumnBank] Account initialization complete");
      }
      /**
       * Process webhook event from Column
       */
      async processWebhook(body, signature, timestamp2) {
        console.log("[ColumnBank] Processing webhook event");
        const event = JSON.parse(body);
        switch (event.type) {
          case "transfer.created":
          case "transfer.updated":
            await this.handleTransferEvent(event.data);
            break;
          case "account.updated":
            await this.handleAccountEvent(event.data);
            break;
          default:
            console.log(`[ColumnBank] Unhandled webhook event type: ${event.type}`);
        }
      }
      /**
       * Handle transfer webhook events
       */
      async handleTransferEvent(transfer) {
        console.log(`[ColumnBank] Handling transfer event: ${transfer.id} (${transfer.status})`);
        if (transfer.direction === "credit" && transfer.status === "completed") {
          await this.processIncomingPayment(transfer);
        }
        if (transfer.status === "failed" || transfer.status === "cancelled") {
          console.warn(`[ColumnBank] Transfer failed: ${transfer.id}`, transfer);
        }
      }
      /**
       * Handle account webhook events
       */
      async handleAccountEvent(account) {
        console.log(`[ColumnBank] Account updated: ${account.id}`);
      }
      /**
       * Create a borrower account for a loan
       */
      async createBorrowerAccount(loanId, borrowerName) {
        console.log(`[ColumnBank] Creating borrower account for loan ${loanId}`);
        const account = await columnClient.createAccount({
          type: "checking",
          holder_name: borrowerName,
          holder_type: "individual",
          metadata: {
            loan_id: loanId,
            account_type: "borrower",
            created_at: (/* @__PURE__ */ new Date()).toISOString()
          }
        });
        const ingestionId = randomUUID10();
        const accountData = JSON.stringify(account);
        await db.insert(paymentIngestions).values({
          id: ingestionId,
          idempotencyKey: `column-account-${account.id}`,
          channel: "column",
          sourceReference: account.id,
          rawPayloadHash: crypto9.createHash("sha256").update(accountData).digest("hex"),
          artifactUri: [`column://accounts/${account.id}`],
          artifactHash: [crypto9.createHash("sha256").update(accountData).digest("hex")],
          receivedAt: /* @__PURE__ */ new Date(),
          normalizedEnvelope: {
            type: "account_creation",
            account_id: account.id,
            loan_id: loanId
          },
          status: "normalized"
        });
        await db.insert(paymentArtifacts).values({
          id: randomUUID10(),
          ingestionId,
          type: "column_account",
          uri: `column://accounts/${account.id}`,
          sha256: crypto9.createHash("sha256").update(JSON.stringify(account)).digest("hex"),
          sizeBytes: Buffer.byteLength(JSON.stringify(account)),
          mime: "application/json",
          sourceMetadata: {
            account_id: account.id,
            account_number: account.account_number,
            routing_number: account.routing_number,
            loan_id: loanId
          }
        });
        return {
          accountId: account.id,
          accountNumber: account.account_number,
          routingNumber: account.routing_number,
          balance: account.balance
        };
      }
      /**
       * Process incoming payment from Column webhook
       */
      async processIncomingPayment(transfer) {
        console.log(`[ColumnBank] Processing incoming payment: ${transfer.id}`);
        const loanId = transfer.metadata?.loan_id || this.parseLoanIdFromReference(transfer.reference_id || "");
        if (!loanId) {
          console.warn(`[ColumnBank] No loan ID found for transfer ${transfer.id}`);
          return;
        }
        const ingestionId = randomUUID10();
        const transferData = JSON.stringify(transfer);
        const idempotencyKey = `column-${transfer.id}`;
        const envelope = {
          message_id: randomUUID10(),
          correlation_id: randomUUID10(),
          idempotency_key: idempotencyKey,
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          source: {
            channel: "column",
            account: transfer.source_account_id || "external"
          },
          payment: {
            value_date: transfer.created_at,
            reference: transfer.reference_id || transfer.id
          },
          borrower: {
            loan_id: String(loanId)
          },
          amount_cents: Math.round(transfer.amount * 100),
          // Convert to cents
          method: transfer.type,
          external: {
            column_transfer_id: transfer.id,
            column_status: transfer.status
          }
        };
        await db.insert(paymentIngestions).values({
          id: ingestionId,
          idempotencyKey,
          channel: transfer.type.toLowerCase(),
          sourceReference: transfer.id,
          rawPayloadHash: crypto9.createHash("sha256").update(transferData).digest("hex"),
          artifactUri: [`column://transfers/${transfer.id}`],
          artifactHash: [crypto9.createHash("sha256").update(transferData).digest("hex")],
          receivedAt: /* @__PURE__ */ new Date(),
          normalizedEnvelope: envelope,
          status: "normalized"
        });
        const artifactId = randomUUID10();
        await db.insert(paymentArtifacts).values({
          id: artifactId,
          ingestionId,
          type: "column_transfer",
          uri: `column://transfers/${transfer.id}`,
          sha256: crypto9.createHash("sha256").update(JSON.stringify(transfer)).digest("hex"),
          sizeBytes: Buffer.byteLength(JSON.stringify(transfer)),
          mime: "application/json",
          sourceMetadata: {
            transfer_id: transfer.id,
            transfer_status: transfer.status,
            transfer,
            processed_at: (/* @__PURE__ */ new Date()).toISOString()
          }
        });
        await db.insert(outboxMessages).values({
          id: randomUUID10(),
          aggregateType: "payments",
          aggregateId: randomUUID10(),
          eventType: "payment.received.column",
          payload: envelope,
          createdAt: /* @__PURE__ */ new Date(),
          publishedAt: null,
          attemptCount: 0,
          lastError: null
        });
        console.log(`[ColumnBank] Payment ingested for loan ${loanId}: ${transfer.id}`);
      }
      /**
       * Get settlement summary for a specific date
       */
      async getSettlementSummary(date2) {
        console.log(`[ColumnBank] Fetching settlement summary for ${date2}`);
        try {
          const startDate = /* @__PURE__ */ new Date(`${date2}T00:00:00Z`);
          const endDate = /* @__PURE__ */ new Date(`${date2}T23:59:59Z`);
          const dayPayments = await db.select({
            id: payments.columnTransferId,
            amount: payments.totalReceived,
            status: payments.status,
            effectiveDate: payments.effectiveDate,
            sourceChannel: payments.sourceChannel
          }).from(payments).where(
            and20(
              eq24(payments.effectiveDate, date2),
              eq24(payments.sourceChannel, "column"),
              isNotNull(payments.columnTransferId)
            )
          );
          let credits = 0;
          let debits = 0;
          const transactions = [];
          for (const payment of dayPayments) {
            const amount = parseFloat(payment.amount || "0") * 100;
            if (amount > 0) {
              credits += amount;
              transactions.push({
                id: payment.id || "",
                amount,
                type: "credit",
                reference: payment.columnTransferId || void 0
              });
            } else {
              debits += Math.abs(amount);
              transactions.push({
                id: payment.id || "",
                amount: Math.abs(amount),
                type: "debit",
                reference: payment.columnTransferId || void 0
              });
            }
          }
          return {
            date: date2,
            credits,
            debits,
            netTotal: credits - debits,
            transactionCount: transactions.length,
            transactions
          };
        } catch (error) {
          console.error(`[ColumnBank] Error fetching settlement summary:`, error);
          return {
            date: date2,
            credits: 0,
            debits: 0,
            netTotal: 0,
            transactionCount: 0,
            transactions: []
          };
        }
      }
      /**
       * Create outgoing transfer (disbursement)
       */
      async createDisbursement(params) {
        console.log(`[ColumnBank] Creating disbursement for loan ${params.loanId}`);
        const sourceAccountId = this.operatingAccountId;
        if (!sourceAccountId) {
          throw new Error("Operating account not configured");
        }
        const transferRequest = {
          type: params.type,
          direction: "debit",
          amount: params.amount,
          source_account_id: sourceAccountId,
          external_account: {
            account_number: params.recipientAccount.accountNumber,
            routing_number: params.recipientAccount.routingNumber,
            account_holder_name: params.recipientAccount.accountHolderName,
            account_type: params.recipientAccount.accountType || "checking"
          },
          description: params.description,
          reference_id: params.reference || `DISB-${params.loanId}-${Date.now()}`,
          metadata: {
            loan_id: params.loanId,
            disbursement_type: "loan_proceeds",
            created_at: (/* @__PURE__ */ new Date()).toISOString()
          }
        };
        const transfer = await columnClient.createTransfer(transferRequest);
        const disbursementIngestionId = randomUUID10();
        const transferData = JSON.stringify(transfer);
        await db.insert(paymentIngestions).values({
          id: disbursementIngestionId,
          idempotencyKey: `column-disb-${transfer.id}`,
          channel: params.type,
          sourceReference: transfer.id,
          rawPayloadHash: crypto9.createHash("sha256").update(transferData).digest("hex"),
          artifactUri: [`column://disbursements/${transfer.id}`],
          artifactHash: [crypto9.createHash("sha256").update(transferData).digest("hex")],
          receivedAt: /* @__PURE__ */ new Date(),
          normalizedEnvelope: {
            type: "disbursement",
            transfer_id: transfer.id,
            loan_id: params.loanId
          },
          status: "normalized"
        });
        await db.insert(paymentArtifacts).values({
          id: randomUUID10(),
          ingestionId: disbursementIngestionId,
          type: "column_disbursement",
          uri: `column://disbursements/${transfer.id}`,
          sha256: crypto9.createHash("sha256").update(JSON.stringify(transfer)).digest("hex"),
          sizeBytes: Buffer.byteLength(JSON.stringify(transfer)),
          mime: "application/json",
          sourceMetadata: {
            transfer_id: transfer.id,
            transfer,
            loan_id: params.loanId
          }
        });
        return {
          transferId: transfer.id,
          status: transfer.status,
          amount: transfer.amount,
          reference: transfer.reference_id || transfer.id
        };
      }
      /**
       * Create escrow disbursement
       */
      async createEscrowDisbursement(params) {
        console.log(`[ColumnBank] Creating escrow disbursement for loan ${params.loanId}`);
        const sourceAccountId = this.escrowAccountId;
        if (!sourceAccountId) {
          throw new Error("Escrow account not configured");
        }
        const transferRequest = {
          type: "ach",
          direction: "debit",
          amount: params.amount,
          source_account_id: sourceAccountId,
          external_account: {
            account_number: params.accountInfo.accountNumber,
            routing_number: params.accountInfo.routingNumber,
            account_holder_name: params.payee,
            account_type: params.accountInfo.accountType || "checking"
          },
          description: params.description,
          reference_id: `ESCROW-${params.loanId}-${Date.now()}`,
          metadata: {
            loan_id: params.loanId,
            disbursement_type: "escrow",
            payee: params.payee,
            created_at: (/* @__PURE__ */ new Date()).toISOString()
          }
        };
        const transfer = await columnClient.createTransfer(transferRequest);
        const escrowIngestionId = randomUUID10();
        const transferData = JSON.stringify(transfer);
        await db.insert(paymentIngestions).values({
          id: escrowIngestionId,
          idempotencyKey: `column-escrow-${transfer.id}`,
          channel: "ach",
          sourceReference: transfer.id,
          rawPayloadHash: crypto9.createHash("sha256").update(transferData).digest("hex"),
          artifactUri: [`column://escrow-disbursements/${transfer.id}`],
          artifactHash: [crypto9.createHash("sha256").update(transferData).digest("hex")],
          receivedAt: /* @__PURE__ */ new Date(),
          normalizedEnvelope: {
            type: "escrow_disbursement",
            transfer_id: transfer.id,
            loan_id: params.loanId,
            payee: params.payee
          },
          status: "normalized"
        });
        await db.insert(paymentArtifacts).values({
          id: randomUUID10(),
          ingestionId: escrowIngestionId,
          type: "column_escrow_disbursement",
          uri: `column://escrow-disbursements/${transfer.id}`,
          sha256: crypto9.createHash("sha256").update(JSON.stringify(transfer)).digest("hex"),
          sizeBytes: Buffer.byteLength(JSON.stringify(transfer)),
          mime: "application/json",
          sourceMetadata: {
            transfer_id: transfer.id,
            transfer,
            loan_id: params.loanId,
            payee: params.payee
          }
        });
        return {
          transferId: transfer.id,
          status: transfer.status,
          amount: transfer.amount,
          reference: transfer.reference_id || transfer.id
        };
      }
      /**
       * Get account balances
       */
      async getAccountBalances() {
        const balances = {};
        if (this.masterAccountId) {
          const account = await columnClient.getAccount(this.masterAccountId);
          balances.master = {
            available: account.available_balance,
            pending: account.pending_balance,
            ledger: account.balance
          };
        }
        if (this.escrowAccountId) {
          const account = await columnClient.getAccount(this.escrowAccountId);
          balances.escrow = {
            available: account.available_balance,
            pending: account.pending_balance,
            ledger: account.balance
          };
        }
        if (this.operatingAccountId) {
          const account = await columnClient.getAccount(this.operatingAccountId);
          balances.operating = {
            available: account.available_balance,
            pending: account.pending_balance,
            ledger: account.balance
          };
        }
        return balances;
      }
      /**
       * Reconcile transactions for a given period
       */
      async reconcileTransactions(accountId, startDate, endDate) {
        console.log(`[ColumnBank] Reconciling transactions for account ${accountId}`);
        const transactions = await columnClient.listTransactions({
          account_id: accountId,
          created_after: startDate,
          created_before: endDate
        });
        let totalDebits = 0;
        let totalCredits = 0;
        for (const tx of transactions) {
          if (tx.direction === "debit") {
            totalDebits += tx.amount;
          } else {
            totalCredits += tx.amount;
          }
        }
        const netChange = totalCredits - totalDebits;
        const account = await columnClient.getAccount(accountId);
        const currentBalance = account.balance;
        const reconciled = true;
        return {
          transactionCount: transactions.length,
          totalDebits,
          totalCredits,
          netChange,
          reconciled
        };
      }
      /**
       * Parse loan ID from reference string
       */
      parseLoanIdFromReference(reference) {
        const patterns = [
          /LOAN-(\d+)/i,
          /loan#(\d+)/i,
          /loan\s+(\d+)/i,
          /^(\d+)$/
        ];
        for (const pattern of patterns) {
          const match = reference.match(pattern);
          if (match && match[1]) {
            return parseInt(match[1], 10);
          }
        }
        return null;
      }
      /**
       * Health check for Column integration
       */
      async healthCheck() {
        try {
          const accounts = await columnClient.listAccounts();
          return {
            status: "healthy",
            accounts: accounts.length > 0,
            api: true
          };
        } catch (error) {
          console.error("[ColumnBank] Health check failed:", error);
          let apiAccessible = false;
          try {
            await columnClient.validateAccount({
              account_number: "000000000",
              routing_number: "000000000"
            });
            apiAccessible = true;
          } catch {
            apiAccessible = false;
          }
          return {
            status: apiAccessible ? "degraded" : "unhealthy",
            accounts: false,
            api: apiAccessible
          };
        }
      }
    };
    columnBankService = new ColumnBankService();
  }
});

// server/routes/column-webhooks.ts
var column_webhooks_exports = {};
__export(column_webhooks_exports, {
  default: () => column_webhooks_default
});
import { Router as Router28 } from "express";
var router23, column_webhooks_default;
var init_column_webhooks = __esm({
  "server/routes/column-webhooks.ts"() {
    "use strict";
    init_column_bank_service();
    init_column_api_client();
    router23 = Router28();
    router23.post("/api/webhooks/column", async (req, res) => {
      console.log("[ColumnWebhook] Received webhook event");
      try {
        const rawBody = JSON.stringify(req.body);
        const signature = req.headers["x-column-signature"];
        const timestamp2 = req.headers["x-column-timestamp"];
        if (!signature || !timestamp2) {
          console.error("[ColumnWebhook] Missing signature or timestamp headers");
          return res.status(401).json({ error: "Missing authentication headers" });
        }
        const isValid = columnClient.verifyWebhookSignature(rawBody, signature, timestamp2);
        if (!isValid) {
          console.error("[ColumnWebhook] Invalid webhook signature");
          return res.status(401).json({ error: "Invalid signature" });
        }
        const webhookTime = parseInt(timestamp2);
        const currentTime = Date.now();
        if (Math.abs(currentTime - webhookTime) > 3e5) {
          console.error("[ColumnWebhook] Webhook timestamp too old");
          return res.status(401).json({ error: "Timestamp expired" });
        }
        await columnBankService.processWebhook(rawBody, signature, timestamp2);
        res.status(200).json({ received: true });
      } catch (error) {
        console.error("[ColumnWebhook] Error processing webhook:", error);
        res.status(200).json({
          received: true,
          error: "Processing error logged"
        });
      }
    });
    router23.post("/api/column/payment-link", async (req, res) => {
      try {
        const { loanId, amount, description } = req.body;
        if (!loanId || !amount) {
          return res.status(400).json({
            error: "Missing required fields: loanId, amount"
          });
        }
        const accountId = process.env.COLUMN_OPERATING_ACCOUNT_ID;
        if (!accountId) {
          return res.status(500).json({
            error: "Payment account not configured"
          });
        }
        const link = await columnClient.createPaymentLink({
          amount,
          description: description || `Payment for Loan ${loanId}`,
          reference_id: `LOAN-${loanId}-${Date.now()}`,
          destination_account_id: accountId,
          expires_at: new Date(Date.now() + 30 * 24 * 60 * 60 * 1e3).toISOString(),
          // 30 days
          metadata: {
            loan_id: loanId,
            created_at: (/* @__PURE__ */ new Date()).toISOString()
          }
        });
        res.json({
          success: true,
          paymentLink: link.url,
          linkId: link.id,
          expiresAt: link.expires_at
        });
      } catch (error) {
        console.error("[Column] Failed to create payment link:", error);
        res.status(500).json({
          error: "Failed to create payment link",
          details: error.message
        });
      }
    });
    router23.get("/api/column/balances", async (req, res) => {
      try {
        const balances = await columnBankService.getAccountBalances();
        res.json({
          success: true,
          balances,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Column] Failed to get balances:", error);
        res.status(500).json({
          error: "Failed to retrieve account balances",
          details: error.message
        });
      }
    });
    router23.post("/api/column/disbursement", async (req, res) => {
      try {
        const {
          loanId,
          amount,
          type = "ach",
          recipientAccount,
          description,
          reference
        } = req.body;
        if (!loanId || !amount || !recipientAccount) {
          return res.status(400).json({
            error: "Missing required fields: loanId, amount, recipientAccount"
          });
        }
        const result = await columnBankService.createDisbursement({
          loanId,
          amount,
          type,
          recipientAccount,
          description,
          reference
        });
        res.json({
          success: true,
          transfer: result,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Column] Failed to create disbursement:", error);
        res.status(500).json({
          error: "Failed to create disbursement",
          details: error.message
        });
      }
    });
    router23.post("/api/column/escrow-disbursement", async (req, res) => {
      try {
        const {
          loanId,
          amount,
          payee,
          description,
          accountInfo
        } = req.body;
        if (!loanId || !amount || !payee || !accountInfo) {
          return res.status(400).json({
            error: "Missing required fields: loanId, amount, payee, accountInfo"
          });
        }
        const result = await columnBankService.createEscrowDisbursement({
          loanId,
          amount,
          payee,
          description,
          accountInfo
        });
        res.json({
          success: true,
          transfer: result,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Column] Failed to create escrow disbursement:", error);
        res.status(500).json({
          error: "Failed to create escrow disbursement",
          details: error.message
        });
      }
    });
    router23.post("/api/column/reconcile", async (req, res) => {
      try {
        const {
          accountId,
          startDate,
          endDate
        } = req.body;
        if (!accountId || !startDate || !endDate) {
          return res.status(400).json({
            error: "Missing required fields: accountId, startDate, endDate"
          });
        }
        const result = await columnBankService.reconcileTransactions(
          accountId,
          startDate,
          endDate
        );
        res.json({
          success: true,
          reconciliation: result,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Column] Failed to reconcile transactions:", error);
        res.status(500).json({
          error: "Failed to reconcile transactions",
          details: error.message
        });
      }
    });
    router23.post("/api/column/validate-account", async (req, res) => {
      try {
        const { accountNumber, routingNumber } = req.body;
        if (!accountNumber || !routingNumber) {
          return res.status(400).json({
            error: "Missing required fields: accountNumber, routingNumber"
          });
        }
        const result = await columnClient.validateAccount({
          account_number: accountNumber,
          routing_number: routingNumber
        });
        res.json({
          success: true,
          validation: result,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Column] Failed to validate account:", error);
        res.status(500).json({
          error: "Failed to validate account",
          details: error.message
        });
      }
    });
    router23.get("/api/column/health", async (req, res) => {
      try {
        const health = await columnBankService.healthCheck();
        const statusCode = health.status === "healthy" ? 200 : 503;
        res.status(statusCode).json({
          ...health,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Column] Health check failed:", error);
        res.status(503).json({
          status: "unhealthy",
          error: error.message,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      }
    });
    router23.post("/api/column/initialize", async (req, res) => {
      try {
        await columnBankService.initializeAccounts();
        res.json({
          success: true,
          message: "Column accounts initialized",
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Column] Failed to initialize accounts:", error);
        res.status(500).json({
          error: "Failed to initialize accounts",
          details: error.message
        });
      }
    });
    column_webhooks_default = router23;
  }
});

// server/compliance/retentionPolicy.ts
import { eq as eq25, and as and21 } from "drizzle-orm";
import { v4 as uuidv43 } from "uuid";
var RetentionPolicyService, retentionPolicyService;
var init_retentionPolicy = __esm({
  "server/compliance/retentionPolicy.ts"() {
    "use strict";
    init_db();
    init_schema();
    init_hashChain();
    RetentionPolicyService = class {
      /**
       * Apply retention policies to data
       */
      async applyRetentionPolicies() {
        const policies = await db.select().from(retentionPolicy);
        for (const policy of policies) {
          await this.processRetentionPolicy(policy);
        }
      }
      /**
       * Process a single retention policy
       */
      async processRetentionPolicy(policy) {
        const cutoffDate = /* @__PURE__ */ new Date();
        cutoffDate.setDate(cutoffDate.getDate() - policy.maxRetentionDays);
        const holds = await this.checkLegalHolds(policy.dataClass);
        if (holds.length === 0) {
          await this.deleteDataByClass(policy.dataClass, cutoffDate);
        } else {
          console.log(`Skipping deletion for ${policy.dataClass} due to legal hold`);
        }
      }
      /**
       * Check if there are active legal holds for a data class
       */
      async checkLegalHolds(dataClass) {
        return await db.select().from(legalHold).where(
          and21(
            eq25(legalHold.scopeType, "artifact"),
            eq25(legalHold.active, true)
          )
        );
      }
      /**
       * Delete data based on class and cutoff date
       */
      async deleteDataByClass(dataClass, cutoffDate) {
        const correlationId = uuidv43();
        switch (dataClass) {
          case "PII.ID":
            await this.anonymizePII(cutoffDate, correlationId);
            break;
          case "FIN.TXN":
            await this.deleteFinancialTransactions(cutoffDate, correlationId);
            break;
          case "DOC.TEMP":
            await this.deleteTemporaryDocuments(cutoffDate, correlationId);
            break;
          default:
            console.log(`Unknown data class: ${dataClass}`);
        }
      }
      /**
       * Anonymize PII data
       */
      async anonymizePII(cutoffDate, correlationId) {
        await db.insert(deletionReceipt).values({
          dataClass: "PII.ID",
          payloadSummary: {
            action: "anonymization",
            cutoffDate: cutoffDate.toISOString(),
            affectedTables: ["borrower_entities", "users"]
          },
          responsibleActor: "SYSTEM.RETENTION_POLICY",
          recordHash: this.generateHash({
            dataClass: "PII.ID",
            cutoffDate: cutoffDate.toISOString(),
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          })
        });
        await hashChainService.createAuditEntry({
          correlationId,
          actorType: "system",
          actorId: "RETENTION_POLICY_ENGINE",
          eventType: "COMPLIANCE.PII_ANONYMIZED",
          resourceType: "pii_data",
          payloadJson: {
            dataClass: "PII.ID",
            cutoffDate: cutoffDate.toISOString()
          }
        });
      }
      /**
       * Delete financial transactions
       */
      async deleteFinancialTransactions(cutoffDate, correlationId) {
        await db.insert(deletionReceipt).values({
          dataClass: "FIN.TXN",
          payloadSummary: {
            action: "deletion",
            cutoffDate: cutoffDate.toISOString(),
            affectedTables: ["payments", "payment_allocations"]
          },
          responsibleActor: "SYSTEM.RETENTION_POLICY",
          recordHash: this.generateHash({
            dataClass: "FIN.TXN",
            cutoffDate: cutoffDate.toISOString(),
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          })
        });
        await hashChainService.createAuditEntry({
          correlationId,
          actorType: "system",
          actorId: "RETENTION_POLICY_ENGINE",
          eventType: "COMPLIANCE.FIN_TXN_DELETED",
          resourceType: "financial_transaction",
          payloadJson: {
            dataClass: "FIN.TXN",
            cutoffDate: cutoffDate.toISOString()
          }
        });
      }
      /**
       * Delete temporary documents
       */
      async deleteTemporaryDocuments(cutoffDate, correlationId) {
        await db.insert(deletionReceipt).values({
          dataClass: "DOC.TEMP",
          payloadSummary: {
            action: "deletion",
            cutoffDate: cutoffDate.toISOString(),
            affectedTables: ["documents"]
          },
          responsibleActor: "SYSTEM.RETENTION_POLICY",
          recordHash: this.generateHash({
            dataClass: "DOC.TEMP",
            cutoffDate: cutoffDate.toISOString(),
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          })
        });
        await hashChainService.createAuditEntry({
          correlationId,
          actorType: "system",
          actorId: "RETENTION_POLICY_ENGINE",
          eventType: "COMPLIANCE.DOC_DELETED",
          resourceType: "document",
          payloadJson: {
            dataClass: "DOC.TEMP",
            cutoffDate: cutoffDate.toISOString()
          }
        });
      }
      /**
       * Create a legal hold
       */
      async createLegalHold(data) {
        const correlationId = uuidv43();
        await db.insert(legalHold).values(data);
        await hashChainService.createAuditEntry({
          correlationId,
          actorType: "user",
          actorId: data.imposedBy,
          eventType: "COMPLIANCE.LEGAL_HOLD_CREATED",
          resourceType: "legal_hold",
          resourceId: data.scopeId,
          payloadJson: data
        });
      }
      /**
       * Release a legal hold
       */
      async releaseLegalHold(holdId, releasedBy) {
        const correlationId = uuidv43();
        await db.update(legalHold).set({
          active: false,
          releasedAt: /* @__PURE__ */ new Date()
        }).where(eq25(legalHold.id, holdId));
        await hashChainService.createAuditEntry({
          correlationId,
          actorType: "user",
          actorId: releasedBy,
          eventType: "COMPLIANCE.LEGAL_HOLD_RELEASED",
          resourceType: "legal_hold",
          resourceId: holdId,
          payloadJson: {
            holdId,
            releasedBy,
            releasedAt: (/* @__PURE__ */ new Date()).toISOString()
          }
        });
      }
      /**
       * Generate hash for deletion receipts
       */
      generateHash(data) {
        const crypto22 = __require("crypto");
        const hash = crypto22.createHash("sha256");
        hash.update(JSON.stringify(data));
        return hash.digest("hex");
      }
    };
    retentionPolicyService = new RetentionPolicyService();
  }
});

// server/compliance/index.ts
var compliance_exports = {};
__export(compliance_exports, {
  ConsentManagementService: () => ConsentManagementService,
  HashChainService: () => HashChainService,
  RetentionPolicyService: () => RetentionPolicyService,
  consentManagementService: () => consentManagementService,
  hashChainService: () => hashChainService,
  initializeComplianceScheduler: () => initializeComplianceScheduler,
  retentionPolicyService: () => retentionPolicyService
});
function initializeComplianceScheduler() {
  const runDailyAt2AM = () => {
    const now = /* @__PURE__ */ new Date();
    const next2AM = new Date(now);
    next2AM.setHours(2, 0, 0, 0);
    if (now >= next2AM) {
      next2AM.setDate(next2AM.getDate() + 1);
    }
    const msUntil2AM = next2AM.getTime() - now.getTime();
    setTimeout(async () => {
      console.log("[Compliance] Running retention policies...");
      try {
        await retentionPolicyService.applyRetentionPolicies();
        console.log("[Compliance] Retention policies applied successfully");
      } catch (error) {
        console.error("[Compliance] Error applying retention policies:", error);
      }
      runDailyAt2AM();
    }, msUntil2AM);
  };
  runDailyAt2AM();
  console.log("[Compliance] Scheduler initialized - will run daily at 2 AM");
}
var init_compliance = __esm({
  "server/compliance/index.ts"() {
    "use strict";
    init_hashChain();
    init_retentionPolicy();
    init_consentManagement();
    init_retentionPolicy();
  }
});

// server/routes/compliance.ts
var compliance_exports2 = {};
__export(compliance_exports2, {
  default: () => compliance_default
});
import { Router as Router29 } from "express";
import { eq as eq26, desc as desc11, and as and22, gte as gte6, lte as lte3, sql as sql16 } from "drizzle-orm";
import { z as z12 } from "zod";
var router24, compliance_default;
var init_compliance2 = __esm({
  "server/routes/compliance.ts"() {
    "use strict";
    init_db();
    init_compliance();
    init_schema();
    router24 = Router29();
    router24.get("/api/compliance/audit-log", async (req, res) => {
      try {
        const { startDate, endDate, eventType, resourceType, entityId, entityType, limit = 100 } = req.query;
        const conditions = [];
        if (entityId) {
          if (entityType === "loan") {
            conditions.push(eq26(complianceAuditLog.loanId, Number(entityId)));
          } else {
            conditions.push(eq26(complianceAuditLog.resourceId, String(entityId)));
          }
        }
        if (startDate) {
          conditions.push(gte6(complianceAuditLog.eventTsUtc, new Date(startDate)));
        }
        if (endDate) {
          conditions.push(lte3(complianceAuditLog.eventTsUtc, new Date(endDate)));
        }
        if (eventType) {
          conditions.push(eq26(complianceAuditLog.eventType, eventType));
        }
        if (resourceType) {
          conditions.push(eq26(complianceAuditLog.resourceType, resourceType));
        }
        const entries = conditions.length > 0 ? await db.select({
          id: complianceAuditLog.id,
          correlationId: complianceAuditLog.correlationId,
          accountId: complianceAuditLog.accountId,
          actorType: complianceAuditLog.actorType,
          actorId: complianceAuditLog.actorId,
          actorName: users.username,
          actorFullName: sql16`CONCAT(${users.firstName}, ' ', ${users.lastName})`,
          eventType: complianceAuditLog.eventType,
          eventTsUtc: complianceAuditLog.eventTsUtc,
          resourceType: complianceAuditLog.resourceType,
          resourceId: complianceAuditLog.resourceId,
          loanId: complianceAuditLog.loanId,
          payloadJson: complianceAuditLog.payloadJson,
          ipAddr: complianceAuditLog.ipAddr,
          userAgent: complianceAuditLog.userAgent,
          recordHash: complianceAuditLog.recordHash
        }).from(complianceAuditLog).leftJoin(users, sql16`${users.id}::text = ${complianceAuditLog.actorId}`).where(and22(...conditions)).orderBy(desc11(complianceAuditLog.eventTsUtc)).limit(Number(limit)) : await db.select({
          id: complianceAuditLog.id,
          correlationId: complianceAuditLog.correlationId,
          accountId: complianceAuditLog.accountId,
          actorType: complianceAuditLog.actorType,
          actorId: complianceAuditLog.actorId,
          actorName: users.username,
          actorFullName: sql16`CONCAT(${users.firstName}, ' ', ${users.lastName})`,
          eventType: complianceAuditLog.eventType,
          eventTsUtc: complianceAuditLog.eventTsUtc,
          resourceType: complianceAuditLog.resourceType,
          resourceId: complianceAuditLog.resourceId,
          loanId: complianceAuditLog.loanId,
          payloadJson: complianceAuditLog.payloadJson,
          ipAddr: complianceAuditLog.ipAddr,
          userAgent: complianceAuditLog.userAgent,
          recordHash: complianceAuditLog.recordHash
        }).from(complianceAuditLog).leftJoin(users, sql16`${users.id}::text = ${complianceAuditLog.actorId}`).orderBy(desc11(complianceAuditLog.eventTsUtc)).limit(Number(limit));
        res.json(entries);
      } catch (error) {
        console.error("Error fetching audit log:", error);
        res.status(500).json({ error: "Failed to fetch audit log" });
      }
    });
    router24.get("/api/compliance/audit-log/verify", async (req, res) => {
      try {
        const result = await hashChainService.verifyChainIntegrity();
        res.json(result);
      } catch (error) {
        console.error("Error verifying audit chain:", error);
        res.status(500).json({ error: "Failed to verify audit chain" });
      }
    });
    router24.post("/api/compliance/audit-log/generate-pack", async (req, res) => {
      try {
        const { startDate, endDate } = req.body;
        if (!startDate || !endDate) {
          return res.status(400).json({ error: "Start and end dates are required" });
        }
        const pack = await hashChainService.generateAuditPack(
          new Date(startDate),
          new Date(endDate)
        );
        res.json(pack);
      } catch (error) {
        console.error("Error generating audit pack:", error);
        res.status(500).json({ error: "Failed to generate audit pack" });
      }
    });
    router24.post("/api/compliance/consent", async (req, res) => {
      try {
        const consentSchema = z12.object({
          subjectId: z12.string(),
          purpose: z12.string(),
          scope: z12.string(),
          channel: z12.enum(["web", "email", "sms", "paper", "ivr"]),
          version: z12.string(),
          evidenceUri: z12.string().optional(),
          locale: z12.string().optional()
        });
        const data = consentSchema.parse(req.body);
        await consentManagementService.recordConsent(data);
        res.json({ success: true });
      } catch (error) {
        console.error("Error recording consent:", error);
        res.status(500).json({ error: "Failed to record consent" });
      }
    });
    router24.delete("/api/compliance/consent/:subjectId/:purpose", async (req, res) => {
      try {
        const { subjectId, purpose } = req.params;
        await consentManagementService.revokeConsent(subjectId, purpose);
        res.json({ success: true });
      } catch (error) {
        console.error("Error revoking consent:", error);
        res.status(500).json({ error: "Failed to revoke consent" });
      }
    });
    router24.get("/api/compliance/consent/:subjectId", async (req, res) => {
      try {
        const { subjectId } = req.params;
        const consents = await consentManagementService.getSubjectConsents(subjectId);
        res.json(consents);
      } catch (error) {
        console.error("Error fetching consents:", error);
        res.status(500).json({ error: "Failed to fetch consents" });
      }
    });
    router24.put("/api/compliance/communication-preferences", async (req, res) => {
      try {
        const prefSchema = z12.object({
          subjectId: z12.string(),
          channel: z12.enum(["email", "sms", "phone", "push", "mail"]),
          topic: z12.string(),
          allowed: z12.boolean(),
          frequency: z12.enum(["immediate", "daily", "weekly", "monthly"]).optional(),
          updatedBy: z12.string()
        });
        const data = prefSchema.parse(req.body);
        await consentManagementService.updateCommunicationPreference(data);
        res.json({ success: true });
      } catch (error) {
        console.error("Error updating preferences:", error);
        res.status(500).json({ error: "Failed to update preferences" });
      }
    });
    router24.get("/api/compliance/communication-preferences/:subjectId", async (req, res) => {
      try {
        const { subjectId } = req.params;
        const preferences = await db.select().from(communicationPreference).where(eq26(communicationPreference.subjectId, subjectId));
        res.json(preferences);
      } catch (error) {
        console.error("Error fetching preferences:", error);
        res.status(500).json({ error: "Failed to fetch preferences" });
      }
    });
    router24.get("/api/compliance/retention-policies", async (req, res) => {
      try {
        const policies = await db.select().from(retentionPolicy);
        res.json(policies);
      } catch (error) {
        console.error("Error fetching retention policies:", error);
        res.status(500).json({ error: "Failed to fetch retention policies" });
      }
    });
    router24.post("/api/compliance/retention-policies", async (req, res) => {
      try {
        const policySchema = z12.object({
          dataClass: z12.string(),
          jurisdiction: z12.string(),
          minRetentionDays: z12.number(),
          maxRetentionDays: z12.number().optional(),
          legalHoldAllowed: z12.boolean().default(true),
          policyVersion: z12.string(),
          notes: z12.string().optional()
        });
        const data = policySchema.parse(req.body);
        const result = await db.insert(retentionPolicy).values(data).returning();
        res.json(result[0]);
      } catch (error) {
        console.error("Error creating retention policy:", error);
        res.status(500).json({ error: "Failed to create retention policy" });
      }
    });
    router24.post("/api/compliance/legal-holds", async (req, res) => {
      try {
        const holdSchema = z12.object({
          scopeType: z12.enum(["artifact", "account", "subject"]),
          scopeId: z12.string(),
          reason: z12.string(),
          imposedBy: z12.string()
        });
        const data = holdSchema.parse(req.body);
        await retentionPolicyService.createLegalHold(data);
        res.json({ success: true });
      } catch (error) {
        console.error("Error creating legal hold:", error);
        res.status(500).json({ error: "Failed to create legal hold" });
      }
    });
    router24.delete("/api/compliance/legal-holds/:holdId", async (req, res) => {
      try {
        const { holdId } = req.params;
        const { releasedBy } = req.body;
        if (!releasedBy) {
          return res.status(400).json({ error: "releasedBy is required" });
        }
        await retentionPolicyService.releaseLegalHold(holdId, releasedBy);
        res.json({ success: true });
      } catch (error) {
        console.error("Error releasing legal hold:", error);
        res.status(500).json({ error: "Failed to release legal hold" });
      }
    });
    router24.get("/api/compliance/legal-holds", async (req, res) => {
      try {
        const holds = await db.select().from(legalHold).where(eq26(legalHold.active, true));
        res.json(holds);
      } catch (error) {
        console.error("Error fetching legal holds:", error);
        res.status(500).json({ error: "Failed to fetch legal holds" });
      }
    });
    router24.post("/api/compliance/dsar", async (req, res) => {
      try {
        const dsarSchema = z12.object({
          subjectId: z12.string(),
          type: z12.enum(["access", "deletion", "correction"]),
          submittedVia: z12.enum(["portal", "email", "mail"]),
          detailsJson: z12.any().optional()
        });
        const data = dsarSchema.parse(req.body);
        const dsarId = await consentManagementService.createDSAR(data);
        res.json({ id: dsarId });
      } catch (error) {
        console.error("Error creating DSAR:", error);
        res.status(500).json({ error: "Failed to create DSAR" });
      }
    });
    router24.put("/api/compliance/dsar/:dsarId/status", async (req, res) => {
      try {
        const { dsarId } = req.params;
        const { status, updatedBy } = req.body;
        if (!status || !updatedBy) {
          return res.status(400).json({ error: "Status and updatedBy are required" });
        }
        await consentManagementService.updateDSARStatus(dsarId, status, updatedBy);
        res.json({ success: true });
      } catch (error) {
        console.error("Error updating DSAR status:", error);
        res.status(500).json({ error: "Failed to update DSAR status" });
      }
    });
    router24.get("/api/compliance/dsar/pending", async (req, res) => {
      try {
        const pending = await consentManagementService.getPendingDSARs();
        res.json(pending);
      } catch (error) {
        console.error("Error fetching pending DSARs:", error);
        res.status(500).json({ error: "Failed to fetch pending DSARs" });
      }
    });
    router24.get("/api/compliance/process-timers", async (req, res) => {
      try {
        const timers = await db.select().from(processTimer);
        res.json(timers);
      } catch (error) {
        console.error("Error fetching process timers:", error);
        res.status(500).json({ error: "Failed to fetch process timers" });
      }
    });
    router24.post("/api/compliance/process-timers", async (req, res) => {
      try {
        const timerSchema = z12.object({
          timerCode: z12.string(),
          jurisdiction: z12.string(),
          windowHoursMin: z12.number(),
          windowHoursMax: z12.number(),
          graceHours: z12.number().default(0),
          version: z12.string()
        });
        const data = timerSchema.parse(req.body);
        const result = await db.insert(processTimer).values(data).returning();
        res.json(result[0]);
      } catch (error) {
        console.error("Error creating process timer:", error);
        res.status(500).json({ error: "Failed to create process timer" });
      }
    });
    router24.get("/api/compliance/notice-delivery", async (req, res) => {
      try {
        const { accountId, noticeCode, status } = req.query;
        const conditions = [];
        if (accountId) {
          conditions.push(eq26(noticeDeliveryLog.accountId, accountId));
        }
        if (noticeCode) {
          conditions.push(eq26(noticeDeliveryLog.noticeCode, noticeCode));
        }
        if (status) {
          conditions.push(eq26(noticeDeliveryLog.deliveryStatus, status));
        }
        const logs = conditions.length > 0 ? await db.select().from(noticeDeliveryLog).where(and22(...conditions)).orderBy(desc11(noticeDeliveryLog.scheduledFor)) : await db.select().from(noticeDeliveryLog).orderBy(desc11(noticeDeliveryLog.scheduledFor));
        res.json(logs);
      } catch (error) {
        console.error("Error fetching notice delivery logs:", error);
        res.status(500).json({ error: "Failed to fetch notice delivery logs" });
      }
    });
    compliance_default = router24;
  }
});

// server/routes/compliance-console.ts
var compliance_console_exports = {};
__export(compliance_console_exports, {
  default: () => compliance_console_default
});
import { Router as Router30 } from "express";
import {
  eq as eq27,
  desc as desc12,
  and as and23,
  gte as gte7,
  lte as lte4,
  or as or10,
  like as like2,
  sql as sql17,
  count as count2
} from "drizzle-orm";
import { startOfDay, endOfDay, subDays } from "date-fns";
function calculateComplianceScore(params) {
  let score = 100;
  if (!params.chainValid) {
    score -= 30;
  }
  if (params.criticalEventsRatio > 0.1) {
    score -= Math.min(20, params.criticalEventsRatio * 100);
  }
  if (!params.hasRetentionPolicies) {
    score -= 10;
  }
  return Math.max(0, Math.min(100, score));
}
var router25, compliance_console_default;
var init_compliance_console = __esm({
  "server/routes/compliance-console.ts"() {
    "use strict";
    init_db();
    init_schema();
    init_auditService();
    init_hashChain();
    router25 = Router30();
    router25.get("/dashboard", async (req, res) => {
      try {
        const userId = req.user?.id || req.session?.userId;
        const todayStart = startOfDay(/* @__PURE__ */ new Date());
        const todayEnd = endOfDay(/* @__PURE__ */ new Date());
        const last30DaysStart = startOfDay(subDays(/* @__PURE__ */ new Date(), 30));
        const [
          totalEvents,
          todayEvents,
          criticalEvents,
          activeHolds,
          retentionPolicies,
          recentDeletions
        ] = await Promise.all([
          // Total events in last 30 days
          db.select({ count: count2() }).from(complianceAuditLog).where(gte7(complianceAuditLog.createdAt, last30DaysStart)).then((r) => r[0]?.count || 0),
          // Today's events
          db.select({ count: count2() }).from(complianceAuditLog).where(
            and23(
              gte7(complianceAuditLog.createdAt, todayStart),
              lte4(complianceAuditLog.createdAt, todayEnd)
            )
          ).then((r) => r[0]?.count || 0),
          // Critical events (security, compliance, errors)
          db.select({ count: count2() }).from(complianceAuditLog).where(
            and23(
              gte7(complianceAuditLog.createdAt, last30DaysStart),
              or10(
                like2(complianceAuditLog.eventType, "SECURITY.%"),
                like2(complianceAuditLog.eventType, "COMPLIANCE.%"),
                like2(complianceAuditLog.eventType, "ERROR.%")
              )
            )
          ).then((r) => r[0]?.count || 0),
          // Active legal holds
          db.select({ count: count2() }).from(legalHold).where(eq27(legalHold.active, true)).then((r) => r[0]?.count || 0),
          // Active retention policies
          db.select({ count: count2() }).from(retentionPolicy).then((r) => r[0]?.count || 0),
          // Recent deletions (last 7 days)
          db.select({ count: count2() }).from(deletionReceipt).where(gte7(deletionReceipt.deletedAtUtc, subDays(/* @__PURE__ */ new Date(), 7))).then((r) => r[0]?.count || 0)
        ]);
        const chainIntegrity = await hashChainService.verifyChainIntegrity();
        const complianceScore = calculateComplianceScore({
          chainValid: chainIntegrity.isValid,
          criticalEventsRatio: totalEvents > 0 ? criticalEvents / totalEvents : 0,
          hasRetentionPolicies: retentionPolicies > 0
        });
        await complianceAudit.logEvent({
          eventType: "COMPLIANCE.DASHBOARD_ACCESSED",
          actorType: "user",
          actorId: userId?.toString(),
          resourceType: "compliance_dashboard",
          details: {
            action: "view_dashboard",
            userId
          },
          userId,
          ipAddress: req.ip,
          userAgent: req.headers["user-agent"]
        });
        res.json({
          metrics: {
            complianceScore,
            totalEvents,
            todayEvents,
            criticalEvents,
            activeHolds,
            retentionPolicies,
            recentDeletions,
            chainIntegrity: {
              valid: chainIntegrity.isValid,
              brokenLinks: chainIntegrity.brokenLinks.length
            }
          }
        });
      } catch (error) {
        console.error("Error fetching compliance dashboard:", error);
        res.status(500).json({ error: "Failed to fetch compliance dashboard" });
      }
    });
    router25.get("/audit-logs", async (req, res) => {
      try {
        const userId = req.user?.id || req.session?.userId;
        const {
          page = 1,
          limit = 50,
          eventType,
          actorType,
          resourceType,
          startDate,
          endDate,
          search
        } = req.query;
        const offset = (Number(page) - 1) * Number(limit);
        let query = db.select().from(complianceAuditLog);
        const conditions = [];
        if (eventType) {
          conditions.push(like2(complianceAuditLog.eventType, `${eventType}%`));
        }
        if (actorType) {
          conditions.push(eq27(complianceAuditLog.actorType, actorType));
        }
        if (resourceType) {
          conditions.push(eq27(complianceAuditLog.resourceType, resourceType));
        }
        if (startDate) {
          conditions.push(gte7(complianceAuditLog.createdAt, new Date(startDate)));
        }
        if (endDate) {
          conditions.push(lte4(complianceAuditLog.createdAt, new Date(endDate)));
        }
        if (search) {
          conditions.push(
            or10(
              like2(complianceAuditLog.actorId, `%${search}%`),
              like2(complianceAuditLog.resourceId, `%${search}%`),
              like2(complianceAuditLog.correlationId, `%${search}%`)
            )
          );
        }
        if (conditions.length > 0) {
          query = query.where(and23(...conditions));
        }
        const totalQuery = db.select({ count: count2() }).from(complianceAuditLog);
        if (conditions.length > 0) {
          totalQuery.where(and23(...conditions));
        }
        const totalResult = await totalQuery;
        const total = totalResult[0]?.count || 0;
        const logs = await query.orderBy(desc12(complianceAuditLog.createdAt)).limit(Number(limit)).offset(offset);
        const transformedLogs = logs.map((log2) => ({
          ...log2,
          description: log2.payloadJson?.description || `${log2.eventType} operation`
        }));
        await complianceAudit.logEvent({
          eventType: "COMPLIANCE.AUDIT_ACCESSED",
          actorType: "user",
          actorId: userId?.toString(),
          resourceType: "audit_logs",
          details: {
            action: "view_audit_logs",
            filters: { eventType, actorType, resourceType, startDate, endDate },
            userId
          },
          userId,
          ipAddress: req.ip,
          userAgent: req.headers["user-agent"]
        });
        res.json({
          logs: transformedLogs,
          pagination: {
            page: Number(page),
            limit: Number(limit),
            total,
            totalPages: Math.ceil(total / Number(limit))
          }
        });
      } catch (error) {
        console.error("Error fetching audit logs:", error);
        res.status(500).json({ error: "Failed to fetch audit logs" });
      }
    });
    router25.get("/event-types", async (req, res) => {
      try {
        const eventTypes = await db.selectDistinct({ eventType: complianceAuditLog.eventType }).from(complianceAuditLog).orderBy(complianceAuditLog.eventType);
        const grouped = eventTypes.reduce((acc, { eventType }) => {
          const [category] = eventType.split(".");
          if (!acc[category]) {
            acc[category] = [];
          }
          acc[category].push(eventType);
          return acc;
        }, {});
        res.json({ eventTypes: grouped });
      } catch (error) {
        console.error("Error fetching event types:", error);
        res.status(500).json({ error: "Failed to fetch event types" });
      }
    });
    router25.get("/chain-integrity", async (req, res) => {
      try {
        const userId = req.user?.id || req.session?.userId;
        const { startId, endId } = req.query;
        const integrity = await hashChainService.verifyChainIntegrity(
          startId ? Number(startId) : void 0,
          endId ? Number(endId) : void 0
        );
        await complianceAudit.logEvent({
          eventType: "COMPLIANCE.INTEGRITY_CHECKED",
          actorType: "user",
          actorId: userId?.toString(),
          resourceType: "hash_chain",
          details: {
            action: "verify_integrity",
            result: integrity.isValid,
            brokenLinks: integrity.brokenLinks.length,
            userId
          },
          userId,
          ipAddress: req.ip,
          userAgent: req.headers["user-agent"]
        });
        res.json(integrity);
      } catch (error) {
        console.error("Error verifying chain integrity:", error);
        res.status(500).json({ error: "Failed to verify chain integrity" });
      }
    });
    router25.post("/audit-pack", async (req, res) => {
      try {
        const userId = req.user?.id || req.session?.userId;
        const { startDate, endDate } = req.body;
        if (!startDate || !endDate) {
          return res.status(400).json({ error: "Start date and end date are required" });
        }
        const auditPack = await hashChainService.generateAuditPack(
          new Date(startDate),
          new Date(endDate)
        );
        await complianceAudit.logEvent({
          eventType: "COMPLIANCE.AUDIT_PACK_GENERATED",
          actorType: "user",
          actorId: userId?.toString(),
          resourceType: "audit_pack",
          details: {
            action: "generate_audit_pack",
            startDate,
            endDate,
            entriesCount: auditPack.entries.length,
            userId
          },
          userId,
          ipAddress: req.ip,
          userAgent: req.headers["user-agent"]
        });
        res.json(auditPack);
      } catch (error) {
        console.error("Error generating audit pack:", error);
        res.status(500).json({ error: "Failed to generate audit pack" });
      }
    });
    router25.get("/retention-policies", async (req, res) => {
      try {
        const policies = await db.select().from(retentionPolicy).orderBy(retentionPolicy.dataClass);
        res.json({ policies });
      } catch (error) {
        console.error("Error fetching retention policies:", error);
        res.status(500).json({ error: "Failed to fetch retention policies" });
      }
    });
    router25.get("/legal-holds", async (req, res) => {
      try {
        const { active } = req.query;
        let query = db.select().from(legalHold);
        if (active !== void 0) {
          query = query.where(eq27(legalHold.active, active === "true"));
        }
        const holds = await query.orderBy(desc12(legalHold.createdAt));
        res.json({ holds });
      } catch (error) {
        console.error("Error fetching legal holds:", error);
        res.status(500).json({ error: "Failed to fetch legal holds" });
      }
    });
    router25.get("/deletion-receipts", async (req, res) => {
      try {
        const { limit = 100 } = req.query;
        const receipts = await db.select().from(deletionReceipt).orderBy(desc12(deletionReceipt.deletedAtUtc)).limit(Number(limit));
        res.json({ receipts });
      } catch (error) {
        console.error("Error fetching deletion receipts:", error);
        res.status(500).json({ error: "Failed to fetch deletion receipts" });
      }
    });
    router25.get("/activity-timeline", async (req, res) => {
      try {
        const { hours = 24 } = req.query;
        const startTime2 = subDays(/* @__PURE__ */ new Date(), Number(hours) / 24);
        const timeline = await db.select({
          hour: sql17`DATE_TRUNC('hour', ${complianceAuditLog.createdAt})`,
          eventCount: count2(),
          criticalCount: sql17`COUNT(CASE WHEN ${complianceAuditLog.eventType} LIKE 'SECURITY.%' OR ${complianceAuditLog.eventType} LIKE 'ERROR.%' THEN 1 END)`
        }).from(complianceAuditLog).where(gte7(complianceAuditLog.createdAt, startTime2)).groupBy(sql17`DATE_TRUNC('hour', ${complianceAuditLog.createdAt})`).orderBy(sql17`DATE_TRUNC('hour', ${complianceAuditLog.createdAt})`);
        res.json({ timeline });
      } catch (error) {
        console.error("Error fetching activity timeline:", error);
        res.status(500).json({ error: "Failed to fetch activity timeline" });
      }
    });
    compliance_console_default = router25;
  }
});

// server/messaging/outbox-service.ts
var OutboxService2, outboxService2;
var init_outbox_service = __esm({
  "server/messaging/outbox-service.ts"() {
    "use strict";
    OutboxService2 = class {
      /**
       * Create outbox message for eventual processing
       * @param message Domain event message
       */
      async createMessage(message) {
        console.log(`[Outbox] Domain event created: ${message.eventType}`, {
          aggregateType: message.aggregateType,
          aggregateId: message.aggregateId,
          correlationId: message.correlationId
        });
      }
    };
    outboxService2 = new OutboxService2();
  }
});

// server/repositories/beneficiary-repo.ts
function normalizeValue(value) {
  if (value === null || value === void 0 || value === "") {
    return null;
  }
  if (typeof value === "string" || typeof value === "number") {
    const numValue = Number(value);
    if (!isNaN(numValue) && isFinite(numValue)) {
      return numValue;
    }
  }
  if (typeof value === "string") {
    return value.trim();
  }
  return value;
}
var BeneficiaryRepository;
var init_beneficiary_repo = __esm({
  "server/repositories/beneficiary-repo.ts"() {
    "use strict";
    init_audit_helper();
    init_outbox_service();
    BeneficiaryRepository = class {
      /**
       * Update beneficiary information with full audit trail
       * @param client Database client
       * @param params Update parameters including correlation ID
       * @returns Update result with old/new values
       */
      async updateBeneficiaryInfo(client5, params) {
        const { loanId, actorId, correlationId, updates, req } = params;
        await setRequestContext(client5, actorId, correlationId);
        return auditAndRun(
          client5,
          async () => {
            const prev = await client5.query(
              `SELECT beneficiary_name, beneficiary_company_name, beneficiary_phone, 
                  beneficiary_email, beneficiary_street_address, beneficiary_city,
                  beneficiary_state, beneficiary_zip_code 
           FROM loans WHERE id = $1 FOR UPDATE`,
              [loanId]
            );
            if (prev.rowCount === 0) {
              throw new Error("LOAN_NOT_FOUND");
            }
            const oldValues = prev.rows[0];
            const updateFields = [];
            const updateValues = [];
            let paramIndex = 2;
            const fieldMapping = {
              beneficiaryName: "beneficiary_name",
              beneficiaryCompanyName: "beneficiary_company_name",
              beneficiaryPhone: "beneficiary_phone",
              beneficiaryEmail: "beneficiary_email",
              beneficiaryStreetAddress: "beneficiary_street_address",
              beneficiaryCity: "beneficiary_city",
              beneficiaryState: "beneficiary_state",
              beneficiaryZipCode: "beneficiary_zip_code"
            };
            const changedFields = [];
            const newValues = {};
            for (const [key, value] of Object.entries(updates)) {
              if (value !== void 0 && fieldMapping[key]) {
                const dbField = fieldMapping[key];
                const oldValue = oldValues[dbField];
                if (normalizeValue(oldValue) !== normalizeValue(value)) {
                  updateFields.push(`${dbField} = $${paramIndex}`);
                  updateValues.push(value);
                  changedFields.push(key);
                  newValues[key] = value;
                  paramIndex++;
                }
              }
            }
            if (updateFields.length === 0) {
              return {
                loanId,
                oldValues: {},
                newValues: {},
                changedFields: []
              };
            }
            updateFields.push(`updated_at = now()`);
            await client5.query(
              `UPDATE loans SET ${updateFields.join(", ")} WHERE id = $1`,
              [loanId, ...updateValues]
            );
            return {
              loanId,
              oldValues: Object.fromEntries(
                changedFields.map((field) => [field, oldValues[fieldMapping[field]]])
              ),
              newValues,
              changedFields
            };
          },
          async (result) => {
            if (result.changedFields.length > 0) {
              for (const field of result.changedFields) {
                await createAuditEvent(client5, {
                  actorId,
                  eventType: "CRM.BENEFICIARY.UPDATED",
                  resourceType: "beneficiary",
                  resourceId: loanId,
                  loanId,
                  payloadJson: {
                    field,
                    oldValue: result.oldValues[field],
                    newValue: result.newValues[field]
                  },
                  correlationId,
                  description: `Beneficiary ${field} updated`,
                  req
                  // Pass request context for IP and user agent
                });
              }
              await outboxService2.createMessage({
                aggregateType: "loan",
                aggregateId: loanId,
                eventType: "beneficiary.updated.v1",
                data: {
                  loanId,
                  changedFields: result.changedFields,
                  oldValues: result.oldValues,
                  newValues: result.newValues,
                  updatedBy: actorId
                },
                correlationId
              });
            }
          }
        );
      }
    };
  }
});

// server/routes/beneficiary-routes.ts
var beneficiary_routes_exports = {};
__export(beneficiary_routes_exports, {
  default: () => beneficiary_routes_default
});
import { Router as Router31 } from "express";
import { z as z13 } from "zod";
import { v4 as uuidv44 } from "uuid";
var router26, beneficiaryRepo, updateBeneficiarySchema, beneficiary_routes_default;
var init_beneficiary_routes = __esm({
  "server/routes/beneficiary-routes.ts"() {
    "use strict";
    init_db();
    init_beneficiary_repo();
    router26 = Router31();
    beneficiaryRepo = new BeneficiaryRepository();
    updateBeneficiarySchema = z13.object({
      beneficiaryName: z13.string().optional(),
      beneficiaryCompanyName: z13.string().optional(),
      beneficiaryPhone: z13.string().optional(),
      beneficiaryEmail: z13.string().email().optional(),
      beneficiaryStreetAddress: z13.string().optional(),
      beneficiaryCity: z13.string().optional(),
      beneficiaryState: z13.string().optional(),
      beneficiaryZipCode: z13.string().optional()
    });
    router26.patch("/loans/:loanId/beneficiary", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const loanId = req.params.loanId;
        const actorId = req.user?.id?.toString() || "system";
        const correlationId = req.correlationId || `beneficiary_update_${uuidv44()}`;
        const validation = updateBeneficiarySchema.safeParse(req.body);
        if (!validation.success) {
          return res.status(400).json({
            error: "Invalid beneficiary data",
            details: validation.error.errors
          });
        }
        const updates = validation.data;
        const cleanUpdates = Object.fromEntries(
          Object.entries(updates).filter(([_, value]) => value !== void 0)
        );
        if (Object.keys(cleanUpdates).length === 0) {
          return res.status(400).json({
            error: "No valid updates provided"
          });
        }
        const result = await beneficiaryRepo.updateBeneficiaryInfo(client5, {
          loanId,
          actorId,
          correlationId,
          updates: cleanUpdates,
          req
          // Pass request for audit context
        });
        res.status(200).json({
          success: true,
          correlationId,
          result: {
            loanId: result.loanId,
            changedFields: result.changedFields,
            changeCount: result.changedFields.length
          },
          message: result.changedFields.length > 0 ? `Updated ${result.changedFields.length} beneficiary field(s)` : "No changes detected"
        });
      } catch (error) {
        console.error("[BeneficiaryRoutes] Error updating beneficiary:", error);
        res.status(500).json({
          error: "Failed to update beneficiary information",
          code: "BENEFICIARY_UPDATE_FAILED"
        });
      } finally {
        client5.release();
      }
    });
    router26.patch("/loans/:loanId/beneficiary/name", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const loanId = req.params.loanId;
        const { newName } = req.body;
        const actorId = req.user?.id?.toString() || "system";
        const correlationId = req.correlationId || `beneficiary_name_${uuidv44()}`;
        if (!newName || typeof newName !== "string") {
          return res.status(400).json({
            error: "Valid newName is required"
          });
        }
        const result = await beneficiaryRepo.updateBeneficiaryInfo(client5, {
          loanId,
          actorId,
          correlationId,
          updates: { beneficiaryName: newName },
          req
          // Pass request for audit context
        });
        res.status(200).json({
          success: true,
          correlationId,
          result: {
            loanId: result.loanId,
            nameUpdated: result.changedFields.includes("beneficiaryName"),
            oldName: result.oldValues.beneficiaryName,
            newName: result.newValues.beneficiaryName
          }
        });
      } catch (error) {
        console.error("[BeneficiaryRoutes] Error updating beneficiary name:", error);
        res.status(500).json({
          error: "Failed to update beneficiary name",
          code: "BENEFICIARY_NAME_UPDATE_FAILED"
        });
      } finally {
        client5.release();
      }
    });
    router26.get("/loans/:loanId/beneficiary/history", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const loanId = req.params.loanId;
        const history = await client5.query(
          `SELECT hist_id, old_row, new_row, operation, changed_at, changed_by, correlation_id
       FROM beneficiary_history 
       WHERE loan_id = $1 
       ORDER BY changed_at DESC, hist_id DESC`,
          [loanId]
        );
        res.json({
          loanId,
          history: history.rows.map((row) => ({
            id: row.hist_id,
            operation: row.operation,
            oldValues: row.old_row,
            newValues: row.new_row,
            changedAt: row.changed_at,
            changedBy: row.changed_by,
            correlationId: row.correlation_id
          }))
        });
      } catch (error) {
        console.error("[BeneficiaryRoutes] Error fetching beneficiary history:", error);
        res.status(500).json({
          error: "Failed to fetch beneficiary history",
          code: "BENEFICIARY_HISTORY_FAILED"
        });
      } finally {
        client5.release();
      }
    });
    beneficiary_routes_default = router26;
  }
});

// server/repositories/investor-repo.ts
var InvestorRepository;
var init_investor_repo = __esm({
  "server/repositories/investor-repo.ts"() {
    "use strict";
    init_audit_helper();
    init_outbox_service();
    InvestorRepository = class {
      /**
       * Add new investor to loan with full audit trail
       */
      async addInvestor(client5, params) {
        const { loanId, investorId, entityType, name, ownershipPercentage, actorId, correlationId, additionalInfo } = params;
        await setRequestContext(client5, actorId, correlationId);
        const loanResult = await client5.query("SELECT loan_number FROM loans WHERE id = $1", [loanId]);
        const loanNumber = loanResult.rows[0]?.loan_number || loanId;
        return auditAndRun(
          client5,
          async () => {
            const existing = await client5.query(
              "SELECT id FROM investors WHERE investor_id = $1 AND loan_id = $2",
              [investorId, loanId]
            );
            if (existing.rowCount && existing.rowCount > 0) {
              throw new Error("INVESTOR_ALREADY_EXISTS");
            }
            const result = await client5.query(
              `INSERT INTO investors (
            investor_id, loan_id, entity_type, name, ownership_percentage,
            contact_name, email, phone, street_address, city, state, zip_code,
            bank_name, account_number, routing_number, account_type, created_at, updated_at
          ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, now(), now())
          RETURNING id`,
              [
                investorId,
                loanId,
                entityType,
                name,
                ownershipPercentage,
                additionalInfo?.contactName || null,
                additionalInfo?.email || null,
                additionalInfo?.phone || null,
                additionalInfo?.streetAddress || null,
                additionalInfo?.city || null,
                additionalInfo?.state || null,
                additionalInfo?.zipCode || null,
                additionalInfo?.bankName || null,
                additionalInfo?.accountNumber || null,
                additionalInfo?.routingNumber || null,
                additionalInfo?.accountType || null
              ]
            );
            return {
              investorId,
              dbId: result.rows[0].id,
              ownershipPercentage,
              name,
              entityType
            };
          },
          async (result) => {
            await createAuditEvent(client5, {
              actorId,
              eventType: "CRM.INVESTOR.ADDED",
              resourceType: "investor_loan",
              resourceId: `${loanId}:${investorId}`,
              loanId,
              payloadJson: {
                investorId: result.investorId,
                name: result.name,
                entityType: result.entityType,
                ownershipPercentage: result.ownershipPercentage
              },
              correlationId,
              description: `Investor ${result.name} added to Loan ${loanNumber}`
            });
            await outboxService2.createMessage({
              aggregateType: "loan",
              aggregateId: loanId,
              eventType: "investor.added.v1",
              payload: {
                loanId,
                investorId: result.investorId,
                name: result.name,
                entityType: result.entityType,
                ownershipPercentage: result.ownershipPercentage,
                addedBy: actorId
              },
              correlationId
            });
          }
        );
      }
      /**
       * Update existing investor with full audit trail
       */
      async updateInvestor(client5, params) {
        const { investorDbId, loanId, actorId, correlationId, req, updates } = params;
        await setRequestContext(client5, actorId, correlationId);
        const loanResult = await client5.query("SELECT loan_number FROM loans WHERE id = $1", [loanId]);
        const loanNumber = loanResult.rows[0]?.loan_number || loanId;
        return auditAndRun(
          client5,
          async () => {
            const prev = await client5.query(
              `SELECT investor_id, name, ownership_percentage, email, phone, 
                  street_address, city, state, zip_code, bank_name, 
                  account_number, routing_number, account_type, is_active, notes
           FROM investors WHERE id = $1 AND loan_id = $2 FOR UPDATE`,
              [investorDbId, loanId]
            );
            if (prev.rowCount === 0) {
              throw new Error("INVESTOR_NOT_FOUND");
            }
            const oldValues = prev.rows[0];
            const investorName = oldValues.name || "Unknown Investor";
            const updateFields = [];
            const updateValues = [];
            let paramIndex = 3;
            const fieldMapping = {
              name: "name",
              ownershipPercentage: "ownership_percentage",
              email: "email",
              phone: "phone",
              streetAddress: "street_address",
              city: "city",
              state: "state",
              zipCode: "zip_code",
              bankName: "bank_name",
              accountNumber: "account_number",
              routingNumber: "routing_number",
              accountType: "account_type",
              isActive: "is_active",
              notes: "notes"
            };
            const changedFields = [];
            const newValues = {};
            for (const [key, value] of Object.entries(updates)) {
              if (value !== void 0 && fieldMapping[key]) {
                const dbField = fieldMapping[key];
                const oldValue = oldValues[dbField];
                if (oldValue !== value) {
                  updateFields.push(`${dbField} = $${paramIndex}`);
                  updateValues.push(value);
                  changedFields.push(key);
                  newValues[key] = value;
                  paramIndex++;
                }
              }
            }
            if (updateFields.length === 0) {
              return {
                oldValues: {},
                newValues: {},
                changedFields: []
              };
            }
            updateFields.push(`updated_at = now()`);
            await client5.query(
              `UPDATE investors SET ${updateFields.join(", ")} WHERE id = $1 AND loan_id = $2`,
              [investorDbId, loanId, ...updateValues]
            );
            return {
              oldValues: Object.fromEntries(
                changedFields.map((field) => [field, oldValues[fieldMapping[field]]])
              ),
              newValues,
              changedFields,
              investorId: oldValues.investor_id,
              investorName
            };
          },
          async (result) => {
            if (result.changedFields.length > 0) {
              for (const field of result.changedFields) {
                await createAuditEvent(client5, {
                  actorId,
                  eventType: "INVESTOR.FIELD_UPDATED",
                  resourceType: "investor_loan",
                  resourceId: `${loanId}:${result.investorId}`,
                  loanId,
                  payloadJson: {
                    investorId: result.investorId,
                    field,
                    oldValue: result.oldValues[field],
                    newValue: result.newValues[field]
                  },
                  correlationId,
                  description: `Investor "${result.investorName}" (${result.investorId}) field '${field}' updated from '${result.oldValues[field]}' to '${result.newValues[field]}' on Loan ${loanNumber}`,
                  req
                  // Pass request context for IP and user agent
                });
              }
              await outboxService2.createMessage({
                aggregateType: "loan",
                aggregateId: loanId,
                eventType: "investor.updated.v1",
                payload: {
                  loanId,
                  investorId: result.investorId,
                  changedFields: result.changedFields,
                  oldValues: result.oldValues,
                  newValues: result.newValues,
                  updatedBy: actorId
                },
                correlationId
              });
            }
          }
        );
      }
      /**
       * Remove investor from loan with full audit trail
       */
      async deleteInvestor(client5, params) {
        const { investorDbId, loanId, actorId, correlationId } = params;
        await setRequestContext(client5, actorId, correlationId);
        return auditAndRun(
          client5,
          async () => {
            const investor = await client5.query(
              "SELECT investor_id, name FROM investors WHERE id = $1 AND loan_id = $2",
              [investorDbId, loanId]
            );
            if (investor.rowCount === 0) {
              throw new Error("INVESTOR_NOT_FOUND");
            }
            const { investor_id, name } = investor.rows[0];
            await client5.query(
              "UPDATE investors SET is_active = false, updated_at = now() WHERE id = $1 AND loan_id = $2",
              [investorDbId, loanId]
            );
            return { investorId: investor_id, name };
          },
          async (result) => {
            await createAuditEvent(client5, {
              actorId,
              eventType: "CRM.INVESTOR.REMOVED",
              resourceType: "investor_loan",
              resourceId: `${loanId}:${result.investorId}`,
              loanId,
              payloadJson: {
                investorId: result.investorId,
                name: result.name
              },
              correlationId,
              description: `Investor ${result.name} removed from loan`
            });
            await outboxService2.createMessage({
              aggregateType: "loan",
              aggregateId: loanId,
              eventType: "investor.removed.v1",
              payload: {
                loanId,
                investorId: result.investorId,
                name: result.name,
                removedBy: actorId
              },
              correlationId
            });
          }
        );
      }
    };
  }
});

// server/routes/investor-routes.ts
var investor_routes_exports = {};
__export(investor_routes_exports, {
  default: () => investor_routes_default
});
import { Router as Router32 } from "express";
import { z as z14 } from "zod";
import { v4 as uuidv45 } from "uuid";
var router27, investorRepo, addInvestorSchema, updateInvestorSchema, investor_routes_default;
var init_investor_routes = __esm({
  "server/routes/investor-routes.ts"() {
    "use strict";
    init_db();
    init_investor_repo();
    router27 = Router32();
    investorRepo = new InvestorRepository();
    addInvestorSchema = z14.object({
      investorId: z14.string().min(1),
      entityType: z14.enum(["individual", "entity"]),
      name: z14.string().min(1),
      ownershipPercentage: z14.number().min(0).max(100),
      contactName: z14.string().optional(),
      email: z14.string().email().optional(),
      phone: z14.string().optional(),
      streetAddress: z14.string().optional(),
      city: z14.string().optional(),
      state: z14.string().optional(),
      zipCode: z14.string().optional(),
      bankName: z14.string().optional(),
      accountNumber: z14.string().optional(),
      routingNumber: z14.string().optional(),
      accountType: z14.enum(["checking", "savings"]).optional()
    });
    updateInvestorSchema = z14.object({
      name: z14.string().optional(),
      ownershipPercentage: z14.number().min(0).max(100).optional(),
      email: z14.string().email().optional(),
      phone: z14.string().optional(),
      streetAddress: z14.string().optional(),
      city: z14.string().optional(),
      state: z14.string().optional(),
      zipCode: z14.string().optional(),
      bankName: z14.string().optional(),
      accountNumber: z14.string().optional(),
      routingNumber: z14.string().optional(),
      accountType: z14.enum(["checking", "savings"]).optional(),
      isActive: z14.boolean().optional(),
      notes: z14.string().optional()
    });
    router27.post("/loans/:loanId/investors", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const loanId = req.params.loanId;
        const actorId = req.user?.id?.toString() || "system";
        const correlationId = req.correlationId || `investor_add_${uuidv45()}`;
        const validation = addInvestorSchema.safeParse(req.body);
        if (!validation.success) {
          return res.status(400).json({
            error: "Invalid investor data",
            details: validation.error.errors
          });
        }
        const data = validation.data;
        const result = await investorRepo.addInvestor(client5, {
          loanId,
          investorId: data.investorId,
          entityType: data.entityType,
          name: data.name,
          ownershipPercentage: data.ownershipPercentage,
          actorId,
          correlationId,
          additionalInfo: {
            contactName: data.contactName,
            email: data.email,
            phone: data.phone,
            streetAddress: data.streetAddress,
            city: data.city,
            state: data.state,
            zipCode: data.zipCode,
            bankName: data.bankName,
            accountNumber: data.accountNumber,
            routingNumber: data.routingNumber,
            accountType: data.accountType
          }
        });
        res.status(201).json({
          success: true,
          correlationId,
          result: {
            dbId: result.dbId,
            investorId: result.investorId,
            loanId
          },
          message: `Investor ${data.name} added successfully`
        });
      } catch (error) {
        console.error("[InvestorRoutes] Error adding investor:", error);
        if (error instanceof Error && error.message === "INVESTOR_ALREADY_EXISTS") {
          return res.status(409).json({
            error: "Investor already exists for this loan",
            code: "INVESTOR_ALREADY_EXISTS"
          });
        }
        res.status(500).json({
          error: "Failed to add investor",
          code: "INVESTOR_ADD_FAILED"
        });
      } finally {
        client5.release();
      }
    });
    router27.patch("/loans/:loanId/investors/:investorDbId", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const loanId = req.params.loanId;
        const investorDbId = req.params.investorDbId;
        const actorId = req.user?.id?.toString() || "system";
        const correlationId = req.correlationId || `investor_update_${uuidv45()}`;
        const validation = updateInvestorSchema.safeParse(req.body);
        if (!validation.success) {
          return res.status(400).json({
            error: "Invalid investor update data",
            details: validation.error.errors
          });
        }
        const updates = validation.data;
        const cleanUpdates = Object.fromEntries(
          Object.entries(updates).filter(([_, value]) => value !== void 0)
        );
        if (Object.keys(cleanUpdates).length === 0) {
          return res.status(400).json({
            error: "No valid updates provided"
          });
        }
        const result = await investorRepo.updateInvestor(client5, {
          investorDbId,
          loanId,
          actorId,
          correlationId,
          req,
          // Pass request context for IP and user agent
          updates: cleanUpdates
        });
        res.status(200).json({
          success: true,
          correlationId,
          result: {
            loanId,
            investorDbId,
            changedFields: result.changedFields,
            changeCount: result.changedFields.length
          },
          message: result.changedFields.length > 0 ? `Updated ${result.changedFields.length} investor field(s)` : "No changes detected"
        });
      } catch (error) {
        console.error("[InvestorRoutes] Error updating investor:", error);
        if (error instanceof Error && error.message === "INVESTOR_NOT_FOUND") {
          return res.status(404).json({
            error: "Investor not found",
            code: "INVESTOR_NOT_FOUND"
          });
        }
        res.status(500).json({
          error: "Failed to update investor",
          code: "INVESTOR_UPDATE_FAILED"
        });
      } finally {
        client5.release();
      }
    });
    router27.delete("/loans/:loanId/investors/:investorDbId", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const loanId = req.params.loanId;
        const investorDbId = req.params.investorDbId;
        const actorId = req.user?.id?.toString() || "system";
        const correlationId = req.correlationId || `investor_delete_${uuidv45()}`;
        const result = await investorRepo.deleteInvestor(client5, {
          investorDbId,
          loanId,
          actorId,
          correlationId
        });
        res.status(200).json({
          success: true,
          correlationId,
          result: {
            loanId,
            investorDbId,
            investorId: result.investorId,
            name: result.name
          },
          message: `Investor ${result.name} removed successfully`
        });
      } catch (error) {
        console.error("[InvestorRoutes] Error deleting investor:", error);
        if (error instanceof Error && error.message === "INVESTOR_NOT_FOUND") {
          return res.status(404).json({
            error: "Investor not found",
            code: "INVESTOR_NOT_FOUND"
          });
        }
        res.status(500).json({
          error: "Failed to remove investor",
          code: "INVESTOR_DELETE_FAILED"
        });
      } finally {
        client5.release();
      }
    });
    router27.get("/loans/:loanId/investors/:investorDbId/history", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const loanId = req.params.loanId;
        const investorDbId = req.params.investorDbId;
        const history = await client5.query(
          `SELECT hist_id, old_row, new_row, operation, changed_at, changed_by, correlation_id
       FROM investor_history 
       WHERE investor_db_id = $1 AND loan_id = $2 
       ORDER BY changed_at DESC, hist_id DESC`,
          [investorDbId, loanId]
        );
        res.json({
          loanId,
          investorDbId,
          history: history.rows.map((row) => ({
            id: row.hist_id,
            operation: row.operation,
            oldValues: row.old_row,
            newValues: row.new_row,
            changedAt: row.changed_at,
            changedBy: row.changed_by,
            correlationId: row.correlation_id
          }))
        });
      } catch (error) {
        console.error("[InvestorRoutes] Error fetching investor history:", error);
        res.status(500).json({
          error: "Failed to fetch investor history",
          code: "INVESTOR_HISTORY_FAILED"
        });
      } finally {
        client5.release();
      }
    });
    investor_routes_default = router27;
  }
});

// server/services/payment-ingestion.ts
import { eq as eq28 } from "drizzle-orm";
import { createHash as createHash10 } from "crypto";
var PaymentIngestionService, paymentIngestionService;
var init_payment_ingestion = __esm({
  "server/services/payment-ingestion.ts"() {
    "use strict";
    init_db();
    init_schema();
    PaymentIngestionService = class _PaymentIngestionService {
      /**
       * Calculate idempotency key according to the rule:
       * sha256(lower(method) || '|' || normalized_reference || '|' || value_date || '|' || amount_cents || '|' || loan_id)
       */
      static calculateIdempotencyKey(data) {
        const keyString = [
          data.method.toLowerCase(),
          data.normalizedReference,
          data.valueDate,
          data.amountCents.toString(),
          data.loanId.toString()
        ].join("|");
        return createHash10("sha256").update(keyString).digest("hex");
      }
      /**
       * Calculate SHA256 hash of raw payload
       */
      static calculatePayloadHash(payload) {
        const payloadString = typeof payload === "string" ? payload : JSON.stringify(payload);
        return createHash10("sha256").update(payloadString).digest("hex");
      }
      /**
       * Persist idempotent ingress for payment signals
       * Returns existing row if duplicate idempotency key is found
       */
      async persistIngestion(data) {
        const idempotencyKey = _PaymentIngestionService.calculateIdempotencyKey({
          method: data.channel,
          normalizedReference: data.sourceReference || "",
          valueDate: data.valueDate,
          amountCents: data.amountCents,
          loanId: data.loanId
        });
        const rawPayloadHash = _PaymentIngestionService.calculatePayloadHash(data.rawPayload);
        const existing = await db.select().from(paymentIngestions).where(eq28(paymentIngestions.idempotencyKey, idempotencyKey)).limit(1);
        if (existing.length > 0) {
          console.log(`[PaymentIngestion] Duplicate idempotency key found: ${idempotencyKey}`);
          return existing[0];
        }
        if (!data.normalizedEnvelope || typeof data.normalizedEnvelope !== "object") {
          throw new Error("Invalid normalized JSON: normalizedEnvelope must be a valid object");
        }
        const newIngestion = {
          idempotencyKey,
          channel: data.channel,
          sourceReference: data.sourceReference,
          rawPayloadHash,
          artifactUri: data.artifactUris || [],
          artifactHash: data.artifactHashes || [],
          normalizedEnvelope: data.normalizedEnvelope,
          status: "received"
        };
        try {
          const [created] = await db.insert(paymentIngestions).values(newIngestion).returning();
          console.log(`[PaymentIngestion] Created new ingestion: ${created.id}`);
          return created;
        } catch (error) {
          if (error.code === "23505" && error.constraint === "payment_ingestions_idempotency_key_unique") {
            const existing2 = await db.select().from(paymentIngestions).where(eq28(paymentIngestions.idempotencyKey, idempotencyKey)).limit(1);
            if (existing2.length > 0) {
              console.log(`[PaymentIngestion] Race condition handled, returning existing: ${idempotencyKey}`);
              return existing2[0];
            }
          }
          throw error;
        }
      }
      /**
       * Update ingestion status
       */
      async updateStatus(id, status) {
        const [updated] = await db.update(paymentIngestions).set({ status }).where(eq28(paymentIngestions.id, id)).returning();
        return updated || null;
      }
      /**
       * Get ingestion by ID
       */
      async getById(id) {
        const [ingestion] = await db.select().from(paymentIngestions).where(eq28(paymentIngestions.id, id)).limit(1);
        return ingestion || null;
      }
      /**
       * Get ingestion by idempotency key
       */
      async getByIdempotencyKey(key) {
        const [ingestion] = await db.select().from(paymentIngestions).where(eq28(paymentIngestions.idempotencyKey, key)).limit(1);
        return ingestion || null;
      }
      /**
       * List ingestions by channel
       */
      async listByChannel(channel, limit = 100) {
        return await db.select().from(paymentIngestions).where(eq28(paymentIngestions.channel, channel)).orderBy(paymentIngestions.receivedAt).limit(limit);
      }
    };
    paymentIngestionService = new PaymentIngestionService();
  }
});

// server/routes/payment-ingestion.ts
var payment_ingestion_exports = {};
__export(payment_ingestion_exports, {
  default: () => payment_ingestion_default
});
import { Router as Router33 } from "express";
import { z as z15 } from "zod";
var router28, ingestionRequestSchema, payment_ingestion_default;
var init_payment_ingestion2 = __esm({
  "server/routes/payment-ingestion.ts"() {
    "use strict";
    init_payment_ingestion();
    router28 = Router33();
    ingestionRequestSchema = z15.object({
      channel: z15.enum(["ach", "wire", "realtime", "check", "card", "paypal", "venmo", "book"]),
      sourceReference: z15.string().optional(),
      rawPayload: z15.any(),
      // Required field
      normalizedEnvelope: z15.object({}).passthrough(),
      artifactUris: z15.array(z15.string()).optional(),
      artifactHashes: z15.array(z15.string()).optional(),
      // For idempotency key calculation
      method: z15.string(),
      normalizedReference: z15.string(),
      valueDate: z15.string(),
      amountCents: z15.number(),
      loanId: z15.number()
    });
    router28.post("/", async (req, res) => {
      try {
        const validatedData = ingestionRequestSchema.parse(req.body);
        const ingestion = await paymentIngestionService.persistIngestion(validatedData);
        res.json({
          success: true,
          data: ingestion,
          message: ingestion.status === "received" ? "Payment ingestion created successfully" : "Duplicate payment detected, returning existing ingestion"
        });
      } catch (error) {
        if (error instanceof z15.ZodError) {
          return res.status(400).json({
            error: "Validation error",
            details: error.errors
          });
        }
        if (error.message?.includes("Invalid normalized JSON")) {
          return res.status(400).json({
            error: "Schema error",
            message: error.message
          });
        }
        console.error("[PaymentIngestion] Error:", error);
        res.status(500).json({
          error: "Internal server error"
        });
      }
    });
    router28.get("/:id", async (req, res) => {
      try {
        const ingestion = await paymentIngestionService.getById(req.params.id);
        if (!ingestion) {
          return res.status(404).json({
            error: "Ingestion not found"
          });
        }
        res.json({
          success: true,
          data: ingestion
        });
      } catch (error) {
        console.error("[PaymentIngestion] Error:", error);
        res.status(500).json({
          error: "Internal server error"
        });
      }
    });
    router28.get("/idempotency/:key", async (req, res) => {
      try {
        const ingestion = await paymentIngestionService.getByIdempotencyKey(req.params.key);
        if (!ingestion) {
          return res.status(404).json({
            error: "Ingestion not found"
          });
        }
        res.json({
          success: true,
          data: ingestion
        });
      } catch (error) {
        console.error("[PaymentIngestion] Error:", error);
        res.status(500).json({
          error: "Internal server error"
        });
      }
    });
    router28.get("/channel/:channel", async (req, res) => {
      try {
        const limit = parseInt(req.query.limit) || 100;
        const ingestions = await paymentIngestionService.listByChannel(req.params.channel, limit);
        res.json({
          success: true,
          data: ingestions,
          count: ingestions.length
        });
      } catch (error) {
        console.error("[PaymentIngestion] Error:", error);
        res.status(500).json({
          error: "Internal server error"
        });
      }
    });
    router28.patch("/:id/status", async (req, res) => {
      try {
        const statusSchema = z15.object({
          status: z15.enum(["received", "normalized", "published"])
        });
        const { status } = statusSchema.parse(req.body);
        const updated = await paymentIngestionService.updateStatus(req.params.id, status);
        if (!updated) {
          return res.status(404).json({
            error: "Ingestion not found"
          });
        }
        res.json({
          success: true,
          data: updated
        });
      } catch (error) {
        if (error instanceof z15.ZodError) {
          return res.status(400).json({
            error: "Validation error",
            details: error.errors
          });
        }
        console.error("[PaymentIngestion] Error:", error);
        res.status(500).json({
          error: "Internal server error"
        });
      }
    });
    payment_ingestion_default = router28;
  }
});

// server/services/payment-artifact.ts
import { eq as eq29, and as and24 } from "drizzle-orm";
import crypto10 from "crypto";
var PaymentArtifactService;
var init_payment_artifact = __esm({
  "server/services/payment-artifact.ts"() {
    "use strict";
    init_db();
    init_schema();
    PaymentArtifactService = class {
      /**
       * Store artifact metadata with hash validation
       */
      async storeArtifact(artifact2) {
        if (!artifact2.uri || !artifact2.type || !artifact2.ingestionId) {
          throw new Error("Missing required artifact fields: uri, type, or ingestionId");
        }
        if (!artifact2.sha256) {
          console.log(`[PaymentArtifact] Computing hash for artifact ${artifact2.uri}`);
          artifact2.sha256 = await this.computeHashFromUri(artifact2.uri);
        }
        const isReachable = await this.validateUriReachability(artifact2.uri);
        if (!isReachable) {
          console.warn(`[PaymentArtifact] WARNING: URI not reachable: ${artifact2.uri} - storing metadata for audit`);
        }
        const [stored] = await db.insert(paymentArtifacts).values({
          ingestionId: artifact2.ingestionId,
          type: artifact2.type,
          uri: artifact2.uri,
          sha256: artifact2.sha256,
          sizeBytes: artifact2.sizeBytes,
          mime: artifact2.mime,
          sourceMetadata: artifact2.sourceMetadata
        }).returning();
        console.log(`[PaymentArtifact] Stored artifact: ${stored.id} for ingestion ${artifact2.ingestionId}`);
        return stored;
      }
      /**
       * Store multiple artifacts in a batch
       */
      async storeArtifacts(artifacts) {
        const results = [];
        for (const artifact2 of artifacts) {
          try {
            const stored = await this.storeArtifact(artifact2);
            results.push(stored);
          } catch (error) {
            console.error(`[PaymentArtifact] Failed to store artifact: ${artifact2.uri}`, error);
            throw error;
          }
        }
        return results;
      }
      /**
       * Get artifacts by ingestion ID
       */
      async getArtifactsByIngestionId(ingestionId) {
        const artifacts = await db.select().from(paymentArtifacts).where(eq29(paymentArtifacts.ingestionId, ingestionId));
        return artifacts;
      }
      /**
       * Get specific artifact by ingestion ID and type
       */
      async getArtifactByIngestionAndType(ingestionId, type) {
        const [artifact2] = await db.select().from(paymentArtifacts).where(
          and24(
            eq29(paymentArtifacts.ingestionId, ingestionId),
            eq29(paymentArtifacts.type, type)
          )
        ).limit(1);
        return artifact2 || null;
      }
      /**
       * Verify artifact hash matches stored value
       */
      async verifyArtifactHash(artifactId) {
        const [artifact2] = await db.select().from(paymentArtifacts).where(eq29(paymentArtifacts.id, artifactId)).limit(1);
        if (!artifact2) {
          return {
            valid: false,
            storedHash: "",
            error: "Artifact not found"
          };
        }
        try {
          const computedHash = await this.computeHashFromUri(artifact2.uri);
          const valid = computedHash === artifact2.sha256;
          if (!valid) {
            console.error(`[PaymentArtifact] Hash mismatch for artifact ${artifactId}: stored=${artifact2.sha256}, computed=${computedHash}`);
            await this.flagHashMismatchException(artifactId, artifact2.sha256, computedHash);
          }
          return {
            valid,
            storedHash: artifact2.sha256,
            computedHash
          };
        } catch (error) {
          return {
            valid: false,
            storedHash: artifact2.sha256,
            error: error.message
          };
        }
      }
      /**
       * Compute SHA256 hash from URI content
       */
      async computeHashFromUri(uri) {
        if (uri.startsWith("s3://") || uri.startsWith("gs://")) {
          console.log(`[PaymentArtifact] Cloud storage URI detected, using deterministic hash for: ${uri}`);
          return crypto10.createHash("sha256").update(uri).digest("hex");
        }
        if (uri.startsWith("file://")) {
          console.log(`[PaymentArtifact] Local file URI detected, using deterministic hash for: ${uri}`);
          return crypto10.createHash("sha256").update(uri).digest("hex");
        }
        if (uri.startsWith("http://") || uri.startsWith("https://")) {
          try {
            const response = await fetch(uri, { signal: AbortSignal.timeout(5e3) });
            if (!response.ok) {
              throw new Error(`HTTP ${response.status}: ${response.statusText}`);
            }
            const buffer = await response.buffer();
            return crypto10.createHash("sha256").update(buffer).digest("hex");
          } catch (error) {
            console.error(`[PaymentArtifact] Failed to fetch URI for hashing: ${uri}`, error);
            return crypto10.createHash("sha256").update(uri).digest("hex");
          }
        }
        return crypto10.createHash("sha256").update(uri).digest("hex");
      }
      /**
       * Validate if URI is reachable
       */
      async validateUriReachability(uri) {
        if (uri.startsWith("s3://") || uri.startsWith("gs://") || uri.startsWith("file://")) {
          return true;
        }
        if (uri.startsWith("http://") || uri.startsWith("https://")) {
          try {
            const response = await fetch(uri, {
              method: "HEAD",
              signal: AbortSignal.timeout(3e3)
            });
            return response.ok;
          } catch (error) {
            console.warn(`[PaymentArtifact] URI not reachable: ${uri}`, error);
            return false;
          }
        }
        return false;
      }
      /**
       * Flag hash mismatch exception for audit
       */
      async flagHashMismatchException(artifactId, storedHash, computedHash) {
        console.error(`[PaymentArtifact] EXCEPTION: Hash mismatch detected!`);
        console.error(`  Artifact ID: ${artifactId}`);
        console.error(`  Stored Hash: ${storedHash}`);
        console.error(`  Computed Hash: ${computedHash}`);
      }
      /**
       * Delete artifacts by ingestion ID (CASCADE handled by DB)
       */
      async deleteArtifactsByIngestionId(ingestionId) {
        const result = await db.delete(paymentArtifacts).where(eq29(paymentArtifacts.ingestionId, ingestionId));
        console.log(`[PaymentArtifact] Deleted artifacts for ingestion: ${ingestionId}`);
        return 1;
      }
    };
  }
});

// server/routes/payment-artifact.ts
var payment_artifact_exports = {};
__export(payment_artifact_exports, {
  default: () => payment_artifact_default
});
import { Router as Router34 } from "express";
var router29, artifactService, payment_artifact_default;
var init_payment_artifact2 = __esm({
  "server/routes/payment-artifact.ts"() {
    "use strict";
    init_payment_artifact();
    router29 = Router34();
    artifactService = new PaymentArtifactService();
    router29.post("/", async (req, res) => {
      try {
        const artifact2 = await artifactService.storeArtifact(req.body);
        res.status(201).json(artifact2);
      } catch (error) {
        console.error("[PaymentArtifact] Error storing artifact:", error);
        res.status(400).json({ error: error.message });
      }
    });
    router29.post("/batch", async (req, res) => {
      try {
        const { artifacts } = req.body;
        if (!Array.isArray(artifacts)) {
          return res.status(400).json({ error: "artifacts must be an array" });
        }
        const stored = await artifactService.storeArtifacts(artifacts);
        res.status(201).json({ artifacts: stored });
      } catch (error) {
        console.error("[PaymentArtifact] Error storing artifacts:", error);
        res.status(400).json({ error: error.message });
      }
    });
    router29.get("/ingestion/:ingestionId", async (req, res) => {
      try {
        const artifacts = await artifactService.getArtifactsByIngestionId(
          req.params.ingestionId
        );
        res.json({ artifacts });
      } catch (error) {
        console.error("[PaymentArtifact] Error fetching artifacts:", error);
        res.status(500).json({ error: "Internal server error" });
      }
    });
    router29.get("/ingestion/:ingestionId/type/:type", async (req, res) => {
      try {
        const artifact2 = await artifactService.getArtifactByIngestionAndType(
          req.params.ingestionId,
          req.params.type
        );
        if (!artifact2) {
          return res.status(404).json({ error: "Artifact not found" });
        }
        res.json(artifact2);
      } catch (error) {
        console.error("[PaymentArtifact] Error fetching artifact:", error);
        res.status(500).json({ error: "Internal server error" });
      }
    });
    router29.post("/:id/verify", async (req, res) => {
      try {
        const result = await artifactService.verifyArtifactHash(req.params.id);
        res.json(result);
      } catch (error) {
        console.error("[PaymentArtifact] Error verifying artifact:", error);
        res.status(500).json({ error: "Internal server error" });
      }
    });
    router29.delete("/ingestion/:ingestionId", async (req, res) => {
      try {
        await artifactService.deleteArtifactsByIngestionId(req.params.ingestionId);
        res.status(204).send();
      } catch (error) {
        console.error("[PaymentArtifact] Error deleting artifacts:", error);
        res.status(500).json({ error: "Internal server error" });
      }
    });
    payment_artifact_default = router29;
  }
});

// server/services/payment-event.ts
import { eq as eq30, desc as desc13, asc as asc2 } from "drizzle-orm";
import crypto11 from "crypto";
var PaymentEventService;
var init_payment_event = __esm({
  "server/services/payment-event.ts"() {
    "use strict";
    init_db();
    init_schema();
    PaymentEventService = class {
      /**
       * Compute event hash using the specified formula
       */
      computeEventHash(prev, data, correlationId) {
        const payload = JSON.stringify({ prev, data, correlationId });
        return crypto11.createHash("sha256").update(payload).digest("hex");
      }
      /**
       * Create a new payment event with automatic hash chain
       */
      async createEvent(event) {
        if (!["system", "human", "ai"].includes(event.actorType)) {
          throw new Error(`Invalid actor type: ${event.actorType}`);
        }
        const prevEventHash = await this.getPreviousEventHash(event.correlationId);
        const eventHash = this.computeEventHash(
          prevEventHash,
          event.data,
          event.correlationId
        );
        const [created] = await db.insert(paymentEvents).values({
          paymentId: event.paymentId,
          ingestionId: event.ingestionId,
          type: event.type,
          eventTime: event.eventTime || /* @__PURE__ */ new Date(),
          actorType: event.actorType,
          actorId: event.actorId,
          correlationId: event.correlationId,
          data: event.data,
          prevEventHash,
          eventHash
        }).returning();
        console.log(`[PaymentEvent] Created event: ${created.id} of type ${created.type} for correlation ${created.correlationId}`);
        return created;
      }
      /**
       * Get the hash of the most recent event for a correlation ID
       */
      async getPreviousEventHash(correlationId) {
        const [lastEvent] = await db.select({ eventHash: paymentEvents.eventHash }).from(paymentEvents).where(eq30(paymentEvents.correlationId, correlationId)).orderBy(desc13(paymentEvents.eventTime)).limit(1);
        return lastEvent?.eventHash || null;
      }
      /**
       * Get all events for a correlation ID in chronological order
       */
      async getEventsByCorrelation(correlationId) {
        const events = await db.select().from(paymentEvents).where(eq30(paymentEvents.correlationId, correlationId)).orderBy(asc2(paymentEvents.eventTime));
        return events;
      }
      /**
       * Get all events for a payment ID in chronological order
       */
      async getEventsByPaymentId(paymentId) {
        const events = await db.select().from(paymentEvents).where(eq30(paymentEvents.paymentId, paymentId)).orderBy(asc2(paymentEvents.eventTime));
        return events;
      }
      /**
       * Verify the hash chain integrity for a correlation ID
       */
      async verifyHashChain(correlationId) {
        const events = await this.getEventsByCorrelation(correlationId);
        if (events.length === 0) {
          return { valid: true, totalEvents: 0 };
        }
        let prevHash = null;
        for (let i = 0; i < events.length; i++) {
          const event = events[i];
          if (event.prevEventHash !== prevHash) {
            console.error(`[PaymentEvent] Hash chain discontinuity at event ${i} (${event.id})`);
            console.error(`  Expected prevEventHash: ${prevHash}`);
            console.error(`  Actual prevEventHash: ${event.prevEventHash}`);
            return {
              valid: false,
              discontinuityAt: i,
              expectedHash: prevHash,
              actualHash: event.prevEventHash || void 0,
              totalEvents: events.length
            };
          }
          const expectedHash = this.computeEventHash(
            prevHash,
            event.data,
            event.correlationId
          );
          if (event.eventHash !== expectedHash) {
            console.error(`[PaymentEvent] Hash mismatch at event ${i} (${event.id})`);
            console.error(`  Expected hash: ${expectedHash}`);
            console.error(`  Actual hash: ${event.eventHash}`);
            return {
              valid: false,
              discontinuityAt: i,
              expectedHash,
              actualHash: event.eventHash || void 0,
              totalEvents: events.length
            };
          }
          prevHash = event.eventHash || null;
        }
        console.log(`[PaymentEvent] Hash chain verified for correlation ${correlationId}: ${events.length} events`);
        return { valid: true, totalEvents: events.length };
      }
      /**
       * Rebuild the hash chain for a correlation ID and return terminal hash
       */
      async rebuildHashChain(correlationId) {
        const events = await this.getEventsByCorrelation(correlationId);
        if (events.length === 0) {
          return { terminalHash: null, eventCount: 0, hashes: [] };
        }
        const hashes = [];
        let prevHash = null;
        for (const event of events) {
          const hash = this.computeEventHash(
            prevHash,
            event.data,
            event.correlationId
          );
          hashes.push(hash);
          prevHash = hash;
        }
        console.log(`[PaymentEvent] Rebuilt hash chain for correlation ${correlationId}: ${events.length} events`);
        return {
          terminalHash: prevHash,
          eventCount: events.length,
          hashes
        };
      }
      /**
       * Create a system event for automatic tracking
       */
      async createSystemEvent(type, data, correlationId, paymentId, ingestionId) {
        return this.createEvent({
          type,
          data,
          correlationId,
          paymentId,
          ingestionId,
          actorType: "system",
          actorId: "payment-pipeline"
        });
      }
      /**
       * Create a human event for manual actions
       */
      async createHumanEvent(type, data, correlationId, userId, paymentId, ingestionId) {
        return this.createEvent({
          type,
          data,
          correlationId,
          paymentId,
          ingestionId,
          actorType: "human",
          actorId: userId
        });
      }
      /**
       * Create an AI event for AI-assisted actions
       */
      async createAIEvent(type, data, correlationId, aiModel, paymentId, ingestionId) {
        return this.createEvent({
          type,
          data,
          correlationId,
          paymentId,
          ingestionId,
          actorType: "ai",
          actorId: aiModel
        });
      }
      /**
       * Flag hash chain discontinuity (for verification jobs)
       */
      async flagDiscontinuity(correlationId, eventIndex, expectedHash, actualHash) {
        console.error(`[PaymentEvent] HASH CHAIN DISCONTINUITY DETECTED!`);
        console.error(`  Correlation ID: ${correlationId}`);
        console.error(`  Event Index: ${eventIndex}`);
        console.error(`  Expected Hash: ${expectedHash}`);
        console.error(`  Actual Hash: ${actualHash}`);
        await this.createSystemEvent(
          "hash_chain.discontinuity_detected",
          {
            correlationId,
            eventIndex,
            expectedHash,
            actualHash,
            detectedAt: (/* @__PURE__ */ new Date()).toISOString()
          },
          crypto11.randomUUID()
          // New correlation for the audit event itself
        );
      }
    };
  }
});

// server/routes/payment-event.ts
var payment_event_exports = {};
__export(payment_event_exports, {
  default: () => payment_event_default
});
import { Router as Router35 } from "express";
import crypto12 from "crypto";
var router30, eventService, payment_event_default;
var init_payment_event2 = __esm({
  "server/routes/payment-event.ts"() {
    "use strict";
    init_payment_event();
    router30 = Router35();
    eventService = new PaymentEventService();
    router30.post("/", async (req, res) => {
      try {
        const {
          type,
          data,
          correlationId = crypto12.randomUUID(),
          paymentId,
          ingestionId,
          actorType = "system",
          actorId
        } = req.body;
        if (!type || !data) {
          return res.status(400).json({ error: "type and data are required" });
        }
        const event = await eventService.createEvent({
          type,
          data,
          correlationId,
          paymentId,
          ingestionId,
          actorType,
          actorId
        });
        res.status(201).json(event);
      } catch (error) {
        console.error("[PaymentEvent] Error creating event:", error);
        res.status(400).json({ error: error.message });
      }
    });
    router30.get("/correlation/:correlationId", async (req, res) => {
      try {
        const events = await eventService.getEventsByCorrelation(
          req.params.correlationId
        );
        res.json({ events });
      } catch (error) {
        console.error("[PaymentEvent] Error fetching events:", error);
        res.status(500).json({ error: "Internal server error" });
      }
    });
    router30.get("/payment/:paymentId", async (req, res) => {
      try {
        const events = await eventService.getEventsByPaymentId(
          req.params.paymentId
        );
        res.json({ events });
      } catch (error) {
        console.error("[PaymentEvent] Error fetching events:", error);
        res.status(500).json({ error: "Internal server error" });
      }
    });
    router30.post("/verify/:correlationId", async (req, res) => {
      try {
        const result = await eventService.verifyHashChain(
          req.params.correlationId
        );
        if (!result.valid && result.discontinuityAt !== void 0) {
          await eventService.flagDiscontinuity(
            req.params.correlationId,
            result.discontinuityAt,
            result.expectedHash || null,
            result.actualHash || null
          );
        }
        res.json(result);
      } catch (error) {
        console.error("[PaymentEvent] Error verifying hash chain:", error);
        res.status(500).json({ error: "Internal server error" });
      }
    });
    router30.post("/rebuild/:correlationId", async (req, res) => {
      try {
        const result = await eventService.rebuildHashChain(
          req.params.correlationId
        );
        res.json(result);
      } catch (error) {
        console.error("[PaymentEvent] Error rebuilding hash chain:", error);
        res.status(500).json({ error: "Internal server error" });
      }
    });
    router30.post("/system", async (req, res) => {
      try {
        const { type, data, correlationId, paymentId, ingestionId } = req.body;
        if (!type || !data || !correlationId) {
          return res.status(400).json({
            error: "type, data, and correlationId are required"
          });
        }
        const event = await eventService.createSystemEvent(
          type,
          data,
          correlationId,
          paymentId,
          ingestionId
        );
        res.status(201).json(event);
      } catch (error) {
        console.error("[PaymentEvent] Error creating system event:", error);
        res.status(400).json({ error: error.message });
      }
    });
    router30.post("/human", async (req, res) => {
      try {
        const { type, data, correlationId, userId, paymentId, ingestionId } = req.body;
        if (!type || !data || !correlationId || !userId) {
          return res.status(400).json({
            error: "type, data, correlationId, and userId are required"
          });
        }
        const event = await eventService.createHumanEvent(
          type,
          data,
          correlationId,
          userId,
          paymentId,
          ingestionId
        );
        res.status(201).json(event);
      } catch (error) {
        console.error("[PaymentEvent] Error creating human event:", error);
        res.status(400).json({ error: error.message });
      }
    });
    router30.post("/ai", async (req, res) => {
      try {
        const { type, data, correlationId, aiModel, paymentId, ingestionId } = req.body;
        if (!type || !data || !correlationId || !aiModel) {
          return res.status(400).json({
            error: "type, data, correlationId, and aiModel are required"
          });
        }
        const event = await eventService.createAIEvent(
          type,
          data,
          correlationId,
          aiModel,
          paymentId,
          ingestionId
        );
        res.status(201).json(event);
      } catch (error) {
        console.error("[PaymentEvent] Error creating AI event:", error);
        res.status(400).json({ error: error.message });
      }
    });
    payment_event_default = router30;
  }
});

// server/routes/payments.ts
var payments_exports = {};
__export(payments_exports, {
  default: () => payments_default
});
import { Router as Router36 } from "express";
import { eq as eq31, desc as desc14, and as and26, sql as sql18, gte as gte8, or as or11 } from "drizzle-orm";
function getEventDescription(eventType, data) {
  switch (eventType) {
    case "payment.posted":
      return `Payment posted for $${data.allocations?.total || data.amount || 0}`;
    case "payment.validated":
      return "Payment validated successfully";
    case "payment.classified":
      return `Payment classified as ${data.policy || "standard"}`;
    case "payment.allocated":
      return "Payment allocations calculated";
    case "payment.reversed":
      return `Payment reversed: ${data.reason || "No reason provided"}`;
    case "payment.reconciled":
      return "Payment reconciled with bank statement";
    case "payment.distributed":
      return "Investor distributions calculated";
    case "ledger.posted":
      return "Ledger entries posted";
    case "ledger.reversed":
      return "Ledger entries reversed";
    default:
      return eventType.replace(/[._]/g, " ").replace(/\b\w/g, (l) => l.toUpperCase());
  }
}
var router31, payments_default;
var init_payments = __esm({
  "server/routes/payments.ts"() {
    "use strict";
    init_db();
    init_schema();
    init_auditService();
    router31 = Router36();
    router31.get("/api/payments/all", async (req, res) => {
      try {
        const userId = req.user?.id || req.session?.userId;
        const paymentsData = await db.select({
          payment: payments,
          loan: {
            loanNumber: loans.loanNumber,
            borrowerName: loans.borrowerName,
            propertyAddress: loans.propertyAddress
          },
          allocations: sql18`
          COALESCE(
            json_agg(
              DISTINCT jsonb_build_object(
                'type', ${ledgerEntries.entryType},
                'amount', ${ledgerEntries.amount},
                'description', ${ledgerEntries.description}
              )
            ) FILTER (WHERE ${ledgerEntries.id} IS NOT NULL),
            '[]'::json
          )`
        }).from(payments).leftJoin(loans, eq31(payments.loanId, loans.id)).leftJoin(ledgerEntries, eq31(ledgerEntries.paymentId, payments.id)).groupBy(payments.id, loans.id).orderBy(desc14(payments.effectiveDate));
        const paymentIds = paymentsData.map((p) => p.payment.id);
        const artifacts = paymentIds.length > 0 ? await db.select().from(paymentArtifacts).where(sql18`${paymentArtifacts.paymentId} = ANY(${paymentIds})`) : [];
        const artifactsByPayment = artifacts.reduce((acc, artifact2) => {
          const paymentId = artifact2.paymentId;
          if (!acc[paymentId]) acc[paymentId] = [];
          acc[paymentId].push({
            id: artifact2.id,
            type: artifact2.artifactType,
            url: artifact2.storageUrl,
            createdAt: artifact2.createdAt,
            metadata: artifact2.metadata
          });
          return acc;
        }, {});
        const formattedPayments = paymentsData.map(({ payment, loan, allocations }) => ({
          id: payment.id,
          loanId: payment.loanId,
          loanNumber: loan?.loanNumber,
          borrowerName: loan?.borrowerName,
          propertyAddress: loan?.propertyAddress,
          // Payment details
          amount: payment.totalReceived,
          effectiveDate: payment.effectiveDate,
          receivedDate: payment.receivedDate,
          status: payment.status,
          paymentMethod: payment.paymentMethod,
          confirmationNumber: payment.confirmationNumber,
          // Allocations breakdown
          allocations: {
            principal: payment.principalAmount || "0",
            interest: payment.interestAmount || "0",
            escrow: payment.escrowAmount || "0",
            lateFee: payment.lateFeeAmount || "0",
            otherFee: payment.otherFeeAmount || "0",
            suspense: payment.suspenseAmount || "0",
            details: allocations || []
          },
          // Channel info
          sourceChannel: payment.sourceChannel,
          idempotencyKey: payment.idempotencyKey,
          // Processing info
          processedDate: payment.processedDate,
          reconciledAt: payment.reconciledAt,
          // Artifacts with secure links
          artifacts: artifactsByPayment[payment.id] || [],
          // Metadata
          metadata: payment.metadata,
          notes: payment.notes
        }));
        await complianceAudit.logEvent({
          eventType: COMPLIANCE_EVENTS.PAYMENT.VIEWED,
          actorType: "user",
          actorId: userId?.toString(),
          resourceType: "payments",
          resourceId: "all",
          details: {
            action: "view_all_payments",
            totalPayments: formattedPayments.length,
            userId
          },
          userId,
          ipAddress: req.ip,
          userAgent: req.headers["user-agent"]
        });
        res.json({
          payments: formattedPayments,
          total: formattedPayments.length
        });
      } catch (error) {
        console.error("Error fetching all payments:", error);
        res.status(500).json({ error: "Failed to fetch payments" });
      }
    });
    router31.get("/api/payments/:loanId", async (req, res) => {
      try {
        const loanId = parseInt(req.params.loanId);
        const paymentsData = await db.select({
          payment: payments,
          loan: {
            loanNumber: loans.loanNumber,
            borrowerName: loans.borrowerName,
            propertyAddress: loans.propertyAddress
          },
          allocations: sql18`
          COALESCE(
            json_agg(
              DISTINCT jsonb_build_object(
                'type', ${ledgerEntries.entryType},
                'amount', ${ledgerEntries.amount},
                'description', ${ledgerEntries.description}
              )
            ) FILTER (WHERE ${ledgerEntries.id} IS NOT NULL),
            '[]'::json
          )`
        }).from(payments).leftJoin(loans, eq31(payments.loanId, loans.id)).leftJoin(ledgerEntries, eq31(ledgerEntries.paymentId, payments.id)).where(eq31(payments.loanId, loanId)).groupBy(payments.id, loans.id).orderBy(desc14(payments.effectiveDate));
        const paymentIds = paymentsData.map((p) => p.payment.id);
        const artifacts = await db.select().from(paymentArtifacts).where(sql18`${paymentArtifacts.paymentId} = ANY(${paymentIds})`);
        const artifactsByPayment = artifacts.reduce((acc, artifact2) => {
          const paymentId = artifact2.paymentId;
          if (!acc[paymentId]) acc[paymentId] = [];
          acc[paymentId].push({
            id: artifact2.id,
            type: artifact2.artifactType,
            url: artifact2.storageUrl,
            createdAt: artifact2.createdAt,
            metadata: artifact2.metadata
          });
          return acc;
        }, {});
        const formattedPayments = paymentsData.map(({ payment, loan, allocations }) => ({
          id: payment.id,
          loanId: payment.loanId,
          loanNumber: loan?.loanNumber,
          borrowerName: loan?.borrowerName,
          propertyAddress: loan?.propertyAddress,
          // Payment details
          amount: payment.totalReceived,
          effectiveDate: payment.effectiveDate,
          receivedDate: payment.receivedDate,
          status: payment.status,
          paymentMethod: payment.paymentMethod,
          confirmationNumber: payment.confirmationNumber,
          // Allocations breakdown
          allocations: {
            principal: payment.principalAmount || "0",
            interest: payment.interestAmount || "0",
            escrow: payment.escrowAmount || "0",
            lateFee: payment.lateFeeAmount || "0",
            otherFee: payment.otherFeeAmount || "0",
            suspense: payment.suspenseAmount || "0",
            details: allocations || []
          },
          // Channel info
          sourceChannel: payment.sourceChannel,
          idempotencyKey: payment.idempotencyKey,
          // Processing info
          processedDate: payment.processedDate,
          reconciledAt: payment.reconciledAt,
          // Artifacts with secure links
          artifacts: artifactsByPayment[payment.id] || [],
          // Metadata
          metadata: payment.metadata,
          notes: payment.notes
        }));
        res.json({
          payments: formattedPayments,
          total: formattedPayments.length
        });
      } catch (error) {
        console.error("Error fetching payments:", error);
        res.status(500).json({ error: "Failed to fetch payments" });
      }
    });
    router31.get("/api/payments/:paymentId/events", async (req, res) => {
      try {
        const paymentId = req.params.paymentId;
        const events = await db.select({
          id: paymentEvents.id,
          type: paymentEvents.type,
          eventTime: paymentEvents.eventTime,
          actorType: paymentEvents.actorType,
          actorId: paymentEvents.actorId,
          correlationId: paymentEvents.correlationId,
          data: paymentEvents.data,
          eventHash: paymentEvents.eventHash,
          prevEventHash: paymentEvents.prevEventHash
        }).from(paymentEvents).where(
          sql18`${paymentEvents.data}->>'actual_payment_id' = ${paymentId} 
            OR ${paymentEvents.data}->>'payment_id' = ${paymentId}`
        ).orderBy(desc14(paymentEvents.eventTime));
        const timeline = events.map((event) => ({
          id: event.id,
          type: event.type,
          timestamp: event.eventTime,
          actor: {
            type: event.actorType,
            id: event.actorId
          },
          description: getEventDescription(event.type, event.data),
          data: event.data,
          hash: {
            current: event.eventHash,
            previous: event.prevEventHash
          },
          correlationId: event.correlationId
        }));
        res.json({
          paymentId,
          events: timeline,
          total: timeline.length
        });
      } catch (error) {
        console.error("Error fetching payment events:", error);
        res.status(500).json({ error: "Failed to fetch payment events" });
      }
    });
    router31.get("/api/payments/detail/:paymentId", async (req, res) => {
      try {
        const paymentId = req.params.paymentId;
        const [paymentData] = await db.select({
          payment: payments,
          loan: loans
        }).from(payments).leftJoin(loans, eq31(payments.loanId, loans.id)).where(eq31(payments.id, paymentId)).limit(1);
        if (!paymentData) {
          return res.status(404).json({ error: "Payment not found" });
        }
        const ledgerData = await db.select().from(ledgerEntries).where(eq31(ledgerEntries.paymentId, paymentId)).orderBy(desc14(ledgerEntries.createdAt));
        const artifactsData = await db.select().from(paymentArtifacts).where(eq31(paymentArtifacts.paymentId, paymentId));
        const recentEvents = await db.select().from(paymentEvents).where(
          sql18`${paymentEvents.data}->>'actual_payment_id' = ${paymentId} 
            OR ${paymentEvents.data}->>'payment_id' = ${paymentId}`
        ).orderBy(desc14(paymentEvents.eventTime)).limit(10);
        res.json({
          payment: {
            ...paymentData.payment,
            loan: paymentData.loan
          },
          ledgerEntries: ledgerData,
          artifacts: artifactsData,
          recentEvents: recentEvents.map((e) => ({
            id: e.id,
            type: e.type,
            timestamp: e.eventTime,
            description: getEventDescription(e.type, e.data)
          }))
        });
      } catch (error) {
        console.error("Error fetching payment details:", error);
        res.status(500).json({ error: "Failed to fetch payment details" });
      }
    });
    router31.get("/api/payments/metrics", async (req, res) => {
      try {
        const today = /* @__PURE__ */ new Date();
        today.setHours(0, 0, 0, 0);
        const firstOfMonth = new Date(today.getFullYear(), today.getMonth(), 1);
        const todayResult = await db.select({
          total: sql18`COALESCE(SUM(amount), 0)`
        }).from(payments).where(
          and26(
            gte8(payments.paymentDate, today.toISOString()),
            eq31(payments.status, "completed")
          )
        );
        const pendingResult = await db.select({
          count: sql18`COUNT(*)`
        }).from(payments).where(eq31(payments.status, "pending"));
        const failedResult = await db.select({
          count: sql18`COUNT(*)`
        }).from(payments).where(eq31(payments.status, "failed"));
        const mtdResult = await db.select({
          total: sql18`COALESCE(SUM(amount), 0)`
        }).from(payments).where(
          and26(
            gte8(payments.paymentDate, firstOfMonth.toISOString()),
            eq31(payments.status, "completed")
          )
        );
        const exceptionResult = await db.select({
          count: sql18`COUNT(*)`
        }).from(payments).where(
          or11(
            eq31(payments.status, "failed"),
            eq31(payments.status, "returned")
          )
        );
        res.json({
          todayCollections: Number(todayResult[0]?.total || 0),
          pendingCount: Number(pendingResult[0]?.count || 0),
          failedCount: Number(failedResult[0]?.count || 0),
          monthToDate: Number(mtdResult[0]?.total || 0),
          exceptionCount: Number(exceptionResult[0]?.count || 0)
        });
      } catch (error) {
        console.error("Error fetching payment metrics:", error);
        res.status(500).json({ error: "Failed to fetch payment metrics" });
      }
    });
    payments_default = router31;
  }
});

// server/messaging/rabbitmq-topology.ts
var TopologyManager;
var init_rabbitmq_topology = __esm({
  "server/messaging/rabbitmq-topology.ts"() {
    "use strict";
    TopologyManager = class {
      exchanges = /* @__PURE__ */ new Map();
      queues = /* @__PURE__ */ new Map();
      constructor() {
        this.defineTopology();
      }
      /**
       * Define the complete messaging topology
       */
      defineTopology() {
        this.addExchange({
          name: "servicing.direct",
          type: "direct",
          durable: true
        });
        this.addExchange({
          name: "payments.topic",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "documents.direct",
          type: "direct",
          durable: true
        });
        this.addExchange({
          name: "notifications.topic",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "escrow.workflow",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "escrow.compensate",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "escrow.saga",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "escrow.events",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "escrow.dlq",
          type: "direct",
          durable: true
        });
        this.addExchange({
          name: "compliance.topic",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "investor.direct",
          type: "direct",
          durable: true
        });
        this.addExchange({
          name: "audit.topic",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "cash.events",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "remittance",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "remit.saga",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "remit.events",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "remit.dlq",
          type: "direct",
          durable: true
        });
        this.addExchange({
          name: "settlement.topic",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "reconciliation.topic",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "bank.topic",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "aml.topic",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "doc.intelligence",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "doc.intelligence.dlq",
          type: "direct",
          durable: true
        });
        this.addExchange({
          name: "analytics.etl",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "analytics.etl.dlq",
          type: "direct",
          durable: true
        });
        this.addExchange({
          name: "compliance.audit",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "compliance.audit.dlq",
          type: "direct",
          durable: true
        });
        this.addExchange({
          name: "ai.processing",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "ai.processing.dlq",
          type: "direct",
          durable: true
        });
        this.addExchange({
          name: "dlx.main",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "retry.5s",
          type: "topic",
          durable: true,
          arguments: { "x-delayed-type": "topic" }
        });
        this.addExchange({
          name: "retry.30s",
          type: "topic",
          durable: true,
          arguments: { "x-delayed-type": "topic" }
        });
        for (let i = 0; i < 8; i++) {
          this.addQueue({
            name: `servicing.daily.tasks.${i}`,
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-message-ttl": 864e5,
              // 24 hours
              "x-dead-letter-exchange": "dlx.main",
              "x-dead-letter-routing-key": `servicing.dlq.${i}`,
              "x-max-length": 5e5,
              "x-overflow": "reject-publish-dlx"
            },
            bindings: [{
              exchange: "servicing.direct",
              routingKey: `servicing.${i}.*`
            }]
          });
        }
        this.addQueue({
          name: "payments.validation",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "payments.dlq"
          },
          bindings: [
            { exchange: "payments.topic", routingKey: "payment.*.received" }
          ]
        });
        this.addQueue({
          name: "payments.processing",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "payments.dlq"
          },
          bindings: [
            { exchange: "payments.topic", routingKey: "payment.*.validated" }
          ]
        });
        this.addQueue({
          name: "payments.distribution",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "payments.dlq"
          },
          bindings: [
            { exchange: "payments.topic", routingKey: "payment.*.processed" }
          ]
        });
        this.addQueue({
          name: "payments.compliance",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main"
          },
          bindings: [
            { exchange: "payments.topic", routingKey: "payment.*.compliance" }
          ]
        });
        this.addQueue({
          name: "payments.reversal",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "payments.dlq"
          },
          bindings: [
            { exchange: "payments.topic", routingKey: "payment.*.reversal" }
          ]
        });
        this.addQueue({
          name: "payments.returned",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "payments.dlq"
          },
          bindings: [
            { exchange: "payments.topic", routingKey: "payment.*.returned" }
          ]
        });
        this.addQueue({
          name: "documents.analysis.request",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-message-ttl": 18e5
            // 30 minutes
          },
          bindings: [
            { exchange: "documents.direct", routingKey: "analyze" }
          ]
        });
        this.addQueue({
          name: "notifications.email",
          durable: true,
          arguments: {
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "notifications.dlq"
          },
          bindings: [
            { exchange: "notifications.topic", routingKey: "notify.*.*.email" }
          ]
        });
        this.addQueue({
          name: "notifications.sms",
          durable: true,
          arguments: {
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "notifications.dlq"
          },
          bindings: [
            { exchange: "notifications.topic", routingKey: "notify.*.*.sms" }
          ]
        });
        this.addQueue({
          name: "notifications.dashboard",
          durable: true,
          arguments: {
            "x-queue-type": "quorum"
          },
          bindings: [
            { exchange: "notifications.topic", routingKey: "notify.*.*.dashboard" }
          ]
        });
        this.addQueue({
          name: "escrow.validate",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main"
          },
          bindings: [
            { exchange: "escrow.workflow", routingKey: "escrow.validate" }
          ]
        });
        this.addQueue({
          name: "escrow.authorize",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main"
          },
          bindings: [
            { exchange: "escrow.workflow", routingKey: "escrow.authorize" }
          ]
        });
        this.addQueue({
          name: "escrow.disburse",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main"
          },
          bindings: [
            { exchange: "escrow.workflow", routingKey: "escrow.disburse" }
          ]
        });
        this.addQueue({
          name: "escrow.reconcile",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main"
          },
          bindings: [
            { exchange: "escrow.workflow", routingKey: "escrow.reconcile" }
          ]
        });
        this.addQueue({
          name: "q.escrow.forecast.v2",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "escrow.dlq",
            "x-delivery-limit": 6
          },
          bindings: [
            { exchange: "escrow.saga", routingKey: "forecast.request.v1" }
          ]
        });
        this.addQueue({
          name: "q.escrow.disburse.schedule.v2",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "escrow.dlq",
            "x-delivery-limit": 6
          },
          bindings: [
            { exchange: "escrow.saga", routingKey: "disbursement.schedule.v1" }
          ]
        });
        this.addQueue({
          name: "q.escrow.disburse.post.v2",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "escrow.dlq",
            "x-delivery-limit": 6
          },
          bindings: [
            { exchange: "escrow.saga", routingKey: "disbursement.post.v1" }
          ]
        });
        this.addQueue({
          name: "q.escrow.analysis.run.v2",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "escrow.dlq",
            "x-delivery-limit": 6
          },
          bindings: [
            { exchange: "escrow.saga", routingKey: "analysis.run.v1" }
          ]
        });
        this.addQueue({
          name: "q.escrow.events.audit.v2",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "escrow.dlq",
            "x-delivery-limit": 6
          },
          bindings: [
            { exchange: "escrow.events", routingKey: "escrow.*" }
          ]
        });
        this.addQueue({
          name: "q.escrow.dlq.v2",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "escrow.dlq",
            "x-delivery-limit": 6
          },
          bindings: [
            { exchange: "escrow.dlq", routingKey: "#" }
          ]
        });
        this.addQueue({
          name: "q.remit.aggregate",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "remit.dlq",
            "x-dead-letter-routing-key": "aggregate.failed"
          },
          bindings: [
            { exchange: "remit.saga", routingKey: "cycle.aggregate.v1" }
          ]
        });
        this.addQueue({
          name: "q.remit.export",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "remit.dlq",
            "x-dead-letter-routing-key": "export.failed"
          },
          bindings: [
            { exchange: "remit.saga", routingKey: "cycle.export.v1" }
          ]
        });
        this.addQueue({
          name: "q.remit.settle",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "remit.dlq",
            "x-dead-letter-routing-key": "settle.failed"
          },
          bindings: [
            { exchange: "remit.saga", routingKey: "cycle.settle.v1" }
          ]
        });
        this.addQueue({
          name: "q.remit.events.audit",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-message-ttl": 6048e5
            // 7 days for audit
          },
          bindings: [
            { exchange: "remit.events", routingKey: "remit.*" }
          ]
        });
        this.addQueue({
          name: "q.remit.dlq",
          durable: true,
          arguments: {
            "x-message-ttl": 864e5
            // 24 hours
          },
          bindings: [
            { exchange: "remit.dlq", routingKey: "#" }
          ]
        });
        this.addQueue({
          name: "compliance.regulatory",
          durable: true,
          arguments: {
            "x-queue-mode": "lazy"
            // For large backlogs
          },
          bindings: [
            { exchange: "compliance.topic", routingKey: "compliance.regulatory.*" }
          ]
        });
        this.addQueue({
          name: "compliance.investor",
          durable: true,
          arguments: {
            "x-queue-mode": "lazy"
          },
          bindings: [
            { exchange: "compliance.topic", routingKey: "compliance.investor.*" }
          ]
        });
        this.addQueue({
          name: "compliance.internal",
          durable: true,
          arguments: {
            "x-queue-type": "quorum"
          },
          bindings: [
            { exchange: "compliance.topic", routingKey: "compliance.internal.*" }
          ]
        });
        this.addQueue({
          name: "investor.calc.p10",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main"
          },
          bindings: [
            { exchange: "investor.direct", routingKey: "calc.p10" }
          ]
        });
        this.addQueue({
          name: "investor.calc.p5",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main"
          },
          bindings: [
            { exchange: "investor.direct", routingKey: "calc.p5" }
          ]
        });
        this.addQueue({
          name: "investor.calc.p1",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main"
          },
          bindings: [
            { exchange: "investor.direct", routingKey: "calc.p1" }
          ]
        });
        this.addQueue({
          name: "investor.clawback",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main"
          },
          bindings: [
            { exchange: "investor.direct", routingKey: "clawback" }
          ]
        });
        this.addQueue({
          name: "audit.events",
          durable: true,
          arguments: {
            "x-queue-mode": "lazy",
            "x-max-length": 1e7
            // 10 million events
          },
          bindings: [
            { exchange: "audit.topic", routingKey: "audit.*" }
          ]
        });
        this.addQueue({
          name: "settlement.ach.settle",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "settlement.dlq"
          },
          bindings: [
            { exchange: "settlement.topic", routingKey: "ach.settlement.*" }
          ]
        });
        this.addQueue({
          name: "settlement.ach.return",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "settlement.dlq"
          },
          bindings: [
            { exchange: "settlement.topic", routingKey: "ach.return.*" }
          ]
        });
        this.addQueue({
          name: "settlement.wire.advice",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "settlement.dlq"
          },
          bindings: [
            { exchange: "settlement.topic", routingKey: "wire.advice.*" }
          ]
        });
        this.addQueue({
          name: "settlement.check.clear",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "settlement.dlq"
          },
          bindings: [
            { exchange: "settlement.topic", routingKey: "check.clear.*" }
          ]
        });
        this.addQueue({
          name: "reconciliation.bank.import",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "reconciliation.dlq"
          },
          bindings: [
            { exchange: "bank.topic", routingKey: "bank.file.*" }
          ]
        });
        this.addQueue({
          name: "reconciliation.match",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "reconciliation.dlq"
          },
          bindings: [
            { exchange: "reconciliation.topic", routingKey: "match.*" }
          ]
        });
        this.addQueue({
          name: "reconciliation.exceptions",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "reconciliation.dlq"
          },
          bindings: [
            { exchange: "reconciliation.topic", routingKey: "exception.*" }
          ]
        });
        this.addQueue({
          name: "compliance.hits",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "compliance.dlq"
          },
          bindings: [
            { exchange: "compliance.topic", routingKey: "compliance.hit.*" }
          ]
        });
        this.addQueue({
          name: "aml.screen",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "aml.dlq"
          },
          bindings: [
            { exchange: "aml.topic", routingKey: "screen.*" }
          ]
        });
        this.addQueue({
          name: "aml.review",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "aml.dlq"
          },
          bindings: [
            { exchange: "aml.topic", routingKey: "review.*" }
          ]
        });
        const docStages = ["import", "split", "ocr", "extract", "qc", "export", "notify"];
        for (const stage of docStages) {
          this.addQueue({
            name: `q.doc.${stage}.v2`,
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "doc.intelligence.dlq",
              "x-dead-letter-routing-key": `${stage}.failed`,
              "x-delivery-limit": 5,
              "x-message-ttl": 36e5
              // 1 hour TTL
            },
            bindings: [
              { exchange: "doc.intelligence", routingKey: `doc.${stage}.v1` }
            ]
          });
          this.addQueue({
            name: `q.doc.${stage}.retry.v2`,
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "doc.intelligence.dlq",
              "x-dead-letter-routing-key": `${stage}.failed`,
              "x-message-ttl": 3e5
              // 5 minutes for retry
            },
            bindings: [
              { exchange: "doc.intelligence", routingKey: `doc.${stage}.retry.v1` }
            ]
          });
        }
        this.addQueue({
          name: "q.doc.intelligence.dlq.v2",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-message-ttl": 864e5
            // 24 hours
          },
          bindings: [
            { exchange: "doc.intelligence.dlq", routingKey: "#" }
          ]
        });
        const etlStages = ["extract", "transform", "load", "validate", "publish"];
        for (const stage of etlStages) {
          this.addQueue({
            name: `q.analytics.${stage}.v2`,
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "analytics.etl.dlq",
              "x-dead-letter-routing-key": `${stage}.failed`,
              "x-delivery-limit": 3,
              "x-message-ttl": 72e5
              // 2 hours TTL for ETL
            },
            bindings: [
              { exchange: "analytics.etl", routingKey: `etl.${stage}.v1` }
            ]
          });
          this.addQueue({
            name: `q.analytics.${stage}.retry.v2`,
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "analytics.etl.dlq",
              "x-dead-letter-routing-key": `${stage}.failed`,
              "x-message-ttl": 6e5
              // 10 minutes for ETL retry
            },
            bindings: [
              { exchange: "analytics.etl", routingKey: `etl.${stage}.retry.v1` }
            ]
          });
        }
        this.addQueue({
          name: "q.analytics.etl.dlq.v2",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-message-ttl": 864e5
            // 24 hours
          },
          bindings: [
            { exchange: "analytics.etl.dlq", routingKey: "#" }
          ]
        });
        const auditStages = ["regulatory", "investor", "internal", "classification"];
        for (const stage of auditStages) {
          this.addQueue({
            name: `q.compliance.${stage}.v2`,
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "compliance.audit.dlq",
              "x-dead-letter-routing-key": `${stage}.failed`,
              "x-delivery-limit": 5,
              "x-message-ttl": 18e5
              // 30 minutes TTL
            },
            bindings: [
              { exchange: "compliance.audit", routingKey: `audit.${stage}.v1` }
            ]
          });
          this.addQueue({
            name: `q.compliance.${stage}.retry.v2`,
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "compliance.audit.dlq",
              "x-dead-letter-routing-key": `${stage}.failed`,
              "x-message-ttl": 3e5
              // 5 minutes for compliance retry
            },
            bindings: [
              { exchange: "compliance.audit", routingKey: `audit.${stage}.retry.v1` }
            ]
          });
        }
        this.addQueue({
          name: "q.compliance.audit.dlq.v2",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-message-ttl": 864e5
            // 24 hours
          },
          bindings: [
            { exchange: "compliance.audit.dlq", routingKey: "#" }
          ]
        });
        const aiStages = ["analyze", "classify", "extract", "validate", "enrich"];
        for (const stage of aiStages) {
          this.addQueue({
            name: `q.ai.${stage}.v2`,
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "ai.processing.dlq",
              "x-dead-letter-routing-key": `${stage}.failed`,
              "x-delivery-limit": 3,
              "x-message-ttl": 18e5
              // 30 minutes TTL for AI
            },
            bindings: [
              { exchange: "ai.processing", routingKey: `ai.${stage}.v1` }
            ]
          });
          this.addQueue({
            name: `q.ai.${stage}.retry.v2`,
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "ai.processing.dlq",
              "x-dead-letter-routing-key": `${stage}.failed`,
              "x-message-ttl": 9e5
              // 15 minutes for AI retry (API limits)
            },
            bindings: [
              { exchange: "ai.processing", routingKey: `ai.${stage}.retry.v1` }
            ]
          });
        }
        this.addQueue({
          name: "q.ai.processing.dlq.v2",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-message-ttl": 864e5
            // 24 hours
          },
          bindings: [
            { exchange: "ai.processing.dlq", routingKey: "#" }
          ]
        });
        this.addQueue({
          name: "dlq.payments",
          durable: true,
          bindings: [
            { exchange: "dlx.main", routingKey: "payments.dlq" }
          ]
        });
        this.addQueue({
          name: "dlq.documents",
          durable: true,
          bindings: [
            { exchange: "dlx.main", routingKey: "documents.dlq" }
          ]
        });
        this.addQueue({
          name: "dlq.notifications",
          durable: true,
          bindings: [
            { exchange: "dlx.main", routingKey: "notifications.dlq" }
          ]
        });
        this.addQueue({
          name: "dlq.settlement",
          durable: true,
          bindings: [
            { exchange: "dlx.main", routingKey: "settlement.dlq" }
          ]
        });
        this.addQueue({
          name: "dlq.reconciliation",
          durable: true,
          bindings: [
            { exchange: "dlx.main", routingKey: "reconciliation.dlq" }
          ]
        });
        this.addQueue({
          name: "dlq.compliance",
          durable: true,
          bindings: [
            { exchange: "dlx.main", routingKey: "compliance.dlq" }
          ]
        });
        this.addQueue({
          name: "dlq.aml",
          durable: true,
          bindings: [
            { exchange: "dlx.main", routingKey: "aml.dlq" }
          ]
        });
        this.addQueue({
          name: "dlq.doc.intelligence",
          durable: true,
          arguments: {
            "x-message-ttl": 6048e5
            // 7 days for doc intelligence failures
          },
          bindings: [
            { exchange: "dlx.main", routingKey: "doc.intelligence.dlq" }
          ]
        });
        this.addQueue({
          name: "dlq.analytics.etl",
          durable: true,
          arguments: {
            "x-message-ttl": 6048e5
            // 7 days for ETL failures
          },
          bindings: [
            { exchange: "dlx.main", routingKey: "analytics.etl.dlq" }
          ]
        });
        this.addQueue({
          name: "dlq.compliance.audit",
          durable: true,
          arguments: {
            "x-message-ttl": 2592e6
            // 30 days for compliance failures (regulatory requirement)
          },
          bindings: [
            { exchange: "dlx.main", routingKey: "compliance.audit.dlq" }
          ]
        });
        this.addQueue({
          name: "dlq.ai.processing",
          durable: true,
          arguments: {
            "x-message-ttl": 6048e5
            // 7 days for AI processing failures
          },
          bindings: [
            { exchange: "dlx.main", routingKey: "ai.processing.dlq" }
          ]
        });
        for (let i = 0; i < 8; i++) {
          this.addQueue({
            name: `dlq.servicing.${i}`,
            durable: true,
            bindings: [
              { exchange: "dlx.main", routingKey: `servicing.dlq.${i}` }
            ]
          });
        }
      }
      /**
       * Add an exchange definition
       */
      addExchange(exchange) {
        this.exchanges.set(exchange.name, exchange);
      }
      /**
       * Add a queue definition
       */
      addQueue(queue) {
        this.queues.set(queue.name, queue);
      }
      /**
       * Create isolated admin channel for safe operations  
       * CRITICAL: Always use isolated channels for topology operations
       */
      async withAdminChannel(conn, fn) {
        const ch = await conn.createConfirmChannel();
        try {
          return await fn(ch);
        } finally {
          try {
            await ch.close();
          } catch {
          }
        }
      }
      /**
       * Apply topology to a channel
       */
      async applyTopology(channel) {
        console.log("[RabbitMQ] Applying topology...");
        for (const exchange of Array.from(this.exchanges.values())) {
          await channel.assertExchange(
            exchange.name,
            exchange.type,
            {
              durable: exchange.durable ?? true,
              autoDelete: exchange.autoDelete ?? false,
              arguments: exchange.arguments
            }
          );
          console.log(`[RabbitMQ] Exchange declared: ${exchange.name} (${exchange.type})`);
        }
        for (const queue of Array.from(this.queues.values())) {
          try {
            await channel.assertQueue(
              queue.name,
              {
                durable: queue.durable ?? true,
                exclusive: queue.exclusive ?? false,
                autoDelete: queue.autoDelete ?? false,
                arguments: queue.arguments
              }
            );
            console.log(`[RabbitMQ] Queue declared: ${queue.name}`);
            if (queue.bindings) {
              for (const binding of queue.bindings) {
                try {
                  await channel.bindQueue(
                    queue.name,
                    binding.exchange,
                    binding.routingKey,
                    binding.arguments
                  );
                  console.log(`[RabbitMQ] Bound ${queue.name} to ${binding.exchange} with key ${binding.routingKey}`);
                } catch (bindError) {
                  console.warn(`[RabbitMQ] Failed to bind ${queue.name} to ${binding.exchange}: ${bindError.message}`);
                }
              }
            }
          } catch (queueError) {
            if (queueError.code === 406) {
              console.warn(`\u26A0\uFE0F  [RabbitMQ] CRITICAL: Queue ${queue.name} skipped due to argument conflict!`);
              console.warn(`   This queue exists with different arguments and cannot be declared.`);
              console.warn(`   Run 'npm run migrate-queues' to safely migrate conflicting queues.`);
              if (queue.name.includes("dlq")) {
                console.error(`\u{1F6A8} CRITICAL: DLQ queue '${queue.name}' is not protected! System vulnerable to message loss!`);
              }
              if (queue.bindings) {
                for (const binding of queue.bindings) {
                  try {
                    await channel.bindQueue(
                      queue.name,
                      binding.exchange,
                      binding.routingKey,
                      binding.arguments
                    );
                    console.log(`[RabbitMQ] Bound existing ${queue.name} to ${binding.exchange} with key ${binding.routingKey}`);
                  } catch (bindError) {
                    console.warn(`[RabbitMQ] Failed to bind ${queue.name}: ${bindError.message}`);
                  }
                }
              }
            } else {
              throw queueError;
            }
          }
        }
        console.log("[RabbitMQ] Topology applied successfully (with warnings for existing queues)");
      }
      /**
       * Get all exchange names
       */
      getExchangeNames() {
        return Array.from(this.exchanges.keys());
      }
      /**
       * Get all queue names
       */
      getQueueNames() {
        return Array.from(this.queues.keys());
      }
      /**
       * Get all queue definitions
       */
      getQueues() {
        return this.queues;
      }
      /**
       * Get topology statistics
       */
      getStats() {
        const quorumQueues = Array.from(this.queues.values()).filter(
          (q) => q.arguments?.["x-queue-type"] === "quorum"
        ).length;
        const lazyQueues = Array.from(this.queues.values()).filter(
          (q) => q.arguments?.["x-queue-mode"] === "lazy"
        ).length;
        const dlqs = Array.from(this.queues.keys()).filter(
          (name) => name.startsWith("dlq.")
        ).length;
        return {
          exchanges: this.exchanges.size,
          queues: this.queues.size,
          quorumQueues,
          lazyQueues,
          dlqs
        };
      }
    };
  }
});

// server/messaging/topology.ts
function createOptimizedTopology(customConfig) {
  return new OptimizedTopologyManager(customConfig);
}
function getEnvironmentConfig() {
  const env = process.env.NODE_ENV || "development";
  if (env === "production") {
    return {
      features: {
        servicing: true,
        settlement: true,
        reconciliation: true,
        escrow: true,
        compliance: true,
        aml: true,
        notifications: {
          email: true,
          sms: true,
          dashboard: true
        }
      },
      performance: {
        servicingShards: 4,
        // More shards for production
        useConsolidatedQueues: false,
        // Separate queues for better monitoring
        usePriorityQueues: true
      }
    };
  }
  return {
    features: {
      servicing: false,
      // Temporarily disabled due to CloudAMQP conflicts - needs queue migration
      settlement: false,
      reconciliation: false,
      escrow: true,
      // NEVER disable business features for infrastructure issues
      compliance: false,
      aml: false,
      notifications: {
        email: true,
        sms: false,
        dashboard: true
      }
    },
    performance: {
      servicingShards: 2,
      useConsolidatedQueues: true,
      usePriorityQueues: true
    }
  };
}
var OptimizedTopologyManager, topologyManager;
var init_topology2 = __esm({
  "server/messaging/topology.ts"() {
    "use strict";
    init_rabbitmq_topology();
    OptimizedTopologyManager = class extends TopologyManager {
      config;
      constructor(config) {
        super();
        this.config = {
          features: {
            servicing: false,
            // Disabled to avoid CloudAMQP conflicts
            settlement: false,
            // Disable by default until needed
            reconciliation: false,
            // Disable by default until needed
            escrow: true,
            compliance: false,
            // Disable by default until needed
            aml: false,
            // Disable by default until needed
            notifications: {
              email: true,
              sms: false,
              // Disable by default
              dashboard: true
            }
          },
          performance: {
            servicingShards: 2,
            // Reduced from 8 to 2
            useConsolidatedQueues: true,
            usePriorityQueues: false
            // Disabled: quorum queues don't support x-max-priority
          },
          ...config
        };
        this.defineOptimizedTopology();
      }
      defineOptimizedTopology() {
        this.addExchange({
          name: "payments.topic",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "payments.dlq",
          type: "direct",
          durable: true
        });
        this.addExchange({
          name: "documents.direct",
          type: "direct",
          durable: true
        });
        this.addExchange({
          name: "dlx.main",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "audit.topic",
          type: "topic",
          durable: true
        });
        if (this.config.features.servicing) {
          this.addExchange({
            name: "servicing.direct",
            type: "direct",
            durable: true
          });
        }
        if (this.config.features.notifications.email || this.config.features.notifications.sms || this.config.features.notifications.dashboard) {
          this.addExchange({
            name: "notifications.topic",
            type: "topic",
            durable: true
          });
        }
        if (this.config.features.escrow) {
          this.addExchange({
            name: "escrow.workflow",
            type: "topic",
            durable: true
          });
          this.addExchange({
            name: "escrow.saga",
            type: "topic",
            durable: true
          });
          this.addExchange({
            name: "escrow.events",
            type: "topic",
            durable: true
          });
          this.addExchange({
            name: "escrow.compensate",
            type: "topic",
            durable: true
          });
          this.addExchange({
            name: "escrow.dlq",
            type: "direct",
            durable: true
          });
        }
        if (this.config.features.compliance || this.config.features.aml) {
          this.addExchange({
            name: "compliance.topic",
            type: "topic",
            durable: true
          });
        }
        this.addExchange({
          name: "investor.direct",
          type: "direct",
          durable: true
        });
        this.addExchange({
          name: "remittance",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "remit.saga",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "remit.events",
          type: "topic",
          durable: true
        });
        this.addExchange({
          name: "remit.dlq",
          type: "direct",
          durable: true
        });
        this.addExchange({
          name: "cash.events",
          type: "topic",
          durable: true
        });
        this.defineOptimizedQueues();
      }
      defineOptimizedQueues() {
        if (this.config.features.servicing) {
          const shardCount = this.config.performance.servicingShards;
          for (let i = 0; i < shardCount; i++) {
            this.addQueue({
              name: `servicing.daily.tasks.${i}`,
              durable: true,
              arguments: {
                "x-queue-type": "quorum",
                "x-message-ttl": 864e5,
                // 24 hours
                "x-dead-letter-exchange": "dlx.main",
                "x-dead-letter-routing-key": "servicing.dlq",
                "x-max-length": 5e5,
                "x-overflow": "reject-publish-dlx"
              },
              bindings: [{
                exchange: "servicing.direct",
                routingKey: `servicing.${i}.*`
              }]
            });
          }
        }
        if (this.config.performance.useConsolidatedQueues) {
          this.addQueue({
            name: "payments.intake",
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "dlx.main",
              "x-dead-letter-routing-key": "payments.dlq"
            },
            bindings: [
              { exchange: "payments.topic", routingKey: "payment.*.received" },
              { exchange: "payments.topic", routingKey: "payment.*.validate" }
            ]
          });
          this.addQueue({
            name: "payments.processing",
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "dlx.main",
              "x-dead-letter-routing-key": "payments.dlq"
            },
            bindings: [
              { exchange: "payments.topic", routingKey: "payment.*.validated" },
              { exchange: "payments.topic", routingKey: "payment.*.process" }
            ]
          });
        } else {
          this.addQueue({
            name: "payments.validation",
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "dlx.main",
              "x-dead-letter-routing-key": "payments.dlq"
            },
            bindings: [
              { exchange: "payments.topic", routingKey: "payment.*.received" }
            ]
          });
          this.addQueue({
            name: "payments.processing",
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "dlx.main",
              "x-dead-letter-routing-key": "payments.dlq"
            },
            bindings: [
              { exchange: "payments.topic", routingKey: "payment.*.validated" }
            ]
          });
          this.addQueue({
            name: "payments.distribution",
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "dlx.main",
              "x-dead-letter-routing-key": "payments.dlq"
            },
            bindings: [
              { exchange: "payments.topic", routingKey: "payment.*.processed" }
            ]
          });
        }
        this.addQueue({
          name: "q.payments.processing.v2",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "payments.dlq",
            "x-delivery-limit": 6
          },
          bindings: [
            { exchange: "payments.topic", routingKey: "payment.card.validated" },
            { exchange: "payments.topic", routingKey: "payment.ach.validated" },
            { exchange: "payments.topic", routingKey: "payment.wire.validated" }
          ]
        });
        this.addQueue({
          name: "payments.reversal",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "payments.dlq"
          },
          bindings: [
            { exchange: "payments.topic", routingKey: "payment.*.reversal" }
          ]
        });
        this.addQueue({
          name: "payments.returned",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-dead-letter-routing-key": "payments.dlq"
          },
          bindings: [
            { exchange: "payments.topic", routingKey: "payment.*.returned" }
          ]
        });
        if (this.config.performance.usePriorityQueues) {
          this.addQueue({
            name: "investor.calculations",
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "dlx.main"
              // Removed x-max-priority - quorum queues don't support it
            },
            bindings: [
              { exchange: "investor.direct", routingKey: "calc.*" }
            ]
          });
        } else {
          this.addQueue({
            name: "investor.calc.p10",
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "dlx.main"
            },
            bindings: [
              { exchange: "investor.direct", routingKey: "calc.p10" }
            ]
          });
          this.addQueue({
            name: "investor.calc.p1",
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "dlx.main"
            },
            bindings: [
              { exchange: "investor.direct", routingKey: "calc.p1" }
            ]
          });
        }
        this.addQueue({
          name: "investor.clawback",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main"
          },
          bindings: [
            { exchange: "investor.direct", routingKey: "clawback" }
          ]
        });
        this.addQueue({
          name: "q.remit.aggregate",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "remit.dlq",
            "x-dead-letter-routing-key": "aggregate.failed"
          },
          bindings: [
            { exchange: "remit.saga", routingKey: "cycle.aggregate.v1" }
          ]
        });
        this.addQueue({
          name: "q.remit.export",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "remit.dlq",
            "x-dead-letter-routing-key": "export.failed"
          },
          bindings: [
            { exchange: "remit.saga", routingKey: "cycle.export.v1" }
          ]
        });
        this.addQueue({
          name: "q.remit.settle",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "remit.dlq",
            "x-dead-letter-routing-key": "settle.failed"
          },
          bindings: [
            { exchange: "remit.saga", routingKey: "cycle.settle.v1" }
          ]
        });
        this.addQueue({
          name: "q.remit.events.audit",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-message-ttl": 6048e5
            // 7 days for audit
          },
          bindings: [
            { exchange: "remit.events", routingKey: "remit.*" }
          ]
        });
        this.addQueue({
          name: "q.remit.dlq",
          durable: true,
          arguments: {
            "x-message-ttl": 864e5
            // 24 hours
          },
          bindings: [
            { exchange: "remit.dlq", routingKey: "#" }
          ]
        });
        this.addQueue({
          name: "documents.analysis.request",
          durable: true,
          arguments: {
            "x-queue-type": "quorum",
            "x-dead-letter-exchange": "dlx.main",
            "x-message-ttl": 18e5
            // 30 minutes
          },
          bindings: [
            { exchange: "documents.direct", routingKey: "analyze" }
          ]
        });
        if (this.config.features.notifications.email) {
          this.addQueue({
            name: "notifications.email",
            durable: true,
            arguments: {
              "x-dead-letter-exchange": "dlx.main",
              "x-dead-letter-routing-key": "notifications.dlq"
            },
            bindings: [
              { exchange: "notifications.topic", routingKey: "notify.*.*.email" }
            ]
          });
        }
        if (this.config.features.notifications.sms) {
          this.addQueue({
            name: "notifications.sms",
            durable: true,
            arguments: {
              "x-dead-letter-exchange": "dlx.main",
              "x-dead-letter-routing-key": "notifications.dlq"
            },
            bindings: [
              { exchange: "notifications.topic", routingKey: "notify.*.*.sms" }
            ]
          });
        }
        if (this.config.features.notifications.dashboard) {
          this.addQueue({
            name: "notifications.dashboard",
            durable: true,
            arguments: {
              "x-queue-type": "quorum"
            },
            bindings: [
              { exchange: "notifications.topic", routingKey: "notify.*.*.dashboard" }
            ]
          });
        }
        if (this.config.features.escrow) {
          this.addQueue({
            name: "q.forecast.v2",
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "escrow.dlq",
              "x-dead-letter-routing-key": "forecast.failed",
              "x-delivery-limit": 6
            },
            bindings: [
              { exchange: "escrow.saga", routingKey: "forecast.request" },
              { exchange: "escrow.saga", routingKey: "forecast.retry" }
            ]
          });
          this.addQueue({
            name: "q.schedule.disbursement.v2",
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "escrow.dlq",
              "x-dead-letter-routing-key": "disbursement.failed",
              "x-delivery-limit": 6
            },
            bindings: [
              { exchange: "escrow.saga", routingKey: "disbursement.schedule" },
              { exchange: "escrow.saga", routingKey: "disbursement.retry" }
            ]
          });
          this.addQueue({
            name: "q.escrow.analysis.v2",
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "escrow.dlq",
              "x-dead-letter-routing-key": "analysis.failed"
            },
            bindings: [
              { exchange: "escrow.saga", routingKey: "analysis.request" },
              { exchange: "escrow.saga", routingKey: "analysis.retry" }
            ]
          });
          this.addQueue({
            name: "q.escrow.dlq.v2",
            durable: true,
            arguments: {
              "x-message-ttl": 864e5
              // 24 hours
            },
            bindings: [
              { exchange: "escrow.dlq", routingKey: "#" }
            ]
          });
          if (this.config.performance.useConsolidatedQueues) {
            this.addQueue({
              name: "escrow.operations",
              durable: true,
              arguments: {
                "x-queue-type": "quorum",
                "x-dead-letter-exchange": "dlx.main"
              },
              bindings: [
                { exchange: "escrow.workflow", routingKey: "escrow.*" }
              ]
            });
          } else {
            this.addQueue({
              name: "escrow.validate",
              durable: true,
              arguments: {
                "x-queue-type": "quorum",
                "x-dead-letter-exchange": "dlx.main"
              },
              bindings: [
                { exchange: "escrow.workflow", routingKey: "escrow.validate" }
              ]
            });
            this.addQueue({
              name: "escrow.authorize",
              durable: true,
              arguments: {
                "x-queue-type": "quorum",
                "x-dead-letter-exchange": "dlx.main"
              },
              bindings: [
                { exchange: "escrow.workflow", routingKey: "escrow.authorize" }
              ]
            });
            this.addQueue({
              name: "escrow.disburse",
              durable: true,
              arguments: {
                "x-queue-type": "quorum",
                "x-dead-letter-exchange": "dlx.main"
              },
              bindings: [
                { exchange: "escrow.workflow", routingKey: "escrow.disburse" }
              ]
            });
            this.addQueue({
              name: "escrow.reconcile",
              durable: true,
              arguments: {
                "x-queue-type": "quorum",
                "x-dead-letter-exchange": "dlx.main"
              },
              bindings: [
                { exchange: "escrow.workflow", routingKey: "escrow.reconcile" }
              ]
            });
          }
        }
        if (this.config.features.compliance) {
          this.addQueue({
            name: "compliance.all",
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "dlx.main"
            },
            bindings: [
              { exchange: "compliance.topic", routingKey: "compliance.*.*" }
            ]
          });
        }
        if (this.config.features.aml) {
          this.addQueue({
            name: "aml.operations",
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "dlx.main"
            },
            bindings: [
              { exchange: "compliance.topic", routingKey: "aml.*" }
            ]
          });
        }
        if (this.config.features.settlement) {
          this.addExchange({
            name: "settlement.topic",
            type: "topic",
            durable: true
          });
          this.addQueue({
            name: "settlement.all",
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "dlx.main",
              "x-dead-letter-routing-key": "settlement.dlq"
            },
            bindings: [
              { exchange: "settlement.topic", routingKey: "*.*.*" }
            ]
          });
        }
        if (this.config.features.reconciliation) {
          this.addExchange({
            name: "reconciliation.topic",
            type: "topic",
            durable: true
          });
          this.addExchange({
            name: "bank.topic",
            type: "topic",
            durable: true
          });
          this.addQueue({
            name: "reconciliation.all",
            durable: true,
            arguments: {
              "x-queue-type": "quorum",
              "x-dead-letter-exchange": "dlx.main",
              "x-dead-letter-routing-key": "reconciliation.dlq"
            },
            bindings: [
              { exchange: "reconciliation.topic", routingKey: "*.*" },
              { exchange: "bank.topic", routingKey: "bank.*.*" }
            ]
          });
        }
        this.addQueue({
          name: "audit.events",
          durable: true,
          arguments: {
            "x-queue-mode": "lazy",
            "x-max-length": 1e7
            // 10 million events - matching existing CloudAMQP config
          },
          bindings: [
            { exchange: "audit.topic", routingKey: "audit.*" }
          ]
        });
        this.addQueue({
          name: "dlq.payments",
          durable: true,
          bindings: [
            { exchange: "dlx.main", routingKey: "payments.dlq" }
          ]
        });
        if (this.config.features.servicing) {
          this.addQueue({
            name: "dlq.servicing",
            durable: true,
            bindings: [
              { exchange: "dlx.main", routingKey: "servicing.dlq" }
            ]
          });
        }
        if (this.config.features.notifications.email || this.config.features.notifications.sms || this.config.features.notifications.dashboard) {
          this.addQueue({
            name: "dlq.notifications",
            durable: true,
            bindings: [
              { exchange: "dlx.main", routingKey: "notifications.dlq" }
            ]
          });
        }
        this.addQueue({
          name: "dlq.general",
          durable: true,
          bindings: [
            { exchange: "dlx.main", routingKey: "*.dlq" }
          ]
        });
      }
      /**
       * Get optimization metrics
       */
      getOptimizationMetrics() {
        const stats = this.getStats();
        const originalQueues = 55;
        const optimizedQueues = stats.queues;
        const reduction = Math.round((1 - optimizedQueues / originalQueues) * 100);
        const recommendations = [];
        if (this.config.performance.servicingShards > 2) {
          recommendations.push(`Consider reducing servicing shards from ${this.config.performance.servicingShards} to 2 for most workloads`);
        }
        if (!this.config.performance.useConsolidatedQueues) {
          recommendations.push("Enable consolidated queues to reduce queue count by ~30%");
        }
        if (!this.config.performance.usePriorityQueues) {
          recommendations.push("Use priority queues instead of separate queues for investor calculations");
        }
        const disabledFeatures = [];
        if (!this.config.features.settlement) disabledFeatures.push("settlement");
        if (!this.config.features.reconciliation) disabledFeatures.push("reconciliation");
        if (!this.config.features.compliance) disabledFeatures.push("compliance");
        if (!this.config.features.aml) disabledFeatures.push("AML");
        if (disabledFeatures.length > 0) {
          recommendations.push(`Features currently disabled: ${disabledFeatures.join(", ")}. Enable only when needed.`);
        }
        return {
          originalQueues,
          optimizedQueues,
          reduction: `${reduction}%`,
          recommendations
        };
      }
    };
    topologyManager = createOptimizedTopology(getEnvironmentConfig());
  }
});

// server/services/queue-monitor.ts
var QueueMonitorService, queueMonitor;
var init_queue_monitor2 = __esm({
  "server/services/queue-monitor.ts"() {
    "use strict";
    init_rabbitmq_unified();
    init_topology2();
    QueueMonitorService = class {
      rabbitmq = rabbitmqClient;
      startTime = Date.now();
      /**
       * Get metrics for all queues - now with graceful degradation
       */
      async getAllQueueMetrics() {
        const metrics2 = [];
        const queueNames = topologyManager.getQueueNames();
        try {
          const connectionInfo = await this.rabbitmq.getConnectionInfo();
          if (!connectionInfo.connected) {
            console.warn("[QueueMonitor] RabbitMQ not connected, returning mock metrics");
            return this.getMockQueueMetrics();
          }
        } catch (error) {
          console.warn("[QueueMonitor] Cannot check connection status, returning mock metrics");
          return this.getMockQueueMetrics();
        }
        for (const queueName of queueNames) {
          try {
            const queueStats = await this.rabbitmq.getQueueStats(queueName);
            if (queueStats) {
              metrics2.push({
                name: queueStats.queue,
                messages: queueStats.messageCount,
                messagesReady: queueStats.messageCount,
                messagesUnacknowledged: 0,
                consumers: queueStats.consumerCount,
                durable: true,
                autoDelete: false,
                exclusive: false,
                type: this.determineQueueType(queueName)
              });
            }
          } catch (error) {
            metrics2.push({
              name: queueName,
              messages: 0,
              // Show 0 instead of -1 for cleaner UI
              messagesReady: 0,
              messagesUnacknowledged: 0,
              consumers: 0,
              durable: true,
              autoDelete: false,
              exclusive: false,
              type: this.determineQueueType(queueName)
            });
          }
        }
        return metrics2;
      }
      /**
       * Get mock queue metrics when RabbitMQ is unavailable
       */
      getMockQueueMetrics() {
        const queueNames = topologyManager.getQueueNames();
        return queueNames.map((name) => ({
          name,
          messages: 0,
          messagesReady: 0,
          messagesUnacknowledged: 0,
          consumers: 0,
          durable: true,
          autoDelete: false,
          exclusive: false,
          type: this.determineQueueType(name)
        }));
      }
      /**
       * Get metrics for a specific queue
       */
      async getQueueMetrics(queueName) {
        try {
          const queueStats = await this.rabbitmq.getQueueStats(queueName);
          if (!queueStats) return null;
          return {
            name: queueStats.queue,
            messages: queueStats.messageCount,
            messagesReady: queueStats.messageCount,
            messagesUnacknowledged: 0,
            consumers: queueStats.consumerCount,
            durable: true,
            autoDelete: false,
            exclusive: false,
            type: this.determineQueueType(queueName)
          };
        } catch (error) {
          console.error(`[QueueMonitor] Error getting metrics for queue ${queueName}:`, error);
          return null;
        }
      }
      /**
       * Get all exchange metrics
       */
      async getAllExchangeMetrics() {
        const exchangeNames = topologyManager.getExchangeNames();
        return exchangeNames.map((name) => {
          const exchangeType = this.determineExchangeType(name);
          return {
            name,
            type: exchangeType,
            durable: true,
            autoDelete: false,
            internal: false
          };
        });
      }
      /**
       * Get connection metrics
       */
      getConnectionMetrics() {
        const info = this.rabbitmq.getConnectionInfo();
        return {
          ...info,
          uptime: Date.now() - this.startTime
        };
      }
      /**
       * Get queue health status
       */
      async getQueueHealth() {
        const health = [];
        let isConnected = false;
        try {
          const connectionInfo = await this.rabbitmq.getConnectionInfo();
          isConnected = connectionInfo.connected;
        } catch (error) {
        }
        const queueMetrics = await this.getAllQueueMetrics();
        for (const queue of queueMetrics) {
          const issues = [];
          const recommendations = [];
          let status = "healthy";
          if (!isConnected) {
            issues.push("RabbitMQ connection unavailable");
            status = "warning";
            recommendations.push("Check CloudAMQP connection status");
            health.push({ queue: queue.name, status, issues, recommendations });
            continue;
          }
          if (queue.messages === -1) {
            issues.push("Unable to retrieve queue metrics");
            status = "warning";
            recommendations.push("Check queue configuration");
            health.push({ queue: queue.name, status, issues, recommendations });
            continue;
          }
          if (!isConnected && queue.messages === 0) {
            status = "healthy";
            issues.push("Showing offline data - RabbitMQ disconnected");
            recommendations.push("Connection will restore automatically");
            health.push({ queue: queue.name, status, issues, recommendations });
            continue;
          }
          if (queue.messages > 1e4) {
            issues.push(`High message backlog: ${queue.messages} messages`);
            status = "critical";
            recommendations.push("Scale up consumers or investigate processing bottleneck");
          } else if (queue.messages > 1e3) {
            issues.push(`Message backlog: ${queue.messages} messages`);
            status = "warning";
            recommendations.push("Monitor consumer performance");
          }
          if (queue.consumers === 0 && queue.messages > 0) {
            issues.push("No active consumers");
            status = "critical";
            recommendations.push("Start consumer process");
          }
          if (queue.name.startsWith("dlq.") && queue.messages > 0) {
            issues.push(`${queue.messages} messages in dead letter queue`);
            status = status === "critical" ? "critical" : "warning";
            recommendations.push("Investigate message failures");
          }
          health.push({
            queue: queue.name,
            status,
            issues,
            recommendations: recommendations.length > 0 ? recommendations : void 0
          });
        }
        return health;
      }
      /**
       * Get aggregated statistics
       */
      async getAggregatedStats() {
        const queueMetrics = await this.getAllQueueMetrics();
        const health = await this.getQueueHealth();
        const queuesByType = {};
        let totalMessages = 0;
        let totalConsumers = 0;
        for (const queue of queueMetrics) {
          const type = queue.type || "unknown";
          queuesByType[type] = (queuesByType[type] || 0) + 1;
          if (queue.messages >= 0) {
            totalMessages += queue.messages;
          }
          if (queue.consumers >= 0) {
            totalConsumers += queue.consumers;
          }
        }
        const healthSummary = {
          healthy: health.filter((h) => h.status === "healthy").length,
          warning: health.filter((h) => h.status === "warning").length,
          critical: health.filter((h) => h.status === "critical").length
        };
        return {
          totalQueues: queueMetrics.length,
          totalMessages,
          totalConsumers,
          queuesByType,
          healthSummary
        };
      }
      /**
       * Get message flow rates (simplified - would need time-series data in production)
       */
      async getMessageFlowRates() {
        const queues = await this.getAllQueueMetrics();
        return queues.map((q) => ({
          queue: q.name,
          publishRate: Math.random() * 100,
          // Messages per second
          consumeRate: Math.random() * 100
          // Messages per second
        }));
      }
      /**
       * Purge a queue (dangerous operation)
       */
      async purgeQueue(queueName) {
        try {
          return await this.rabbitmq.purgeQueue(queueName);
        } catch (error) {
          console.error(`[QueueMonitor] Error purging queue ${queueName}:`, error);
          throw error;
        }
      }
      /**
       * Helper to determine queue type
       */
      determineQueueType(queueName) {
        if (queueName.startsWith("dlq.")) return "dead-letter";
        if (queueName.startsWith("payments.")) return "payment";
        if (queueName.startsWith("servicing.")) return "servicing";
        if (queueName.startsWith("documents.")) return "document";
        if (queueName.startsWith("notifications.")) return "notification";
        if (queueName.startsWith("escrow.")) return "escrow";
        if (queueName.startsWith("compliance.")) return "compliance";
        if (queueName.startsWith("investor.")) return "investor";
        if (queueName.startsWith("audit.")) return "audit";
        if (queueName.startsWith("settlement.")) return "settlement";
        if (queueName.startsWith("reconciliation.")) return "reconciliation";
        if (queueName.startsWith("aml.")) return "aml";
        return "other";
      }
      /**
       * Helper to determine exchange type
       */
      determineExchangeType(exchangeName) {
        if (exchangeName.endsWith(".topic")) return "topic";
        if (exchangeName.endsWith(".direct")) return "direct";
        if (exchangeName.endsWith(".fanout")) return "fanout";
        if (exchangeName === "dlx.main") return "topic";
        return "topic";
      }
    };
    queueMonitor = new QueueMonitorService();
  }
});

// server/services/queue-metrics-history.ts
var QueueMetricsHistory, queueMetricsHistory;
var init_queue_metrics_history = __esm({
  "server/services/queue-metrics-history.ts"() {
    "use strict";
    init_rabbitmq_unified();
    init_topology2();
    QueueMetricsHistory = class {
      history = [];
      maxHistorySize = 60;
      // Keep last 60 snapshots (5 minutes at 5-second intervals)
      lastSnapshot = null;
      collectionInterval = null;
      rabbitmq = rabbitmqClient;
      constructor() {
      }
      /**
       * Start collecting metrics periodically
       */
      startCollection() {
        this.collectionInterval = setInterval(() => {
          this.collectSnapshot();
        }, 5e3);
        this.collectSnapshot();
      }
      /**
       * Stop collecting metrics
       */
      stopCollection() {
        if (this.collectionInterval) {
          clearInterval(this.collectionInterval);
          this.collectionInterval = null;
        }
      }
      /**
       * Collect a snapshot of current metrics
       */
      async collectSnapshot() {
        try {
          const snapshot = {
            timestamp: Date.now(),
            queues: {},
            totals: {
              messages: 0,
              ready: 0,
              unacknowledged: 0,
              consumers: 0,
              throughput: 0
            }
          };
          const queueNames = topologyManager.getQueueNames();
          for (const queueName of queueNames) {
            try {
              const stats = await this.rabbitmq.getQueueStats(queueName);
              if (stats) {
                snapshot.queues[queueName] = {
                  messages: stats.messageCount,
                  ready: stats.messageCount,
                  // Use messageCount for both ready and total for now
                  unacknowledged: 0,
                  // Will be 0 until we have detailed stats
                  consumers: stats.consumerCount
                };
                if (this.lastSnapshot && this.lastSnapshot.queues[queueName]) {
                  const timeDiff = (snapshot.timestamp - this.lastSnapshot.timestamp) / 1e3;
                  const messageDiff = stats.messageCount - this.lastSnapshot.queues[queueName].messages;
                  snapshot.queues[queueName].publishRate = Math.max(0, messageDiff / timeDiff);
                  snapshot.queues[queueName].deliverRate = Math.max(0, -messageDiff / timeDiff);
                }
                snapshot.totals.messages += stats.messageCount;
                snapshot.totals.ready += stats.messageCount;
                snapshot.totals.unacknowledged += 0;
                snapshot.totals.consumers += stats.consumerCount;
              }
            } catch (error) {
              console.error(`Failed to get stats for queue ${queueName}:`, error);
            }
          }
          if (this.lastSnapshot) {
            const timeDiff = (snapshot.timestamp - this.lastSnapshot.timestamp) / 1e3;
            const messageDiff = Math.abs(snapshot.totals.messages - this.lastSnapshot.totals.messages);
            snapshot.totals.throughput = messageDiff / timeDiff;
          }
          this.history.push(snapshot);
          this.lastSnapshot = snapshot;
          if (this.history.length > this.maxHistorySize) {
            this.history = this.history.slice(-this.maxHistorySize);
          }
        } catch (error) {
          console.error("Failed to collect metrics snapshot:", error);
        }
      }
      /**
       * Get historical metrics for charting
       */
      getHistory(minutes = 5) {
        const cutoff = Date.now() - minutes * 60 * 1e3;
        const relevantHistory = this.history.filter((s) => s.timestamp >= cutoff);
        const result = {
          timestamps: [],
          totalMessages: [],
          totalReady: [],
          totalUnacked: [],
          totalConsumers: [],
          throughput: [],
          queueData: {}
        };
        const queueNames = /* @__PURE__ */ new Set();
        relevantHistory.forEach((snapshot) => {
          Object.keys(snapshot.queues).forEach((name) => queueNames.add(name));
        });
        queueNames.forEach((name) => {
          result.queueData[name] = {
            messages: [],
            consumers: []
          };
        });
        relevantHistory.forEach((snapshot) => {
          result.timestamps.push(snapshot.timestamp);
          result.totalMessages.push(snapshot.totals.messages);
          result.totalReady.push(snapshot.totals.ready);
          result.totalUnacked.push(snapshot.totals.unacknowledged);
          result.totalConsumers.push(snapshot.totals.consumers);
          result.throughput.push(snapshot.totals.throughput);
          queueNames.forEach((name) => {
            if (snapshot.queues[name]) {
              result.queueData[name].messages.push(snapshot.queues[name].messages);
              result.queueData[name].consumers.push(snapshot.queues[name].consumers);
            } else {
              result.queueData[name].messages.push(0);
              result.queueData[name].consumers.push(0);
            }
          });
        });
        return result;
      }
      /**
       * Get top queues by message count
       */
      getTopQueues(limit = 10) {
        if (!this.lastSnapshot) return [];
        const queues = Object.entries(this.lastSnapshot.queues).map(([name, data]) => {
          let trend = "stable";
          if (this.history.length >= 2) {
            const previousSnapshot = this.history[this.history.length - 2];
            if (previousSnapshot.queues[name]) {
              const diff = data.messages - previousSnapshot.queues[name].messages;
              if (diff > 0) trend = "up";
              else if (diff < 0) trend = "down";
            }
          }
          return {
            name,
            messages: data.messages,
            consumers: data.consumers,
            trend
          };
        }).sort((a, b) => b.messages - a.messages).slice(0, limit);
        return queues;
      }
      /**
       * Get processing rate statistics
       */
      getProcessingRates() {
        if (!this.lastSnapshot) {
          return {
            averagePublishRate: 0,
            averageDeliverRate: 0,
            peakPublishRate: 0,
            peakDeliverRate: 0
          };
        }
        let totalPublish = 0;
        let totalDeliver = 0;
        let peakPublish = 0;
        let peakDeliver = 0;
        let count3 = 0;
        Object.values(this.lastSnapshot.queues).forEach((queue) => {
          if (queue.publishRate !== void 0) {
            totalPublish += queue.publishRate;
            peakPublish = Math.max(peakPublish, queue.publishRate);
            count3++;
          }
          if (queue.deliverRate !== void 0) {
            totalDeliver += queue.deliverRate;
            peakDeliver = Math.max(peakDeliver, queue.deliverRate);
          }
        });
        return {
          averagePublishRate: count3 > 0 ? totalPublish / count3 : 0,
          averageDeliverRate: count3 > 0 ? totalDeliver / count3 : 0,
          peakPublishRate: peakPublish,
          peakDeliverRate: peakDeliver
        };
      }
    };
    queueMetricsHistory = new QueueMetricsHistory();
  }
});

// server/routes/queue-monitor-routes.ts
var queue_monitor_routes_exports = {};
__export(queue_monitor_routes_exports, {
  default: () => queue_monitor_routes_default
});
import { Router as Router37 } from "express";
import { spawn } from "child_process";
var router32, logger3, testProcess, testStartTime, TEST_TIMEOUT, queue_monitor_routes_default;
var init_queue_monitor_routes = __esm({
  "server/routes/queue-monitor-routes.ts"() {
    "use strict";
    init_middleware();
    init_queue_monitor2();
    init_queue_metrics_history();
    init_api_helpers();
    init_logger();
    router32 = Router37();
    logger3 = loggers.queue;
    testProcess = null;
    testStartTime = null;
    TEST_TIMEOUT = 30 * 60 * 1e3;
    router32.use(requireAuth2);
    router32.use(requireRole("admin", "servicer"));
    router32.get("/queues", asyncHandler(async (req, res) => {
      const metrics2 = await queueMonitor.getAllQueueMetrics();
      sendSuccess3(res, metrics2);
    }));
    router32.get("/queues/:queueName", asyncHandler(async (req, res) => {
      const { queueName } = req.params;
      const metrics2 = await queueMonitor.getQueueMetrics(queueName);
      if (!metrics2) {
        return sendError4(res, 404, "Queue not found", "QUEUE_NOT_FOUND");
      }
      sendSuccess3(res, metrics2);
    }));
    router32.get("/exchanges", asyncHandler(async (req, res) => {
      const metrics2 = await queueMonitor.getAllExchangeMetrics();
      sendSuccess3(res, metrics2);
    }));
    router32.get("/connections", asyncHandler(async (req, res) => {
      const metrics2 = queueMonitor.getConnectionMetrics();
      sendSuccess3(res, metrics2);
    }));
    router32.get("/health", asyncHandler(async (req, res) => {
      const health = await queueMonitor.getQueueHealth();
      sendSuccess3(res, health);
    }));
    router32.get("/stats", asyncHandler(async (req, res) => {
      const stats = await queueMonitor.getAggregatedStats();
      sendSuccess3(res, stats);
    }));
    router32.get("/flow-rates", asyncHandler(async (req, res) => {
      const rates = await queueMonitor.getMessageFlowRates();
      sendSuccess3(res, rates);
    }));
    router32.post("/queues/:queueName/purge", requireRole("admin"), asyncHandler(async (req, res) => {
      const { queueName } = req.params;
      const protectedQueues = ["payments.validation", "payments.processing", "payments.distribution"];
      if (protectedQueues.includes(queueName)) {
        return sendError4(res, 403, "Cannot purge protected queue", "PROTECTED_QUEUE");
      }
      const count3 = await queueMonitor.purgeQueue(queueName);
      logger3.warn(`Queue purged: ${queueName}`, { purgedMessages: count3 });
      sendSuccess3(res, { purgedMessages: count3 }, `Purged ${count3} messages from ${queueName}`);
    }));
    router32.get("/history", asyncHandler(async (req, res) => {
      const minutes = parseInt(req.query.minutes) || 5;
      const history = queueMetricsHistory.getHistory(minutes);
      sendSuccess3(res, history);
    }));
    router32.get("/top-queues", asyncHandler(async (req, res) => {
      const limit = parseInt(req.query.limit) || 10;
      const topQueues = queueMetricsHistory.getTopQueues(limit);
      sendSuccess3(res, topQueues);
    }));
    router32.get("/processing-rates", asyncHandler(async (req, res) => {
      const rates = queueMetricsHistory.getProcessingRates();
      sendSuccess3(res, rates);
    }));
    router32.post("/purge-dlq", requireRole("admin"), async (req, res) => {
      try {
        const { queueName } = req.body;
        if (!queueName || !queueName.startsWith("dlq.")) {
          return res.status(400).json({ error: "Can only purge dead letter queues" });
        }
        const url = process.env.CLOUDAMQP_URL;
        if (!url) {
          return res.status(500).json({ error: "RabbitMQ URL not configured" });
        }
        const { rabbitmqClient: rabbitmqClient2 } = await Promise.resolve().then(() => (init_rabbitmq_unified(), rabbitmq_unified_exports));
        const connection2 = await rabbitmqClient2.getAdminConnection();
        const channel = await connection2.createChannel();
        const stats = await channel.checkQueue(queueName);
        const messageCount = stats.messageCount;
        await channel.purgeQueue(queueName);
        await channel.close();
        console.log(`[QueueMonitor] Purged ${messageCount} messages from ${queueName}`);
        res.json({
          success: true,
          queueName,
          purgedCount: messageCount,
          message: `Successfully purged ${messageCount} messages from ${queueName}`
        });
      } catch (error) {
        console.error("[QueueMonitor] Error purging DLQ:", error);
        res.status(500).json({ error: "Failed to purge dead letter queue" });
      }
    });
    router32.post("/test-runner", requireRole("admin"), async (req, res) => {
      try {
        const { action } = req.body;
        if (action === "start") {
          if (testProcess) {
            testProcess.kill();
            testProcess = null;
          }
          testProcess = spawn("tsx", ["scripts/test-queue-infrastructure.ts"], {
            stdio: "inherit"
          });
          testStartTime = Date.now();
          setTimeout(() => {
            if (testProcess) {
              console.log("[QueueMonitor] Test runner reached 30 minute timeout, stopping...");
              testProcess.kill();
              testProcess = null;
              testStartTime = null;
            }
          }, TEST_TIMEOUT);
          testProcess.on("exit", (code, signal) => {
            console.log(`[QueueMonitor] Test runner exited with code ${code} and signal ${signal}`);
            testProcess = null;
            testStartTime = null;
          });
          res.json({
            success: true,
            running: true,
            message: "Test runner started successfully"
          });
        } else if (action === "stop") {
          if (testProcess) {
            testProcess.kill();
            testProcess = null;
            testStartTime = null;
            res.json({
              success: true,
              running: false,
              message: "Test runner stopped successfully"
            });
          } else {
            res.json({
              success: false,
              running: false,
              message: "No test runner is currently running"
            });
          }
        } else if (action === "status") {
          const isRunning = testProcess !== null;
          const runtime = isRunning && testStartTime ? Date.now() - testStartTime : 0;
          res.json({
            running: isRunning,
            runtime,
            timeRemaining: isRunning ? Math.max(0, TEST_TIMEOUT - runtime) : 0
          });
        } else {
          res.status(400).json({ error: 'Invalid action. Use "start", "stop", or "status"' });
        }
      } catch (error) {
        console.error("[QueueMonitor] Error controlling test runner:", error);
        res.status(500).json({ error: "Failed to control test runner" });
      }
    });
    queue_monitor_routes_default = router32;
  }
});

// server/routes/dlq-routes.ts
var dlq_routes_exports = {};
__export(dlq_routes_exports, {
  default: () => dlq_routes_default
});
import { Router as Router38 } from "express";
import { eq as eq32 } from "drizzle-orm";
var router33, rabbitmq, dlq_routes_default;
var init_dlq_routes = __esm({
  "server/routes/dlq-routes.ts"() {
    "use strict";
    init_rabbitmq_unified();
    init_middleware();
    init_db();
    init_schema();
    router33 = Router38();
    rabbitmq = rabbitmqClient;
    router33.get("/dlq/:queueName/info", requireAuth2, async (req, res) => {
      try {
        const { queueName } = req.params;
        if (!queueName.startsWith("dlq.")) {
          return res.status(400).json({ error: "Queue name must start with dlq." });
        }
        try {
          const connectionInfo = await rabbitmq.getConnectionInfo();
          if (!connectionInfo.connected) {
            return res.json({
              queue: queueName,
              messageCount: 0,
              consumerCount: 0,
              originalQueue: queueName.replace("dlq.", ""),
              info: {
                status: "offline",
                message: "RabbitMQ connection unavailable"
              }
            });
          }
        } catch (error) {
          return res.json({
            queue: queueName,
            messageCount: 0,
            consumerCount: 0,
            originalQueue: queueName.replace("dlq.", ""),
            info: {
              status: "offline",
              message: "Connection check failed"
            }
          });
        }
        let channel;
        try {
          channel = await rabbitmq.getDLQChannel();
          if (!channel) {
            return res.json({
              queue: queueName,
              messageCount: 0,
              consumerCount: 0,
              originalQueue: queueName.replace("dlq.", ""),
              info: {
                status: "offline",
                message: "DLQ channel unavailable"
              }
            });
          }
          const stats = await channel.checkQueue(queueName);
          res.json({
            queue: queueName,
            messageCount: stats.messageCount,
            consumerCount: stats.consumerCount,
            originalQueue: queueName.replace("dlq.", ""),
            info: {
              status: "connected",
              durable: true,
              arguments: stats.arguments || {}
            }
          });
        } catch (error) {
          res.json({
            queue: queueName,
            messageCount: 0,
            consumerCount: 0,
            originalQueue: queueName.replace("dlq.", ""),
            info: {
              status: "not_found",
              message: "Queue does not exist"
            }
          });
        } finally {
          if (channel) {
            try {
              await channel.close();
            } catch (closeError) {
              console.error("Error closing DLQ channel:", closeError);
            }
          }
        }
      } catch (error) {
        console.error("Error getting DLQ info:", error);
        res.json({
          queue: req.params.queueName,
          messageCount: 0,
          consumerCount: 0,
          originalQueue: req.params.queueName.replace("dlq.", ""),
          info: {
            status: "error",
            message: "Failed to retrieve queue information"
          }
        });
      }
    });
    router33.get("/dlq/:queueName/messages", requireAuth2, async (req, res) => {
      try {
        const { queueName } = req.params;
        const { limit = 10 } = req.query;
        if (!queueName.startsWith("dlq.")) {
          return res.status(400).json({ error: "Queue name must start with dlq." });
        }
        try {
          const connectionInfo = await rabbitmq.getConnectionInfo();
          if (!connectionInfo.connected) {
            return res.json({
              queue: queueName,
              messages: [],
              totalFetched: 0,
              info: { status: "offline", message: "RabbitMQ connection unavailable" }
            });
          }
        } catch (error) {
          return res.json({
            queue: queueName,
            messages: [],
            totalFetched: 0,
            info: { status: "offline", message: "Connection check failed" }
          });
        }
        let channel;
        try {
          channel = await rabbitmq.getDLQChannel();
          if (!channel) {
            return res.json({
              queue: queueName,
              messages: [],
              totalFetched: 0,
              info: { status: "offline", message: "DLQ channel unavailable" }
            });
          }
          const messages = [];
          let message;
          let count3 = 0;
          const maxMessages = Math.min(parseInt(limit, 10), 100);
          while (count3 < maxMessages) {
            message = await channel.get(queueName, { noAck: false });
            if (!message) {
              break;
            }
            try {
              const content = JSON.parse(message.content.toString());
              let enrichedContent = content;
              if (queueName.includes("payment") && content.loanId) {
                try {
                  const loan = await db.select().from(loans).where(eq32(loans.id, content.loanId)).limit(1);
                  if (loan.length > 0) {
                    enrichedContent = {
                      ...content,
                      _context: {
                        loanBalance: loan[0].currentBalance,
                        loanStatus: loan[0].status,
                        borrowerName: loan[0].borrowerName,
                        originalAmount: loan[0].originalAmount
                      }
                    };
                  }
                } catch (error) {
                  console.error("Error fetching loan context:", error);
                }
              }
              messages.push({
                messageId: message.properties.messageId || `msg-${count3}`,
                correlationId: message.properties.correlationId,
                timestamp: message.properties.timestamp || Date.now(),
                headers: message.properties.headers || {},
                exchange: message.fields.exchange,
                routingKey: message.fields.routingKey,
                redelivered: message.fields.redelivered,
                deliveryTag: message.fields.deliveryTag.toString(),
                content: enrichedContent,
                contentSize: message.content.length,
                failureReason: message.properties.headers?.["x-death"] ? message.properties.headers["x-death"][0] : null
              });
              channel.reject(message, true);
              count3++;
            } catch (error) {
              messages.push({
                messageId: `msg-${count3}`,
                correlationId: null,
                timestamp: Date.now(),
                headers: message.properties.headers || {},
                exchange: message.fields.exchange,
                routingKey: message.fields.routingKey,
                redelivered: message.fields.redelivered,
                deliveryTag: message.fields.deliveryTag.toString(),
                content: message.content.toString(),
                contentSize: message.content.length,
                failureReason: { error: "Failed to parse message content" }
              });
              channel.reject(message, true);
              count3++;
            }
          }
          res.json({
            queue: queueName,
            messages,
            totalFetched: messages.length
          });
        } catch (error) {
          console.error("Error fetching DLQ messages:", error);
          res.json({
            queue: req.params.queueName,
            messages: [],
            totalFetched: 0,
            info: { status: "error", message: "Failed to fetch DLQ messages" }
          });
        } finally {
          if (channel) {
            try {
              await channel.close();
            } catch (closeError) {
              console.error("Error closing DLQ channel:", closeError);
            }
          }
        }
      } catch (error) {
        console.error("Error in DLQ messages endpoint:", error);
        res.json({
          queue: req.params.queueName,
          messages: [],
          totalFetched: 0,
          info: { status: "error", message: "Connection error" }
        });
      }
    });
    router33.post("/dlq/:queueName/retry", requireAuth2, async (req, res) => {
      try {
        const { queueName } = req.params;
        const { messageCount = 1, editedMessage, resolution } = req.body;
        if (!queueName.startsWith("dlq.")) {
          return res.status(400).json({ error: "Queue name must start with dlq." });
        }
        const channel = await rabbitmq.getDLQChannel();
        if (!channel) {
          return res.status(503).json({ error: "Message broker not connected" });
        }
        const queueInfo = await channel.checkQueue(queueName);
        await channel.close();
        res.json({
          queue: queueName,
          messageCount: queueInfo.messageCount,
          consumerCount: queueInfo.consumerCount,
          originalQueue: queueName.replace("dlq.", ""),
          info: queueInfo
        });
      } catch (error) {
        console.error("Error fetching DLQ info:", error);
        res.status(500).json({ error: "Failed to fetch DLQ info" });
      }
    });
    router33.post("/dlq/:queueName/retry", requireAuth2, async (req, res) => {
      try {
        const { queueName } = req.params;
        const { messageCount = 1, editedMessage, resolution } = req.body;
        if (!queueName.startsWith("dlq.")) {
          return res.status(400).json({ error: "Queue name must start with dlq." });
        }
        const channel = await rabbitmq.getDLQChannel();
        if (!channel) {
          return res.status(503).json({ error: "Message broker not connected" });
        }
        const originalQueue = queueName.replace("dlq.", "");
        const retriedMessages = [];
        if (resolution && resolution.action === "accept_overpayment") {
          const message = await channel.get(queueName, { noAck: false });
          if (message) {
            try {
              const content = JSON.parse(message.content.toString());
              const modifiedContent = {
                ...content,
                acceptOverpayment: true,
                overpaymentAmount: resolution.overpaymentAmount,
                refundRequired: true,
                _resolution: {
                  action: "accept_overpayment",
                  timestamp: (/* @__PURE__ */ new Date()).toISOString(),
                  approvedBy: req.user?.id || "system"
                }
              };
              await channel.sendToQueue(
                originalQueue,
                Buffer.from(JSON.stringify(modifiedContent)),
                {
                  persistent: true,
                  headers: {
                    ...message.properties.headers,
                    "x-retried-from-dlq": true,
                    "x-retry-timestamp": (/* @__PURE__ */ new Date()).toISOString(),
                    "x-resolution-action": "accept_overpayment",
                    "x-original-error": message.properties.headers?.["x-death"] ? JSON.stringify(message.properties.headers["x-death"][0]) : null
                  }
                }
              );
              channel.ack(message);
              retriedMessages.push({
                messageId: message.properties.messageId,
                movedTo: originalQueue,
                timestamp: (/* @__PURE__ */ new Date()).toISOString(),
                resolution: "accept_overpayment"
              });
            } catch (error) {
              channel.reject(message, true);
              throw error;
            }
          }
        } else if (editedMessage) {
          const message = await channel.get(queueName, { noAck: false });
          if (message) {
            try {
              await channel.sendToQueue(
                originalQueue,
                Buffer.from(JSON.stringify(editedMessage)),
                {
                  persistent: true,
                  headers: {
                    ...message.properties.headers,
                    "x-retried-from-dlq": true,
                    "x-retry-timestamp": (/* @__PURE__ */ new Date()).toISOString(),
                    "x-message-edited": true,
                    "x-original-error": message.properties.headers?.["x-death"] ? JSON.stringify(message.properties.headers["x-death"][0]) : null
                  }
                }
              );
              channel.ack(message);
              retriedMessages.push({
                messageId: message.properties.messageId,
                movedTo: originalQueue,
                timestamp: (/* @__PURE__ */ new Date()).toISOString(),
                edited: true
              });
            } catch (error) {
              channel.reject(message, true);
              throw error;
            }
          }
        } else {
          for (let i = 0; i < messageCount; i++) {
            const message = await channel.get(queueName, { noAck: false });
            if (!message) {
              break;
            }
            try {
              await channel.sendToQueue(
                originalQueue,
                message.content,
                {
                  persistent: true,
                  headers: {
                    ...message.properties.headers,
                    "x-retried-from-dlq": true,
                    "x-retry-timestamp": (/* @__PURE__ */ new Date()).toISOString(),
                    "x-original-error": message.properties.headers?.["x-death"] ? JSON.stringify(message.properties.headers["x-death"][0]) : null
                  }
                }
              );
              channel.ack(message);
              retriedMessages.push({
                messageId: message.properties.messageId,
                movedTo: originalQueue,
                timestamp: (/* @__PURE__ */ new Date()).toISOString()
              });
            } catch (error) {
              channel.reject(message, true);
              throw error;
            }
          }
        }
        res.json({
          success: true,
          retriedCount: retriedMessages.length,
          messages: retriedMessages
        });
        await channel.close();
      } catch (error) {
        console.error("Error retrying DLQ messages:", error);
        res.status(500).json({ error: "Failed to retry DLQ messages" });
      }
    });
    router33.delete("/dlq/:queueName/purge", requireAuth2, async (req, res) => {
      try {
        const { queueName } = req.params;
        if (!queueName.startsWith("dlq.")) {
          return res.status(400).json({ error: "Queue name must start with dlq." });
        }
        const channel = await rabbitmq.getDLQChannel();
        if (!channel) {
          return res.status(503).json({ error: "Message broker not connected" });
        }
        const result = await channel.purgeQueue(queueName);
        await channel.close();
        res.json({
          success: true,
          queue: queueName,
          messagesPurged: result.messageCount
        });
      } catch (error) {
        console.error("Error purging DLQ:", error);
        res.status(500).json({ error: "Failed to purge DLQ" });
      }
    });
    router33.delete("/dlq/:queueName/message", requireAuth2, async (req, res) => {
      try {
        const { queueName } = req.params;
        if (!queueName.startsWith("dlq.")) {
          return res.status(400).json({ error: "Queue name must start with dlq." });
        }
        const channel = await rabbitmq.getDLQChannel();
        if (!channel) {
          return res.status(503).json({ error: "Message broker not connected" });
        }
        const message = await channel.get(queueName, { noAck: false });
        if (!message) {
          return res.status(404).json({ error: "No messages in queue" });
        }
        channel.ack(message);
        await channel.close();
        res.json({
          success: true,
          removed: true,
          messageId: message.properties.messageId
        });
      } catch (error) {
        console.error("Error removing message from DLQ:", error);
        res.status(500).json({ error: "Failed to remove message" });
      }
    });
    dlq_routes_default = router33;
  }
});

// server/escrow/forecast-service.ts
import { randomUUID as randomUUID11 } from "crypto";
var EscrowForecastService;
var init_forecast_service = __esm({
  "server/escrow/forecast-service.ts"() {
    "use strict";
    init_db();
    EscrowForecastService = class {
      constructor(db2 = pool) {
        this.db = db2;
      }
      /**
       * Generate 12-month rolling forecast for a loan
       */
      async generateForecast(request) {
        const { loan_id, as_of_date, correlation_id } = request;
        console.log(`[EscrowForecast] Generating forecast for loan ${loan_id} as of ${as_of_date}`);
        try {
          await this.db.query("BEGIN");
          await this.db.query(
            "DELETE FROM escrow_forecast WHERE loan_id = $1",
            [loan_id]
          );
          const escrowItemsResult = await this.db.query(`
        SELECT 
          ed.id as escrow_id,
          ed.disbursement_type as escrow_type,
          ed.payee_name,
          ed.payment_amount as amount,
          EXTRACT(DAY FROM ed.next_due_date)::integer as due_day,
          ed.frequency,
          ed.next_due_date
        FROM escrow_disbursements ed
        WHERE ed.loan_id = $1
          AND ed.status = 'active'
          AND ed.is_on_hold = false
        ORDER BY ed.disbursement_type, ed.payee_name
      `, [loan_id]);
          if (escrowItemsResult.rows.length === 0) {
            console.log(`[EscrowForecast] No active escrow disbursements for loan ${loan_id}`);
            await this.db.query("COMMIT");
            return {
              loan_id,
              forecasts: [],
              correlation_id
            };
          }
          const forecasts = [];
          const asOfDate = new Date(as_of_date);
          const endDate = new Date(asOfDate);
          endDate.setFullYear(endDate.getFullYear() + 1);
          for (const item of escrowItemsResult.rows) {
            const itemForecasts = await this.generateItemForecast(
              loan_id,
              item.escrow_id,
              item.amount || "0",
              item.frequency || "monthly",
              item.next_due_date || asOfDate.toISOString().split("T")[0],
              asOfDate,
              endDate
            );
            forecasts.push(...itemForecasts);
          }
          forecasts.sort((a, b) => a.due_date.localeCompare(b.due_date));
          await this.db.query("COMMIT");
          console.log(`[EscrowForecast] Generated ${forecasts.length} forecast entries for loan ${loan_id}`);
          return {
            loan_id,
            forecasts,
            correlation_id
          };
        } catch (error) {
          await this.db.query("ROLLBACK");
          console.error("[EscrowForecast] Error generating forecast:", error);
          throw error;
        }
      }
      /**
       * Generate forecast for a single escrow disbursement
       */
      async generateItemForecast(loan_id, escrow_id, amount, frequency, startDate, asOfDate, endDate) {
        const forecasts = [];
        const amountMinor = Math.round(parseFloat(amount) * 100);
        let currentDate = new Date(startDate);
        while (currentDate < asOfDate) {
          currentDate = this.getNextDueDate(currentDate, frequency);
        }
        while (currentDate <= endDate) {
          const dueDate = currentDate.toISOString().split("T")[0];
          await this.db.query(`
        INSERT INTO escrow_forecast (
          forecast_id,
          loan_id,
          escrow_id,
          due_date,
          amount_minor,
          created_at
        ) VALUES ($1, $2, $3, $4, $5, NOW())
        ON CONFLICT (loan_id, escrow_id, due_date) DO UPDATE
        SET amount_minor = $5, created_at = NOW()
      `, [randomUUID11(), loan_id, escrow_id, dueDate, amountMinor]);
          forecasts.push({
            escrow_id,
            due_date: dueDate,
            amount_minor: amountMinor.toString()
          });
          currentDate = this.getNextDueDate(currentDate, frequency);
        }
        return forecasts;
      }
      /**
       * Calculate next due date based on frequency
       */
      getNextDueDate(currentDate, frequency) {
        const nextDate = new Date(currentDate);
        switch (frequency) {
          case "monthly":
            nextDate.setMonth(nextDate.getMonth() + 1);
            break;
          case "quarterly":
            nextDate.setMonth(nextDate.getMonth() + 3);
            break;
          case "semi_annual":
            nextDate.setMonth(nextDate.getMonth() + 6);
            break;
          case "annual":
            nextDate.setFullYear(nextDate.getFullYear() + 1);
            break;
          case "once":
            nextDate.setFullYear(nextDate.getFullYear() + 100);
            break;
          default:
            nextDate.setMonth(nextDate.getMonth() + 1);
        }
        return nextDate;
      }
      /**
       * Get existing forecast for a loan
       */
      async getForecast(loan_id) {
        const result = await this.db.query(`
      SELECT 
        forecast_id,
        loan_id,
        escrow_id,
        due_date,
        amount_minor,
        created_at
      FROM escrow_forecast
      WHERE loan_id = $1
      ORDER BY due_date, escrow_id
    `, [loan_id]);
        return result.rows.map((row) => ({
          forecast_id: row.forecast_id,
          loan_id: row.loan_id,
          escrow_id: row.escrow_id,
          due_date: row.due_date.toISOString().split("T")[0],
          amount_minor: BigInt(row.amount_minor),
          created_at: row.created_at
        }));
      }
      /**
       * Get forecast summary for a date range
       */
      async getForecastSummary(loan_id, startDate, endDate) {
        const result = await this.db.query(`
      SELECT 
        COALESCE(SUM(amount_minor), 0) as total_amount_minor,
        COUNT(*) as payment_count
      FROM escrow_forecast
      WHERE loan_id = $1
        AND due_date >= $2
        AND due_date <= $3
    `, [loan_id, startDate, endDate]);
        return {
          total_amount_minor: BigInt(result.rows[0].total_amount_minor || 0),
          payment_count: parseInt(result.rows[0].payment_count || 0)
        };
      }
    };
  }
});

// server/escrow/forecast-consumer.ts
var EscrowForecastConsumer;
var init_forecast_consumer = __esm({
  "server/escrow/forecast-consumer.ts"() {
    "use strict";
    init_rabbitmq_unified();
    init_forecast_service();
    EscrowForecastConsumer = class {
      forecastService;
      consumerTag = "escrow-forecast-consumer";
      constructor() {
        this.forecastService = new EscrowForecastService();
      }
      async start() {
        console.log("[EscrowForecast] Starting forecast consumer");
        const rabbitmq2 = rabbitmqClient;
        try {
          await rabbitmq2.consume(
            "q.forecast.v2",
            this.handleMessage.bind(this),
            {
              prefetch: 10,
              consumerTag: this.consumerTag
            }
          );
          console.log("[EscrowForecast] Consumer started successfully");
        } catch (error) {
          console.error("[EscrowForecast] Failed to start consumer:", error);
          throw error;
        }
      }
      async stop() {
        console.log("[EscrowForecast] Stopping forecast consumer");
        await rabbitmqClient.cancelConsumer(this.consumerTag);
      }
      async handleMessage(envelope, message) {
        const startTime2 = Date.now();
        const rabbitmq2 = rabbitmqClient;
        try {
          const request = envelope.payload;
          console.log(`[EscrowForecast] Processing forecast request for loan ${request.loan_id}`);
          if (!request.loan_id || !request.as_of_date || !request.correlation_id) {
            throw new Error("Invalid forecast request: missing required fields");
          }
          const response = await this.forecastService.generateForecast(request);
          await rabbitmq2.publishJSON(
            "escrow.events",
            "forecast.generated",
            response,
            {
              correlationId: request.correlation_id
            }
          );
          const duration = Date.now() - startTime2;
          console.log(`[EscrowForecast] Forecast generated for loan ${request.loan_id} in ${duration}ms`);
        } catch (error) {
          console.error("[EscrowForecast] Error processing message:", error);
          throw error;
        }
      }
    };
  }
});

// server/domain/posting.ts
var posting_exports = {};
__export(posting_exports, {
  postChargeOff: () => postChargeOff,
  postEscrowPayment: () => postEscrowPayment,
  postEvent: () => postEvent,
  postFeeAssessment: () => postFeeAssessment,
  postInterestAccrual: () => postInterestAccrual,
  postLoanOrigination: () => postLoanOrigination,
  postPaymentReceived: () => postPaymentReceived,
  reverseEvent: () => reverseEvent
});
import { randomUUID as randomUUID12 } from "crypto";
async function postEvent(repo2, args) {
  const eventId = randomUUID12();
  await repo2.begin();
  try {
    await repo2.createEvent({
      eventId,
      loanId: args.loanId,
      effectiveDate: args.effectiveDate,
      schema: args.schema,
      correlationId: args.correlationId
    });
    let debitSum = 0n;
    let creditSum = 0n;
    for (const line of args.lines) {
      const hasDebit = line.debitMinor !== void 0 && line.debitMinor > 0n;
      const hasCredit = line.creditMinor !== void 0 && line.creditMinor > 0n;
      if (hasDebit && hasCredit) {
        throw new Error("Each line must have either debit OR credit, not both");
      }
      if (!hasDebit && !hasCredit) {
        throw new Error("Each line must have either debit or credit");
      }
      if ((line.debitMinor ?? 0n) < 0n || (line.creditMinor ?? 0n) < 0n) {
        throw new Error("Negative amounts not allowed");
      }
      debitSum += line.debitMinor ?? 0n;
      creditSum += line.creditMinor ?? 0n;
      await repo2.addEntry({
        eventId,
        loanId: args.loanId,
        account: line.account,
        debitMinor: line.debitMinor,
        creditMinor: line.creditMinor,
        currency: args.currency,
        memo: line.memo
      });
    }
    if (debitSum !== creditSum) {
      throw new Error(`Event unbalanced: debit=${debitSum} credit=${creditSum}`);
    }
    if (debitSum === 0n) {
      throw new Error("Event has no entries or zero amounts");
    }
    await repo2.finalizeEvent(eventId);
    await repo2.commit();
    try {
      const { auditService, COMPLIANCE_EVENTS: COMPLIANCE_EVENTS2 } = await Promise.resolve().then(() => (init_auditService(), auditService_exports));
      await auditService.logEvent({
        eventType: COMPLIANCE_EVENTS2.ACCOUNTING.LEDGER_EVENT_CREATED,
        entityType: "loan",
        entityId: args.loanId.toString(),
        correlationId: args.correlationId,
        description: `Ledger event created: ${args.schema}`,
        details: {
          event_id: eventId,
          schema: args.schema,
          effective_date: args.effectiveDate,
          currency: args.currency,
          line_count: args.lines.length,
          debit_total: debitSum.toString(),
          credit_total: creditSum.toString()
        }
      });
    } catch (auditError) {
      console.error("[PostEvent] Audit logging failed:", auditError);
    }
    return { eventId };
  } catch (error) {
    await repo2.rollback();
    throw error;
  }
}
async function postPaymentReceived(repo2, loanId, amountMinor, effectiveDate, correlationId, allocations) {
  const lines = [];
  lines.push({
    account: "cash",
    debitMinor: amountMinor,
    memo: "Payment received"
  });
  for (const alloc of allocations) {
    if (alloc.amountMinor > 0n) {
      lines.push({
        account: alloc.account,
        creditMinor: alloc.amountMinor,
        memo: alloc.memo
      });
    }
  }
  return postEvent(repo2, {
    loanId,
    effectiveDate,
    correlationId,
    schema: "posting.payment.v1",
    currency: "USD",
    lines
  });
}
async function postInterestAccrual(repo2, loanId, interestMinor, effectiveDate, correlationId) {
  return postEvent(repo2, {
    loanId,
    effectiveDate,
    correlationId,
    schema: "posting.accrual.v1",
    currency: "USD",
    lines: [
      {
        account: "interest_receivable",
        debitMinor: interestMinor,
        memo: "Daily interest accrual"
      },
      {
        account: "interest_income",
        creditMinor: interestMinor,
        memo: "Interest earned"
      }
    ]
  });
}
async function postFeeAssessment(repo2, loanId, feeMinor, feeType, effectiveDate, correlationId) {
  return postEvent(repo2, {
    loanId,
    effectiveDate,
    correlationId,
    schema: "posting.fee.v1",
    currency: "USD",
    lines: [
      {
        account: "fees_receivable",
        debitMinor: feeMinor,
        memo: `${feeType} fee assessed`
      },
      {
        account: "fee_income",
        creditMinor: feeMinor,
        memo: `${feeType} fee income`
      }
    ]
  });
}
async function postEscrowPayment(repo2, loanId, escrowMinor, payee, effectiveDate, correlationId) {
  return postEvent(repo2, {
    loanId,
    effectiveDate,
    correlationId,
    schema: "posting.escrow.v1",
    currency: "USD",
    lines: [
      {
        account: "escrow_liability",
        debitMinor: escrowMinor,
        memo: `Escrow payment to ${payee}`
      },
      {
        account: "cash",
        creditMinor: escrowMinor,
        memo: `Payment to ${payee}`
      }
    ]
  });
}
async function postLoanOrigination(repo2, loanId, principalMinor, effectiveDate, correlationId) {
  return postEvent(repo2, {
    loanId,
    effectiveDate,
    correlationId,
    schema: "posting.origination.v1",
    currency: "USD",
    lines: [
      {
        account: "loan_principal",
        debitMinor: principalMinor,
        memo: "Loan origination - principal balance"
      },
      {
        account: "cash",
        creditMinor: principalMinor,
        memo: "Loan funding disbursement"
      }
    ]
  });
}
async function postChargeOff(repo2, loanId, amountMinor, effectiveDate, correlationId, reason = "Loan charged off") {
  return postEvent(repo2, {
    loanId,
    effectiveDate,
    correlationId,
    schema: "posting.chargeoff.v1",
    currency: "USD",
    lines: [
      {
        account: "writeoff_expense",
        debitMinor: amountMinor,
        memo: reason
      },
      {
        account: "loan_principal",
        creditMinor: amountMinor,
        memo: "Principal written off"
      }
    ]
  });
}
async function reverseEvent(repo2, originalEventId, effectiveDate, correlationId, reason) {
  const originalEntries = await repo2.getEventEntries(originalEventId);
  if (originalEntries.length === 0) {
    throw new Error(`Event ${originalEventId} not found`);
  }
  const lines = originalEntries.map((entry) => ({
    account: entry.account,
    debitMinor: entry.creditMinor,
    // Swap
    creditMinor: entry.debitMinor,
    // Swap
    memo: `Reversal: ${reason}`
  }));
  return postEvent(repo2, {
    loanId: originalEntries[0].loanId,
    effectiveDate,
    correlationId,
    schema: "posting.reversal.v1",
    currency: "USD",
    lines
  });
}
var init_posting = __esm({
  "server/domain/posting.ts"() {
    "use strict";
  }
});

// server/db/ledger-repository.ts
var ledger_repository_exports = {};
__export(ledger_repository_exports, {
  PgLedgerRepository: () => PgLedgerRepository
});
var PgLedgerRepository;
var init_ledger_repository = __esm({
  "server/db/ledger-repository.ts"() {
    "use strict";
    PgLedgerRepository = class {
      pool;
      client;
      constructor(pool17) {
        this.pool = pool17;
      }
      async begin() {
        this.client = await this.pool.connect();
        await this.client.query("BEGIN");
      }
      async commit() {
        if (!this.client) throw new Error("No transaction in progress");
        await this.client.query("COMMIT");
        this.client.release();
        this.client = void 0;
      }
      async rollback() {
        if (this.client) {
          await this.client.query("ROLLBACK");
          this.client.release();
          this.client = void 0;
        }
      }
      async createEvent(args) {
        const client5 = this.client || this.pool;
        await client5.query(
          `INSERT INTO ledger_event (event_id, loan_id, effective_date, schema, correlation_id)
       VALUES ($1, $2, $3, $4, $5)`,
          [args.eventId, args.loanId, args.effectiveDate, args.schema, args.correlationId]
        );
      }
      async addEntry(args) {
        const client5 = this.client || this.pool;
        await client5.query(
          `INSERT INTO ledger_entry (event_id, loan_id, account, debit_minor, credit_minor, currency, memo)
       VALUES ($1, $2, $3::gl_account, $4, $5, $6, $7)`,
          [
            args.eventId,
            args.loanId,
            args.account,
            args.debitMinor?.toString() || "0",
            args.creditMinor?.toString() || "0",
            args.currency,
            args.memo
          ]
        );
      }
      async finalizeEvent(eventId) {
        const client5 = this.client || this.pool;
        await client5.query("SELECT sp_finalize_ledger_event($1)", [eventId]);
      }
      async latestBalances(loanId) {
        const client5 = this.client || this.pool;
        const result = await client5.query(
          "SELECT * FROM get_loan_balances($1)",
          [loanId]
        );
        if (result.rows.length === 0) {
          return {
            principalMinor: 0n,
            interestReceivableMinor: 0n,
            escrowLiabilityMinor: 0n,
            feesReceivableMinor: 0n,
            cashMinor: 0n
          };
        }
        const row = result.rows[0];
        return {
          principalMinor: BigInt(row.principal_minor || 0),
          interestReceivableMinor: BigInt(row.interest_receivable_minor || 0),
          escrowLiabilityMinor: BigInt(row.escrow_liability_minor || 0),
          feesReceivableMinor: BigInt(row.fees_receivable_minor || 0),
          cashMinor: BigInt(row.cash_minor || 0)
        };
      }
      async getEventEntries(eventId) {
        const client5 = this.client || this.pool;
        const result = await client5.query(
          `SELECT entry_id, event_id, loan_id, account::text as account, 
              debit_minor, credit_minor, currency, memo, created_at
       FROM ledger_entry
       WHERE event_id = $1
       ORDER BY created_at`,
          [eventId]
        );
        return result.rows.map((row) => ({
          entryId: row.entry_id,
          eventId: row.event_id,
          loanId: row.loan_id,
          account: row.account,
          debitMinor: BigInt(row.debit_minor || 0),
          creditMinor: BigInt(row.credit_minor || 0),
          currency: row.currency,
          memo: row.memo,
          createdAt: row.created_at
        }));
      }
      /**
       * Get account balance for a specific account and loan
       */
      async getAccountBalance(loanId, account) {
        const client5 = this.client || this.pool;
        const result = await client5.query(
          `SELECT COALESCE(SUM(debit_minor - credit_minor), 0) as balance
       FROM ledger_entry
       WHERE loan_id = $1 AND account = $2::gl_account
         AND event_id IN (SELECT event_id FROM ledger_event WHERE finalized_at IS NOT NULL)`,
          [loanId, account]
        );
        return BigInt(result.rows[0]?.balance || 0);
      }
      /**
       * Get all events for a loan
       */
      async getLoanEvents(loanId, limit = 100) {
        const client5 = this.client || this.pool;
        const result = await client5.query(
          `SELECT event_id, effective_date, schema, correlation_id, finalized_at
       FROM ledger_event
       WHERE loan_id = $1
       ORDER BY effective_date DESC, created_at DESC
       LIMIT $2`,
          [loanId, limit]
        );
        return result.rows.map((row) => ({
          eventId: row.event_id,
          effectiveDate: row.effective_date,
          schema: row.schema,
          correlationId: row.correlation_id,
          finalizedAt: row.finalized_at
        }));
      }
      /**
       * Check if correlation ID exists (for idempotency)
       */
      async correlationIdExists(correlationId) {
        const client5 = this.client || this.pool;
        const result = await client5.query(
          "SELECT 1 FROM ledger_event WHERE correlation_id = $1 LIMIT 1",
          [correlationId]
        );
        return result.rows.length > 0;
      }
      /**
       * Get trial balance for all loans
       */
      async getTrialBalance() {
        const client5 = this.client || this.pool;
        const result = await client5.query(`
      SELECT 
        account::text as account,
        COALESCE(SUM(debit_minor), 0) as debit_total,
        COALESCE(SUM(credit_minor), 0) as credit_total,
        COALESCE(SUM(debit_minor - credit_minor), 0) as balance
      FROM ledger_entry
      WHERE event_id IN (SELECT event_id FROM ledger_event WHERE finalized_at IS NOT NULL)
      GROUP BY account
      ORDER BY account
    `);
        return result.rows.map((row) => ({
          account: row.account,
          debitTotal: BigInt(row.debit_total),
          creditTotal: BigInt(row.credit_total),
          balance: BigInt(row.balance)
        }));
      }
    };
  }
});

// server/escrow/disbursement-service.ts
import { randomUUID as randomUUID13 } from "crypto";
var EscrowDisbursementService;
var init_disbursement_service = __esm({
  "server/escrow/disbursement-service.ts"() {
    "use strict";
    init_db();
    init_posting();
    init_ledger_repository();
    EscrowDisbursementService = class {
      constructor(db2 = pool) {
        this.db = db2;
        this.ledgerRepo = new PgLedgerRepository(db2);
      }
      ledgerRepo;
      /**
       * Schedule disbursements based on forecast
       */
      async scheduleDisbursements(request) {
        const { loan_id, effective_date, correlation_id } = request;
        console.log(`[EscrowDisbursement] Scheduling disbursements for loan ${loan_id} effective ${effective_date}`);
        try {
          await this.db.query("BEGIN");
          const endDate = new Date(effective_date);
          endDate.setDate(endDate.getDate() + 30);
          const forecastResult = await this.db.query(`
        SELECT 
          ef.escrow_id,
          ef.due_date,
          ef.amount_minor,
          ed.disbursement_type as escrow_type,
          ed.payee_name
        FROM escrow_forecast ef
        JOIN escrow_disbursements ed ON ed.id = ef.escrow_id
        WHERE ef.loan_id = $1
          AND ef.due_date >= $2
          AND ef.due_date <= $3
          AND NOT EXISTS (
            SELECT 1 FROM escrow_disbursement edb
            WHERE edb.loan_id = ef.loan_id
              AND edb.escrow_id = ef.escrow_id
              AND edb.due_date = ef.due_date
              AND edb.status != 'canceled'
          )
        ORDER BY ef.due_date, ef.escrow_id
      `, [loan_id, effective_date, endDate.toISOString().split("T")[0]]);
          const scheduled = [];
          for (const forecast of forecastResult.rows) {
            const disb_id = randomUUID13();
            await this.db.query(`
          INSERT INTO escrow_disbursement (
            disb_id,
            loan_id,
            escrow_id,
            due_date,
            amount_minor,
            status,
            scheduled_at
          ) VALUES ($1, $2, $3, $4, $5, 'scheduled', NOW())
        `, [
              disb_id,
              loan_id,
              forecast.escrow_id,
              forecast.due_date,
              forecast.amount_minor
            ]);
            scheduled.push({
              disb_id,
              escrow_id: forecast.escrow_id,
              due_date: forecast.due_date.toISOString().split("T")[0],
              amount_minor: forecast.amount_minor.toString()
            });
            console.log(`[EscrowDisbursement] Scheduled ${forecast.escrow_type} payment of $${(forecast.amount_minor / 100).toFixed(2)} to ${forecast.payee_name} on ${forecast.due_date}`);
          }
          await this.db.query("COMMIT");
          console.log(`[EscrowDisbursement] Scheduled ${scheduled.length} disbursements for loan ${loan_id}`);
          return {
            loan_id,
            scheduled,
            correlation_id
          };
        } catch (error) {
          await this.db.query("ROLLBACK");
          console.error("[EscrowDisbursement] Error scheduling disbursements:", error);
          throw error;
        }
      }
      /**
       * Process due disbursements
       */
      async processDueDisbursements(asOfDate) {
        console.log(`[EscrowDisbursement] Processing disbursements due as of ${asOfDate}`);
        let processedCount = 0;
        try {
          const dueResult = await this.db.query(`
        SELECT 
          edb.disb_id,
          edb.loan_id,
          edb.escrow_id,
          edb.due_date,
          edb.amount_minor,
          ed.disbursement_type as escrow_type,
          ed.payee_name,
          l.loan_number,
          ea.balance as escrow_balance
        FROM escrow_disbursement edb
        JOIN escrow_disbursements ed ON ed.id = edb.escrow_id
        JOIN loans l ON l.id = edb.loan_id
        JOIN escrow_accounts ea ON ea.loan_id = edb.loan_id
        WHERE edb.status = 'scheduled'
          AND edb.due_date <= $1
        ORDER BY edb.loan_id, edb.due_date
      `, [asOfDate]);
          for (const disb of dueResult.rows) {
            try {
              await this.postDisbursement(disb);
              processedCount++;
            } catch (error) {
              console.error(`[EscrowDisbursement] Failed to process disbursement ${disb.disb_id}:`, error);
            }
          }
          console.log(`[EscrowDisbursement] Processed ${processedCount} disbursements`);
        } catch (error) {
          console.error("[EscrowDisbursement] Error processing due disbursements:", error);
          throw error;
        }
        return processedCount;
      }
      /**
       * Post a single disbursement to the ledger
       */
      async postDisbursement(disbursement2) {
        const amountMinor = BigInt(disbursement2.amount_minor);
        const escrowBalance2 = BigInt(Math.round(parseFloat(disbursement2.escrow_balance) * 100));
        console.log(`[EscrowDisbursement] Posting ${disbursement2.escrow_type} disbursement of $${(Number(amountMinor) / 100).toFixed(2)} for loan ${disbursement2.loan_number}`);
        const hasInsufficientFunds = escrowBalance2 < amountMinor;
        try {
          await this.db.query("BEGIN");
          const { eventId } = await postEvent(this.ledgerRepo, {
            loanId: disbursement2.loan_id,
            effectiveDate: disbursement2.due_date.toISOString().split("T")[0],
            correlationId: `escrow_disb_${disbursement2.disb_id}`,
            schema: "escrow.disbursement.v1",
            currency: "USD",
            lines: hasInsufficientFunds ? [
              // Advance from servicer (use suspense account for tracking advances)
              {
                account: "suspense",
                debitMinor: amountMinor - escrowBalance2,
                memo: `Escrow advance for ${disbursement2.escrow_type} - ${disbursement2.payee_name}`
              },
              {
                account: "cash",
                creditMinor: amountMinor - escrowBalance2,
                memo: `Advance funded for insufficient escrow`
              },
              // Use available escrow balance
              {
                account: "escrow_liability",
                debitMinor: escrowBalance2,
                memo: `${disbursement2.escrow_type} payment to ${disbursement2.payee_name}`
              },
              {
                account: "cash",
                creditMinor: escrowBalance2,
                memo: `Escrow disbursement`
              }
            ] : [
              // Normal disbursement from escrow
              {
                account: "escrow_liability",
                debitMinor: amountMinor,
                memo: `${disbursement2.escrow_type} payment to ${disbursement2.payee_name}`
              },
              {
                account: "cash",
                creditMinor: amountMinor,
                memo: `Escrow disbursement to ${disbursement2.payee_name}`
              }
            ]
          });
          await this.db.query(`
        UPDATE escrow_disbursement
        SET status = 'posted',
            event_id = $1,
            posted_at = NOW()
        WHERE disb_id = $2
      `, [eventId, disbursement2.disb_id]);
          await this.db.query(`
        UPDATE escrow_accounts
        SET last_disbursement_date = $1
        WHERE loan_id = $2
      `, [disbursement2.due_date, disbursement2.loan_id]);
          await this.db.query("COMMIT");
          console.log(`[EscrowDisbursement] Successfully posted disbursement ${disbursement2.disb_id} with event ${eventId}`);
        } catch (error) {
          await this.db.query("ROLLBACK");
          throw error;
        }
      }
      /**
       * Cancel a scheduled disbursement
       */
      async cancelDisbursement(disb_id, reason) {
        console.log(`[EscrowDisbursement] Canceling disbursement ${disb_id}: ${reason}`);
        await this.db.query(`
      UPDATE escrow_disbursement
      SET status = 'canceled',
          posted_at = NOW()
      WHERE disb_id = $1
        AND status = 'scheduled'
    `, [disb_id]);
      }
      /**
       * Get disbursement history for a loan
       */
      async getDisbursementHistory(loan_id) {
        const result = await this.db.query(`
      SELECT 
        disb_id,
        loan_id,
        escrow_id,
        due_date,
        amount_minor,
        status,
        event_id,
        scheduled_at,
        posted_at
      FROM escrow_disbursement
      WHERE loan_id = $1
      ORDER BY due_date DESC, escrow_id
    `, [loan_id]);
        return result.rows.map((row) => ({
          disb_id: row.disb_id,
          loan_id: row.loan_id,
          escrow_id: row.escrow_id,
          due_date: row.due_date.toISOString().split("T")[0],
          amount_minor: BigInt(row.amount_minor),
          status: row.status,
          event_id: row.event_id,
          scheduled_at: row.scheduled_at,
          posted_at: row.posted_at
        }));
      }
    };
  }
});

// server/escrow/disbursement-consumer.ts
var EscrowDisbursementConsumer;
var init_disbursement_consumer = __esm({
  "server/escrow/disbursement-consumer.ts"() {
    "use strict";
    init_rabbitmq_unified();
    init_disbursement_service();
    EscrowDisbursementConsumer = class {
      disbursementService;
      consumerTag = "escrow-disbursement-consumer";
      constructor() {
        this.disbursementService = new EscrowDisbursementService();
      }
      async start() {
        console.log("[EscrowDisbursement] Starting disbursement consumer");
        const rabbitmq2 = rabbitmqClient;
        try {
          await rabbitmq2.consume(
            {
              queue: "q.schedule.disbursement.v2",
              prefetch: 10,
              consumerTag: this.consumerTag
            },
            this.handleMessage.bind(this)
          );
          console.log("[EscrowDisbursement] Consumer started successfully");
        } catch (error) {
          console.error("[EscrowDisbursement] Failed to start consumer:", error);
          throw error;
        }
      }
      async stop() {
        console.log("[EscrowDisbursement] Stopping disbursement consumer");
        const rabbitmq2 = rabbitmqClient();
        await rabbitmq2.cancel(this.consumerTag);
      }
      async handleMessage(envelope, message) {
        const startTime2 = Date.now();
        const rabbitmq2 = rabbitmqClient();
        try {
          const request = envelope.payload;
          console.log(`[EscrowDisbursement] Processing schedule request for loan ${request.loan_id}`);
          if (!request.loan_id || !request.effective_date || !request.correlation_id) {
            throw new Error("Invalid disbursement schedule request: missing required fields");
          }
          const response = await this.disbursementService.scheduleDisbursements(request);
          await rabbitmq2.publish({
            exchange: "escrow.events",
            routingKey: "disbursement.scheduled",
            message: response,
            options: {
              correlationId: request.correlation_id,
              persistent: true
            }
          });
          const duration = Date.now() - startTime2;
          console.log(`[EscrowDisbursement] Scheduled ${response.scheduled_count} disbursements for loan ${request.loan_id} in ${duration}ms`);
        } catch (error) {
          console.error("[EscrowDisbursement] Error processing message:", error);
          throw error;
        }
      }
    };
  }
});

// server/escrow/analysis-service.ts
import { randomUUID as randomUUID14 } from "crypto";
var EscrowAnalysisService;
var init_analysis_service = __esm({
  "server/escrow/analysis-service.ts"() {
    "use strict";
    init_db();
    EscrowAnalysisService = class {
      constructor(db2 = pool) {
        this.db = db2;
      }
      /**
       * Perform annual escrow analysis
       */
      async performAnalysis(request) {
        const { loan_id, as_of_date, generate_statement, correlation_id } = request;
        console.log(`[EscrowAnalysis] Starting analysis for loan ${loan_id} as of ${as_of_date}`);
        try {
          await this.db.query("BEGIN");
          const loanResult = await this.db.query(`
        SELECT 
          l.id,
          l.loan_number,
          l.state as loan_state,
          ea.balance as escrow_balance,
          ea.monthly_payment as current_monthly
        FROM loans l
        LEFT JOIN escrow_accounts ea ON ea.loan_id = l.id
        WHERE l.id = $1
      `, [loan_id]);
          if (loanResult.rows.length === 0) {
            throw new Error(`Loan ${loan_id} not found`);
          }
          const loan = loanResult.rows[0];
          const currentBalance = Math.round(parseFloat(loan.escrow_balance || "0") * 100);
          const policy = await this.getEscrowPolicy(loan_id, loan.loan_state);
          const periodStart = new Date(as_of_date);
          const periodEnd = new Date(periodStart);
          periodEnd.setFullYear(periodEnd.getFullYear() + 1);
          const forecastResult = await this.db.query(`
        SELECT 
          ef.escrow_id,
          ef.due_date,
          ef.amount_minor,
          ed.disbursement_type as escrow_type,
          ed.payee_name
        FROM escrow_forecast ef
        JOIN escrow_disbursements ed ON ed.id = ef.escrow_id
        WHERE ef.loan_id = $1
          AND ef.due_date >= $2
          AND ef.due_date < $3
        ORDER BY ef.due_date, ef.escrow_id
      `, [loan_id, periodStart.toISOString().split("T")[0], periodEnd.toISOString().split("T")[0]]);
          let annualExpected = BigInt(0);
          const monthlyProjections = /* @__PURE__ */ new Map();
          for (const forecast of forecastResult.rows) {
            const amountMinor = BigInt(forecast.amount_minor);
            annualExpected += amountMinor;
            const month = forecast.due_date.toISOString().substring(0, 7);
            const current = monthlyProjections.get(month) || BigInt(0);
            monthlyProjections.set(month, current + amountMinor);
          }
          const monthlyAverage = annualExpected / BigInt(12);
          const cushionTarget = monthlyAverage * BigInt(policy?.cushion_months || 2);
          let runningBalance = BigInt(currentBalance);
          let lowestBalance = runningBalance;
          let lowestMonth = periodStart.toISOString().substring(0, 7);
          const sortedMonths = Array.from(monthlyProjections.keys()).sort();
          for (const month of sortedMonths) {
            const disbursements = monthlyProjections.get(month) || BigInt(0);
            runningBalance += monthlyAverage;
            runningBalance -= disbursements;
            if (runningBalance < lowestBalance) {
              lowestBalance = runningBalance;
              lowestMonth = month;
            }
          }
          console.log(`[EscrowAnalysis] Lowest projected balance: $${(Number(lowestBalance) / 100).toFixed(2)} in ${lowestMonth}`);
          let shortage = BigInt(0);
          let deficiency = BigInt(0);
          let surplus = BigInt(0);
          if (lowestBalance < BigInt(0)) {
            deficiency = -lowestBalance;
            shortage = cushionTarget - BigInt(currentBalance) + deficiency;
          } else if (lowestBalance < cushionTarget) {
            shortage = cushionTarget - lowestBalance;
          } else {
            const surplusAmount = lowestBalance - cushionTarget;
            if (surplusAmount > (policy?.surplus_refund_threshold_minor || BigInt(5e3))) {
              surplus = surplusAmount;
            }
          }
          let newMonthlyTarget = monthlyAverage + cushionTarget / BigInt(12);
          if (shortage > BigInt(0)) {
            const shortageMonths = policy?.shortage_amortization_months || 12;
            const shortageRecovery = shortage / BigInt(shortageMonths);
            newMonthlyTarget += shortageRecovery;
          }
          let deficiencyRecoveryMonthly = BigInt(0);
          if (deficiency > BigInt(0)) {
            const deficiencyMonths = policy?.deficiency_amortization_months || 12;
            deficiencyRecoveryMonthly = deficiency / BigInt(deficiencyMonths);
          }
          const versionResult = await this.db.query(`
        SELECT COALESCE(MAX(version), 0) + 1 as next_version
        FROM escrow_analysis
        WHERE loan_id = $1
      `, [loan_id]);
          const version = versionResult.rows[0].next_version;
          const analysis_id = randomUUID14();
          await this.db.query(`
        INSERT INTO escrow_analysis (
          analysis_id,
          loan_id,
          as_of_date,
          period_start,
          period_end,
          annual_expected_minor,
          cushion_target_minor,
          current_balance_minor,
          shortage_minor,
          deficiency_minor,
          surplus_minor,
          new_monthly_target_minor,
          deficiency_recovery_monthly_minor,
          version,
          created_at
        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, NOW())
      `, [
            analysis_id,
            loan_id,
            as_of_date,
            periodStart.toISOString().split("T")[0],
            periodEnd.toISOString().split("T")[0],
            annualExpected.toString(),
            cushionTarget.toString(),
            currentBalance.toString(),
            shortage.toString(),
            deficiency.toString(),
            surplus.toString(),
            newMonthlyTarget.toString(),
            deficiencyRecoveryMonthly.toString(),
            version
          ]);
          for (const forecast of forecastResult.rows) {
            await this.db.query(`
          INSERT INTO escrow_analysis_item (
            analysis_id,
            escrow_id,
            forecast_due_date,
            forecast_amount_minor
          ) VALUES ($1, $2, $3, $4)
        `, [
              analysis_id,
              forecast.escrow_id,
              forecast.due_date,
              forecast.amount_minor
            ]);
          }
          let statementGenerated = false;
          if (generate_statement) {
            const documentHash = `stmt_${analysis_id}_${Date.now()}`;
            await this.db.query(`
          INSERT INTO escrow_statement (
            analysis_id,
            document_hash,
            generated_at
          ) VALUES ($1, $2, NOW())
        `, [analysis_id, documentHash]);
            statementGenerated = true;
            console.log(`[EscrowAnalysis] Statement generated with hash ${documentHash}`);
          }
          await this.db.query("COMMIT");
          console.log(`[EscrowAnalysis] Analysis complete for loan ${loan_id}:`);
          console.log(`  - Annual Expected: $${(Number(annualExpected) / 100).toFixed(2)}`);
          console.log(`  - Cushion Target: $${(Number(cushionTarget) / 100).toFixed(2)}`);
          console.log(`  - Current Balance: $${(Number(currentBalance) / 100).toFixed(2)}`);
          if (shortage > BigInt(0)) {
            console.log(`  - SHORTAGE: $${(Number(shortage) / 100).toFixed(2)}`);
          }
          if (deficiency > BigInt(0)) {
            console.log(`  - DEFICIENCY: $${(Number(deficiency) / 100).toFixed(2)}`);
          }
          if (surplus > BigInt(0)) {
            console.log(`  - SURPLUS: $${(Number(surplus) / 100).toFixed(2)}`);
          }
          console.log(`  - New Monthly Payment: $${(Number(newMonthlyTarget) / 100).toFixed(2)}`);
          return {
            analysis_id,
            loan_id,
            shortage_minor: shortage.toString(),
            deficiency_minor: deficiency.toString(),
            surplus_minor: surplus.toString(),
            new_monthly_target_minor: newMonthlyTarget.toString(),
            deficiency_recovery_monthly_minor: deficiencyRecoveryMonthly.toString(),
            statement_generated: statementGenerated,
            correlation_id
          };
        } catch (error) {
          await this.db.query("ROLLBACK");
          console.error("[EscrowAnalysis] Error performing analysis:", error);
          throw error;
        }
      }
      /**
       * Get escrow policy for loan
       */
      async getEscrowPolicy(loan_id, state) {
        const jurisdiction = state ? `US_${state.toUpperCase()}` : "US_FEDERAL";
        const policyResult = await this.db.query(`
      SELECT 
        policy_id,
        product_code,
        jurisdiction,
        cushion_months,
        shortage_amortization_months,
        deficiency_amortization_months,
        surplus_refund_threshold_minor,
        collect_surplus_as_reduction,
        pay_when_insufficient,
        rounding,
        created_at
      FROM escrow_policy
      WHERE jurisdiction = $1
      ORDER BY created_at DESC
      LIMIT 1
    `, [jurisdiction]);
        if (policyResult.rows.length === 0) {
          const federalResult = await this.db.query(`
        SELECT * FROM escrow_policy
        WHERE jurisdiction = 'US_FEDERAL'
        ORDER BY created_at DESC
        LIMIT 1
      `);
          if (federalResult.rows.length > 0) {
            return this.mapPolicyRow(federalResult.rows[0]);
          }
          return null;
        }
        return this.mapPolicyRow(policyResult.rows[0]);
      }
      mapPolicyRow(row) {
        return {
          policy_id: row.policy_id,
          product_code: row.product_code,
          jurisdiction: row.jurisdiction,
          cushion_months: row.cushion_months,
          shortage_amortization_months: row.shortage_amortization_months,
          deficiency_amortization_months: row.deficiency_amortization_months,
          surplus_refund_threshold_minor: BigInt(row.surplus_refund_threshold_minor),
          collect_surplus_as_reduction: row.collect_surplus_as_reduction,
          pay_when_insufficient: row.pay_when_insufficient,
          rounding: row.rounding,
          created_at: row.created_at
        };
      }
      /**
       * Get latest analysis for a loan
       */
      async getLatestAnalysis(loan_id) {
        const result = await this.db.query(`
      SELECT 
        analysis_id,
        loan_id,
        as_of_date,
        period_start,
        period_end,
        annual_expected_minor,
        cushion_target_minor,
        current_balance_minor,
        shortage_minor,
        deficiency_minor,
        surplus_minor,
        new_monthly_target_minor,
        deficiency_recovery_monthly_minor,
        version,
        created_at
      FROM escrow_analysis
      WHERE loan_id = $1
      ORDER BY version DESC
      LIMIT 1
    `, [loan_id]);
        if (result.rows.length === 0) {
          return null;
        }
        const row = result.rows[0];
        return {
          analysis_id: row.analysis_id,
          loan_id: row.loan_id,
          as_of_date: row.as_of_date.toISOString().split("T")[0],
          period_start: row.period_start.toISOString().split("T")[0],
          period_end: row.period_end.toISOString().split("T")[0],
          annual_expected_minor: BigInt(row.annual_expected_minor),
          cushion_target_minor: BigInt(row.cushion_target_minor),
          current_balance_minor: BigInt(row.current_balance_minor),
          shortage_minor: BigInt(row.shortage_minor),
          deficiency_minor: BigInt(row.deficiency_minor),
          surplus_minor: BigInt(row.surplus_minor),
          new_monthly_target_minor: BigInt(row.new_monthly_target_minor),
          deficiency_recovery_monthly_minor: BigInt(row.deficiency_recovery_monthly_minor),
          version: row.version,
          created_at: row.created_at
        };
      }
    };
  }
});

// server/escrow/analysis-consumer.ts
import * as crypto13 from "crypto";
var EscrowAnalysisConsumer;
var init_analysis_consumer = __esm({
  "server/escrow/analysis-consumer.ts"() {
    "use strict";
    init_rabbitmq_unified();
    init_analysis_service();
    EscrowAnalysisConsumer = class {
      analysisService;
      consumerTag = "escrow-analysis-consumer";
      constructor() {
        this.analysisService = new EscrowAnalysisService();
      }
      async start() {
        console.log("[EscrowAnalysis] Starting analysis consumer");
        const rabbitmq2 = rabbitmqClient;
        try {
          await rabbitmq2.consume(
            "q.escrow.analysis.v2",
            this.handleMessage.bind(this),
            {
              prefetch: 5,
              consumerTag: this.consumerTag
            }
          );
          console.log("[EscrowAnalysis] Consumer started successfully");
        } catch (error) {
          console.error("[EscrowAnalysis] Failed to start consumer:", error);
          throw error;
        }
      }
      async stop() {
        console.log("[EscrowAnalysis] Stopping analysis consumer");
      }
      async handleMessage(envelope, message) {
        const startTime2 = Date.now();
        const rabbitmq2 = rabbitmqClient;
        try {
          const request = envelope.payload;
          console.log(`[EscrowAnalysis] Processing analysis request for loan ${request.loan_id}`);
          if (!request.loan_id || !request.as_of_date || !request.correlation_id) {
            throw new Error("Invalid analysis request: missing required fields");
          }
          const response = await this.analysisService.performAnalysis(request);
          const responseEnvelope = {
            message_id: crypto13.randomUUID(),
            schema: "escrow.analysis.completed.v1",
            correlation_id: request.correlation_id,
            payload: response,
            timestamp: (/* @__PURE__ */ new Date()).toISOString(),
            priority: 5
          };
          await rabbitmq2.publishJSON(
            "escrow.events",
            "analysis.completed",
            responseEnvelope,
            {
              correlationId: request.correlation_id
            }
          );
          if (request.generate_statement) {
            console.log(`[EscrowAnalysis] Generating statement for loan ${request.loan_id}`);
            const statementEnvelope = {
              message_id: crypto13.randomUUID(),
              schema: "escrow.statement.generate.v1",
              correlation_id: `${request.correlation_id}_statement`,
              payload: {
                loan_id: request.loan_id,
                analysis_id: response.analysis_id,
                as_of_date: request.as_of_date,
                correlation_id: `${request.correlation_id}_statement`
              },
              timestamp: (/* @__PURE__ */ new Date()).toISOString(),
              priority: 5
            };
            await rabbitmq2.publishJSON(
              "escrow.events",
              "statement.generate",
              statementEnvelope
            );
          }
          const duration = Date.now() - startTime2;
          console.log(`[EscrowAnalysis] Analysis completed for loan ${request.loan_id} in ${duration}ms`);
        } catch (error) {
          console.error("[EscrowAnalysis] Error processing message:", error);
          throw error;
        }
      }
    };
  }
});

// server/escrow/daily-cycle.ts
var EscrowDailyCycle;
var init_daily_cycle = __esm({
  "server/escrow/daily-cycle.ts"() {
    "use strict";
    init_rabbitmq_unified();
    init_forecast_service();
    init_disbursement_service();
    init_analysis_service();
    init_db();
    EscrowDailyCycle = class {
      forecastService;
      disbursementService;
      analysisService;
      constructor() {
        this.forecastService = new EscrowForecastService();
        this.disbursementService = new EscrowDisbursementService();
        this.analysisService = new EscrowAnalysisService();
      }
      /**
       * Run daily escrow cycle
       */
      async runCycle(cycleDate) {
        const startTime2 = Date.now();
        console.log(`[EscrowCycle] Starting daily escrow cycle for ${cycleDate}`);
        try {
          const stats = {
            loansProcessed: 0,
            forecastsGenerated: 0,
            disbursementsScheduled: 0,
            disbursementsPosted: 0,
            analysesPerformed: 0,
            errors: []
          };
          console.log("[EscrowCycle] Step 1: Processing due disbursements");
          try {
            const postedCount = await this.disbursementService.processDueDisbursements(cycleDate);
            stats.disbursementsPosted = postedCount;
          } catch (error) {
            console.error("[EscrowCycle] Error processing disbursements:", error);
            stats.errors.push(`Disbursement processing: ${error instanceof Error ? error.message : "Unknown error"}`);
          }
          const loansResult = await pool.query(`
        SELECT DISTINCT l.id, l.loan_number, ea.id as escrow_account_id
        FROM loans l
        JOIN escrow_accounts ea ON ea.loan_id = l.id
        WHERE l.status IN ('active', 'current', 'delinquent', 'default')
          AND ea.is_active = true
        ORDER BY l.id
      `);
          stats.loansProcessed = loansResult.rows.length;
          console.log(`[EscrowCycle] Processing ${stats.loansProcessed} loans with active escrow accounts`);
          const rabbitmq2 = rabbitmqClient;
          console.log("[EscrowCycle] Step 2: Generating forecasts");
          for (const loan of loansResult.rows) {
            try {
              await rabbitmq2.publishJSON(
                "escrow.saga",
                "forecast.request",
                {
                  loan_id: loan.id,
                  as_of_date: cycleDate,
                  correlation_id: `cycle_forecast_${loan.id}_${cycleDate}`
                }
              );
              stats.forecastsGenerated++;
            } catch (error) {
              console.error(`[EscrowCycle] Error queueing forecast for loan ${loan.id}:`, error);
              stats.errors.push(`Forecast loan ${loan.id}: ${error instanceof Error ? error.message : "Unknown"}`);
            }
          }
          console.log("[EscrowCycle] Step 3: Scheduling disbursements");
          for (const loan of loansResult.rows) {
            try {
              await rabbitmq2.publishJSON(
                "escrow.saga",
                "disbursement.schedule",
                {
                  loan_id: loan.id,
                  effective_date: cycleDate,
                  correlation_id: `cycle_disbursement_${loan.id}_${cycleDate}`
                }
              );
              stats.disbursementsScheduled++;
            } catch (error) {
              console.error(`[EscrowCycle] Error queueing disbursement schedule for loan ${loan.id}:`, error);
              stats.errors.push(`Schedule loan ${loan.id}: ${error instanceof Error ? error.message : "Unknown"}`);
            }
          }
          console.log("[EscrowCycle] Step 4: Checking for required annual analyses");
          const analysisDate = new Date(cycleDate);
          const analysisDueResult = await pool.query(`
        SELECT l.id, l.loan_number
        FROM loans l
        JOIN escrow_accounts ea ON ea.loan_id = l.id
        WHERE l.status IN ('active', 'current', 'delinquent', 'default')
          AND ea.is_active = true
          AND (
            -- Anniversary analysis
            DATE_PART('month', l.closing_date) = DATE_PART('month', $1::date)
            AND DATE_PART('day', l.closing_date) = DATE_PART('day', $1::date)
            OR
            -- No analysis in last 11 months
            NOT EXISTS (
              SELECT 1 FROM escrow_analysis ea2
              WHERE ea2.loan_id = l.id
                AND ea2.as_of_date > $1::date - INTERVAL '11 months'
            )
          )
      `, [cycleDate]);
          for (const loan of analysisDueResult.rows) {
            try {
              await rabbitmq2.publishJSON(
                "escrow.saga",
                "analysis.request",
                {
                  loan_id: loan.id,
                  as_of_date: cycleDate,
                  generate_statement: true,
                  correlation_id: `cycle_analysis_${loan.id}_${cycleDate}`
                }
              );
              stats.analysesPerformed++;
              console.log(`[EscrowCycle] Queued annual analysis for loan ${loan.loan_number}`);
            } catch (error) {
              console.error(`[EscrowCycle] Error queueing analysis for loan ${loan.id}:`, error);
              stats.errors.push(`Analysis loan ${loan.id}: ${error instanceof Error ? error.message : "Unknown"}`);
            }
          }
          const duration = Date.now() - startTime2;
          console.log("[EscrowCycle] ========================================");
          console.log(`[EscrowCycle] Daily Escrow Cycle Complete for ${cycleDate}`);
          console.log("[EscrowCycle] ----------------------------------------");
          console.log(`[EscrowCycle] Duration: ${duration}ms`);
          console.log(`[EscrowCycle] Loans Processed: ${stats.loansProcessed}`);
          console.log(`[EscrowCycle] Forecasts Generated: ${stats.forecastsGenerated}`);
          console.log(`[EscrowCycle] Disbursements Posted: ${stats.disbursementsPosted}`);
          console.log(`[EscrowCycle] Disbursements Scheduled: ${stats.disbursementsScheduled}`);
          console.log(`[EscrowCycle] Analyses Performed: ${stats.analysesPerformed}`);
          if (stats.errors.length > 0) {
            console.log(`[EscrowCycle] Errors: ${stats.errors.length}`);
            stats.errors.forEach((err) => console.error(`[EscrowCycle]   - ${err}`));
          }
          console.log("[EscrowCycle] ========================================");
          await rabbitmq2.publishJSON(
            "escrow.events",
            "cycle.completed",
            {
              cycleDate,
              stats,
              timestamp: (/* @__PURE__ */ new Date()).toISOString()
            }
          );
        } catch (error) {
          console.error("[EscrowCycle] Fatal error in daily cycle:", error);
          throw error;
        }
      }
      /**
       * Schedule daily cycle to run at specific time
       */
      scheduleDaily(hour = 2, minute = 0) {
        const now = /* @__PURE__ */ new Date();
        const scheduledTime = /* @__PURE__ */ new Date();
        scheduledTime.setHours(hour, minute, 0, 0);
        if (scheduledTime <= now) {
          scheduledTime.setDate(scheduledTime.getDate() + 1);
        }
        const msUntilRun = scheduledTime.getTime() - now.getTime();
        console.log(`[EscrowCycle] Daily cycle scheduled for ${scheduledTime.toISOString()}`);
        console.log(`[EscrowCycle] Will run in ${Math.round(msUntilRun / 1e3 / 60)} minutes`);
        setTimeout(() => {
          const cycleDate = (/* @__PURE__ */ new Date()).toISOString().split("T")[0];
          this.runCycle(cycleDate).catch((error) => {
            console.error("[EscrowCycle] Daily cycle failed:", error);
          });
          this.scheduleDaily(hour, minute);
        }, msUntilRun);
      }
    };
  }
});

// server/escrow/escrow-manager.ts
function getEscrowManager() {
  if (!escrowManager) {
    escrowManager = new EscrowManager();
  }
  return escrowManager;
}
var EscrowManager, escrowManager;
var init_escrow_manager = __esm({
  "server/escrow/escrow-manager.ts"() {
    "use strict";
    init_forecast_consumer();
    init_disbursement_consumer();
    init_analysis_consumer();
    init_daily_cycle();
    EscrowManager = class {
      forecastConsumer;
      disbursementConsumer;
      analysisConsumer;
      dailyCycle;
      isRunning = false;
      constructor() {
        this.forecastConsumer = new EscrowForecastConsumer();
        this.disbursementConsumer = new EscrowDisbursementConsumer();
        this.analysisConsumer = new EscrowAnalysisConsumer();
        this.dailyCycle = new EscrowDailyCycle();
      }
      /**
       * Start all escrow consumers and services
       */
      async start() {
        if (this.isRunning) {
          console.warn("[EscrowManager] Already running");
          return;
        }
        console.log("[EscrowManager] Starting escrow subsystem...");
        try {
          await Promise.all([
            this.forecastConsumer.start(),
            this.disbursementConsumer.start(),
            this.analysisConsumer.start()
          ]);
          this.dailyCycle.scheduleDaily(2, 0);
          this.isRunning = true;
          console.log("[EscrowManager] Escrow subsystem started successfully");
        } catch (error) {
          console.error("[EscrowManager] Failed to start escrow subsystem:", error);
          await this.stop();
          throw error;
        }
      }
      /**
       * Stop all escrow consumers and services
       */
      async stop() {
        console.log("[EscrowManager] Stopping escrow subsystem...");
        const stopTasks = [];
        try {
          stopTasks.push(this.forecastConsumer.stop());
        } catch (error) {
          console.error("[EscrowManager] Error stopping forecast consumer:", error);
        }
        try {
          stopTasks.push(this.disbursementConsumer.stop());
        } catch (error) {
          console.error("[EscrowManager] Error stopping disbursement consumer:", error);
        }
        try {
          stopTasks.push(this.analysisConsumer.stop());
        } catch (error) {
          console.error("[EscrowManager] Error stopping analysis consumer:", error);
        }
        await Promise.allSettled(stopTasks);
        this.isRunning = false;
        console.log("[EscrowManager] Escrow subsystem stopped");
      }
      /**
       * Run escrow daily cycle manually
       */
      async runDailyCycle(cycleDate) {
        const date2 = cycleDate || (/* @__PURE__ */ new Date()).toISOString().split("T")[0];
        console.log(`[EscrowManager] Running manual escrow cycle for ${date2}`);
        try {
          await this.dailyCycle.runCycle(date2);
          console.log("[EscrowManager] Manual escrow cycle completed");
        } catch (error) {
          console.error("[EscrowManager] Manual escrow cycle failed:", error);
          throw error;
        }
      }
      /**
       * Get subsystem status
       */
      getStatus() {
        return {
          isRunning: this.isRunning,
          consumers: {
            forecast: this.isRunning,
            disbursement: this.isRunning,
            analysis: this.isRunning
          }
        };
      }
    };
    escrowManager = null;
  }
});

// server/escrow/routes.ts
var routes_exports = {};
__export(routes_exports, {
  escrowRoutes: () => router34
});
import { Router as Router39 } from "express";
var router34, forecastService, disbursementService, analysisService, requireAdmin3;
var init_routes = __esm({
  "server/escrow/routes.ts"() {
    "use strict";
    init_middleware();
    init_escrow_manager();
    init_forecast_service();
    init_disbursement_service();
    init_analysis_service();
    init_rabbitmq_unified();
    init_db();
    router34 = Router39();
    forecastService = new EscrowForecastService();
    disbursementService = new EscrowDisbursementService();
    analysisService = new EscrowAnalysisService();
    requireAdmin3 = async (req, res, next) => {
      await loadUserPolicy(req, res, () => {
        if (!req.userPolicy?.hasResourcePermission("admin_dashboard", "read")) {
          return res.status(403).json({ error: "Admin access required" });
        }
        next();
      });
    };
    router34.get("/status", requireAuth2, requireAdmin3, (req, res) => {
      const manager = getEscrowManager();
      const status = manager.getStatus();
      res.json({
        subsystem: "escrow",
        ...status,
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      });
    });
    router34.post("/cycle", requireAuth2, requireAdmin3, async (req, res) => {
      try {
        const { cycle_date } = req.body;
        const date2 = cycle_date || (/* @__PURE__ */ new Date()).toISOString().split("T")[0];
        console.log(`[EscrowRoutes] Manual cycle triggered by user ${req.user?.username} for ${date2}`);
        const manager = getEscrowManager();
        manager.runDailyCycle(date2).catch((error) => {
          console.error("[EscrowRoutes] Manual cycle failed:", error);
        });
        res.json({
          message: "Escrow daily cycle initiated",
          cycle_date: date2,
          status: "processing"
        });
      } catch (error) {
        console.error("[EscrowRoutes] Error initiating cycle:", error);
        res.status(500).json({ error: "Failed to initiate escrow cycle" });
      }
    });
    router34.get("/forecast/:loanId", requireAuth2, async (req, res) => {
      try {
        const loanId = parseInt(req.params.loanId);
        const loanResult = await pool.query(
          "SELECT id FROM loans WHERE id = $1",
          [loanId]
        );
        if (loanResult.rows.length === 0) {
          return res.status(404).json({ error: "Loan not found" });
        }
        const forecasts = await forecastService.getForecast(loanId);
        res.json({
          loan_id: loanId,
          forecasts: forecasts.map((f) => ({
            escrow_id: f.escrow_id,
            due_date: f.due_date,
            amount: (Number(f.amount_minor) / 100).toFixed(2)
          })),
          count: forecasts.length
        });
      } catch (error) {
        console.error("[EscrowRoutes] Error getting forecast:", error);
        res.status(500).json({ error: "Failed to get escrow forecast" });
      }
    });
    router34.post("/forecast/:loanId", requireAuth2, async (req, res) => {
      try {
        const loanId = parseInt(req.params.loanId);
        const { as_of_date } = req.body;
        const date2 = as_of_date || (/* @__PURE__ */ new Date()).toISOString().split("T")[0];
        console.log(`[EscrowRoutes] Forecast generation requested for loan ${loanId} by user ${req.user?.username}`);
        const rabbitmq2 = rabbitmqClient();
        await rabbitmq2.publishMessage(
          "escrow.saga",
          "forecast.request",
          {
            loan_id: loanId,
            as_of_date: date2,
            correlation_id: `manual_forecast_${loanId}_${Date.now()}`
          },
          { persistent: true }
        );
        res.json({
          message: "Forecast generation initiated",
          loan_id: loanId,
          as_of_date: date2,
          status: "queued"
        });
      } catch (error) {
        console.error("[EscrowRoutes] Error initiating forecast:", error);
        res.status(500).json({ error: "Failed to initiate forecast generation" });
      }
    });
    router34.get("/disbursements/:loanId", requireAuth2, async (req, res) => {
      try {
        const loanId = parseInt(req.params.loanId);
        const disbursements = await disbursementService.getDisbursementHistory(loanId);
        res.json({
          loan_id: loanId,
          disbursements: disbursements.map((d) => ({
            disb_id: d.disb_id,
            escrow_id: d.escrow_id,
            due_date: d.due_date,
            amount: (Number(d.amount_minor) / 100).toFixed(2),
            status: d.status,
            event_id: d.event_id,
            scheduled_at: d.scheduled_at,
            posted_at: d.posted_at
          })),
          count: disbursements.length
        });
      } catch (error) {
        console.error("[EscrowRoutes] Error getting disbursements:", error);
        res.status(500).json({ error: "Failed to get disbursement history" });
      }
    });
    router34.post("/disbursements/:loanId", requireAuth2, requireAdmin3, async (req, res) => {
      try {
        const loanId = parseInt(req.params.loanId);
        const { effective_date } = req.body;
        const date2 = effective_date || (/* @__PURE__ */ new Date()).toISOString().split("T")[0];
        console.log(`[EscrowRoutes] Disbursement scheduling requested for loan ${loanId} by user ${req.user?.username}`);
        const rabbitmq2 = rabbitmqClient();
        await rabbitmq2.publishMessage(
          "escrow.saga",
          "disbursement.schedule",
          {
            loan_id: loanId,
            effective_date: date2,
            correlation_id: `manual_disbursement_${loanId}_${Date.now()}`
          },
          { persistent: true }
        );
        res.json({
          message: "Disbursement scheduling initiated",
          loan_id: loanId,
          effective_date: date2,
          status: "queued"
        });
      } catch (error) {
        console.error("[EscrowRoutes] Error scheduling disbursements:", error);
        res.status(500).json({ error: "Failed to schedule disbursements" });
      }
    });
    router34.get("/analysis/:loanId", requireAuth2, async (req, res) => {
      try {
        const loanId = parseInt(req.params.loanId);
        const analysis = await analysisService.getLatestAnalysis(loanId);
        if (!analysis) {
          return res.status(404).json({ error: "No analysis found for loan" });
        }
        res.json({
          loan_id: loanId,
          analysis: {
            analysis_id: analysis.analysis_id,
            as_of_date: analysis.as_of_date,
            period_start: analysis.period_start,
            period_end: analysis.period_end,
            annual_expected: (Number(analysis.annual_expected_minor) / 100).toFixed(2),
            cushion_target: (Number(analysis.cushion_target_minor) / 100).toFixed(2),
            current_balance: (Number(analysis.current_balance_minor) / 100).toFixed(2),
            shortage: (Number(analysis.shortage_minor) / 100).toFixed(2),
            deficiency: (Number(analysis.deficiency_minor) / 100).toFixed(2),
            surplus: (Number(analysis.surplus_minor) / 100).toFixed(2),
            new_monthly_target: (Number(analysis.new_monthly_target_minor) / 100).toFixed(2),
            deficiency_recovery_monthly: (Number(analysis.deficiency_recovery_monthly_minor) / 100).toFixed(2),
            version: analysis.version,
            created_at: analysis.created_at
          }
        });
      } catch (error) {
        console.error("[EscrowRoutes] Error getting analysis:", error);
        res.status(500).json({ error: "Failed to get escrow analysis" });
      }
    });
    router34.post("/analysis/:loanId", requireAuth2, requireAdmin3, async (req, res) => {
      try {
        const loanId = parseInt(req.params.loanId);
        const { as_of_date, generate_statement } = req.body;
        const date2 = as_of_date || (/* @__PURE__ */ new Date()).toISOString().split("T")[0];
        console.log(`[EscrowRoutes] Analysis requested for loan ${loanId} by user ${req.user?.username}`);
        const rabbitmq2 = rabbitmqClient();
        await rabbitmq2.publishMessage(
          "escrow.saga",
          "analysis.request",
          {
            loan_id: loanId,
            as_of_date: date2,
            generate_statement: generate_statement || false,
            correlation_id: `manual_analysis_${loanId}_${Date.now()}`
          },
          { persistent: true }
        );
        res.json({
          message: "Escrow analysis initiated",
          loan_id: loanId,
          as_of_date: date2,
          generate_statement: generate_statement || false,
          status: "queued"
        });
      } catch (error) {
        console.error("[EscrowRoutes] Error initiating analysis:", error);
        res.status(500).json({ error: "Failed to initiate escrow analysis" });
      }
    });
    router34.get("/stats", requireAuth2, requireAdmin3, async (req, res) => {
      try {
        const statsResult = await pool.query(`
      SELECT 
        COUNT(DISTINCT loan_id) as total_loans,
        COUNT(*) as total_forecasts,
        SUM(amount_minor) / 100 as total_forecast_amount
      FROM escrow_forecast
      WHERE due_date >= CURRENT_DATE
        AND due_date <= CURRENT_DATE + INTERVAL '12 months'
    `);
        const disbResult = await pool.query(`
      SELECT 
        COUNT(*) as total_disbursements,
        COUNT(*) FILTER (WHERE status = 'scheduled') as scheduled,
        COUNT(*) FILTER (WHERE status = 'posted') as posted,
        COUNT(*) FILTER (WHERE status = 'canceled') as canceled,
        SUM(amount_minor) FILTER (WHERE status = 'posted') / 100 as total_posted_amount
      FROM escrow_disbursement
      WHERE due_date >= CURRENT_DATE - INTERVAL '30 days'
    `);
        const analysisResult = await pool.query(`
      SELECT 
        COUNT(DISTINCT loan_id) as loans_analyzed,
        SUM(shortage_minor) / 100 as total_shortages,
        SUM(deficiency_minor) / 100 as total_deficiencies,
        SUM(surplus_minor) / 100 as total_surpluses
      FROM escrow_analysis
      WHERE created_at >= CURRENT_DATE - INTERVAL '30 days'
    `);
        res.json({
          forecasts: {
            total_loans: parseInt(statsResult.rows[0].total_loans),
            total_forecasts: parseInt(statsResult.rows[0].total_forecasts),
            total_amount: parseFloat(statsResult.rows[0].total_forecast_amount || 0).toFixed(2)
          },
          disbursements: {
            total: parseInt(disbResult.rows[0].total_disbursements),
            scheduled: parseInt(disbResult.rows[0].scheduled),
            posted: parseInt(disbResult.rows[0].posted),
            canceled: parseInt(disbResult.rows[0].canceled),
            total_posted_amount: parseFloat(disbResult.rows[0].total_posted_amount || 0).toFixed(2)
          },
          analysis: {
            loans_analyzed: parseInt(analysisResult.rows[0].loans_analyzed),
            total_shortages: parseFloat(analysisResult.rows[0].total_shortages || 0).toFixed(2),
            total_deficiencies: parseFloat(analysisResult.rows[0].total_deficiencies || 0).toFixed(2),
            total_surpluses: parseFloat(analysisResult.rows[0].total_surpluses || 0).toFixed(2)
          }
        });
      } catch (error) {
        console.error("[EscrowRoutes] Error getting stats:", error);
        res.status(500).json({ error: "Failed to get escrow statistics" });
      }
    });
  }
});

// server/docs/repo.ts
import { sql as sql19 } from "drizzle-orm";
var DocsRepo;
var init_repo = __esm({
  "server/docs/repo.ts"() {
    "use strict";
    init_db();
    DocsRepo = class {
      /**
       * Get the latest template for a document type and jurisdiction
       */
      async getLatestTemplate(type, jurisdiction) {
        const result = await db.execute(sql19`
      SELECT 
        template_id, 
        type,
        jurisdiction,
        version,
        engine, 
        html_source, 
        css_source, 
        font_family
      FROM document_template
      WHERE type = ${type} 
        AND (jurisdiction IS NULL OR jurisdiction = ${jurisdiction || null})
        AND retired_at IS NULL
      ORDER BY jurisdiction NULLS LAST, version DESC
      LIMIT 1
    `);
        if (!result.rows.length) {
          return null;
        }
        const row = result.rows[0];
        return {
          template_id: row.template_id,
          type: row.type,
          jurisdiction: row.jurisdiction,
          version: row.version,
          engine: row.engine,
          html_source: row.html_source,
          css_source: row.css_source,
          font_family: row.font_family,
          created_at: /* @__PURE__ */ new Date()
        };
      }
      /**
       * Insert a document artifact
       */
      async insertArtifact(artifact2) {
        const result = await db.execute(sql19`
      INSERT INTO document_artifact(
        type, loan_id, related_id, period_start, period_end, tax_year,
        template_id, payload_json, inputs_hash, pdf_hash, pdf_bytes, size_bytes, event_id
      )
      VALUES (
        ${artifact2.type},
        ${artifact2.loan_id || null},
        ${artifact2.related_id || null},
        ${artifact2.period_start || null},
        ${artifact2.period_end || null},
        ${artifact2.tax_year || null},
        ${artifact2.template_id},
        ${JSON.stringify(artifact2.payload_json)},
        ${artifact2.inputs_hash},
        ${artifact2.pdf_hash},
        ${artifact2.pdf_bytes},
        ${artifact2.size_bytes},
        ${artifact2.event_id || null}
      )
      RETURNING doc_id
    `);
        return result.rows[0].doc_id;
      }
      /**
       * Get document artifact by ID
       */
      async getArtifact(docId) {
        const result = await db.execute(sql19`
      SELECT * FROM document_artifact WHERE doc_id = ${docId}
    `);
        if (!result.rows.length) {
          return null;
        }
        const row = result.rows[0];
        return {
          doc_id: row.doc_id,
          type: row.type,
          loan_id: row.loan_id,
          related_id: row.related_id,
          period_start: row.period_start,
          period_end: row.period_end,
          tax_year: row.tax_year,
          template_id: row.template_id,
          payload_json: row.payload_json,
          inputs_hash: row.inputs_hash,
          pdf_hash: row.pdf_hash,
          pdf_bytes: row.pdf_bytes,
          size_bytes: row.size_bytes,
          created_at: row.created_at,
          event_id: row.event_id
        };
      }
      /**
       * Get documents for a loan
       */
      async getDocumentsForLoan(loanId, type) {
        let query = sql19`
      SELECT * FROM document_artifact 
      WHERE loan_id = ${loanId}
    `;
        if (type) {
          query = sql19`
        SELECT * FROM document_artifact 
        WHERE loan_id = ${loanId} AND type = ${type}
        ORDER BY created_at DESC
      `;
        } else {
          query = sql19`
        SELECT * FROM document_artifact 
        WHERE loan_id = ${loanId}
        ORDER BY created_at DESC
      `;
        }
        const result = await db.execute(query);
        return result.rows.map((row) => ({
          doc_id: row.doc_id,
          type: row.type,
          loan_id: row.loan_id,
          related_id: row.related_id,
          period_start: row.period_start,
          period_end: row.period_end,
          tax_year: row.tax_year,
          template_id: row.template_id,
          payload_json: row.payload_json,
          inputs_hash: row.inputs_hash,
          pdf_hash: row.pdf_hash,
          pdf_bytes: row.pdf_bytes,
          size_bytes: row.size_bytes,
          created_at: row.created_at,
          event_id: row.event_id
        }));
      }
      /**
       * Link a notice to a sent document
       */
      async linkNoticeSent(noticeId, docId) {
        await db.execute(sql19`
      UPDATE notice_schedule 
      SET status = 'sent', sent_doc_id = ${docId}
      WHERE notice_id = ${noticeId}
    `);
      }
      /**
       * Get scheduled notices
       */
      async getScheduledNotices(before) {
        const cutoff = before || /* @__PURE__ */ new Date();
        const result = await db.execute(sql19`
      SELECT * FROM notice_schedule 
      WHERE status = 'scheduled' AND scheduled_for <= ${cutoff}
      ORDER BY scheduled_for ASC
    `);
        return result.rows.map((row) => ({
          notice_id: row.notice_id,
          loan_id: row.loan_id,
          notice_template_id: row.notice_template_id,
          trigger_code: row.trigger_code,
          params: row.params,
          scheduled_for: row.scheduled_for,
          status: row.status,
          sent_doc_id: row.sent_doc_id,
          created_at: row.created_at
        }));
      }
      /**
       * Schedule a notice
       */
      async scheduleNotice(notice) {
        const result = await db.execute(sql19`
      INSERT INTO notice_schedule(
        loan_id, notice_template_id, trigger_code, params, scheduled_for
      )
      VALUES (
        ${notice.loan_id},
        ${notice.notice_template_id},
        ${notice.trigger_code},
        ${JSON.stringify(notice.params || {})},
        ${notice.scheduled_for}
      )
      ON CONFLICT (loan_id, notice_template_id, scheduled_for) 
      DO NOTHING
      RETURNING notice_id
    `);
        if (!result.rows.length) {
          throw new Error("Notice already scheduled");
        }
        return result.rows[0].notice_id;
      }
      /**
       * Cancel a scheduled notice
       */
      async cancelNotice(noticeId) {
        await db.execute(sql19`
      UPDATE notice_schedule 
      SET status = 'canceled'
      WHERE notice_id = ${noticeId} AND status = 'scheduled'
    `);
      }
      /**
       * Get lender entity information
       */
      async getLenderEntity() {
        const result = await db.execute(sql19`
      SELECT * FROM lender_entity LIMIT 1
    `);
        if (!result.rows.length) {
          return null;
        }
        return result.rows[0];
      }
      /**
       * Insert default templates
       */
      async insertDefaultTemplates() {
        await db.execute(sql19`
      INSERT INTO lender_entity (legal_name, dba_name, tin, nmls_id, mailing_address, service_email, service_phone)
      VALUES (
        'LoanServe Financial LLC',
        'LoanServe Pro',
        '12-3456789',
        'MLS123456',
        '{"street": "100 Financial Plaza", "city": "New York", "state": "NY", "zip": "10001"}',
        'servicing@loanserve.pro',
        '1-800-555-0100'
      )
      ON CONFLICT DO NOTHING
    `);
        await db.execute(sql19`
      INSERT INTO document_template (type, version, engine, html_source, css_source)
      VALUES (
        'billing_statement',
        1,
        'handlebars-html',
        ${this.getDefaultBillingStatementHTML()},
        ${this.getDefaultCSS()}
      )
      ON CONFLICT DO NOTHING
    `);
        await db.execute(sql19`
      INSERT INTO document_template (type, version, engine, html_source, css_source)
      VALUES (
        'escrow_analysis',
        1,
        'handlebars-html',
        ${this.getDefaultEscrowAnalysisHTML()},
        ${this.getDefaultCSS()}
      )
      ON CONFLICT DO NOTHING
    `);
        await db.execute(sql19`
      INSERT INTO document_template (type, version, engine, html_source, css_source)
      VALUES (
        'year_end_1098',
        1,
        'handlebars-html',
        ${this.getDefault1098HTML()},
        ${this.getDefaultCSS()}
      )
      ON CONFLICT DO NOTHING
    `);
      }
      getDefaultBillingStatementHTML() {
        return `<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Billing Statement</title>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>Monthly Billing Statement</h1>
      <div class="period">{{statement_period.start}} - {{statement_period.end}}</div>
    </div>
    
    <div class="borrower-info">
      <h2>Account Information</h2>
      <p>{{borrower.name}}<br>{{borrower.mailing_address}}</p>
      <p>Loan ID: {{loan_id}}</p>
    </div>
    
    <div class="summary">
      <h2>Account Summary</h2>
      <table>
        <tr><td>Previous Balance:</td><td>{{formatMinor previous_balance_minor}}</td></tr>
        <tr><td>Escrow Payment:</td><td>{{formatMinor escrow_monthly_target_minor}}</td></tr>
        <tr><td>Total Due:</td><td class="total">{{formatMinor total_due_minor}}</td></tr>
        <tr><td>Due Date:</td><td>{{statement_period.due_date}}</td></tr>
      </table>
    </div>
    
    <div class="transactions">
      <h2>Transaction History</h2>
      <table>
        <thead>
          <tr><th>Date</th><th>Description</th><th>Debit</th><th>Credit</th></tr>
        </thead>
        <tbody>
          {{#each transactions}}
          <tr>
            <td>{{posted_at}}</td>
            <td>{{description}}</td>
            <td>{{#if debit_minor}}{{formatMinor debit_minor}}{{/if}}</td>
            <td>{{#if credit_minor}}{{formatMinor credit_minor}}{{/if}}</td>
          </tr>
          {{/each}}
        </tbody>
      </table>
    </div>
    
    {{#if messages}}
    <div class="messages">
      {{#each messages}}
      <p>{{this}}</p>
      {{/each}}
    </div>
    {{/if}}
  </div>
</body>
</html>`;
      }
      getDefaultEscrowAnalysisHTML() {
        return `<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Escrow Analysis</title>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>Annual Escrow Analysis</h1>
      <div class="period">Period: {{period_start}} - {{period_end}}</div>
    </div>
    
    <div class="summary">
      <h2>Analysis Summary</h2>
      <table>
        <tr><td>Annual Expected:</td><td>{{formatMinor annual_expected_minor}}</td></tr>
        <tr><td>Cushion Target:</td><td>{{formatMinor cushion_target_minor}}</td></tr>
        <tr><td>Current Balance:</td><td>{{formatMinor current_balance_minor}}</td></tr>
        {{#if shortage_minor}}<tr><td>Shortage:</td><td>{{formatMinor shortage_minor}}</td></tr>{{/if}}
        {{#if deficiency_minor}}<tr><td>Deficiency:</td><td>{{formatMinor deficiency_minor}}</td></tr>{{/if}}
        {{#if surplus_minor}}<tr><td>Surplus:</td><td>{{formatMinor surplus_minor}}</td></tr>{{/if}}
        <tr><td>New Monthly Payment:</td><td class="total">{{formatMinor new_monthly_target_minor}}</td></tr>
      </table>
    </div>
    
    <div class="items">
      <h2>Scheduled Items</h2>
      <table>
        <thead>
          <tr><th>Due Date</th><th>Type</th><th>Payee</th><th>Amount</th></tr>
        </thead>
        <tbody>
          {{#each items}}
          <tr>
            <td>{{due_date}}</td>
            <td>{{type}}</td>
            <td>{{payee}}</td>
            <td>{{formatMinor amount_minor}}</td>
          </tr>
          {{/each}}
        </tbody>
      </table>
    </div>
  </div>
</body>
</html>`;
      }
      getDefault1098HTML() {
        return `<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Form 1098 - Mortgage Interest Statement</title>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>Form 1098</h1>
      <h2>Mortgage Interest Statement</h2>
      <div class="tax-year">Tax Year {{tax_year}}</div>
    </div>
    
    <div class="parties">
      <div class="lender">
        <h3>LENDER</h3>
        <p>{{lender.name}}<br>{{lender.address}}</p>
        {{#if lender.tin_last4}}<p>TIN: ***-**-{{lender.tin_last4}}</p>{{/if}}
      </div>
      
      <div class="borrower">
        <h3>BORROWER</h3>
        <p>{{borrower.name}}<br>{{borrower.mailing_address}}</p>
        {{#if borrower.tin_last4}}<p>TIN: ***-**-{{borrower.tin_last4}}</p>{{/if}}
      </div>
    </div>
    
    <div class="amounts">
      <table>
        <tr>
          <td>1. Mortgage Interest Received:</td>
          <td class="amount">{{formatMinor interest_received_minor}}</td>
        </tr>
        {{#if mortgage_insurance_premiums_minor}}
        <tr>
          <td>2. Mortgage Insurance Premiums:</td>
          <td class="amount">{{formatMinor mortgage_insurance_premiums_minor}}</td>
        </tr>
        {{/if}}
        {{#if points_paid_minor}}
        <tr>
          <td>3. Points Paid on Purchase:</td>
          <td class="amount">{{formatMinor points_paid_minor}}</td>
        </tr>
        {{/if}}
      </table>
    </div>
    
    <div class="property">
      <p><strong>Property Address:</strong> {{property_address}}</p>
      <p><strong>Account Number:</strong> {{account_number}}</p>
    </div>
    
    <div class="footer">
      <p>This is important tax information and is being furnished to the Internal Revenue Service.</p>
    </div>
  </div>
</body>
</html>`;
      }
      getDefaultCSS() {
        return `
body { 
  font-family: 'DejaVu Sans', sans-serif; 
  font-size: 12pt; 
  line-height: 1.6; 
  color: #000; 
  margin: 0; 
  padding: 0;
}
.container { 
  max-width: 8.5in; 
  margin: 0 auto; 
  padding: 0.5in;
}
.header { 
  border-bottom: 2px solid #000; 
  padding-bottom: 10px; 
  margin-bottom: 20px;
}
h1 { 
  font-size: 18pt; 
  margin: 0 0 5px 0;
}
h2 { 
  font-size: 14pt; 
  margin: 15px 0 10px 0;
  color: #333;
}
h3 { 
  font-size: 12pt; 
  margin: 10px 0 5px 0;
  color: #555;
}
table { 
  width: 100%; 
  border-collapse: collapse;
  margin: 10px 0;
}
td, th { 
  padding: 5px 10px; 
  text-align: left;
  border-bottom: 1px solid #ddd;
}
th { 
  font-weight: bold; 
  background: #f5f5f5;
}
.total { 
  font-weight: bold; 
  font-size: 14pt;
}
.amount { 
  text-align: right; 
  font-family: monospace;
}
.period { 
  font-size: 10pt; 
  color: #666;
}
.borrower-info, .lender, .borrower { 
  margin: 20px 0;
}
.parties { 
  display: flex; 
  justify-content: space-between;
}
.footer { 
  margin-top: 30px; 
  padding-top: 20px; 
  border-top: 1px solid #ccc; 
  font-size: 10pt; 
  color: #666;
}
.messages { 
  background: #f9f9f9; 
  border: 1px solid #ddd; 
  padding: 10px; 
  margin: 20px 0;
}
@media print {
  body { margin: 0; }
  .container { padding: 0; }
}`;
      }
    };
  }
});

// server/docs/document-builders.ts
import { sql as sql20 } from "drizzle-orm";
var DocumentBuilders;
var init_document_builders = __esm({
  "server/docs/document-builders.ts"() {
    "use strict";
    init_db();
    DocumentBuilders = class {
      /**
       * Build billing statement data
       */
      async buildBillingStatement(loanId, periodStart, periodEnd, dueDate) {
        const loanResult = await db.execute(sql20`
      SELECT 
        l.id,
        l.loan_number,
        l.borrower_name,
        l.co_borrower_name,
        l.mailing_address_1,
        l.mailing_address_2,
        l.mailing_city,
        l.mailing_state,
        l.mailing_zip
      FROM loans l
      WHERE l.id = ${loanId}
    `);
        if (!loanResult.rows.length) {
          throw new Error(`Loan ${loanId} not found`);
        }
        const loan = loanResult.rows[0];
        const borrowerAddress = [
          loan.mailing_address_1,
          loan.mailing_address_2,
          `${loan.mailing_city}, ${loan.mailing_state} ${loan.mailing_zip}`
        ].filter(Boolean).join("\n");
        const balanceResult = await db.execute(sql20`
      SELECT 
        COALESCE(SUM(CASE 
          WHEN le.account LIKE '%_receivable' AND le.debit > 0 THEN le.debit 
          WHEN le.account = 'suspense' AND le.credit > 0 THEN -le.credit
          ELSE 0 
        END), 0) as previous_balance
      FROM ledger_entry le
      JOIN ledger_event ev ON le.event_id = ev.event_id
      WHERE ev.loan_id = ${loanId}
        AND ev.created_at < ${periodStart}::timestamptz
    `);
        const previousBalance = BigInt(balanceResult.rows[0]?.previous_balance || 0);
        const transactionsResult = await db.execute(sql20`
      SELECT 
        ev.created_at as posted_at,
        ev.description,
        le.account,
        le.debit,
        le.credit
      FROM ledger_entry le
      JOIN ledger_event ev ON le.event_id = ev.event_id
      WHERE ev.loan_id = ${loanId}
        AND ev.created_at >= ${periodStart}::timestamptz
        AND ev.created_at < ${periodEnd}::timestamptz
        AND le.account NOT LIKE '%_contra%'
      ORDER BY ev.created_at ASC, ev.description ASC
    `);
        const transactions = transactionsResult.rows.map((row) => {
          const isPayment = row.account === "cash" && row.debit > 0;
          const isFee = row.account === "fee_income" && row.credit > 0;
          return {
            posted_at: new Date(row.posted_at).toISOString().split("T")[0],
            description: row.description,
            debit_minor: isFee ? BigInt(row.credit) : void 0,
            credit_minor: isPayment ? BigInt(row.debit) : void 0
          };
        }).filter((t) => t.debit_minor || t.credit_minor);
        const escrowResult = await db.execute(sql20`
      SELECT escrow_payment
      FROM payment_schedules
      WHERE loan_id = ${loanId}
        AND due_date >= ${dueDate}::date
      ORDER BY due_date ASC
      LIMIT 1
    `);
        const escrowTarget = BigInt(escrowResult.rows[0]?.escrow_payment || 0) * 100n;
        const scheduledResult = await db.execute(sql20`
      SELECT 
        principal_payment + interest_payment + escrow_payment + COALESCE(fee_payment, 0) as total_payment
      FROM payment_schedules
      WHERE loan_id = ${loanId}
        AND due_date = ${dueDate}::date
    `);
        const scheduledPayment = BigInt(scheduledResult.rows[0]?.total_payment || 0) * 100n;
        const paymentsInPeriod = transactions.filter((t) => t.credit_minor).reduce((sum3, t) => sum3 + (t.credit_minor || 0n), 0n);
        const totalDue = previousBalance + scheduledPayment - paymentsInPeriod;
        const pastDue = previousBalance > 0n ? previousBalance : 0n;
        const policyResult = await db.execute(sql20`
      SELECT 
        grace_period_days,
        late_fee_flat,
        late_fee_percentage
      FROM fee_policies
      WHERE loan_id = ${loanId}
        AND effective_date <= ${dueDate}::date
      ORDER BY effective_date DESC
      LIMIT 1
    `);
        const policy = policyResult.rows[0] || {
          grace_period_days: 10,
          late_fee_flat: null,
          late_fee_percentage: null
        };
        return {
          loan_id: loanId,
          borrower: {
            name: `${loan.borrower_name}${loan.co_borrower_name ? " & " + loan.co_borrower_name : ""}`,
            mailing_address: borrowerAddress
          },
          statement_period: {
            start: periodStart,
            end: periodEnd,
            due_date: dueDate
          },
          previous_balance_minor: previousBalance,
          transactions,
          escrow_monthly_target_minor: escrowTarget,
          total_due_minor: totalDue,
          past_due_minor: pastDue,
          late_fee_policy: {
            grace_days: policy.grace_period_days,
            amount_minor: policy.late_fee_flat ? BigInt(policy.late_fee_flat * 100) : void 0,
            percent_bps: policy.late_fee_percentage ? Math.round(policy.late_fee_percentage * 100) : void 0
          },
          messages: pastDue > 0n ? ["Payment is past due. Please remit immediately to avoid additional fees."] : []
        };
      }
      /**
       * Build escrow analysis document data
       */
      async buildEscrowAnalysis(analysisId) {
        const analysisResult = await db.execute(sql20`
      SELECT * FROM escrow_analysis
      WHERE analysis_id = ${analysisId}
    `);
        if (!analysisResult.rows.length) {
          throw new Error(`Escrow analysis ${analysisId} not found`);
        }
        const analysis = analysisResult.rows[0];
        const itemsResult = await db.execute(sql20`
      SELECT * FROM escrow_analysis_item
      WHERE analysis_id = ${analysisId}
      ORDER BY due_date ASC, type, payee
    `);
        const items = itemsResult.rows.map((row) => ({
          due_date: new Date(row.due_date).toISOString().split("T")[0],
          type: row.type,
          payee: row.payee,
          amount_minor: BigInt(row.amount_minor)
        }));
        return {
          loan_id: analysis.loan_id,
          analysis_id: analysisId,
          period_start: new Date(analysis.period_start).toISOString().split("T")[0],
          period_end: new Date(analysis.period_end).toISOString().split("T")[0],
          annual_expected_minor: BigInt(analysis.annual_expected_minor),
          cushion_target_minor: BigInt(analysis.cushion_target_minor),
          current_balance_minor: BigInt(analysis.current_balance_minor),
          shortage_minor: BigInt(analysis.shortage_minor || 0),
          deficiency_minor: BigInt(analysis.deficiency_minor || 0),
          surplus_minor: BigInt(analysis.surplus_minor || 0),
          new_monthly_target_minor: BigInt(analysis.new_monthly_target_minor),
          deficiency_recovery_monthly_minor: BigInt(analysis.deficiency_recovery_monthly_minor || 0),
          items
        };
      }
      /**
       * Build 1098 tax document data (cash basis)
       */
      async buildYear1098(loanId, taxYear) {
        const loanResult = await db.execute(sql20`
      SELECT 
        l.id,
        l.loan_number,
        l.borrower_name,
        l.co_borrower_name,
        l.borrower_tin,
        l.mailing_address_1,
        l.mailing_address_2,
        l.mailing_city,
        l.mailing_state,
        l.mailing_zip,
        l.property_address_1,
        l.property_city,
        l.property_state,
        l.property_zip
      FROM loans l
      WHERE l.id = ${loanId}
    `);
        if (!loanResult.rows.length) {
          throw new Error(`Loan ${loanId} not found`);
        }
        const loan = loanResult.rows[0];
        const borrowerAddress = [
          loan.mailing_address_1,
          loan.mailing_address_2,
          `${loan.mailing_city}, ${loan.mailing_state} ${loan.mailing_zip}`
        ].filter(Boolean).join("\n");
        const propertyAddress = [
          loan.property_address_1,
          `${loan.property_city}, ${loan.property_state} ${loan.property_zip}`
        ].join("\n");
        const lenderResult = await db.execute(sql20`
      SELECT * FROM lender_entity LIMIT 1
    `);
        if (!lenderResult.rows.length) {
          throw new Error("Lender entity not configured");
        }
        const lender = lenderResult.rows[0];
        const lenderAddr = lender.mailing_address;
        const lenderAddress = `${lenderAddr.street}
${lenderAddr.city}, ${lenderAddr.state} ${lenderAddr.zip}`;
        const yearStart = `${taxYear}-01-01`;
        const yearEnd = `${taxYear}-12-31`;
        const interestResult = await db.execute(sql20`
      SELECT 
        COALESCE(SUM(applied_to_interest), 0) as interest_received
      FROM payment_postings
      WHERE loan_id = ${loanId}
        AND effective_date >= ${yearStart}::date
        AND effective_date <= ${yearEnd}::date
        AND status = 'posted'
    `);
        const interestReceived = BigInt(interestResult.rows[0]?.interest_received || 0) * 100n;
        const miResult = await db.execute(sql20`
      SELECT 
        COALESCE(SUM(le.credit), 0) as mi_premiums
      FROM ledger_entry le
      JOIN ledger_event ev ON le.event_id = ev.event_id
      WHERE ev.loan_id = ${loanId}
        AND le.account = 'mortgage_insurance_expense'
        AND ev.created_at >= ${yearStart}::timestamptz
        AND ev.created_at <= ${yearEnd}::timestamptz
    `);
        const miPremiums = BigInt(miResult.rows[0]?.mi_premiums || 0);
        const borrowerTinLast4 = loan.borrower_tin ? loan.borrower_tin.slice(-4) : void 0;
        const lenderTinLast4 = lender.tin ? lender.tin.slice(-4) : void 0;
        return {
          loan_id: loanId,
          tax_year: taxYear,
          borrower: {
            name: `${loan.borrower_name}${loan.co_borrower_name ? " & " + loan.co_borrower_name : ""}`,
            mailing_address: borrowerAddress,
            tin_last4: borrowerTinLast4
          },
          lender: {
            name: lender.legal_name,
            address: lenderAddress,
            tin_last4: lenderTinLast4
          },
          interest_received_minor: interestReceived,
          mortgage_insurance_premiums_minor: miPremiums > 0n ? miPremiums : void 0,
          property_address: propertyAddress,
          account_number: loan.loan_number
        };
      }
    };
  }
});

// server/docs/render-service.ts
import Handlebars2 from "handlebars";
import PDFDocument2 from "pdfkit";
import crypto14 from "crypto";
var RenderService;
var init_render_service = __esm({
  "server/docs/render-service.ts"() {
    "use strict";
    Handlebars2.registerHelper("formatMinor", (value) => {
      if (!value) return "0.00";
      const num2 = Number(value) / 100;
      return num2.toFixed(2);
    });
    Handlebars2.registerHelper("formatDateISO", (date2) => {
      if (!date2) return "";
      const d = typeof date2 === "string" ? new Date(date2) : date2;
      return d.toISOString().split("T")[0];
    });
    RenderService = class {
      /**
       * Render HTML template with data
       */
      renderHTML(htmlSource, cssSource, data) {
        const template = Handlebars2.compile(htmlSource, {
          noEscape: false,
          strict: true
        });
        const body = template(data);
        return `
      <!DOCTYPE html>
      <html>
      <head>
        <meta charset="utf-8">
        <style>${cssSource}</style>
      </head>
      <body>${body}</body>
      </html>
    `;
      }
      /**
       * Generate deterministic PDF from HTML (simplified version)
       * In production, would use puppeteer with specific settings for byte-stable output
       */
      async generatePDF(html, fontFamily = "Helvetica") {
        return new Promise((resolve, reject) => {
          const chunks = [];
          const doc = new PDFDocument2({
            size: "LETTER",
            margin: 72,
            // 1 inch margins
            bufferPages: true,
            autoFirstPage: false,
            info: {
              Producer: "LoanServe Pro",
              Creator: "LoanServe Pro Document Service"
            }
          });
          doc.on("data", (chunk) => chunks.push(chunk));
          doc.on("end", () => resolve(Buffer.concat(chunks)));
          doc.on("error", reject);
          doc.addPage();
          const textContent = this.extractTextFromHTML(html);
          doc.font(fontFamily);
          doc.fontSize(12);
          doc.text(textContent, {
            align: "left",
            width: doc.page.width - 144,
            // Account for margins
            height: doc.page.height - 144
          });
          doc.end();
        });
      }
      /**
       * Extract text from HTML (simplified version)
       */
      extractTextFromHTML(html) {
        return html.replace(/<style[^>]*>[\s\S]*?<\/style>/gi, "").replace(/<script[^>]*>[\s\S]*?<\/script>/gi, "").replace(/<[^>]+>/g, " ").replace(/\s+/g, " ").trim();
      }
      /**
       * Calculate deterministic hash of inputs
       */
      calculateInputsHash(payloadJson, templateId, cssSource, engine, version) {
        const input = JSON.stringify({
          payload: payloadJson,
          template: templateId,
          css: cssSource,
          engine,
          version
        });
        return crypto14.createHash("sha256").update(input).digest("hex");
      }
      /**
       * Calculate hash of PDF bytes
       */
      calculatePDFHash(pdfBytes) {
        return crypto14.createHash("sha256").update(pdfBytes).digest("hex");
      }
      /**
       * Full rendering pipeline
       */
      async renderDocument(request, template) {
        if (template.engine !== "handlebars-html") {
          throw new Error(`Unsupported engine: ${template.engine}`);
        }
        const html = this.renderHTML(
          template.html_source,
          template.css_source,
          request.payload
        );
        const pdf_bytes = await this.generatePDF(html, template.font_family);
        const inputs_hash = this.calculateInputsHash(
          request.payload,
          request.template_id,
          template.css_source,
          template.engine,
          template.version
        );
        const pdf_hash = this.calculatePDFHash(pdf_bytes);
        return {
          html,
          pdf_bytes,
          inputs_hash,
          pdf_hash,
          size_bytes: pdf_bytes.length
        };
      }
    };
  }
});

// server/docs/routes.ts
var routes_exports2 = {};
__export(routes_exports2, {
  default: () => routes_default
});
import { Router as Router40 } from "express";
var router35, repo, builders, renderer, routes_default;
var init_routes2 = __esm({
  "server/docs/routes.ts"() {
    "use strict";
    init_repo();
    init_document_builders();
    init_render_service();
    init_middleware();
    init_db();
    init_schema();
    router35 = Router40();
    repo = new DocsRepo();
    builders = new DocumentBuilders();
    renderer = new RenderService();
    router35.post("/api/documents/generate/statement", requireAuth2, async (req, res) => {
      try {
        const { loan_id, period_start, period_end, due_date } = req.body;
        if (!loan_id || !period_start || !period_end || !due_date) {
          return res.status(400).json({ error: "Missing required parameters" });
        }
        const payload = await builders.buildBillingStatement(
          loan_id,
          period_start,
          period_end,
          due_date
        );
        const template = await repo.getLatestTemplate("billing_statement");
        if (!template) {
          return res.status(404).json({ error: "No billing statement template found" });
        }
        const rendered = await renderer.renderDocument(
          {
            type: "billing_statement",
            template_id: template.template_id,
            payload
          },
          template
        );
        const docId = await repo.insertArtifact({
          type: "billing_statement",
          loan_id,
          period_start,
          period_end,
          template_id: template.template_id,
          payload_json: payload,
          inputs_hash: rendered.inputs_hash,
          pdf_hash: rendered.pdf_hash,
          pdf_bytes: rendered.pdf_bytes,
          size_bytes: rendered.size_bytes
        });
        await db.insert(crmActivity).values({
          loanId: loan_id,
          userId: req.user?.id || 1,
          activityType: "document",
          activityData: {
            description: `Billing Statement generated for period ${period_start} to ${period_end}`,
            documentType: "billing_statement",
            documentId: docId,
            periodStart: period_start,
            periodEnd: period_end,
            dueDate: due_date,
            source: "document_generation"
          },
          isSystem: false,
          createdAt: /* @__PURE__ */ new Date()
        });
        res.json({
          success: true,
          doc_id: docId,
          size_bytes: rendered.size_bytes,
          pdf_hash: rendered.pdf_hash
        });
      } catch (error) {
        console.error("Statement generation error:", error);
        res.status(500).json({ error: "Failed to generate statement" });
      }
    });
    router35.post("/api/documents/generate/escrow-analysis", requireAuth2, async (req, res) => {
      try {
        const { analysis_id } = req.body;
        if (!analysis_id) {
          return res.status(400).json({ error: "Missing analysis_id" });
        }
        const payload = await builders.buildEscrowAnalysis(analysis_id);
        const template = await repo.getLatestTemplate("escrow_analysis");
        if (!template) {
          return res.status(404).json({ error: "No escrow analysis template found" });
        }
        const rendered = await renderer.renderDocument(
          {
            type: "escrow_analysis",
            template_id: template.template_id,
            payload
          },
          template
        );
        const docId = await repo.insertArtifact({
          type: "escrow_analysis",
          loan_id: payload.loan_id,
          related_id: analysis_id,
          template_id: template.template_id,
          payload_json: payload,
          inputs_hash: rendered.inputs_hash,
          pdf_hash: rendered.pdf_hash,
          pdf_bytes: rendered.pdf_bytes,
          size_bytes: rendered.size_bytes
        });
        res.json({
          success: true,
          doc_id: docId,
          size_bytes: rendered.size_bytes,
          pdf_hash: rendered.pdf_hash
        });
      } catch (error) {
        console.error("Escrow analysis generation error:", error);
        res.status(500).json({ error: "Failed to generate escrow analysis" });
      }
    });
    router35.post("/api/documents/generate/1098", requireAuth2, async (req, res) => {
      try {
        const { loan_id, tax_year } = req.body;
        if (!loan_id || !tax_year) {
          return res.status(400).json({ error: "Missing required parameters" });
        }
        const payload = await builders.buildYear1098(loan_id, tax_year);
        const template = await repo.getLatestTemplate("year_end_1098");
        if (!template) {
          return res.status(404).json({ error: "No 1098 template found" });
        }
        const rendered = await renderer.renderDocument(
          {
            type: "year_end_1098",
            template_id: template.template_id,
            payload
          },
          template
        );
        const docId = await repo.insertArtifact({
          type: "year_end_1098",
          loan_id,
          tax_year,
          template_id: template.template_id,
          payload_json: payload,
          inputs_hash: rendered.inputs_hash,
          pdf_hash: rendered.pdf_hash,
          pdf_bytes: rendered.pdf_bytes,
          size_bytes: rendered.size_bytes
        });
        res.json({
          success: true,
          doc_id: docId,
          size_bytes: rendered.size_bytes,
          pdf_hash: rendered.pdf_hash
        });
      } catch (error) {
        console.error("1098 generation error:", error);
        res.status(500).json({ error: "Failed to generate 1098" });
      }
    });
    router35.get("/api/documents/loan/:loanId", requireAuth2, async (req, res) => {
      try {
        const { loanId } = req.params;
        const { type } = req.query;
        const documents2 = await repo.getDocumentsForLoan(
          parseInt(loanId),
          type
        );
        const documentList = documents2.map((doc) => ({
          doc_id: doc.doc_id,
          type: doc.type,
          period_start: doc.period_start,
          period_end: doc.period_end,
          tax_year: doc.tax_year,
          size_bytes: doc.size_bytes,
          created_at: doc.created_at
        }));
        res.json(documentList);
      } catch (error) {
        console.error("Get documents error:", error);
        res.status(500).json({ error: "Failed to get documents" });
      }
    });
    router35.get("/api/documents/:docId/download", requireAuth2, async (req, res) => {
      try {
        const { docId } = req.params;
        const document = await repo.getArtifact(docId);
        if (!document) {
          return res.status(404).json({ error: "Document not found" });
        }
        res.set({
          "Content-Type": "application/pdf",
          "Content-Length": document.size_bytes.toString(),
          "Content-Disposition": `attachment; filename="${document.type}_${document.doc_id}.pdf"`,
          "X-Document-Hash": document.pdf_hash
        });
        res.send(document.pdf_bytes);
      } catch (error) {
        console.error("Document download error:", error);
        res.status(500).json({ error: "Failed to download document" });
      }
    });
    router35.post("/api/notices/schedule", requireAuth2, async (req, res) => {
      try {
        const { loan_id, notice_template_id, trigger_code, params, scheduled_for } = req.body;
        if (!loan_id || !notice_template_id || !trigger_code || !scheduled_for) {
          return res.status(400).json({ error: "Missing required parameters" });
        }
        const noticeId = await repo.scheduleNotice({
          loan_id,
          notice_template_id,
          trigger_code,
          params,
          scheduled_for: new Date(scheduled_for)
        });
        res.json({
          success: true,
          notice_id: noticeId
        });
      } catch (error) {
        console.error("Notice scheduling error:", error);
        res.status(500).json({ error: "Failed to schedule notice" });
      }
    });
    router35.get("/api/notices/scheduled", requireAuth2, async (req, res) => {
      try {
        const notices = await repo.getScheduledNotices();
        res.json(notices);
      } catch (error) {
        console.error("Get notices error:", error);
        res.status(500).json({ error: "Failed to get scheduled notices" });
      }
    });
    router35.post("/api/notices/:noticeId/cancel", requireAuth2, async (req, res) => {
      try {
        const { noticeId } = req.params;
        await repo.cancelNotice(noticeId);
        res.json({
          success: true,
          message: "Notice canceled"
        });
      } catch (error) {
        console.error("Notice cancel error:", error);
        res.status(500).json({ error: "Failed to cancel notice" });
      }
    });
    router35.post("/api/documents/init-templates", requireAuth2, async (req, res) => {
      try {
        await repo.insertDefaultTemplates();
        res.json({
          success: true,
          message: "Default templates created"
        });
      } catch (error) {
        console.error("Template initialization error:", error);
        res.status(500).json({ error: "Failed to initialize templates" });
      }
    });
    routes_default = router35;
  }
});

// server/cash/repo.ts
import { createHash as createHash11 } from "crypto";
var CashRepo;
var init_repo2 = __esm({
  "server/cash/repo.ts"() {
    "use strict";
    CashRepo = class {
      constructor(pool17) {
        this.pool = pool17;
      }
      async withTx(fn) {
        const client5 = await this.pool.connect();
        try {
          await client5.query("BEGIN");
          const result = await fn(client5);
          await client5.query("COMMIT");
          return result;
        } catch (error) {
          await client5.query("ROLLBACK");
          throw error;
        } finally {
          client5.release();
        }
      }
      // Bank Account operations
      async createBankAccount(client5, account) {
        const result = await client5.query(`
      INSERT INTO bank_account (
        name, bank_id, account_number_mask, currency,
        type, gl_cash_account, active
      ) VALUES ($1, $2, $3, $4, $5, $6, $7)
      RETURNING bank_acct_id
    `, [
          account.name,
          account.bank_id,
          account.account_number_mask,
          account.currency,
          account.type,
          account.gl_cash_account,
          account.active
        ]);
        return result.rows[0].bank_acct_id;
      }
      async getBankAccount(bankAcctId) {
        const result = await this.pool.query(`
      SELECT * FROM bank_account WHERE bank_acct_id = $1
    `, [bankAcctId]);
        return result.rows[0] || null;
      }
      // ACH Batch operations
      async createAchBatch(client5, batch) {
        const result = await client5.query(`
      INSERT INTO ach_batch (
        bank_acct_id, service_class, company_id, company_name,
        effective_entry_date, created_by, total_entries, 
        total_amount_minor, status
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
      RETURNING ach_batch_id
    `, [
          batch.bank_acct_id,
          batch.service_class,
          batch.company_id,
          batch.company_name,
          batch.effective_entry_date,
          batch.created_by,
          batch.total_entries,
          batch.total_amount_minor.toString(),
          batch.status
        ]);
        return result.rows[0].ach_batch_id;
      }
      async addAchEntry(client5, entry) {
        const result = await client5.query(`
      INSERT INTO ach_entry (
        ach_batch_id, loan_id, txn_code, rdfi_routing,
        dda_account_mask, amount_minor, trace_number,
        addenda, idempotency_key
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
      RETURNING ach_entry_id
    `, [
          entry.ach_batch_id,
          entry.loan_id || null,
          entry.txn_code,
          entry.rdfi_routing,
          entry.dda_account_mask,
          entry.amount_minor.toString(),
          entry.trace_number || null,
          entry.addenda || null,
          entry.idempotency_key
        ]);
        return result.rows[0].ach_entry_id;
      }
      async sealAchBatch(client5, achBatchId) {
        const entriesResult = await client5.query(`
      SELECT COUNT(*) as count, SUM(amount_minor) as total
      FROM ach_entry WHERE ach_batch_id = $1
    `, [achBatchId]);
        const { count: count3, total } = entriesResult.rows[0];
        const odfiRouting = "123456789";
        const entries = await client5.query(`
      SELECT ach_entry_id FROM ach_entry
      WHERE ach_batch_id = $1 AND trace_number IS NULL
      ORDER BY created_at
    `, [achBatchId]);
        for (let i = 0; i < entries.rows.length; i++) {
          const traceNumber = odfiRouting + String(i + 1).padStart(7, "0");
          await client5.query(`
        UPDATE ach_entry SET trace_number = $1
        WHERE ach_entry_id = $2
      `, [traceNumber, entries.rows[i].ach_entry_id]);
        }
        await client5.query(`
      UPDATE ach_batch 
      SET status = 'sealed',
          total_entries = $1,
          total_amount_minor = $2
      WHERE ach_batch_id = $3
    `, [count3, total || "0", achBatchId]);
      }
      async updateBatchStatus(client5, achBatchId, status) {
        await client5.query(`
      UPDATE ach_batch SET status = $1
      WHERE ach_batch_id = $2
    `, [status, achBatchId]);
      }
      // ACH Returns
      async recordAchReturn(client5, achReturn) {
        const result = await client5.query(`
      INSERT INTO ach_return (
        ach_entry_id, return_code, return_date,
        amount_minor, addenda, processed_at
      ) VALUES ($1, $2, $3, $4, $5, $6)
      ON CONFLICT (ach_entry_id) DO NOTHING
      RETURNING ach_return_id
    `, [
          achReturn.ach_entry_id,
          achReturn.return_code,
          achReturn.return_date,
          achReturn.amount_minor.toString(),
          achReturn.addenda || null,
          achReturn.processed_at || null
        ]);
        return result.rows[0]?.ach_return_id || null;
      }
      async findAchEntryByTrace(traceNumber) {
        const result = await this.pool.query(`
      SELECT * FROM ach_entry WHERE trace_number = $1
    `, [traceNumber]);
        if (result.rows.length === 0) return null;
        const row = result.rows[0];
        return {
          ...row,
          amount_minor: BigInt(row.amount_minor)
        };
      }
      // Bank Statement operations
      async ingestBankStatement(client5, file) {
        const fileHash = createHash11("sha256").update(file.raw_bytes).digest("hex");
        const result = await client5.query(`
      INSERT INTO bank_statement_file (
        bank_acct_id, format, as_of_date,
        raw_bytes, file_hash
      ) VALUES ($1, $2, $3, $4, $5)
      ON CONFLICT (bank_acct_id, as_of_date, file_hash) DO NOTHING
      RETURNING stmt_file_id
    `, [
          file.bank_acct_id,
          file.format,
          file.as_of_date,
          file.raw_bytes,
          fileHash
        ]);
        return result.rows[0]?.stmt_file_id || null;
      }
      async addBankTransaction(client5, txn) {
        const result = await client5.query(`
      INSERT INTO bank_txn (
        stmt_file_id, bank_acct_id, posted_date, value_date,
        amount_minor, type, bank_ref, description,
        matched, matched_event_id
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
      RETURNING bank_txn_id
    `, [
          txn.stmt_file_id,
          txn.bank_acct_id,
          txn.posted_date,
          txn.value_date || null,
          txn.amount_minor.toString(),
          txn.type,
          txn.bank_ref || null,
          txn.description || null,
          txn.matched,
          txn.matched_event_id || null
        ]);
        return result.rows[0].bank_txn_id;
      }
      async getUnmatchedTransactions(bankAcctId, startDate, endDate) {
        let query = `
      SELECT * FROM bank_txn 
      WHERE matched = false
    `;
        const params = [];
        let paramIndex = 1;
        if (bankAcctId) {
          query += ` AND bank_acct_id = $${paramIndex++}`;
          params.push(bankAcctId);
        }
        if (startDate) {
          query += ` AND posted_date >= $${paramIndex++}`;
          params.push(startDate);
        }
        if (endDate) {
          query += ` AND posted_date <= $${paramIndex++}`;
          params.push(endDate);
        }
        query += ` ORDER BY posted_date DESC`;
        const result = await this.pool.query(query, params);
        return result.rows.map((row) => ({
          ...row,
          amount_minor: BigInt(row.amount_minor)
        }));
      }
      // Reconciliation operations
      async addMatchCandidate(client5, candidate) {
        await client5.query(`
      INSERT INTO cash_match_candidate (
        bank_txn_id, event_id, score, reason
      ) VALUES ($1, $2, $3, $4)
    `, [
          candidate.bank_txn_id,
          candidate.event_id || null,
          candidate.score,
          candidate.reason
        ]);
      }
      async getTopMatchCandidate(bankTxnId) {
        const result = await this.pool.query(`
      SELECT * FROM cash_match_candidate
      WHERE bank_txn_id = $1
      ORDER BY score DESC
      LIMIT 1
    `, [bankTxnId]);
        return result.rows[0] || null;
      }
      async markTransactionMatched(client5, bankTxnId, eventId) {
        await client5.query(`
      UPDATE bank_txn 
      SET matched = true, matched_event_id = $1
      WHERE bank_txn_id = $2
    `, [eventId, bankTxnId]);
        await client5.query(`
      UPDATE recon_exception
      SET status = 'resolved'
      WHERE bank_txn_id = $1 AND status != 'resolved'
    `, [bankTxnId]);
      }
      async createReconException(client5, exception) {
        const result = await client5.query(`
      INSERT INTO recon_exception (
        bank_txn_id, variance_minor, status,
        assigned_to, note
      ) VALUES ($1, $2, $3, $4, $5)
      ON CONFLICT (bank_txn_id) 
      DO UPDATE SET
        variance_minor = EXCLUDED.variance_minor,
        status = CASE 
          WHEN recon_exception.status = 'resolved' THEN recon_exception.status
          ELSE EXCLUDED.status
        END,
        note = COALESCE(EXCLUDED.note, recon_exception.note)
      RETURNING recon_id
    `, [
          exception.bank_txn_id,
          exception.variance_minor.toString(),
          exception.status,
          exception.assigned_to || null,
          exception.note || null
        ]);
        return result.rows[0].recon_id;
      }
      async updateExceptionStatus(client5, reconId, status, note) {
        await client5.query(`
      UPDATE recon_exception 
      SET status = $1, note = COALESCE($2, note)
      WHERE recon_id = $3
    `, [status, note || null, reconId]);
      }
      async getOpenExceptions() {
        const result = await this.pool.query(`
      SELECT re.*, bt.posted_date, bt.amount_minor as txn_amount,
             bt.type, bt.description
      FROM recon_exception re
      JOIN bank_txn bt ON bt.bank_txn_id = re.bank_txn_id
      WHERE re.status IN ('new', 'investigating')
      ORDER BY re.created_at DESC
    `);
        return result.rows.map((row) => ({
          ...row,
          variance_minor: BigInt(row.variance_minor)
        }));
      }
    };
  }
});

// server/services/message-publisher.ts
import { randomUUID as randomUUID16 } from "crypto";
var MessagePublisher;
var init_message_publisher = __esm({
  "server/services/message-publisher.ts"() {
    "use strict";
    init_rabbitmq_unified();
    MessagePublisher = class {
      constructor(pool17) {
        this.pool = pool17;
      }
      rabbitmq = null;
      /**
       * Get or create RabbitMQ connection
       */
      async getRabbitMQ() {
        if (!this.rabbitmq) {
          this.rabbitmq = rabbitmqClient;
        }
        return this.rabbitmq;
      }
      /**
       * Publish a message to RabbitMQ
       */
      async publish(options) {
        try {
          const rabbitmq2 = await this.getRabbitMQ();
          const envelope = {
            message_id: randomUUID16(),
            correlation_id: options.correlationId || randomUUID16(),
            trace_id: randomUUID16(),
            schema: `${options.exchange}.${options.routingKey}`,
            timestamp: (/* @__PURE__ */ new Date()).toISOString(),
            source: "loanserve-pro",
            priority: options.priority || 0,
            payload: options.message
          };
          return await rabbitmq2.publish(envelope, {
            exchange: options.exchange,
            routingKey: options.routingKey,
            persistent: options.persistent !== false,
            mandatory: false,
            priority: options.priority || 0
          });
        } catch (error) {
          console.error(`[MessagePublisher] Failed to publish message:`, error);
          if (this.pool) {
            await this.storeInOutbox(options);
          }
          return false;
        }
      }
      /**
       * Store failed message in outbox for retry
       */
      async storeInOutbox(options) {
        try {
          await this.pool.query(`
        INSERT INTO outbox (
          exchange,
          routing_key,
          payload,
          correlation_id,
          priority,
          created_at,
          status,
          attempts
        ) VALUES ($1, $2, $3, $4, $5, NOW(), 'pending', 0)
      `, [
            options.exchange,
            options.routingKey,
            JSON.stringify(options.message),
            options.correlationId || randomUUID16(),
            options.priority || 0
          ]);
          console.log("[MessagePublisher] Stored message in outbox for retry");
        } catch (error) {
          console.error("[MessagePublisher] Failed to store message in outbox:", error);
        }
      }
      /**
       * Publish message for specific domain events
       */
      async publishEvent(domain, event, payload, correlationId) {
        return this.publish({
          exchange: `${domain}.topic`,
          routingKey: `${domain}.${event}`,
          message: payload,
          correlationId
        });
      }
    };
  }
});

// server/cash/ach-service.ts
var AchService;
var init_ach_service = __esm({
  "server/cash/ach-service.ts"() {
    "use strict";
    init_repo2();
    init_message_publisher();
    AchService = class {
      constructor(pool17) {
        this.pool = pool17;
        this.repo = new CashRepo(pool17);
        this.publisher = new MessagePublisher(pool17);
        this.companyId = "1234567890";
        this.companyName = "LOANSERVE PRO";
        this.odfiRouting = "123456789";
      }
      repo;
      publisher;
      companyId;
      companyName;
      odfiRouting;
      /**
       * Create a new ACH batch
       */
      async createBatch(bankAcctId, serviceClass, effectiveDate, createdBy) {
        return await this.repo.withTx(async (client5) => {
          const batchId = await this.repo.createAchBatch(client5, {
            bank_acct_id: bankAcctId,
            service_class: serviceClass,
            company_id: this.companyId,
            company_name: this.companyName,
            effective_entry_date: effectiveDate,
            created_by: createdBy,
            total_entries: 0,
            total_amount_minor: 0n,
            status: "open"
          });
          console.log(`[ACH] Created batch ${batchId}`);
          return batchId;
        });
      }
      /**
       * Add entry to an open batch
       */
      async addEntry(batchId, txnCode, routing, accountNumber, amount, loanId, addenda) {
        return await this.repo.withTx(async (client5) => {
          const batchResult = await client5.query(`
        SELECT status FROM ach_batch WHERE ach_batch_id = $1
      `, [batchId]);
          if (batchResult.rows[0]?.status !== "open") {
            throw new Error(`Batch ${batchId} is not open`);
          }
          const accountMask = accountNumber.slice(-4).padStart(accountNumber.length, "*");
          const idempotencyKey = `${batchId}:${routing}:${accountMask}:${amount}:${Date.now()}`;
          const entryId = await this.repo.addAchEntry(client5, {
            ach_batch_id: batchId,
            loan_id: loanId,
            txn_code: txnCode,
            rdfi_routing: routing,
            dda_account_mask: accountMask,
            amount_minor: BigInt(Math.round(amount * 100)),
            addenda,
            idempotency_key: idempotencyKey
          });
          console.log(`[ACH] Added entry ${entryId} to batch ${batchId}`);
          return entryId;
        });
      }
      /**
       * Seal batch and generate NACHA file
       */
      async generateNachaFile(request) {
        return await this.repo.withTx(async (client5) => {
          const { achBatchId } = request;
          await this.repo.sealAchBatch(client5, achBatchId);
          const batchResult = await client5.query(`
        SELECT * FROM ach_batch WHERE ach_batch_id = $1
      `, [achBatchId]);
          if (batchResult.rows.length === 0) {
            throw new Error(`Batch ${achBatchId} not found`);
          }
          const batch = batchResult.rows[0];
          const entriesResult = await client5.query(`
        SELECT * FROM ach_entry 
        WHERE ach_batch_id = $1
        ORDER BY created_at
      `, [achBatchId]);
          const entries = entriesResult.rows;
          const fileLines = [];
          const fileHeader = this.createFileHeader();
          fileLines.push(this.formatNachaRecord(fileHeader));
          const batchHeader = this.createBatchHeader(batch, 1);
          fileLines.push(this.formatNachaRecord(batchHeader));
          let entryCount = 0;
          let hashTotal = 0;
          let debitTotal = 0n;
          let creditTotal = 0n;
          for (const entry of entries) {
            const entryDetail = this.createEntryDetail(entry, ++entryCount);
            fileLines.push(this.formatNachaRecord(entryDetail));
            hashTotal += parseInt(entry.rdfi_routing.substring(0, 8));
            const amount = BigInt(entry.amount_minor);
            if (entry.txn_code === "27" || entry.txn_code === "37") {
              debitTotal += amount;
            } else {
              creditTotal += amount;
            }
          }
          const batchControl = this.createBatchControl(
            batch.service_class,
            entryCount,
            hashTotal,
            debitTotal,
            creditTotal,
            batch.company_id,
            1
          );
          fileLines.push(batchControl);
          const fileControl = this.createFileControl(
            1,
            // batch count
            entryCount,
            hashTotal,
            debitTotal,
            creditTotal
          );
          fileLines.push(fileControl);
          const totalRecords = fileLines.length;
          const blocksNeeded = Math.ceil(totalRecords / 10);
          const recordsToAdd = blocksNeeded * 10 - totalRecords;
          for (let i = 0; i < recordsToAdd; i++) {
            fileLines.push("9".repeat(94));
          }
          await this.repo.updateBatchStatus(client5, achBatchId, "filed");
          await this.publisher.publish({
            exchange: "cash.events",
            routingKey: "ach.file.created.v1",
            message: {
              ach_batch_id: achBatchId,
              entry_count: entryCount,
              total_amount_minor: (debitTotal + creditTotal).toString(),
              effective_date: batch.effective_entry_date
            },
            correlationId: `ach:file:${achBatchId}`
          });
          console.log(`[ACH] Generated NACHA file for batch ${achBatchId}`);
          return Buffer.from(fileLines.join("\n"));
        });
      }
      /**
       * Process ACH return
       */
      async processReturn(returnData) {
        await this.repo.withTx(async (client5) => {
          const entry = await this.repo.findAchEntryByTrace(returnData.traceNumber);
          if (!entry) {
            console.error(`[ACH] Entry not found for trace ${returnData.traceNumber}`);
            return;
          }
          const returnId = await this.repo.recordAchReturn(client5, {
            ach_entry_id: entry.ach_entry_id,
            return_code: returnData.returnCode,
            return_date: returnData.returnDate,
            amount_minor: returnData.amountMinor,
            addenda: returnData.addenda,
            processed_at: /* @__PURE__ */ new Date()
          });
          if (!returnId) {
            console.log(`[ACH] Return already recorded for entry ${entry.ach_entry_id}`);
            return;
          }
          await this.publisher.publish({
            exchange: "cash.events",
            routingKey: "ach.return.received.v1",
            message: {
              ach_return_id: returnId,
              ach_entry_id: entry.ach_entry_id,
              loan_id: entry.loan_id,
              return_code: returnData.returnCode,
              amount_minor: returnData.amountMinor.toString()
            },
            correlationId: `ach:return:${entry.ach_entry_id}`
          });
          if (entry.loan_id) {
            await this.publisher.publish({
              exchange: "payments.topic",
              routingKey: "payment.reversal.requested",
              message: {
                loan_id: entry.loan_id,
                reason: `ACH Return ${returnData.returnCode}`,
                amount_minor: returnData.amountMinor.toString(),
                ach_entry_id: entry.ach_entry_id
              },
              correlationId: `ach:return:reversal:${entry.ach_entry_id}`
            });
          }
          console.log(`[ACH] Processed return ${returnId} for entry ${entry.ach_entry_id}`);
        });
      }
      // NACHA format helpers
      createFileHeader() {
        const now = /* @__PURE__ */ new Date();
        return {
          recordType: "1",
          priorityCode: "01",
          immediateDestination: ` ${this.odfiRouting}`,
          immediateOrigin: ` ${this.companyId}`,
          fileCreationDate: this.formatDate(now),
          fileCreationTime: this.formatTime(now),
          fileIdModifier: "A",
          recordSize: "094",
          blockingFactor: "10",
          formatCode: "1",
          immediateDestinationName: "BANK NAME".padEnd(23),
          immediateOriginName: this.companyName.padEnd(23),
          referenceCode: "".padEnd(8)
        };
      }
      createBatchHeader(batch, batchNumber) {
        return {
          recordType: "5",
          serviceClassCode: batch.service_class,
          companyName: batch.company_name.padEnd(16),
          companyDiscretionaryData: "".padEnd(20),
          companyId: batch.company_id,
          standardEntryClass: "PPD",
          companyEntryDescription: "LOAN PMT".padEnd(10),
          companyDescriptiveDate: "".padEnd(6),
          effectiveEntryDate: this.formatDateCompact(new Date(batch.effective_entry_date)),
          settlementDate: "   ",
          originatorStatusCode: "1",
          originatingDfiId: this.odfiRouting.substring(0, 8),
          batchNumber: String(batchNumber).padStart(7, "0")
        };
      }
      createEntryDetail(entry, sequence) {
        const amount = Math.round(Number(entry.amount_minor) / 100);
        return {
          recordType: "6",
          transactionCode: entry.txn_code,
          receivingDfiId: entry.rdfi_routing.substring(0, 8),
          checkDigit: this.calculateCheckDigit(entry.rdfi_routing),
          dfiAccountNumber: entry.dda_account_mask.padEnd(17),
          amount: String(amount).padStart(10, "0"),
          individualIdNumber: (entry.loan_id || "").toString().padEnd(15),
          individualName: "BORROWER".padEnd(22),
          discretionaryData: "  ",
          addendaRecordIndicator: "0",
          traceNumber: entry.trace_number || ""
        };
      }
      createBatchControl(serviceClass, entryCount, hashTotal, debitTotal, creditTotal, companyId, batchNumber) {
        const debitAmount = Math.round(Number(debitTotal) / 100);
        const creditAmount = Math.round(Number(creditTotal) / 100);
        return [
          "8",
          serviceClass,
          String(entryCount).padStart(6, "0"),
          String(hashTotal).padStart(10, "0").slice(-10),
          String(debitAmount).padStart(12, "0"),
          String(creditAmount).padStart(12, "0"),
          companyId,
          "".padEnd(25),
          this.odfiRouting.substring(0, 8),
          String(batchNumber).padStart(7, "0")
        ].join("");
      }
      createFileControl(batchCount, entryCount, hashTotal, debitTotal, creditTotal) {
        const debitAmount = Math.round(Number(debitTotal) / 100);
        const creditAmount = Math.round(Number(creditTotal) / 100);
        return [
          "9",
          String(batchCount).padStart(6, "0"),
          String(entryCount).padStart(8, "0"),
          String(entryCount).padStart(8, "0"),
          String(hashTotal).padStart(10, "0").slice(-10),
          String(debitAmount).padStart(12, "0"),
          String(creditAmount).padStart(12, "0"),
          "".padEnd(39)
        ].join("");
      }
      formatNachaRecord(record) {
        if (typeof record === "string") return record;
        return Object.values(record).join("");
      }
      formatDate(date2) {
        return date2.toISOString().slice(2, 10).replace(/-/g, "");
      }
      formatDateCompact(date2) {
        return date2.toISOString().slice(2, 10).replace(/-/g, "");
      }
      formatTime(date2) {
        return date2.toISOString().slice(11, 16).replace(/:/g, "");
      }
      calculateCheckDigit(routing) {
        return routing.charAt(8) || "0";
      }
    };
  }
});

// server/cash/statement-parser.ts
var StatementParser;
var init_statement_parser = __esm({
  "server/cash/statement-parser.ts"() {
    "use strict";
    StatementParser = class {
      /**
       * Parse bank statement based on format
       */
      async parseStatement(rawBytes, format2, bankAcctId) {
        switch (format2) {
          case "bai2":
            return this.parseBAI2(rawBytes.toString("utf-8"), bankAcctId);
          case "camt.053":
            return this.parseCAMT053(rawBytes.toString("utf-8"), bankAcctId);
          default:
            throw new Error(`Unsupported format: ${format2}`);
        }
      }
      /**
       * Parse BAI2 format statement
       */
      parseBAI2(content, bankAcctId) {
        const transactions = [];
        const lines = content.split(/\r?\n/);
        let currentAccount = "";
        let currentDate = "";
        for (const line of lines) {
          if (!line.trim()) continue;
          const recordCode = line.substring(0, 2);
          switch (recordCode) {
            case "01":
              break;
            case "02":
              break;
            case "03":
              const parts = line.split(",");
              currentAccount = parts[1] || "";
              break;
            case "16":
              const txnParts = line.split(",");
              if (txnParts.length >= 5) {
                const typeCode = txnParts[1];
                const amount = parseFloat(txnParts[2]) / 100;
                const reference = txnParts[3];
                const description = txnParts[4];
                const date2 = txnParts[5] || currentDate;
                transactions.push({
                  bankAcctId,
                  postedDate: this.formatBAI2Date(date2),
                  amountMinor: BigInt(Math.round(Math.abs(amount) * 100)),
                  type: this.mapBAI2TypeCode(typeCode),
                  bankRef: reference,
                  description
                });
              }
              break;
            case "88":
              break;
            case "49":
              break;
            case "98":
              break;
            case "99":
              break;
          }
        }
        return transactions;
      }
      /**
       * Parse CAMT.053 XML format statement
       */
      parseCAMT053(content, bankAcctId) {
        const transactions = [];
        const entries = content.match(/<Ntry>.*?<\/Ntry>/gs) || [];
        for (const entry of entries) {
          const amount = this.extractXMLValue(entry, "Amt");
          const creditDebit = this.extractXMLValue(entry, "CdtDbtInd");
          const bookingDate = this.extractXMLValue(entry, "BookgDt");
          const valueDate = this.extractXMLValue(entry, "ValDt");
          const reference = this.extractXMLValue(entry, "AcctSvcrRef");
          const description = this.extractXMLValue(entry, "AddtlNtryInf");
          if (amount && creditDebit && bookingDate) {
            transactions.push({
              bankAcctId,
              postedDate: this.formatCAMTDate(bookingDate),
              valueDate: valueDate ? this.formatCAMTDate(valueDate) : void 0,
              amountMinor: BigInt(Math.round(parseFloat(amount) * 100)),
              type: creditDebit === "CRDT" ? "credit" : "debit",
              bankRef: reference,
              description
            });
          }
        }
        return transactions;
      }
      /**
       * Map BAI2 type codes to transaction types
       */
      mapBAI2TypeCode(code) {
        const firstChar = code.charAt(0);
        switch (firstChar) {
          case "1":
          // Credits
          case "2":
            return "credit";
          case "4":
          // Debits
          case "5":
            return "debit";
          case "6":
            return "fee";
          case "7":
            return "return";
          default:
            return "credit";
        }
      }
      /**
       * Format BAI2 date (YYMMDD or YYYYMMDD)
       */
      formatBAI2Date(dateStr) {
        if (!dateStr) return (/* @__PURE__ */ new Date()).toISOString().split("T")[0];
        if (dateStr.length === 6) {
          const year = parseInt(dateStr.substring(0, 2));
          const fullYear = year < 50 ? 2e3 + year : 1900 + year;
          const month = dateStr.substring(2, 4);
          const day = dateStr.substring(4, 6);
          return `${fullYear}-${month}-${day}`;
        } else if (dateStr.length === 8) {
          const year = dateStr.substring(0, 4);
          const month = dateStr.substring(4, 6);
          const day = dateStr.substring(6, 8);
          return `${year}-${month}-${day}`;
        }
        return (/* @__PURE__ */ new Date()).toISOString().split("T")[0];
      }
      /**
       * Format CAMT date (YYYY-MM-DD)
       */
      formatCAMTDate(dateStr) {
        return dateStr.split("T")[0];
      }
      /**
       * Extract value from XML
       */
      extractXMLValue(xml, tag) {
        const regex = new RegExp(`<${tag}[^>]*>(.*?)</${tag}>`, "s");
        const match = xml.match(regex);
        return match ? match[1].trim() : "";
      }
    };
  }
});

// server/cash/reconciliation-service.ts
var ReconciliationService;
var init_reconciliation_service = __esm({
  "server/cash/reconciliation-service.ts"() {
    "use strict";
    init_repo2();
    init_statement_parser();
    init_message_publisher();
    init_ledger_repository();
    init_posting();
    ReconciliationService = class {
      constructor(pool17) {
        this.pool = pool17;
        this.repo = new CashRepo(pool17);
        this.parser = new StatementParser();
        this.publisher = new MessagePublisher(pool17);
        this.ledgerRepo = new PgLedgerRepository(pool17);
      }
      repo;
      parser;
      publisher;
      ledgerRepo;
      matchThreshold = 85;
      dateWindowDays = 3;
      /**
       * Ingest bank statement file
       */
      async ingestStatement(bankAcctId, format2, asOfDate, rawBytes) {
        await this.repo.withTx(async (client5) => {
          const stmtFileId = await this.repo.ingestBankStatement(client5, {
            bank_acct_id: bankAcctId,
            format: format2,
            as_of_date: asOfDate,
            raw_bytes: rawBytes,
            file_hash: ""
            // Hash is calculated in repo
          });
          if (!stmtFileId) {
            console.log(`[Reconciliation] Statement already ingested for ${asOfDate}`);
            return;
          }
          const transactions = await this.parser.parseStatement(rawBytes, format2, bankAcctId);
          for (const txn of transactions) {
            const bankTxnId = await this.repo.addBankTransaction(client5, {
              stmt_file_id: stmtFileId,
              bank_acct_id: bankAcctId,
              posted_date: txn.postedDate,
              value_date: txn.valueDate,
              amount_minor: txn.amountMinor,
              type: txn.type,
              bank_ref: txn.bankRef,
              description: txn.description,
              matched: false,
              matched_event_id: void 0
            });
            await this.generateMatchCandidates(client5, bankTxnId, txn);
          }
          await this.publisher.publish({
            exchange: "cash.events",
            routingKey: "cash.stmt.ingested.v1",
            message: {
              stmt_file_id: stmtFileId,
              bank_acct_id: bankAcctId,
              format: format2,
              transaction_count: transactions.length
            },
            correlationId: `stmt:ingest:${stmtFileId}`
          });
          console.log(`[Reconciliation] Ingested ${transactions.length} transactions from statement`);
        });
        await this.autoMatchTransactions(bankAcctId);
      }
      /**
       * Generate match candidates for a bank transaction
       */
      async generateMatchCandidates(client5, bankTxnId, txn) {
        const bankAccount = await this.repo.getBankAccount(txn.bank_acct_id || txn.bankAcctId);
        if (!bankAccount) return;
        const glAccount = bankAccount.gl_cash_account;
        const startDate = new Date(txn.postedDate);
        const endDate = new Date(txn.postedDate);
        startDate.setDate(startDate.getDate() - this.dateWindowDays);
        endDate.setDate(endDate.getDate() + this.dateWindowDays);
        const eventsResult = await client5.query(`
      SELECT DISTINCT
        le.event_id,
        le.correlation_id,
        le.event_date,
        le.memo,
        SUM(CASE 
          WHEN len.account = $1 AND len.debit_minor > 0 THEN len.debit_minor
          WHEN len.account = $1 AND len.credit_minor > 0 THEN -len.credit_minor
          ELSE 0
        END) as net_amount
      FROM ledger_event le
      JOIN ledger_entry len ON len.event_id = le.event_id
      WHERE le.event_date BETWEEN $2 AND $3
        AND len.account = $1
      GROUP BY le.event_id, le.correlation_id, le.event_date, le.memo
      HAVING SUM(CASE 
        WHEN len.account = $1 AND len.debit_minor > 0 THEN len.debit_minor
        WHEN len.account = $1 AND len.credit_minor > 0 THEN -len.credit_minor
        ELSE 0
      END) != 0
      ORDER BY le.event_date DESC
      LIMIT 20
    `, [glAccount, startDate.toISOString(), endDate.toISOString()]);
        const candidates = [];
        for (const event of eventsResult.rows) {
          let score = 0;
          const reasons = [];
          const eventAmount = BigInt(event.net_amount);
          const txnAmount = BigInt(txn.amount_minor || txn.amountMinor);
          const expectedAmount = txn.type === "credit" ? txnAmount : -txnAmount;
          if (eventAmount === expectedAmount) {
            score += 60;
            reasons.push("Amount exact match");
          } else {
            const diff = Math.abs(Number(eventAmount - expectedAmount));
            const pct = diff / Number(txnAmount);
            if (pct < 0.01) {
              score += 50;
              reasons.push("Amount within 1%");
            } else if (pct < 0.05) {
              score += 30;
              reasons.push("Amount within 5%");
            }
          }
          const daysDiff = Math.abs(
            (new Date(event.event_date).getTime() - new Date(txn.postedDate).getTime()) / (1e3 * 60 * 60 * 24)
          );
          if (daysDiff === 0) {
            score += 30;
            reasons.push("Same day");
          } else if (daysDiff <= 1) {
            score += 25;
            reasons.push("Within 1 day");
          } else if (daysDiff <= 3) {
            score += 10;
            reasons.push("Within 3 days");
          }
          if (txn.bank_ref || txn.bankRef) {
            const ref = (txn.bank_ref || txn.bankRef).toLowerCase();
            if (event.correlation_id && event.correlation_id.toLowerCase().includes(ref)) {
              score += 15;
              reasons.push("Reference match in correlation ID");
            }
            if (event.memo && event.memo.toLowerCase().includes(ref)) {
              score += 10;
              reasons.push("Reference match in memo");
            }
          }
          if (txn.description && event.correlation_id) {
            if (txn.description.toLowerCase().includes(event.correlation_id.toLowerCase())) {
              score += 100;
              reasons.push("Correlation ID found in description");
            }
          }
          if (score > 0) {
            candidates.push({
              eventId: event.event_id,
              score,
              reason: reasons.join(", ")
            });
          }
        }
        candidates.sort((a, b) => b.score - a.score);
        for (const candidate of candidates.slice(0, 3)) {
          await this.repo.addMatchCandidate(client5, {
            bank_txn_id: bankTxnId,
            event_id: candidate.eventId,
            score: candidate.score,
            reason: candidate.reason
          });
        }
      }
      /**
       * Auto-match transactions
       */
      async autoMatchTransactions(bankAcctId) {
        const unmatchedTxns = await this.repo.getUnmatchedTransactions(bankAcctId);
        let matchedCount = 0;
        for (const txn of unmatchedTxns) {
          const topCandidate = await this.repo.getTopMatchCandidate(txn.bank_txn_id);
          if (topCandidate && topCandidate.score >= this.matchThreshold) {
            await this.repo.withTx(async (client5) => {
              await this.repo.markTransactionMatched(
                client5,
                txn.bank_txn_id,
                topCandidate.event_id
              );
              await this.publisher.publish({
                exchange: "cash.events",
                routingKey: "cash.reconciled.v1",
                message: {
                  bank_txn_id: txn.bank_txn_id,
                  event_id: topCandidate.event_id,
                  score: topCandidate.score,
                  auto_matched: true
                },
                correlationId: `recon:auto:${txn.bank_txn_id}`
              });
            });
            matchedCount++;
            console.log(`[Reconciliation] Auto-matched transaction ${txn.bank_txn_id} with score ${topCandidate.score}`);
          } else {
            const variance = topCandidate?.event_id ? await this.calculateVariance(txn.bank_txn_id, topCandidate.event_id) : txn.amount_minor;
            await this.repo.withTx(async (client5) => {
              await this.repo.createReconException(client5, {
                bank_txn_id: txn.bank_txn_id,
                variance_minor: variance,
                status: "new",
                note: topCandidate ? `Best match score: ${topCandidate.score}` : "No matching candidates found"
              });
            });
            console.log(`[Reconciliation] Created exception for transaction ${txn.bank_txn_id}`);
          }
        }
        console.log(`[Reconciliation] Auto-matched ${matchedCount} of ${unmatchedTxns.length} transactions`);
        return matchedCount;
      }
      /**
       * Manual match
       */
      async manualMatch(bankTxnId, eventId) {
        await this.repo.withTx(async (client5) => {
          await this.repo.markTransactionMatched(client5, bankTxnId, eventId);
          await this.publisher.publish({
            exchange: "cash.events",
            routingKey: "cash.reconciled.v1",
            message: {
              bank_txn_id: bankTxnId,
              event_id: eventId,
              auto_matched: false
            },
            correlationId: `recon:manual:${bankTxnId}`
          });
        });
        console.log(`[Reconciliation] Manually matched transaction ${bankTxnId} to event ${eventId}`);
      }
      /**
       * Write off exception
       */
      async writeOff(reconId, reason) {
        await this.repo.withTx(async (client5) => {
          const exceptionResult = await client5.query(`
        SELECT re.*, bt.amount_minor, bt.type, bt.bank_acct_id
        FROM recon_exception re
        JOIN bank_txn bt ON bt.bank_txn_id = re.bank_txn_id
        WHERE re.recon_id = $1
      `, [reconId]);
          if (exceptionResult.rows.length === 0) {
            throw new Error(`Exception ${reconId} not found`);
          }
          const exception = exceptionResult.rows[0];
          const bankAccount = await this.repo.getBankAccount(exception.bank_acct_id);
          if (!bankAccount) {
            throw new Error(`Bank account ${exception.bank_acct_id} not found`);
          }
          const correlationId = `writeoff:${exception.bank_txn_id}`;
          const amount = BigInt(exception.amount_minor);
          if (exception.type === "fee") {
            await postEvent(this.ledgerRepo, {
              loanId: 0,
              // System transaction
              effectiveDate: (/* @__PURE__ */ new Date()).toISOString().split("T")[0],
              correlationId,
              schema: "posting.bank_fee.v1",
              currency: "USD",
              lines: [
                {
                  account: "fee_expense",
                  debitMinor: amount,
                  memo: `Bank fee: ${reason}`
                },
                {
                  account: bankAccount.gl_cash_account,
                  creditMinor: amount,
                  memo: `Bank fee writeoff`
                }
              ]
            });
          }
          await this.repo.updateExceptionStatus(client5, reconId, "written_off", reason);
          await this.repo.markTransactionMatched(client5, exception.bank_txn_id, correlationId);
        });
        console.log(`[Reconciliation] Written off exception ${reconId}: ${reason}`);
      }
      async calculateVariance(bankTxnId, eventId) {
        const txnResult = await this.pool.query(`
      SELECT amount_minor FROM bank_txn WHERE bank_txn_id = $1
    `, [bankTxnId]);
        const eventResult = await this.pool.query(`
      SELECT SUM(debit_minor - credit_minor) as net_amount
      FROM ledger_entry WHERE event_id = $1
    `, [eventId]);
        const bankAmount = BigInt(txnResult.rows[0]?.amount_minor || 0);
        const eventAmount = BigInt(eventResult.rows[0]?.net_amount || 0);
        return bankAmount - eventAmount;
      }
    };
  }
});

// server/cash/routes.ts
var routes_exports3 = {};
__export(routes_exports3, {
  registerCashRoutes: () => registerCashRoutes
});
import { z as z16 } from "zod";
function registerCashRoutes(router41, pool17) {
  const repo2 = new CashRepo(pool17);
  const achService = new AchService(pool17);
  const reconService = new ReconciliationService(pool17);
  router41.post("/api/cash/bank-accounts", async (req, res) => {
    try {
      const data = CreateBankAccountSchema.parse(req.body);
      const bankAcctId = await repo2.withTx(async (client5) => {
        return await repo2.createBankAccount(client5, {
          ...data,
          active: true
        });
      });
      res.json({ bank_acct_id: bankAcctId });
    } catch (error) {
      console.error("[Cash] Error creating bank account:", error);
      res.status(400).json({
        error: error instanceof Error ? error.message : "Invalid request"
      });
    }
  });
  router41.get("/api/cash/bank-accounts/:id", async (req, res) => {
    try {
      const account = await repo2.getBankAccount(req.params.id);
      if (!account) {
        return res.status(404).json({ error: "Bank account not found" });
      }
      res.json(account);
    } catch (error) {
      console.error("[Cash] Error fetching bank account:", error);
      res.status(500).json({ error: "Internal server error" });
    }
  });
  router41.post("/api/cash/ach/batches", async (req, res) => {
    try {
      const data = CreateAchBatchSchema.parse(req.body);
      const batchId = await achService.createBatch(
        data.bank_acct_id,
        data.service_class,
        data.effective_date,
        data.created_by
      );
      res.json({ ach_batch_id: batchId });
    } catch (error) {
      console.error("[Cash] Error creating ACH batch:", error);
      res.status(400).json({
        error: error instanceof Error ? error.message : "Invalid request"
      });
    }
  });
  router41.post("/api/cash/ach/entries", async (req, res) => {
    try {
      const data = AddAchEntrySchema.parse(req.body);
      const entryId = await achService.addEntry(
        data.batch_id,
        data.txn_code,
        data.routing,
        data.account_number,
        data.amount,
        data.loan_id,
        data.addenda
      );
      res.json({ ach_entry_id: entryId });
    } catch (error) {
      console.error("[Cash] Error adding ACH entry:", error);
      res.status(400).json({
        error: error instanceof Error ? error.message : "Invalid request"
      });
    }
  });
  router41.post("/api/cash/ach/batches/:id/seal", async (req, res) => {
    try {
      const fileBuffer = await achService.generateNachaFile({
        achBatchId: req.params.id
      });
      res.setHeader("Content-Type", "text/plain");
      res.setHeader("Content-Disposition", `attachment; filename="ach_batch_${req.params.id}.txt"`);
      res.send(fileBuffer);
    } catch (error) {
      console.error("[Cash] Error sealing ACH batch:", error);
      res.status(500).json({ error: "Failed to generate NACHA file" });
    }
  });
  router41.post("/api/cash/ach/returns", async (req, res) => {
    try {
      const { traceNumber, returnCode, returnDate, amount } = req.body;
      await achService.processReturn({
        traceNumber,
        returnCode,
        returnDate,
        amountMinor: BigInt(Math.round(amount * 100)),
        addenda: req.body.addenda
      });
      res.json({ success: true });
    } catch (error) {
      console.error("[Cash] Error processing ACH return:", error);
      res.status(500).json({ error: "Failed to process return" });
    }
  });
  router41.post("/api/cash/statements", async (req, res) => {
    try {
      const data = IngestStatementSchema.parse(req.body);
      const rawBytes = Buffer.from(data.file_base64, "base64");
      await reconService.ingestStatement(
        data.bank_acct_id,
        data.format,
        data.as_of_date,
        rawBytes
      );
      res.json({ success: true });
    } catch (error) {
      console.error("[Cash] Error ingesting statement:", error);
      res.status(400).json({
        error: error instanceof Error ? error.message : "Invalid statement"
      });
    }
  });
  router41.get("/api/cash/reconciliation/unmatched", async (req, res) => {
    try {
      const transactions = await repo2.getUnmatchedTransactions(
        req.query.bank_acct_id,
        req.query.start_date,
        req.query.end_date
      );
      res.json(transactions);
    } catch (error) {
      console.error("[Cash] Error fetching unmatched transactions:", error);
      res.status(500).json({ error: "Internal server error" });
    }
  });
  router41.get("/api/cash/reconciliation/exceptions", async (req, res) => {
    try {
      const exceptions = await repo2.getOpenExceptions();
      res.json(exceptions);
    } catch (error) {
      console.error("[Cash] Error fetching exceptions:", error);
      res.status(500).json({ error: "Internal server error" });
    }
  });
  router41.post("/api/cash/reconciliation/match", async (req, res) => {
    try {
      const data = ManualMatchSchema.parse(req.body);
      await reconService.manualMatch(data.bank_txn_id, data.event_id);
      res.json({ success: true });
    } catch (error) {
      console.error("[Cash] Error matching transaction:", error);
      res.status(400).json({
        error: error instanceof Error ? error.message : "Match failed"
      });
    }
  });
  router41.post("/api/cash/reconciliation/writeoff", async (req, res) => {
    try {
      const data = WriteOffSchema.parse(req.body);
      await reconService.writeOff(data.recon_id, data.reason);
      res.json({ success: true });
    } catch (error) {
      console.error("[Cash] Error writing off exception:", error);
      res.status(400).json({
        error: error instanceof Error ? error.message : "Write-off failed"
      });
    }
  });
  router41.post("/api/cash/reconciliation/auto-match", async (req, res) => {
    try {
      const bankAcctId = req.body.bank_acct_id;
      const matchedCount = await reconService.autoMatchTransactions(bankAcctId);
      res.json({
        matched_count: matchedCount,
        success: true
      });
    } catch (error) {
      console.error("[Cash] Error auto-matching:", error);
      res.status(500).json({ error: "Auto-match failed" });
    }
  });
  console.log("[Routes] Registered cash management routes");
}
var CreateBankAccountSchema, CreateAchBatchSchema, AddAchEntrySchema, IngestStatementSchema, ManualMatchSchema, WriteOffSchema;
var init_routes3 = __esm({
  "server/cash/routes.ts"() {
    "use strict";
    init_repo2();
    init_ach_service();
    init_reconciliation_service();
    CreateBankAccountSchema = z16.object({
      name: z16.string(),
      bank_id: z16.string(),
      account_number_mask: z16.string(),
      currency: z16.string().default("USD"),
      type: z16.enum(["operating", "custodial_p_i", "escrow", "fees"]),
      gl_cash_account: z16.string().default("cash")
    });
    CreateAchBatchSchema = z16.object({
      bank_acct_id: z16.string().uuid(),
      service_class: z16.enum(["200", "220", "225"]),
      effective_date: z16.string(),
      created_by: z16.string()
    });
    AddAchEntrySchema = z16.object({
      batch_id: z16.string().uuid(),
      txn_code: z16.enum(["22", "27", "32", "37"]),
      routing: z16.string().regex(/^\d{9}$/),
      account_number: z16.string(),
      amount: z16.number().positive(),
      loan_id: z16.number().optional(),
      addenda: z16.string().optional()
    });
    IngestStatementSchema = z16.object({
      bank_acct_id: z16.string().uuid(),
      format: z16.enum(["bai2", "camt.053"]),
      as_of_date: z16.string(),
      file_base64: z16.string()
    });
    ManualMatchSchema = z16.object({
      bank_txn_id: z16.string().uuid(),
      event_id: z16.string().uuid()
    });
    WriteOffSchema = z16.object({
      recon_id: z16.string().uuid(),
      reason: z16.string()
    });
  }
});

// server/remittance/repo.ts
import { ulid as ulid5 } from "ulid";
import { createHash as createHash12 } from "crypto";
var RemittanceRepository;
var init_repo3 = __esm({
  "server/remittance/repo.ts"() {
    "use strict";
    RemittanceRepository = class {
      constructor(pool17, ledgerRepo) {
        this.pool = pool17;
        this.ledgerRepo = ledgerRepo;
      }
      // Contract management
      async createContract(contract) {
        const contractId = ulid5();
        const result = await this.pool.query(
          `INSERT INTO investor_contract 
       (contract_id, investor_id, product_code, method, remittance_day, cutoff_day,
        custodial_bank_acct_id, servicer_fee_bps, late_fee_split_bps)
       VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
       RETURNING *`,
          [
            contractId,
            contract.investor_id,
            contract.product_code,
            contract.method,
            contract.remittance_day,
            contract.cutoff_day,
            contract.custodial_bank_acct_id,
            contract.servicer_fee_bps,
            contract.late_fee_split_bps
          ]
        );
        return result.rows[0];
      }
      async getContract(contractId) {
        const result = await this.pool.query(
          "SELECT * FROM investor_contract WHERE contract_id = $1",
          [contractId]
        );
        return result.rows[0] || null;
      }
      async getContractsByInvestor(investorId) {
        const result = await this.pool.query(
          "SELECT * FROM investor_contract WHERE investor_id = $1",
          [investorId]
        );
        return result.rows;
      }
      // Waterfall rules
      async createWaterfallRule(rule) {
        const ruleId = ulid5();
        const result = await this.pool.query(
          `INSERT INTO investor_waterfall_rule 
       (rule_id, contract_id, rank, bucket, cap_minor)
       VALUES ($1, $2, $3, $4, $5)
       RETURNING *`,
          [ruleId, rule.contract_id, rule.rank, rule.bucket, rule.cap_minor || null]
        );
        return result.rows[0];
      }
      async getWaterfallRules(contractId) {
        const result = await this.pool.query(
          "SELECT * FROM investor_waterfall_rule WHERE contract_id = $1 ORDER BY rank",
          [contractId]
        );
        return result.rows;
      }
      // Remittance cycles
      async createCycle(cycle) {
        const cycleId = ulid5();
        const result = await this.pool.query(
          `INSERT INTO remittance_cycle 
       (cycle_id, contract_id, period_start, period_end, status)
       VALUES ($1, $2, $3, $4, $5)
       RETURNING *`,
          [cycleId, cycle.contractId, cycle.periodStart, cycle.periodEnd, "open"]
        );
        return result.rows[0];
      }
      async getCycle(cycleId) {
        const result = await this.pool.query(
          "SELECT * FROM remittance_cycle WHERE cycle_id = $1",
          [cycleId]
        );
        return result.rows[0] || null;
      }
      async getCurrentCycle(contractId) {
        const result = await this.pool.query(
          `SELECT * FROM remittance_cycle 
       WHERE contract_id = $1 AND status IN ('open', 'locked')
       ORDER BY period_start DESC
       LIMIT 1`,
          [contractId]
        );
        return result.rows[0] || null;
      }
      async updateCycleStatus(cycleId, status) {
        await this.pool.query(
          "UPDATE remittance_cycle SET status = $1 WHERE cycle_id = $2",
          [status, cycleId]
        );
      }
      async updateCycleTotals(cycleId, totals) {
        await this.pool.query(
          `UPDATE remittance_cycle 
       SET total_principal_minor = $1,
           total_interest_minor = $2,
           total_fees_minor = $3,
           servicer_fee_minor = $4,
           investor_due_minor = $5
       WHERE cycle_id = $6`,
          [
            totals.principal,
            totals.interest,
            totals.fees,
            totals.servicerFee,
            totals.investorDue,
            cycleId
          ]
        );
      }
      // Remittance items
      async createItem(item) {
        const result = await this.pool.query(
          `INSERT INTO remittance_item 
       (cycle_id, loan_id, principal_minor, interest_minor, 
        fees_minor, investor_share_minor, servicer_fee_minor)
       VALUES ($1, $2, $3, $4, $5, $6, $7)
       RETURNING *`,
          [
            item.cycle_id,
            item.loan_id || null,
            item.principal_minor,
            item.interest_minor,
            item.fees_minor,
            item.investor_share_minor,
            item.servicer_fee_minor
          ]
        );
        return result.rows[0];
      }
      async getItems(cycleId) {
        const result = await this.pool.query(
          "SELECT * FROM remittance_item WHERE cycle_id = $1",
          [cycleId]
        );
        return result.rows;
      }
      // Export management
      async createExport(cycleId, format2, data) {
        const hash = createHash12("sha256").update(data).digest("hex");
        const result = await this.pool.query(
          `INSERT INTO remittance_export 
       (cycle_id, format, file_hash, bytes)
       VALUES ($1, $2, $3, $4)
       RETURNING *`,
          [cycleId, format2, hash, data]
        );
        return result.rows[0];
      }
      async getExport(exportId) {
        const result = await this.pool.query(
          "SELECT * FROM remittance_export WHERE export_id = $1",
          [exportId]
        );
        return result.rows[0] || null;
      }
      // Loan collections for period from payment_posting
      async getLoanCollections(contractId, periodStart, periodEnd, custodialBankAcctId) {
        const query = `
      WITH contract_loans AS (
        SELECT DISTINCT 
          l.id as loan_id, 
          l.loan_number, 
          l.principal_balance
        FROM loans l
        JOIN investors io ON l.id = io.loan_id
        JOIN investor_contract ic ON io.investor_id = ic.investor_id
        WHERE ic.contract_id = $1
      )
      SELECT 
        cl.loan_id,
        cl.loan_number,
        cl.principal_balance,
        COALESCE(SUM((pp.applied->>'principal_collected')::numeric), 0) as principal_collected,
        COALESCE(SUM((pp.applied->>'interest_collected')::numeric), 0) as interest_collected,
        COALESCE(SUM((pp.applied->>'late_fees_collected')::numeric), 0) as late_fees_collected,
        COALESCE(SUM((pp.applied->>'escrow_collected')::numeric), 0) as escrow_collected
      FROM contract_loans cl
      LEFT JOIN payment_intake pi ON cl.loan_id = pi.loan_id
      LEFT JOIN payment_posting pp ON pi.payment_id = pp.payment_id
      WHERE (pi.effective_date >= $2 AND pi.effective_date <= $3)
        OR pi.payment_id IS NULL
      GROUP BY cl.loan_id, cl.loan_number, cl.principal_balance`;
        const result = await this.pool.query(query, [contractId, periodStart, periodEnd]);
        return result.rows;
      }
      // Process remittance settlement with proper ledger entries
      async processRemittanceSettlement(cycleId) {
        const cycle = await this.getCycle(cycleId);
        if (!cycle || cycle.status !== "locked") {
          throw new Error("Cycle must be locked before processing");
        }
        const contract = await this.getContract(cycle.contract_id);
        if (!contract) {
          throw new Error("Contract not found");
        }
        await this.updateCycleStatus(cycleId, "settled");
      }
    };
  }
});

// server/remittance/service.ts
var service_exports = {};
__export(service_exports, {
  RemittanceService: () => RemittanceService
});
import { format as formatDate, startOfMonth, endOfMonth, addMonths, isBefore } from "date-fns";
import { Parser } from "json2csv";
var RemittanceService;
var init_service2 = __esm({
  "server/remittance/service.ts"() {
    "use strict";
    init_repo3();
    RemittanceService = class {
      constructor(pool17, ledgerRepo) {
        this.pool = pool17;
        this.ledgerRepo = ledgerRepo;
        this.repo = new RemittanceRepository(pool17, ledgerRepo);
      }
      repo;
      // Contract management
      async createContract(data) {
        const contract = await this.repo.createContract({
          investor_id: data.investorId,
          product_code: data.productCode,
          method: data.method,
          remittance_day: data.remittanceDay,
          cutoff_day: data.cutoffDay,
          custodial_bank_acct_id: data.custodialBankAcctId,
          servicer_fee_bps: data.servicerFeeBps,
          late_fee_split_bps: data.lateFeeSpiltBps
        });
        for (const rule of data.waterfallRules) {
          await this.repo.createWaterfallRule({
            contract_id: contract.contract_id,
            rank: rule.rank,
            bucket: rule.bucket,
            cap_minor: rule.capMinor
          });
        }
        return contract;
      }
      // Cycle management
      async initiateCycle(contractId) {
        const contract = await this.repo.getContract(contractId);
        if (!contract) {
          throw new Error("Contract not found");
        }
        const existingCycle = await this.repo.getCurrentCycle(contractId);
        if (existingCycle && existingCycle.status === "open") {
          throw new Error("An open cycle already exists");
        }
        const now = /* @__PURE__ */ new Date();
        const cutoffDate = new Date(now.getFullYear(), now.getMonth(), contract.cutoff_day);
        let periodStart;
        let periodEnd;
        if (isBefore(now, cutoffDate)) {
          periodStart = startOfMonth(addMonths(now, -1));
          periodEnd = endOfMonth(addMonths(now, -1));
        } else {
          periodStart = startOfMonth(now);
          periodEnd = cutoffDate;
        }
        const cycle = await this.repo.createCycle({
          contractId,
          periodStart,
          periodEnd
        });
        try {
          const { getPublisher } = await import("../messaging/publisher");
          const publisher = await getPublisher();
          await publisher.publish({
            exchange: "remit.events",
            routingKey: "remittance.cycle.created.v1",
            content: {
              cycleId: cycle.cycle_id,
              contractId: cycle.contract_id,
              periodStart: cycle.period_start.toISOString(),
              periodEnd: cycle.period_end.toISOString(),
              status: cycle.status
            }
          });
        } catch (error) {
          console.error("[RemittanceService] Failed to publish cycle created event:", error);
        }
        return cycle;
      }
      // Process collections and calculate waterfall
      async calculateWaterfall(cycleId) {
        const cycle = await this.repo.getCycle(cycleId);
        if (!cycle) {
          throw new Error("Cycle not found");
        }
        const contract = await this.repo.getContract(cycle.contract_id);
        if (!contract) {
          throw new Error("Contract not found");
        }
        const rules = await this.repo.getWaterfallRules(contract.contract_id);
        const collections = await this.repo.getLoanCollections(
          contract.contract_id,
          cycle.period_start,
          cycle.period_end
        );
        let totalPrincipalToInvestor = 0n;
        let totalInterestToInvestor = 0n;
        let totalFeesToInvestor = 0n;
        let totalServicerFee = 0n;
        let totalInvestorDue = 0n;
        for (const loan of collections) {
          const principalCollected = BigInt(Math.round(Number(loan.principal_collected || 0)));
          const interestCollected = BigInt(Math.round(Number(loan.interest_collected || 0)));
          const lateFeesCollected = BigInt(Math.round(Number(loan.late_fees_collected || 0)));
          const servicerFeeOnInterest = interestCollected * BigInt(contract.servicer_fee_bps) / 10000n;
          let loanInvestorPrincipal = 0n;
          let loanInvestorInterest = 0n;
          let loanInvestorFees = 0n;
          let loanServicerFee = servicerFeeOnInterest;
          const sortedRules = rules.sort((a, b) => a.rank - b.rank);
          for (const rule of sortedRules) {
            switch (rule.bucket) {
              case "interest":
                let interestToInvestor = interestCollected - servicerFeeOnInterest;
                if (rule.cap_minor) {
                  const cap = BigInt(rule.cap_minor);
                  interestToInvestor = interestToInvestor > cap ? cap : interestToInvestor;
                }
                loanInvestorInterest = interestToInvestor;
                break;
              case "principal":
                loanInvestorPrincipal = principalCollected;
                if (rule.cap_minor) {
                  const cap = BigInt(rule.cap_minor);
                  loanInvestorPrincipal = loanInvestorPrincipal > cap ? cap : loanInvestorPrincipal;
                }
                break;
              case "late_fees":
                const investorFeePortion = lateFeesCollected * BigInt(contract.late_fee_split_bps) / 10000n;
                const servicerFeePortion = lateFeesCollected - investorFeePortion;
                loanInvestorFees = investorFeePortion;
                loanServicerFee += servicerFeePortion;
                break;
            }
          }
          const loanInvestorShare = loanInvestorPrincipal + loanInvestorInterest + loanInvestorFees;
          await this.repo.createItem({
            cycle_id: cycleId,
            loan_id: loan.loan_id,
            principal_minor: loanInvestorPrincipal.toString(),
            interest_minor: loanInvestorInterest.toString(),
            fees_minor: loanInvestorFees.toString(),
            investor_share_minor: loanInvestorShare.toString(),
            servicer_fee_minor: loanServicerFee.toString()
          });
          totalPrincipalToInvestor += loanInvestorPrincipal;
          totalInterestToInvestor += loanInvestorInterest;
          totalFeesToInvestor += loanInvestorFees;
          totalServicerFee += loanServicerFee;
          totalInvestorDue += loanInvestorShare;
        }
        await this.repo.updateCycleTotals(cycleId, {
          principal: totalPrincipalToInvestor.toString(),
          interest: totalInterestToInvestor.toString(),
          fees: totalFeesToInvestor.toString(),
          servicerFee: totalServicerFee.toString(),
          investorDue: totalInvestorDue.toString()
        });
        return {
          contractId: contract.contract_id,
          totalCollected: (totalInvestorDue + totalServicerFee).toString(),
          buckets: {
            interest: totalInterestToInvestor.toString(),
            principal: totalPrincipalToInvestor.toString(),
            late_fees: totalFeesToInvestor.toString(),
            escrow: "0",
            recoveries: "0"
          },
          servicerFee: totalServicerFee.toString(),
          investorDue: totalInvestorDue.toString()
        };
      }
      // Lock cycle for processing
      async lockCycle(cycleId) {
        const cycle = await this.repo.getCycle(cycleId);
        if (!cycle || cycle.status !== "open") {
          throw new Error("Cycle must be open to lock");
        }
        await this.repo.updateCycleStatus(cycleId, "locked");
      }
      // Generate remittance export
      async generateExport(cycleId, format2) {
        const cycle = await this.repo.getCycle(cycleId);
        if (!cycle) {
          throw new Error("Cycle not found");
        }
        const items = await this.repo.getItems(cycleId);
        const sortedItems = items.sort((a, b) => {
          const aId = a.loan_id || "";
          const bId = b.loan_id || "";
          return aId.localeCompare(bId);
        });
        const exportItems = sortedItems.map((item) => ({
          loan_id: item.loan_id || "",
          period_start: formatDate(cycle.period_start, "yyyy-MM-dd"),
          period_end: formatDate(cycle.period_end, "yyyy-MM-dd"),
          principal_minor: item.principal_minor,
          interest_minor: item.interest_minor,
          fees_minor: item.fees_minor,
          investor_share_minor: item.investor_share_minor,
          servicer_fee_minor: item.servicer_fee_minor
        }));
        let exportRecord;
        if (format2 === "csv") {
          const fields = [
            "loan_id",
            "period_start",
            "period_end",
            "principal_minor",
            "interest_minor",
            "fees_minor",
            "investor_share_minor",
            "servicer_fee_minor"
          ];
          const parser = new Parser({ fields });
          const csv = parser.parse(exportItems);
          const buffer = Buffer.from(csv);
          exportRecord = await this.repo.createExport(cycleId, format2, buffer);
        } else {
          const xml = this.generateXML(cycle, sortedItems);
          const buffer = Buffer.from(xml);
          exportRecord = await this.repo.createExport(cycleId, format2, buffer);
        }
        await this.repo.updateCycleStatus(cycleId, "file_generated");
        try {
          const { getPublisher } = await import("../messaging/publisher");
          const publisher = await getPublisher();
          await publisher.publish({
            exchange: "remit.events",
            routingKey: "remittance.file.generated.v1",
            content: {
              cycleId,
              exportId: exportRecord.export_id,
              format: format2,
              fileHash: exportRecord.file_hash,
              timestamp: (/* @__PURE__ */ new Date()).toISOString()
            }
          });
        } catch (error) {
          console.error("[RemittanceService] Failed to publish file generation event:", error);
        }
        return exportRecord.export_id;
      }
      generateXML(cycle, items) {
        const periodStart = formatDate(cycle.period_start, "yyyy-MM-dd");
        const periodEnd = formatDate(cycle.period_end, "yyyy-MM-dd");
        const xml = `<?xml version="1.0" encoding="UTF-8"?>
<Remittance>
  ${items.map((item) => `
  <Item>
    <loan_id>${item.loan_id || ""}</loan_id>
    <period_start>${periodStart}</period_start>
    <period_end>${periodEnd}</period_end>
    <principal_minor>${item.principal_minor}</principal_minor>
    <interest_minor>${item.interest_minor}</interest_minor>
    <fees_minor>${item.fees_minor}</fees_minor>
    <investor_share_minor>${item.investor_share_minor}</investor_share_minor>
    <servicer_fee_minor>${item.servicer_fee_minor}</servicer_fee_minor>
  </Item>`).join("")}
</Remittance>`;
        return xml;
      }
      // Process remittance settlement with proper ledger entries
      async settleRemittance(cycleId) {
        const cycle = await this.repo.getCycle(cycleId);
        if (!cycle || cycle.status !== "locked") {
          throw new Error("Cycle must be locked before settling");
        }
        const contract = await this.repo.getContract(cycle.contract_id);
        if (!contract) {
          throw new Error("Contract not found");
        }
        const { postEvent: postEvent2 } = await Promise.resolve().then(() => (init_posting(), posting_exports));
        const { LedgerRepository } = await Promise.resolve().then(() => (init_ledger_repository(), ledger_repository_exports));
        const ledgerRepo = new LedgerRepository(this.pool);
        const principalMinor = BigInt(cycle.total_principal_minor);
        const interestMinor = BigInt(cycle.total_interest_minor);
        const feesMinor = BigInt(cycle.total_fees_minor);
        const servicerFeeMinor = BigInt(cycle.servicer_fee_minor);
        const investorDueMinor = BigInt(cycle.investor_due_minor);
        const interestCollected = interestMinor + servicerFeeMinor;
        const servicerFeeFromInterest = interestCollected * BigInt(contract.servicer_fee_bps) / 10000n;
        const interestToInvestor = interestMinor;
        const lines = [];
        if (principalMinor > 0n) {
          lines.push({
            account: "investor_payable_principal",
            debitMinor: principalMinor,
            memo: `Settle principal remittance cycle ${cycleId}`
          });
        }
        if (interestToInvestor > 0n) {
          lines.push({
            account: "investor_payable_interest",
            debitMinor: interestToInvestor,
            memo: `Settle interest remittance cycle ${cycleId}`
          });
        }
        if (feesMinor > 0n) {
          lines.push({
            account: "investor_payable_fees",
            debitMinor: feesMinor,
            memo: `Settle fees remittance cycle ${cycleId}`
          });
        }
        if (investorDueMinor > 0n) {
          lines.push({
            account: "cash",
            creditMinor: investorDueMinor,
            memo: `Cash payment to investor for cycle ${cycleId}`
          });
        }
        if (servicerFeeMinor > 0n) {
          lines.push({
            account: "servicer_fee_income",
            creditMinor: servicerFeeMinor,
            memo: `Servicer fee income for cycle ${cycleId}`
          });
        }
        if (lines.length > 0) {
          await postEvent2(ledgerRepo, {
            loanId: 0,
            // Portfolio-level entry
            effectiveDate: (/* @__PURE__ */ new Date()).toISOString().split("T")[0],
            correlationId: `remit:${cycleId}`,
            schema: "posting.remittance.v1",
            currency: "USD",
            lines
          });
        }
        await this.repo.updateCycleStatus(cycleId, "settled");
        try {
          const { getPublisher } = await import("../messaging/publisher");
          const publisher = await getPublisher();
          await publisher.publish({
            exchange: "remit.events",
            routingKey: "remittance.settled.v1",
            content: {
              cycleId,
              principalMinor: principalMinor.toString(),
              interestMinor: interestToInvestor.toString(),
              feesMinor: feesMinor.toString(),
              investorDueMinor: investorDueMinor.toString(),
              servicerFeeMinor: servicerFeeMinor.toString(),
              settledAt: (/* @__PURE__ */ new Date()).toISOString()
            }
          });
        } catch (error) {
          console.error("[RemittanceService] Failed to publish settled event:", error);
        }
      }
      // Get remittance report
      async getReport(cycleId) {
        const cycle = await this.repo.getCycle(cycleId);
        if (!cycle) {
          throw new Error("Cycle not found");
        }
        const contract = await this.repo.getContract(cycle.contract_id);
        if (!contract) {
          throw new Error("Contract not found");
        }
        const items = await this.repo.getItems(cycleId);
        const investorResult = await this.pool.query(
          "SELECT name FROM investor WHERE investor_id = $1",
          [contract.investor_id]
        );
        const investorName = investorResult.rows[0]?.name || "Unknown";
        const loanCount = new Set(items.filter((i) => i.loan_id).map((i) => i.loan_id)).size;
        const loanData = await this.repo.getLoanCollections(
          contract.contract_id,
          cycle.period_start,
          cycle.period_end
        );
        const beginningUPB = loanData.reduce((sum3, loan) => sum3 + BigInt(loan.current_balance_minor || 0), 0n);
        const totalPrincipal = BigInt(cycle.total_principal_minor);
        const endingUPB = beginningUPB - totalPrincipal;
        return {
          cycleId: cycle.cycle_id,
          contractId: cycle.contract_id,
          investorName,
          periodStart: cycle.period_start,
          periodEnd: cycle.period_end,
          loanCount,
          beginningUPB: beginningUPB.toString(),
          endingUPB: endingUPB.toString(),
          scheduledInterest: "0",
          // Would need schedule data
          scheduledPrincipal: "0",
          // Would need schedule data
          actualInterest: cycle.total_interest_minor,
          actualPrincipal: cycle.total_principal_minor,
          lateFees: cycle.total_fees_minor,
          servicerFee: cycle.servicer_fee_minor,
          investorRemittance: cycle.investor_due_minor
        };
      }
      // Get export file
      async getExportFile(exportId) {
        const exportRecord = await this.repo.getExport(exportId);
        return exportRecord ? exportRecord.bytes : null;
      }
    };
  }
});

// server/remittance/reconciliation.ts
import { ulid as ulid6 } from "ulid";
import { Decimal } from "decimal.js";
var ReconciliationService2;
var init_reconciliation = __esm({
  "server/remittance/reconciliation.ts"() {
    "use strict";
    ReconciliationService2 = class {
      constructor(pool17) {
        this.pool = pool17;
      }
      /**
       * Create reconciliation snapshot table if it doesn't exist
       */
      async ensureTable() {
        await this.pool.query(`
      CREATE TABLE IF NOT EXISTS remittance_recon_snapshot (
        snapshot_id VARCHAR(26) PRIMARY KEY,
        cycle_id VARCHAR(26) NOT NULL,
        period_start TIMESTAMP NOT NULL,
        period_end TIMESTAMP NOT NULL,
        
        -- Remittance side totals
        remit_investor_share_minor BIGINT NOT NULL,
        remit_servicer_fee_minor BIGINT NOT NULL,
        remit_total_minor BIGINT NOT NULL,
        
        -- GL side totals
        gl_investor_payable_minor BIGINT NOT NULL,
        gl_servicer_income_minor BIGINT NOT NULL,
        gl_total_minor BIGINT NOT NULL,
        
        -- Signed differences
        diff_investor_minor BIGINT NOT NULL,
        diff_servicer_minor BIGINT NOT NULL,
        diff_total_minor BIGINT NOT NULL,
        
        -- Status
        is_balanced BOOLEAN NOT NULL,
        variance_threshold_minor BIGINT DEFAULT 0,
        reconciled_at TIMESTAMP DEFAULT NOW(),
        reconciled_by VARCHAR(100),
        notes TEXT,
        
        -- Indexes
        INDEX idx_cycle_id (cycle_id),
        INDEX idx_period (period_start, period_end),
        INDEX idx_balanced (is_balanced)
      )
    `);
      }
      /**
       * Generate reconciliation report for a remittance cycle
       */
      async generateReconciliation(cycleId, userId) {
        const cycleResult = await this.pool.query(
          `SELECT * FROM remittance_cycle WHERE cycle_id = $1`,
          [cycleId]
        );
        if (cycleResult.rows.length === 0) {
          throw new Error(`Cycle ${cycleId} not found`);
        }
        const cycle = cycleResult.rows[0];
        const remitResult = await this.pool.query(`
      SELECT 
        COALESCE(SUM(investor_share_minor::BIGINT), 0) as investor_total,
        COALESCE(SUM(servicer_fee_minor::BIGINT), 0) as servicer_total
      FROM remittance_item
      WHERE cycle_id = $1
    `, [cycleId]);
        const remitTotals = remitResult.rows[0];
        const remitInvestor = new Decimal(remitTotals.investor_total);
        const remitServicer = new Decimal(remitTotals.servicer_total);
        const remitTotal = remitInvestor.plus(remitServicer);
        const glPayableResult = await this.pool.query(`
      SELECT 
        COALESCE(SUM(
          CASE 
            WHEN entry_type = 'CREDIT' THEN amount_minor::BIGINT
            WHEN entry_type = 'DEBIT' THEN -amount_minor::BIGINT
            ELSE 0
          END
        ), 0) as payable_movement
      FROM ledger_entry
      WHERE account_code = '2110' -- Investor Payables account
        AND effective_date >= $1
        AND effective_date <= $2
        AND metadata->>'cycle_id' = $3
    `, [cycle.period_start, cycle.period_end, cycleId]);
        const glIncomeResult = await this.pool.query(`
      SELECT 
        COALESCE(SUM(
          CASE 
            WHEN entry_type = 'CREDIT' THEN amount_minor::BIGINT
            WHEN entry_type = 'DEBIT' THEN -amount_minor::BIGINT
            ELSE 0
          END
        ), 0) as income_movement
      FROM ledger_entry
      WHERE account_code = '4020' -- Servicer Fee Income account
        AND effective_date >= $1
        AND effective_date <= $2
        AND metadata->>'cycle_id' = $3
    `, [cycle.period_start, cycle.period_end, cycleId]);
        const glPayable = new Decimal(glPayableResult.rows[0].payable_movement);
        const glIncome = new Decimal(glIncomeResult.rows[0].income_movement);
        const glTotal = glPayable.plus(glIncome);
        const diffInvestor = glPayable.minus(remitInvestor);
        const diffServicer = glIncome.minus(remitServicer);
        const diffTotal = glTotal.minus(remitTotal);
        const threshold = new Decimal(0);
        const isBalanced = diffInvestor.abs().lte(threshold) && diffServicer.abs().lte(threshold) && diffTotal.abs().lte(threshold);
        const snapshotId = ulid6();
        const snapshot = {
          snapshot_id: snapshotId,
          cycle_id: cycleId,
          period_start: cycle.period_start,
          period_end: cycle.period_end,
          remit_investor_share_minor: remitInvestor.toFixed(0),
          remit_servicer_fee_minor: remitServicer.toFixed(0),
          remit_total_minor: remitTotal.toFixed(0),
          gl_investor_payable_minor: glPayable.toFixed(0),
          gl_servicer_income_minor: glIncome.toFixed(0),
          gl_total_minor: glTotal.toFixed(0),
          diff_investor_minor: diffInvestor.toFixed(0),
          diff_servicer_minor: diffServicer.toFixed(0),
          diff_total_minor: diffTotal.toFixed(0),
          is_balanced: isBalanced,
          variance_threshold_minor: threshold.toFixed(0),
          reconciled_at: /* @__PURE__ */ new Date(),
          reconciled_by: userId,
          notes: isBalanced ? "Reconciliation passed - zero variance" : "RECONCILIATION FAILED - variance detected"
        };
        await this.pool.query(`
      INSERT INTO remittance_recon_snapshot (
        snapshot_id, cycle_id, period_start, period_end,
        remit_investor_share_minor, remit_servicer_fee_minor, remit_total_minor,
        gl_investor_payable_minor, gl_servicer_income_minor, gl_total_minor,
        diff_investor_minor, diff_servicer_minor, diff_total_minor,
        is_balanced, variance_threshold_minor, reconciled_by, notes
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17)
    `, [
          snapshot.snapshot_id,
          snapshot.cycle_id,
          snapshot.period_start,
          snapshot.period_end,
          snapshot.remit_investor_share_minor,
          snapshot.remit_servicer_fee_minor,
          snapshot.remit_total_minor,
          snapshot.gl_investor_payable_minor,
          snapshot.gl_servicer_income_minor,
          snapshot.gl_total_minor,
          snapshot.diff_investor_minor,
          snapshot.diff_servicer_minor,
          snapshot.diff_total_minor,
          snapshot.is_balanced,
          snapshot.variance_threshold_minor,
          snapshot.reconciled_by,
          snapshot.notes
        ]);
        console.log("[Reconciliation] Report generated:", {
          cycleId,
          isBalanced,
          remittance: {
            investor: remitInvestor.toFixed(2),
            servicer: remitServicer.toFixed(2),
            total: remitTotal.toFixed(2)
          },
          gl: {
            payable: glPayable.toFixed(2),
            income: glIncome.toFixed(2),
            total: glTotal.toFixed(2)
          },
          differences: {
            investor: diffInvestor.toFixed(2),
            servicer: diffServicer.toFixed(2),
            total: diffTotal.toFixed(2)
          }
        });
        return snapshot;
      }
      /**
       * Get reconciliation history for a cycle
       */
      async getReconciliationHistory(cycleId) {
        const result = await this.pool.query(
          `SELECT * FROM remittance_recon_snapshot 
       WHERE cycle_id = $1 
       ORDER BY reconciled_at DESC`,
          [cycleId]
        );
        return result.rows;
      }
      /**
       * Get latest reconciliation for a cycle
       */
      async getLatestReconciliation(cycleId) {
        const result = await this.pool.query(
          `SELECT * FROM remittance_recon_snapshot 
       WHERE cycle_id = $1 
       ORDER BY reconciled_at DESC 
       LIMIT 1`,
          [cycleId]
        );
        return result.rows[0] || null;
      }
      /**
       * Get all unbalanced reconciliations
       */
      async getUnbalancedReconciliations() {
        const result = await this.pool.query(
          `SELECT * FROM remittance_recon_snapshot 
       WHERE is_balanced = false 
       ORDER BY reconciled_at DESC`
        );
        return result.rows;
      }
    };
  }
});

// server/remittance/scheduler.ts
var scheduler_exports = {};
__export(scheduler_exports, {
  RemittanceScheduler: () => RemittanceScheduler
});
import { addDays, endOfMonth as endOfMonth2, isAfter, isWeekend } from "date-fns";
var RemittanceScheduler;
var init_scheduler = __esm({
  "server/remittance/scheduler.ts"() {
    "use strict";
    init_repo3();
    RemittanceScheduler = class {
      constructor(pool17) {
        this.pool = pool17;
        this.repo = new RemittanceRepository(pool17);
      }
      repo;
      intervalId;
      // Calculate business days (excluding weekends for now, holidays configurable later)
      addBusinessDays(date2, days) {
        let result = new Date(date2);
        let addedDays = 0;
        while (addedDays < days) {
          result = addDays(result, 1);
          if (!isWeekend(result)) {
            addedDays++;
          }
        }
        return result;
      }
      // Calculate period bounds based on cutoff day
      calculatePeriodBounds(cutoffDay, referenceDate = /* @__PURE__ */ new Date()) {
        const year = referenceDate.getFullYear();
        const month = referenceDate.getMonth();
        const cutoffDate = new Date(year, month, Math.min(cutoffDay, new Date(year, month + 1, 0).getDate()));
        let periodStart;
        let periodEnd;
        if (isAfter(referenceDate, cutoffDate)) {
          periodStart = cutoffDate;
          periodEnd = endOfMonth2(cutoffDate);
        } else {
          const prevMonth = month === 0 ? 11 : month - 1;
          const prevYear = month === 0 ? year - 1 : year;
          const prevCutoffDay = Math.min(cutoffDay, new Date(prevYear, prevMonth + 1, 0).getDate());
          periodStart = new Date(prevYear, prevMonth, prevCutoffDay);
          periodEnd = cutoffDate;
        }
        const settlementDate = periodEnd;
        const remittanceDays = 5;
        return { periodStart, periodEnd, settlementDate, remittanceDays };
      }
      // Process all contracts and manage their cycles
      async processCycles() {
        console.log("[RemittanceScheduler] Processing cycles...");
        const now = /* @__PURE__ */ new Date();
        try {
          const contractsResult = await this.pool.query(
            `SELECT * FROM investor_contract WHERE status = 'active'`
          );
          const contracts = contractsResult.rows;
          for (const contract of contracts) {
            await this.processContractCycle(contract, now);
          }
          await this.closeExpiredCycles(now);
          await this.lockCyclesForExport(now);
          await this.settleCyclesOnSchedule(now);
          console.log("[RemittanceScheduler] Cycle processing complete");
        } catch (error) {
          console.error("[RemittanceScheduler] Error processing cycles:", error);
        }
      }
      // Process individual contract cycle
      async processContractCycle(contract, now) {
        const existingCycleResult = await this.pool.query(
          `SELECT * FROM remittance_cycle 
       WHERE contract_id = $1 
       AND status IN ('open', 'locked')
       ORDER BY created_at DESC
       LIMIT 1`,
          [contract.contract_id]
        );
        const existingCycle = existingCycleResult.rows[0];
        const bounds = this.calculatePeriodBounds(contract.cutoff_day, now);
        if (!existingCycle || existingCycle.status === "settled" && isAfter(now, bounds.periodStart)) {
          const periodCycleResult = await this.pool.query(
            `SELECT * FROM remittance_cycle 
         WHERE contract_id = $1 
         AND period_start = $2 
         AND period_end = $3`,
            [contract.contract_id, bounds.periodStart, bounds.periodEnd]
          );
          if (periodCycleResult.rows.length === 0) {
            const settlementDate = this.addBusinessDays(bounds.periodEnd, contract.remittance_day);
            await this.pool.query(
              `INSERT INTO remittance_cycle (
            contract_id, 
            period_start, 
            period_end,
            settlement_date,
            status,
            total_principal_minor,
            total_interest_minor,
            total_fees_minor,
            servicer_fee_minor,
            investor_due_minor
          ) VALUES ($1, $2, $3, $4, 'open', '0', '0', '0', '0', '0')
          RETURNING cycle_id`,
              [
                contract.contract_id,
                bounds.periodStart,
                bounds.periodEnd,
                settlementDate
              ]
            );
            console.log(`[RemittanceScheduler] Created new cycle for contract ${contract.contract_id}`);
          }
        }
      }
      // Close cycles that have passed their period_end
      async closeExpiredCycles(now) {
        const result = await this.pool.query(
          `UPDATE remittance_cycle 
       SET status = 'closed'
       WHERE status = 'open' 
       AND period_end < $1
       RETURNING cycle_id, contract_id`,
          [now]
        );
        if (result.rows.length > 0) {
          console.log(`[RemittanceScheduler] Closed ${result.rows.length} expired cycles`);
          for (const cycle of result.rows) {
            try {
              const { RemittanceService: RemittanceService2 } = await Promise.resolve().then(() => (init_service2(), service_exports));
              const { PgLedgerRepository: PgLedgerRepository2 } = await Promise.resolve().then(() => (init_ledger_repository(), ledger_repository_exports));
              const ledgerRepo = new PgLedgerRepository2(this.pool);
              const service = new RemittanceService2(this.pool, ledgerRepo);
              await service.calculateWaterfall(cycle.cycle_id);
              console.log(`[RemittanceScheduler] Calculated waterfall for cycle ${cycle.cycle_id}`);
              await this.pool.query(
                `UPDATE remittance_cycle SET status = 'locked' WHERE cycle_id = $1`,
                [cycle.cycle_id]
              );
            } catch (error) {
              console.error(`[RemittanceScheduler] Error calculating waterfall for cycle ${cycle.cycle_id}:`, error);
            }
          }
        }
      }
      // Lock cycles that are ready for export (after calculation)
      async lockCyclesForExport(now) {
        const result = await this.pool.query(
          `UPDATE remittance_cycle 
       SET status = 'locked'
       WHERE status = 'closed' 
       AND total_principal_minor IS NOT NULL
       AND total_interest_minor IS NOT NULL
       AND status != 'locked'
       RETURNING cycle_id`
        );
        if (result.rows.length > 0) {
          console.log(`[RemittanceScheduler] Locked ${result.rows.length} cycles for export`);
        }
      }
      // Settle cycles on their scheduled settlement date
      async settleCyclesOnSchedule(now) {
        const result = await this.pool.query(
          `SELECT cycle_id FROM remittance_cycle 
       WHERE status = 'locked' 
       AND settlement_date <= $1`,
          [now]
        );
        if (result.rows.length > 0) {
          console.log(`[RemittanceScheduler] Found ${result.rows.length} cycles ready for settlement`);
          for (const row of result.rows) {
            try {
              const { RemittanceService: RemittanceService2 } = await Promise.resolve().then(() => (init_service2(), service_exports));
              const { PgLedgerRepository: PgLedgerRepository2 } = await Promise.resolve().then(() => (init_ledger_repository(), ledger_repository_exports));
              const ledgerRepo = new PgLedgerRepository2(this.pool);
              const service = new RemittanceService2(this.pool, ledgerRepo);
              await service.settleRemittance(row.cycle_id);
              console.log(`[RemittanceScheduler] Settled cycle ${row.cycle_id}`);
            } catch (error) {
              console.error(`[RemittanceScheduler] Error settling cycle ${row.cycle_id}:`, error);
            }
          }
        }
      }
      // Start the scheduler with daily runs
      start() {
        this.processCycles();
        const now = /* @__PURE__ */ new Date();
        const tomorrow2AM = new Date(now);
        tomorrow2AM.setDate(tomorrow2AM.getDate() + 1);
        tomorrow2AM.setHours(2, 0, 0, 0);
        if (now.getHours() < 2) {
          tomorrow2AM.setDate(now.getDate());
        }
        const msUntil2AM = tomorrow2AM.getTime() - now.getTime();
        setTimeout(() => {
          this.processCycles();
          this.intervalId = setInterval(() => {
            this.processCycles();
          }, 24 * 60 * 60 * 1e3);
        }, msUntil2AM);
        const hoursUntil = Math.round(msUntil2AM / (1e3 * 60 * 60));
        console.log(`[RemittanceScheduler] Started. Next run in ${hoursUntil} hours at 2 AM`);
      }
      // Stop the scheduler
      stop() {
        if (this.intervalId) {
          clearInterval(this.intervalId);
          console.log("[RemittanceScheduler] Stopped");
        }
      }
      // Manual trigger for testing
      async runNow() {
        await this.processCycles();
      }
    };
  }
});

// server/remittance/routes.ts
var routes_exports4 = {};
__export(routes_exports4, {
  createRemittanceRoutes: () => createRemittanceRoutes
});
import { Router as Router41 } from "express";
import { z as z17 } from "zod";
function createRemittanceRoutes(pool17) {
  const router41 = Router41();
  const ledgerRepo = new PgLedgerRepository(pool17);
  const service = new RemittanceService(pool17, ledgerRepo);
  const reconService = new ReconciliationService2(pool17);
  router41.post("/contracts", async (req, res) => {
    try {
      const data = createContractSchema.parse(req.body);
      const contract = await service.createContract(data);
      res.json(contract);
    } catch (error) {
      console.error("Error creating contract:", error);
      res.status(400).json({
        error: error instanceof z17.ZodError ? error.errors : "Failed to create contract"
      });
    }
  });
  router41.post("/cycles/initiate", async (req, res) => {
    try {
      const { contractId } = z17.object({
        contractId: z17.string().uuid()
      }).parse(req.body);
      const cycle = await service.initiateCycle(contractId);
      res.json(cycle);
    } catch (error) {
      console.error("Error initiating cycle:", error);
      res.status(400).json({
        error: error instanceof Error ? error.message : "Failed to initiate cycle"
      });
    }
  });
  router41.post("/cycles/:cycleId/calculate", async (req, res) => {
    try {
      const { cycleId } = req.params;
      const calculation = await service.calculateWaterfall(cycleId);
      res.json(calculation);
    } catch (error) {
      console.error("Error calculating waterfall:", error);
      res.status(400).json({
        error: error instanceof Error ? error.message : "Failed to calculate waterfall"
      });
    }
  });
  router41.post("/cycles/:cycleId/lock", async (req, res) => {
    try {
      const { cycleId } = req.params;
      await service.lockCycle(cycleId);
      res.json({ success: true, message: "Cycle locked successfully" });
    } catch (error) {
      console.error("Error locking cycle:", error);
      res.status(400).json({
        error: error instanceof Error ? error.message : "Failed to lock cycle"
      });
    }
  });
  router41.post("/cycles/:cycleId/settle", async (req, res) => {
    try {
      const { cycleId } = req.params;
      await service.settleRemittance(cycleId);
      res.json({ success: true, message: "Remittance settled successfully" });
    } catch (error) {
      console.error("Error settling remittance:", error);
      res.status(400).json({
        error: error instanceof Error ? error.message : "Failed to settle remittance"
      });
    }
  });
  router41.post("/cycles/:cycleId/export", async (req, res) => {
    try {
      const { cycleId } = req.params;
      const { format: format2 } = z17.object({
        format: z17.enum(["csv", "xml"])
      }).parse(req.body);
      const exportId = await service.generateExport(cycleId, format2);
      res.json({ exportId, format: format2 });
    } catch (error) {
      console.error("Error generating export:", error);
      res.status(400).json({
        error: error instanceof Error ? error.message : "Failed to generate export"
      });
    }
  });
  router41.get("/exports/:exportId/download", async (req, res) => {
    try {
      const { exportId } = req.params;
      const file = await service.getExportFile(exportId);
      if (!file) {
        return res.status(404).json({ error: "Export not found" });
      }
      const isXML = file.toString("utf8").startsWith("<?xml");
      const contentType = isXML ? "application/xml" : "text/csv";
      const extension = isXML ? "xml" : "csv";
      res.setHeader("Content-Type", contentType);
      res.setHeader("Content-Disposition", `attachment; filename="remittance_${exportId}.${extension}"`);
      res.send(file);
    } catch (error) {
      console.error("Error downloading export:", error);
      res.status(500).json({ error: "Failed to download export" });
    }
  });
  router41.post("/scheduler/run", async (req, res) => {
    try {
      const { RemittanceScheduler: RemittanceScheduler2 } = await Promise.resolve().then(() => (init_scheduler(), scheduler_exports));
      const scheduler = new RemittanceScheduler2(pool17);
      await scheduler.runNow();
      res.json({ success: true, message: "Scheduler run completed" });
    } catch (error) {
      console.error("Error running scheduler manually:", error);
      res.status(400).json({
        error: error instanceof Error ? error.message : "Failed to run scheduler"
      });
    }
  });
  router41.get("/cycles/:cycleId/report", async (req, res) => {
    try {
      const { cycleId } = req.params;
      const report = await service.getReport(cycleId);
      res.json(report);
    } catch (error) {
      console.error("Error generating report:", error);
      res.status(500).json({ error: "Failed to generate report" });
    }
  });
  router41.post("/reconciliation/setup", async (req, res) => {
    try {
      await reconService.ensureTable();
      res.json({ success: true, message: "Reconciliation table created" });
    } catch (error) {
      console.error("Error setting up reconciliation:", error);
      res.status(500).json({ error: "Failed to setup reconciliation" });
    }
  });
  router41.post("/cycles/:cycleId/reconcile", async (req, res) => {
    try {
      const { cycleId } = req.params;
      const userId = req.body.userId || "system";
      const snapshot = await reconService.generateReconciliation(cycleId, userId);
      res.json({
        success: true,
        isBalanced: snapshot.is_balanced,
        differences: {
          investor: snapshot.diff_investor_minor,
          servicer: snapshot.diff_servicer_minor,
          total: snapshot.diff_total_minor
        },
        snapshot
      });
    } catch (error) {
      console.error("Error generating reconciliation:", error);
      res.status(400).json({
        error: error instanceof Error ? error.message : "Failed to reconcile"
      });
    }
  });
  router41.get("/cycles/:cycleId/reconciliation", async (req, res) => {
    try {
      const { cycleId } = req.params;
      const latest = await reconService.getLatestReconciliation(cycleId);
      res.json(latest);
    } catch (error) {
      console.error("Error fetching reconciliation:", error);
      res.status(500).json({ error: "Failed to fetch reconciliation" });
    }
  });
  router41.get("/reconciliation/unbalanced", async (req, res) => {
    try {
      const unbalanced = await reconService.getUnbalancedReconciliations();
      res.json(unbalanced);
    } catch (error) {
      console.error("Error fetching unbalanced reconciliations:", error);
      res.status(500).json({ error: "Failed to fetch unbalanced reconciliations" });
    }
  });
  return router41;
}
var createContractSchema;
var init_routes4 = __esm({
  "server/remittance/routes.ts"() {
    "use strict";
    init_service2();
    init_reconciliation();
    init_ledger_repository();
    createContractSchema = z17.object({
      investorId: z17.string().uuid(),
      productCode: z17.string(),
      method: z17.enum(["scheduled_p_i", "actual_cash", "scheduled_p_i_with_interest_shortfall"]),
      remittanceDay: z17.number().min(1).max(31),
      cutoffDay: z17.number().min(1).max(31),
      custodialBankAcctId: z17.string().uuid(),
      servicerFeeBps: z17.number().min(0).max(1e4),
      lateFeeSpiltBps: z17.number().min(0).max(1e4),
      waterfallRules: z17.array(z17.object({
        rank: z17.number(),
        bucket: z17.enum(["interest", "principal", "late_fees", "escrow", "recoveries"]),
        capMinor: z17.string().optional()
      }))
    });
  }
});

// src/security/jwt.ts
var jwt_exports = {};
__export(jwt_exports, {
  requireAuth: () => requireAuth4,
  verifyJwt: () => verifyJwt
});
import jwksClient from "jwks-rsa";
import jwt3 from "jsonwebtoken";
function getKey(header, callback2) {
  client3.getSigningKey(header.kid, (err, key) => {
    if (err) return callback2(err);
    const signingKey = key.getPublicKey();
    callback2(null, signingKey);
  });
}
function verifyJwt(token) {
  return new Promise((resolve, reject) => {
    jwt3.verify(token, getKey, {
      audience: process.env.JWT_AUDIENCE,
      issuer: process.env.JWT_ISSUER,
      algorithms: ["RS256"]
    }, (err, decoded) => err ? reject(err) : resolve(decoded));
  });
}
function requireAuth4() {
  return async (req, res, next) => {
    const auth = req.headers.authorization || "";
    const token = auth.startsWith("Bearer ") ? auth.slice(7) : null;
    if (!token) {
      return res.status(401).json({ error: "missing token" });
    }
    try {
      const claims = await verifyJwt(token);
      req.user = {
        sub: claims.sub,
        email: claims.email,
        roles: claims.roles || claims["https://loanserve.io/roles"] || [],
        groups: claims.groups || [],
        tenant_id: claims["https://loanserve.io/tenant_id"] || claims.tenant_id
      };
      next();
    } catch (e) {
      console.error("[JWT] Verification error:", e);
      res.status(401).json({ error: "invalid token" });
    }
  };
}
var client3;
var init_jwt = __esm({
  "src/security/jwt.ts"() {
    "use strict";
    client3 = jwksClient({
      jwksUri: process.env.JWKS_URL,
      cache: true,
      cacheMaxEntries: 5,
      cacheMaxAge: 6e5
      // 10 minutes
    });
  }
});

// src/security/rbac.ts
var rbac_exports = {};
__export(rbac_exports, {
  getUserRoles: () => getUserRoles,
  hasPerm: () => hasPerm,
  hasRole: () => hasRole,
  requirePerm: () => requirePerm,
  setDefaultTenantRole: () => setDefaultTenantRole
});
function hasPerm(user, perm) {
  const roles2 = user?.roles || [];
  const allowed = PERMS[perm] || [];
  return roles2.some((r) => allowed.includes(r));
}
function requirePerm(perm) {
  return (req, res, next) => {
    if (!hasPerm(req.user, perm)) {
      console.warn(`[RBAC] Permission denied: ${req.user?.sub} requested ${perm}`);
      return res.status(403).json({ error: "forbidden", required_permission: perm });
    }
    next();
  };
}
function getUserRoles(user) {
  return user?.roles || [];
}
function hasRole(user, role) {
  const roles2 = getUserRoles(user);
  return roles2.includes(role);
}
function setDefaultTenantRole(user, tenantId) {
  if (!user.roles || user.roles.length === 0) {
    user.roles = [process.env.DEFAULT_TENANT_ROLE || "investor.viewer"];
  }
  user.tenant_id = tenantId;
}
var PERMS;
var init_rbac = __esm({
  "src/security/rbac.ts"() {
    "use strict";
    PERMS = {
      "loan:read": ["admin", "investor.admin", "investor.operator", "investor.viewer", "escrow.operator"],
      "loan:write": ["admin", "investor.admin", "investor.operator", "escrow.operator"],
      "loan:delete": ["admin"],
      "export:run": ["admin", "investor.admin", "investor.operator"],
      "export:manage": ["admin", "investor.admin"],
      "qc:run": ["admin", "investor.admin", "investor.operator"],
      "qc:manage": ["admin", "investor.admin"],
      "notify:request": ["admin", "investor.admin", "investor.operator", "escrow.operator"],
      "notify:manage": ["admin", "investor.admin"],
      "docs:upload": ["admin", "investor.admin", "escrow.operator"],
      "docs:manage": ["admin", "investor.admin"],
      "wire:approve": ["admin", "investor.admin"],
      "wire:request": ["admin", "investor.admin", "investor.operator"],
      "escrow:manage": ["admin", "escrow.operator"],
      "tenant:admin": ["admin"],
      "audit:read": ["admin", "investor.admin"],
      "retention:manage": ["admin"],
      "security:manage": ["admin"]
    };
  }
});

// src/server/db.ts
var db_exports2 = {};
__export(db_exports2, {
  db: () => db,
  pool: () => pool
});
var init_db2 = __esm({
  "src/server/db.ts"() {
    "use strict";
    init_db();
  }
});

// src/security/abac.ts
var abac_exports = {};
__export(abac_exports, {
  applyDbContext: () => applyDbContext,
  checkLoanAccess: () => checkLoanAccess,
  grantLoanAccess: () => grantLoanAccess,
  requireLoanAccess: () => requireLoanAccess,
  setTenantAndUserContext: () => setTenantAndUserContext
});
function setTenantAndUserContext() {
  return async (req, res, next) => {
    const tenantId = req.user?.tenant_id || req.session?.tenant_id;
    const userSub = req.user?.sub || "system";
    if (!tenantId) {
      return res.status(400).json({
        error: "missing tenant context",
        message: "All requests must include tenant identification"
      });
    }
    req.dbContext = {
      tenantId,
      userSub
    };
    next();
  };
}
async function applyDbContext(client5, context) {
  await client5.query(`SET LOCAL app.tenant_id = $1`, [context.tenantId]);
  await client5.query(`SET LOCAL app.user_sub = $1`, [context.userSub]);
}
async function checkLoanAccess(client5, context, loanId, requiredRole = "viewer") {
  try {
    const result = await client5.query(`
      SELECT roles FROM loan_acl 
      WHERE tenant_id = $1 AND loan_id = $2 AND user_sub = $3
    `, [context.tenantId, loanId, context.userSub]);
    if (result.rows.length === 0) {
      return false;
    }
    const userRoles2 = result.rows[0].roles || [];
    return userRoles2.includes(requiredRole) || userRoles2.includes("admin");
  } catch (error) {
    console.error("[ABAC] Loan access check failed:", error);
    return false;
  }
}
async function grantLoanAccess(client5, context, loanId, targetUserSub, roles2) {
  await client5.query(`
    INSERT INTO loan_acl (tenant_id, loan_id, user_sub, roles)
    VALUES ($1, $2, $3, $4)
    ON CONFLICT (tenant_id, loan_id, user_sub)
    DO UPDATE SET roles = $4, updated_at = now()
  `, [context.tenantId, loanId, targetUserSub, roles2]);
}
function requireLoanAccess(role = "viewer") {
  return async (req, res, next) => {
    const loanId = req.params.loanId || req.body.loanId;
    if (!loanId) {
      return res.status(400).json({ error: "loan ID required" });
    }
    const { pool: pool17 } = await Promise.resolve().then(() => (init_db2(), db_exports2));
    const client5 = await pool17.connect();
    try {
      await applyDbContext(client5, req.dbContext);
      const hasAccess = await checkLoanAccess(client5, req.dbContext, loanId, role);
      if (!hasAccess) {
        return res.status(403).json({
          error: "loan access denied",
          loan_id: loanId,
          required_role: role
        });
      }
      next();
    } catch (error) {
      console.error("[ABAC] Loan access middleware error:", error);
      res.status(500).json({ error: "access control error" });
    } finally {
      client5.release();
    }
  };
}
var init_abac = __esm({
  "src/security/abac.ts"() {
    "use strict";
  }
});

// src/security/headers.ts
import helmet from "helmet";
function configureSecurityHeaders() {
  return helmet({
    // Strict Transport Security
    hsts: {
      maxAge: 31536e3,
      // 1 year
      includeSubDomains: true,
      preload: true
    },
    // Content Security Policy
    contentSecurityPolicy: {
      directives: {
        defaultSrc: [process.env.CSP_DEFAULT_SRC || "'self'"],
        scriptSrc: [
          "'self'",
          "'unsafe-inline'",
          // Required for Chart.js in observability dashboard
          "https://cdnjs.cloudflare.com"
          // PDF.js worker
        ],
        styleSrc: [
          "'self'",
          "'unsafe-inline'"
          // Required for dynamic styles
        ],
        imgSrc: [
          process.env.CSP_IMG_SRC || "'self' data:",
          "https:"
          // Allow HTTPS images
        ],
        connectSrc: [
          process.env.CSP_CONNECT_SRC || "'self' https://api.openai.com https://vault.internal",
          "wss:"
          // WebSocket connections
        ],
        fontSrc: ["'self'", "data:", "https:"],
        objectSrc: ["'none'"],
        mediaSrc: ["'self'"],
        frameSrc: ["'none'"],
        frameAncestors: ["'none'"],
        formAction: ["'self'"],
        upgradeInsecureRequests: []
      }
    },
    // Additional security headers
    crossOriginEmbedderPolicy: false,
    // Disable if causing issues
    crossOriginOpenerPolicy: { policy: "same-origin" },
    crossOriginResourcePolicy: { policy: "same-site" },
    // Prevent MIME type sniffing
    noSniff: true,
    // Prevent XSS attacks
    xssFilter: true,
    // Referrer policy
    referrerPolicy: { policy: "strict-origin-when-cross-origin" },
    // Permissions policy
    permittedCrossDomainPolicies: false
  });
}
function apiSecurityHeaders() {
  return (req, res, next) => {
    res.setHeader("X-Content-Type-Options", "nosniff");
    res.setHeader("X-Frame-Options", "DENY");
    res.setHeader("X-XSS-Protection", "1; mode=block");
    res.setHeader("Strict-Transport-Security", "max-age=31536000; includeSubDomains");
    res.removeHeader("X-Powered-By");
    res.removeHeader("Server");
    if (req.path.includes("/api/")) {
      res.setHeader("Cache-Control", "no-store, no-cache, must-revalidate, proxy-revalidate");
      res.setHeader("Pragma", "no-cache");
      res.setHeader("Expires", "0");
    }
    next();
  };
}
function configureRateLimiting() {
  let rateLimit;
  try {
    rateLimit = __require("express-rate-limit");
  } catch (error) {
    console.warn("[Security] express-rate-limit not available, using placeholder");
    rateLimit = () => (req, res, next) => next();
  }
  const apiLimiter2 = rateLimit({
    windowMs: 15 * 60 * 1e3,
    // 15 minutes
    max: 100,
    // 100 requests per window
    message: {
      error: "Too many requests",
      retryAfter: 900
      // seconds
    },
    standardHeaders: true,
    legacyHeaders: false,
    skip: (req) => {
      return req.path === "/health" || req.path === "/metrics";
    }
  });
  const authLimiter2 = rateLimit({
    windowMs: 15 * 60 * 1e3,
    // 15 minutes
    max: 5,
    // 5 login attempts per window
    message: {
      error: "Too many authentication attempts",
      retryAfter: 900
    },
    skipSuccessfulRequests: true
  });
  const wireTransferLimiter2 = rateLimit({
    windowMs: 60 * 60 * 1e3,
    // 1 hour
    max: 10,
    // 10 wire transfer requests per hour
    message: {
      error: "Wire transfer request limit exceeded",
      retryAfter: 3600
    }
  });
  return {
    apiLimiter: apiLimiter2,
    authLimiter: authLimiter2,
    wireTransferLimiter: wireTransferLimiter2
  };
}
var init_headers = __esm({
  "src/security/headers.ts"() {
    "use strict";
  }
});

// src/security/crypto.ts
import { KMSClient, GenerateDataKeyCommand, DecryptCommand } from "@aws-sdk/client-kms";
import axios3 from "axios";
import { createCipheriv, createDecipheriv, randomBytes as randomBytes3, createHash as createHash13 } from "crypto";
async function getTenantDEK(tenantId) {
  const vaultPath = `${process.env.VAULT_ADDR}/v1/${process.env.VAULT_KV_PATH}/tenants/${tenantId}/dek`;
  try {
    const response = await axios3.get(vaultPath, {
      headers: { "X-Vault-Token": process.env.VAULT_TOKEN },
      timeout: 5e3
    });
    const encryptedDEK = Buffer.from(response.data.data.data.ciphertext, "base64");
    const decryptCommand = new DecryptCommand({ CiphertextBlob: encryptedDEK });
    const decryptResult = await kms.send(decryptCommand);
    return {
      plaintext: Buffer.from(decryptResult.Plaintext),
      ciphertext: encryptedDEK
    };
  } catch (error) {
    console.log(`[Crypto] Generating new DEK for tenant ${tenantId}`);
    const generateCommand = new GenerateDataKeyCommand({
      KeyId: process.env.KMS_KEY_ARN,
      KeySpec: "AES_256"
    });
    const generateResult = await kms.send(generateCommand);
    const plaintext = Buffer.from(generateResult.Plaintext);
    const ciphertext = Buffer.from(generateResult.CiphertextBlob);
    try {
      await axios3.post(vaultPath, {
        data: { ciphertext: ciphertext.toString("base64") }
      }, {
        headers: { "X-Vault-Token": process.env.VAULT_TOKEN },
        timeout: 5e3
      });
    } catch (vaultError) {
      console.warn("[Crypto] Failed to store DEK in Vault:", vaultError);
    }
    return { plaintext, ciphertext };
  }
}
async function enc(tenantId, plaintext, aad) {
  const { plaintext: dek } = await getTenantDEK(tenantId);
  const key = dek;
  const iv = randomBytes3(12);
  const cipher = createCipheriv("aes-256-gcm", key, iv, { authTagLength: 16 });
  cipher.setAAD(Buffer.from(aad, "utf-8"));
  const ciphertext = Buffer.concat([
    cipher.update(Buffer.from(plaintext, "utf-8")),
    cipher.final()
  ]);
  const authTag = cipher.getAuthTag();
  return Buffer.concat([iv, ciphertext, authTag]).toString("base64");
}
async function dec(tenantId, b64Payload, aad) {
  const { plaintext: dek } = await getTenantDEK(tenantId);
  const key = dek;
  const raw = Buffer.from(b64Payload, "base64");
  if (raw.length < 28) {
    throw new Error("Invalid encrypted payload length");
  }
  const iv = raw.subarray(0, 12);
  const authTag = raw.subarray(raw.length - 16);
  const ciphertext = raw.subarray(12, raw.length - 16);
  const decipher = createDecipheriv("aes-256-gcm", key, iv, { authTagLength: 16 });
  decipher.setAAD(Buffer.from(aad, "utf-8"));
  decipher.setAuthTag(authTag);
  const plaintext = Buffer.concat([
    decipher.update(ciphertext),
    decipher.final()
  ]);
  return plaintext.toString("utf-8");
}
function tokenize(value) {
  return createHash13("sha256").update(value.toLowerCase().trim()).digest("hex");
}
var kms;
var init_crypto = __esm({
  "src/security/crypto.ts"() {
    "use strict";
    kms = new KMSClient({
      region: process.env.AWS_REGION || "us-east-1"
    });
  }
});

// src/security/pii-protection.ts
async function encryptPIIData(tenantId, loanId, data) {
  const result = {};
  if (data.email) {
    result.email_enc = await enc(tenantId, data.email, `email:${loanId}`);
    result.email_tok = tokenize(data.email.toLowerCase());
  }
  if (data.phone) {
    const normalizedPhone = data.phone.replace(/[^\d]/g, "");
    result.phone_enc = await enc(tenantId, normalizedPhone, `phone:${loanId}`);
    result.phone_tok = tokenize(normalizedPhone);
  }
  if (data.ssn_last4) {
    result.ssn_last4_enc = await enc(tenantId, data.ssn_last4, `ssn:${loanId}`);
    result.ssn_last4_tok = tokenize(data.ssn_last4);
  }
  if (data.dob) {
    result.dob_enc = await enc(tenantId, data.dob, `dob:${loanId}`);
  }
  if (data.full_name) {
    result.full_name_enc = await enc(tenantId, data.full_name, `name:${loanId}`);
    result.full_name_tok = tokenize(data.full_name.toLowerCase());
  }
  return result;
}
async function decryptPIIData(tenantId, loanId, encryptedData) {
  const result = {};
  try {
    if (encryptedData.email_enc) {
      result.email = await dec(tenantId, encryptedData.email_enc, `email:${loanId}`);
    }
    if (encryptedData.phone_enc) {
      result.phone = await dec(tenantId, encryptedData.phone_enc, `phone:${loanId}`);
    }
    if (encryptedData.ssn_last4_enc) {
      result.ssn_last4 = await dec(tenantId, encryptedData.ssn_last4_enc, `ssn:${loanId}`);
    }
    if (encryptedData.dob_enc) {
      result.dob = await dec(tenantId, encryptedData.dob_enc, `dob:${loanId}`);
    }
    if (encryptedData.full_name_enc) {
      result.full_name = await dec(tenantId, encryptedData.full_name_enc, `name:${loanId}`);
    }
  } catch (error) {
    console.error("[PII] Decryption error:", error);
    throw new Error("Failed to decrypt PII data");
  }
  return result;
}
function redactPII(data) {
  if (typeof data !== "object" || data === null) {
    return data;
  }
  const redacted = Array.isArray(data) ? [] : {};
  for (const [key, value] of Object.entries(data)) {
    const lowerKey = key.toLowerCase();
    if (lowerKey.includes("ssn") || lowerKey.includes("social")) {
      redacted[key] = "[REDACTED-SSN]";
    } else if (lowerKey.includes("email")) {
      if (typeof value === "string" && value.includes("@")) {
        const [local, domain] = value.split("@");
        redacted[key] = `${local.charAt(0)}***@${domain}`;
      } else {
        redacted[key] = "[REDACTED-EMAIL]";
      }
    } else if (lowerKey.includes("phone") || lowerKey.includes("tel")) {
      if (typeof value === "string" && value.length >= 4) {
        redacted[key] = `***-***-${value.slice(-4)}`;
      } else {
        redacted[key] = "[REDACTED-PHONE]";
      }
    } else if (lowerKey.includes("dob") || lowerKey.includes("birth")) {
      redacted[key] = "[REDACTED-DOB]";
    } else if (typeof value === "object") {
      redacted[key] = redactPII(value);
    } else {
      redacted[key] = value;
    }
  }
  return redacted;
}
var PIIRepository;
var init_pii_protection = __esm({
  "src/security/pii-protection.ts"() {
    "use strict";
    init_crypto();
    PIIRepository = class {
      client;
      context;
      constructor(client5, context) {
        this.client = client5;
        this.context = context;
      }
      /**
       * Store encrypted PII data
       */
      async upsertBorrowerPII(loanId, data) {
        const encryptedData = await encryptPIIData(this.context.tenantId, loanId, data);
        await this.client.query(`
      INSERT INTO pii_borrowers (
        tenant_id, loan_id, 
        email_enc, email_tok,
        phone_enc, phone_tok,
        ssn_last4_enc, ssn_last4_tok,
        dob_enc,
        full_name_enc, full_name_tok
      )
      VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)
      ON CONFLICT (tenant_id, loan_id)
      DO UPDATE SET
        email_enc = COALESCE($3, pii_borrowers.email_enc),
        email_tok = COALESCE($4, pii_borrowers.email_tok),
        phone_enc = COALESCE($5, pii_borrowers.phone_enc),
        phone_tok = COALESCE($6, pii_borrowers.phone_tok),
        ssn_last4_enc = COALESCE($7, pii_borrowers.ssn_last4_enc),
        ssn_last4_tok = COALESCE($8, pii_borrowers.ssn_last4_tok),
        dob_enc = COALESCE($9, pii_borrowers.dob_enc),
        full_name_enc = COALESCE($10, pii_borrowers.full_name_enc),
        full_name_tok = COALESCE($11, pii_borrowers.full_name_tok),
        updated_at = now()
    `, [
          this.context.tenantId,
          loanId,
          encryptedData.email_enc,
          encryptedData.email_tok,
          encryptedData.phone_enc,
          encryptedData.phone_tok,
          encryptedData.ssn_last4_enc,
          encryptedData.ssn_last4_tok,
          encryptedData.dob_enc,
          encryptedData.full_name_enc,
          encryptedData.full_name_tok
        ]);
      }
      /**
       * Retrieve and decrypt PII data
       */
      async getBorrowerPII(loanId) {
        const result = await this.client.query(`
      SELECT 
        email_enc, phone_enc, ssn_last4_enc, dob_enc, full_name_enc
      FROM pii_borrowers
      WHERE tenant_id = $1 AND loan_id = $2
    `, [this.context.tenantId, loanId]);
        if (result.rows.length === 0) {
          return null;
        }
        const encryptedData = result.rows[0];
        return await decryptPIIData(this.context.tenantId, loanId, encryptedData);
      }
      /**
       * Search by tokenized values (for lookups without revealing PII)
       */
      async findByEmailToken(emailToken) {
        const result = await this.client.query(`
      SELECT loan_id FROM pii_borrowers
      WHERE tenant_id = $1 AND email_tok = $2
    `, [this.context.tenantId, emailToken]);
        return result.rows.map((row) => row.loan_id);
      }
      async findByPhoneToken(phoneToken) {
        const result = await this.client.query(`
      SELECT loan_id FROM pii_borrowers
      WHERE tenant_id = $1 AND phone_tok = $2
    `, [this.context.tenantId, phoneToken]);
        return result.rows.map((row) => row.loan_id);
      }
    };
  }
});

// src/security/wire-fraud-protection.ts
var WireRiskEngine, WireTransferService;
var init_wire_fraud_protection = __esm({
  "src/security/wire-fraud-protection.ts"() {
    "use strict";
    init_pii_protection();
    WireRiskEngine = class {
      /**
       * Assess risk factors for wire transfer request
       */
      static assessRisk(request, loanData) {
        const flags = [];
        let score = 0;
        if (request.amount > 5e4) {
          flags.push("HIGH_AMOUNT");
          score += 25;
        }
        if (request.amount > 1e5) {
          flags.push("VERY_HIGH_AMOUNT");
          score += 25;
        }
        if (!request.recipientName || request.recipientName.length < 3) {
          flags.push("INVALID_RECIPIENT_NAME");
          score += 30;
        }
        if (!request.recipientRouting || !/^\d{9}$/.test(request.recipientRouting)) {
          flags.push("INVALID_ROUTING_NUMBER");
          score += 40;
        }
        if (!request.recipientAccount || request.recipientAccount.length < 4) {
          flags.push("INVALID_ACCOUNT_NUMBER");
          score += 40;
        }
        const hour = (/* @__PURE__ */ new Date()).getHours();
        if (hour < 9 || hour > 17) {
          flags.push("OFF_HOURS_REQUEST");
          score += 15;
        }
        if (request.purpose?.toLowerCase().includes("urgent")) {
          flags.push("URGENT_REQUEST");
          score += 10;
        }
        const fraudKeywords = ["lottery", "prince", "inheritance", "tax refund", "prize"];
        const purpose = request.purpose?.toLowerCase() || "";
        if (fraudKeywords.some((keyword) => purpose.includes(keyword))) {
          flags.push("FRAUD_KEYWORDS");
          score += 50;
        }
        return {
          score: Math.min(100, score),
          flags,
          requiresAdditionalApproval: score > 50 || flags.includes("VERY_HIGH_AMOUNT")
        };
      }
    };
    WireTransferService = class {
      client;
      context;
      constructor(client5, context) {
        this.client = client5;
        this.context = context;
      }
      /**
       * Submit wire transfer request
       */
      async submitRequest(request) {
        const riskAssessment = WireRiskEngine.assessRisk(request, null);
        const result = await this.client.query(`
      INSERT INTO wire_transfer_requests (
        id, tenant_id, loan_id, amount, 
        recipient_name, recipient_bank, recipient_account, recipient_routing,
        purpose, requested_by, status, risk_score, risk_flags,
        created_at
      )
      VALUES (
        gen_random_uuid(), $1, $2, $3,
        $4, $5, $6, $7,
        $8, $9, 'pending', $10, $11,
        now()
      )
      RETURNING id
    `, [
          this.context.tenantId,
          request.loanId,
          request.amount,
          request.recipientName,
          request.recipientBank,
          request.recipientAccount,
          request.recipientRouting,
          request.purpose,
          request.requestedBy,
          riskAssessment.score,
          riskAssessment.flags
        ]);
        const wireId = result.rows[0].id;
        await this.auditWireAction(wireId, "WIRE_REQUESTED", {
          amount: request.amount,
          recipient: request.recipientName,
          riskScore: riskAssessment.score,
          flags: riskAssessment.flags
        });
        if (riskAssessment.score > 80) {
          await this.rejectTransfer(wireId, "system", "Automatic rejection due to high risk score");
        }
        return wireId;
      }
      /**
       * Approve wire transfer
       */
      async approveTransfer(wireId, approverSub, approverRole, reason, ipAddress = "", userAgent = "") {
        const approval = {
          approverSub,
          approverRole,
          action: "approve",
          reason,
          approvedAt: /* @__PURE__ */ new Date(),
          ipAddress,
          userAgent
        };
        await this.client.query(`
      INSERT INTO wire_transfer_approvals (
        wire_id, approver_sub, approver_role, action, reason,
        ip_address, user_agent, created_at
      )
      VALUES ($1, $2, $3, $4, $5, $6, $7, now())
    `, [
          wireId,
          approval.approverSub,
          approval.approverRole,
          approval.action,
          approval.reason,
          approval.ipAddress,
          approval.userAgent
        ]);
        const approvalCount = await this.getApprovalCount(wireId);
        const requiredApprovals = await this.getRequiredApprovals(wireId);
        if (approvalCount >= requiredApprovals) {
          await this.client.query(`
        UPDATE wire_transfer_requests 
        SET status = 'approved', approved_at = now()
        WHERE id = $1
      `, [wireId]);
          await this.auditWireAction(wireId, "WIRE_APPROVED", {
            approver: approverSub,
            totalApprovals: approvalCount
          });
          return true;
        }
        await this.auditWireAction(wireId, "WIRE_APPROVAL_RECORDED", {
          approver: approverSub,
          approvalsReceived: approvalCount,
          approvalsRequired: requiredApprovals
        });
        return false;
      }
      /**
       * Reject wire transfer
       */
      async rejectTransfer(wireId, approverSub, reason, ipAddress = "", userAgent = "") {
        await this.client.query(`
      INSERT INTO wire_transfer_approvals (
        wire_id, approver_sub, approver_role, action, reason,
        ip_address, user_agent, created_at
      )
      VALUES ($1, $2, 'system', 'reject', $3, $4, $5, now())
    `, [wireId, approverSub, reason, ipAddress, userAgent]);
        await this.client.query(`
      UPDATE wire_transfer_requests 
      SET status = 'rejected', rejected_at = now()
      WHERE id = $1
    `, [wireId]);
        await this.auditWireAction(wireId, "WIRE_REJECTED", {
          rejectedBy: approverSub,
          reason
        });
      }
      /**
       * Get wire transfer details with redacted PII for logs
       */
      async getWireTransfer(wireId, includePII = false) {
        const result = await this.client.query(`
      SELECT * FROM wire_transfer_requests
      WHERE id = $1 AND tenant_id = $2
    `, [wireId, this.context.tenantId]);
        if (result.rows.length === 0) {
          return null;
        }
        const wire = result.rows[0];
        if (!includePII) {
          wire.recipient_account = `***${wire.recipient_account?.slice(-4) || ""}`;
          wire.recipient_routing = `***${wire.recipient_routing?.slice(-4) || ""}`;
        }
        return {
          id: wire.id,
          loanId: wire.loan_id,
          amount: parseFloat(wire.amount),
          recipientName: wire.recipient_name,
          recipientBank: wire.recipient_bank,
          recipientAccount: wire.recipient_account,
          recipientRouting: wire.recipient_routing,
          purpose: wire.purpose,
          requestedBy: wire.requested_by,
          requestedAt: wire.created_at,
          status: wire.status,
          approvals: [],
          // Would load separately
          riskScore: wire.risk_score,
          riskFlags: wire.risk_flags || []
        };
      }
      async getApprovalCount(wireId) {
        const result = await this.client.query(`
      SELECT COUNT(*) as count
      FROM wire_transfer_approvals
      WHERE wire_id = $1 AND action = 'approve'
    `, [wireId]);
        return parseInt(result.rows[0].count);
      }
      async getRequiredApprovals(wireId) {
        const wire = await this.client.query(`
      SELECT amount, risk_score FROM wire_transfer_requests
      WHERE id = $1
    `, [wireId]);
        const amount = parseFloat(wire.rows[0].amount);
        const riskScore = wire.rows[0].risk_score;
        if (amount > 1e5 || riskScore > 70) return 2;
        if (amount > 25e3 || riskScore > 40) return 1;
        return 0;
      }
      async auditWireAction(wireId, action, details) {
        console.log(`[Wire Fraud Audit] ${action}`, {
          wireId,
          actorId: this.context.userSub,
          tenantId: this.context.tenantId,
          details: redactPII(details),
          timestamp: /* @__PURE__ */ new Date()
        });
      }
    };
  }
});

// src/security/retention-policies.ts
var RetentionService, RetentionOperations;
var init_retention_policies = __esm({
  "src/security/retention-policies.ts"() {
    "use strict";
    RetentionService = class _RetentionService {
      client;
      context;
      // Default retention periods by table (days)
      static DEFAULT_RETENTION = {
        "audit_logs": 2555,
        // 7 years
        "audit_chain_events": 2555,
        // 7 years (never purge by default)
        "wire_transfer_requests": 2555,
        // 7 years
        "wire_transfer_approvals": 2555,
        // 7 years
        "pii_borrowers": 2555,
        // 7 years
        "loan_acl": 1095,
        // 3 years
        "secure_sessions": 90,
        // 90 days
        "notifications": 365,
        // 1 year
        "documents": 3650,
        // 10 years
        "payments": 2555,
        // 7 years
        "escrow_analysis": 2555,
        // 7 years
        "general_ledger_events": 2555,
        // 7 years
        "general_ledger_entries": 2555,
        // 7 years
        "loan_balances": 1095
        // 3 years (snapshots)
      };
      constructor(client5, context) {
        this.client = client5;
        this.context = context;
      }
      /**
       * Create or update retention policy
       */
      async setRetentionPolicy(policy) {
        const result = await this.client.query(`
      INSERT INTO retention_policies (
        tenant_id, table_name, retention_days, policy_type,
        legal_hold_reason, legal_hold_until, created_by
      )
      VALUES ($1, $2, $3, $4, $5, $6, $7)
      ON CONFLICT (tenant_id, table_name)
      DO UPDATE SET
        retention_days = $3,
        policy_type = $4,
        legal_hold_reason = $5,
        legal_hold_until = $6,
        updated_at = now()
      RETURNING id
    `, [
          policy.tenantId,
          policy.tableName,
          policy.retentionDays,
          policy.policyType,
          policy.legalHoldReason,
          policy.legalHoldUntil,
          policy.createdBy
        ]);
        await this.logRetentionOperation({
          tenantId: policy.tenantId,
          tableName: policy.tableName,
          operationType: policy.policyType === "legal_hold" ? "legal_hold_applied" : "purge",
          recordsAffected: 0,
          dateRangeStart: /* @__PURE__ */ new Date(),
          dateRangeEnd: /* @__PURE__ */ new Date(),
          executedBy: policy.createdBy,
          executionReason: `Retention policy ${policy.policyType === "legal_hold" ? "legal hold applied" : "updated"}`
        });
        return result.rows[0].id;
      }
      /**
       * Get retention policy for table
       */
      async getRetentionPolicy(tableName) {
        const result = await this.client.query(`
      SELECT * FROM retention_policies
      WHERE tenant_id = $1 AND table_name = $2
    `, [this.context.tenantId, tableName]);
        if (result.rows.length === 0) {
          return null;
        }
        const row = result.rows[0];
        return {
          id: row.id,
          tenantId: row.tenant_id,
          tableName: row.table_name,
          retentionDays: row.retention_days,
          policyType: row.policy_type,
          legalHoldReason: row.legal_hold_reason,
          legalHoldUntil: row.legal_hold_until,
          createdBy: row.created_by,
          createdAt: row.created_at,
          updatedAt: row.updated_at
        };
      }
      /**
       * Apply legal hold to table
       */
      async applyLegalHold(tableName, reason, holdUntil, appliedBy) {
        await this.setRetentionPolicy({
          tenantId: this.context.tenantId,
          tableName,
          retentionDays: _RetentionService.DEFAULT_RETENTION[tableName] || 3650,
          policyType: "legal_hold",
          legalHoldReason: reason,
          legalHoldUntil: holdUntil,
          createdBy: appliedBy
        });
        console.log(`[Retention] Legal hold applied to ${tableName} until ${holdUntil.toISOString()}: ${reason}`);
      }
      /**
       * Release legal hold
       */
      async releaseLegalHold(tableName, releasedBy) {
        await this.client.query(`
      UPDATE retention_policies
      SET 
        policy_type = 'automatic',
        legal_hold_reason = NULL,
        legal_hold_until = NULL,
        updated_at = now()
      WHERE tenant_id = $1 AND table_name = $2
    `, [this.context.tenantId, tableName]);
        await this.logRetentionOperation({
          tenantId: this.context.tenantId,
          tableName,
          operationType: "legal_hold_released",
          recordsAffected: 0,
          dateRangeStart: /* @__PURE__ */ new Date(),
          dateRangeEnd: /* @__PURE__ */ new Date(),
          executedBy: releasedBy,
          executionReason: "Legal hold released"
        });
        console.log(`[Retention] Legal hold released for ${tableName}`);
      }
      /**
       * Execute retention policy for a table
       */
      async executeRetention(tableName, dryRun = false) {
        const policy = await this.getRetentionPolicy(tableName);
        if (!policy) {
          const defaultRetention = _RetentionService.DEFAULT_RETENTION[tableName] || 3650;
          await this.setRetentionPolicy({
            tenantId: this.context.tenantId,
            tableName,
            retentionDays: defaultRetention,
            policyType: "automatic",
            createdBy: "system"
          });
          return this.executeRetention(tableName, dryRun);
        }
        if (policy.policyType === "legal_hold") {
          console.log(`[Retention] Skipping ${tableName} - under legal hold until ${policy.legalHoldUntil}`);
          return { wouldDelete: 0, actuallyDeleted: 0 };
        }
        const cutoffDate = /* @__PURE__ */ new Date();
        cutoffDate.setDate(cutoffDate.getDate() - policy.retentionDays);
        const dateColumn = this.getDateColumnForTable(tableName);
        if (!dateColumn) {
          console.warn(`[Retention] No date column configured for table ${tableName}`);
          return { wouldDelete: 0, actuallyDeleted: 0 };
        }
        const countResult = await this.client.query(`
      SELECT COUNT(*) as count
      FROM ${tableName}
      WHERE tenant_id = $1 AND ${dateColumn} < $2
    `, [this.context.tenantId, cutoffDate]);
        const wouldDelete = parseInt(countResult.rows[0].count);
        if (wouldDelete === 0) {
          return { wouldDelete: 0, actuallyDeleted: 0 };
        }
        if (dryRun) {
          console.log(`[Retention] DRY RUN: Would delete ${wouldDelete} records from ${tableName} older than ${cutoffDate.toISOString()}`);
          return { wouldDelete, actuallyDeleted: 0 };
        }
        const deleteResult = await this.client.query(`
      DELETE FROM ${tableName}
      WHERE tenant_id = $1 AND ${dateColumn} < $2
    `, [this.context.tenantId, cutoffDate]);
        const actuallyDeleted = deleteResult.rowCount || 0;
        await this.logRetentionOperation({
          tenantId: this.context.tenantId,
          tableName,
          operationType: "purge",
          recordsAffected: actuallyDeleted,
          dateRangeStart: /* @__PURE__ */ new Date(0),
          // Beginning of time
          dateRangeEnd: cutoffDate,
          executedBy: "system",
          executionReason: `Automatic retention: ${policy.retentionDays} days`
        });
        console.log(`[Retention] Purged ${actuallyDeleted} records from ${tableName}`);
        return { wouldDelete, actuallyDeleted };
      }
      /**
       * Run retention for all tables
       */
      async executeAllRetentions(dryRun = false) {
        const results = {};
        const tables = Object.keys(_RetentionService.DEFAULT_RETENTION);
        for (const tableName of tables) {
          try {
            results[tableName] = await this.executeRetention(tableName, dryRun);
          } catch (error) {
            console.error(`[Retention] Error processing ${tableName}:`, error);
            results[tableName] = { error: error.message, wouldDelete: 0, actuallyDeleted: 0 };
          }
        }
        return results;
      }
      /**
       * Get retention statistics
       */
      async getRetentionStats() {
        const policyResult = await this.client.query(`
      SELECT COUNT(*) as total, COUNT(CASE WHEN policy_type = 'legal_hold' THEN 1 END) as legal_holds
      FROM retention_policies
      WHERE tenant_id = $1
    `, [this.context.tenantId]);
        const stats = {
          totalPolicies: parseInt(policyResult.rows[0].total),
          legalHolds: parseInt(policyResult.rows[0].legal_holds),
          upcomingRetentions: []
        };
        const tables = Object.keys(_RetentionService.DEFAULT_RETENTION);
        for (const tableName of tables) {
          const policy = await this.getRetentionPolicy(tableName);
          if (!policy || policy.policyType === "legal_hold") continue;
          const cutoffDate = /* @__PURE__ */ new Date();
          cutoffDate.setDate(cutoffDate.getDate() - policy.retentionDays + 30);
          const dateColumn = this.getDateColumnForTable(tableName);
          if (!dateColumn) continue;
          try {
            const countResult = await this.client.query(`
          SELECT COUNT(*) as count
          FROM ${tableName}
          WHERE tenant_id = $1 AND ${dateColumn} < $2
        `, [this.context.tenantId, cutoffDate]);
            const recordCount = parseInt(countResult.rows[0].count);
            if (recordCount > 0) {
              stats.upcomingRetentions.push({
                tableName,
                recordCount,
                cutoffDate
              });
            }
          } catch (error) {
            console.warn(`[Retention] Unable to check ${tableName}:`, error);
          }
        }
        return stats;
      }
      async logRetentionOperation(operation) {
        await this.client.query(`
      INSERT INTO retention_log (
        tenant_id, table_name, operation_type, records_affected,
        date_range_start, date_range_end, executed_by, execution_reason
      )
      VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
    `, [
          operation.tenantId,
          operation.tableName,
          operation.operationType,
          operation.recordsAffected,
          operation.dateRangeStart,
          operation.dateRangeEnd,
          operation.executedBy,
          operation.executionReason
        ]);
      }
      getDateColumnForTable(tableName) {
        const dateColumns = {
          "audit_logs": "created_at",
          "audit_chain_events": "created_at",
          "wire_transfer_requests": "created_at",
          "wire_transfer_approvals": "created_at",
          "pii_borrowers": "created_at",
          "loan_acl": "created_at",
          "secure_sessions": "created_at",
          "notifications": "created_at",
          "documents": "created_at",
          "payments": "created_at",
          "escrow_analysis": "created_at",
          "general_ledger_events": "created_at",
          "general_ledger_entries": "created_at",
          "loan_balances": "created_at"
        };
        return dateColumns[tableName] || null;
      }
    };
    RetentionOperations = class {
      client;
      constructor(client5) {
        this.client = client5;
      }
      /**
       * Run retention for all tenants (called by maintenance consumer)
       */
      async runRetentionForAllTenants() {
        let processedTenants = 0;
        let errors = 0;
        try {
          console.log("[Retention] Starting retention job for all tenants");
          const tenantResult = await this.client.query(`
        SELECT DISTINCT tenant_id FROM retention_policies
        UNION
        SELECT DISTINCT tenant_id FROM audit_logs
      `);
          for (const row of tenantResult.rows) {
            const tenantId = row.tenant_id;
            const context = { tenantId, userSub: "retention-scheduler" };
            try {
              await this.client.query(`SET LOCAL app.tenant_id = $1`, [tenantId]);
              const retentionService = new RetentionService(this.client, context);
              const results = await retentionService.executeAllRetentions(false);
              console.log(`[Retention] Completed retention for tenant ${tenantId}:`, results);
              processedTenants++;
            } catch (error) {
              console.error(`[Retention] Error processing tenant ${tenantId}:`, error);
              errors++;
            }
          }
        } catch (error) {
          console.error("[Retention] Retention job error:", error);
          errors++;
        }
        return { processedTenants, errors };
      }
    };
  }
});

// src/security/audit-chain.ts
var audit_chain_exports = {};
__export(audit_chain_exports, {
  AuditChainManager: () => AuditChainManager,
  getAuditChain: () => getAuditChain
});
import { createHash as createHash14, createHmac as createHmac4 } from "crypto";
async function getAuditChain() {
  if (!chainManager) {
    const { pool: pool17 } = await Promise.resolve().then(() => (init_db2(), db_exports2));
    const client5 = pool17;
    chainManager = new AuditChainManager(client5);
  }
  return chainManager;
}
async function getLastChainState(tenantId) {
  const chain = await getAuditChain();
  return chain.getLastChainState(tenantId);
}
var AuditChainManager, chainManager;
var init_audit_chain = __esm({
  "src/security/audit-chain.ts"() {
    "use strict";
    AuditChainManager = class {
      client;
      hmacKey;
      constructor(client5, hmacKey) {
        this.client = client5;
        this.hmacKey = hmacKey || process.env.AUDIT_CHAIN_KEY || "default-audit-key";
      }
      /**
       * Generate deterministic hash for audit event
       */
      generateEventHash(event, previousHash) {
        const canonical = JSON.stringify({
          eventType: event.eventType,
          actorType: event.actorType,
          actorId: event.actorId,
          resourceType: event.resourceType,
          resourceId: event.resourceId,
          tenantId: event.tenantId,
          eventData: this.canonicalizeEventData(event.eventData),
          timestamp: event.timestamp.toISOString(),
          previousHash,
          sequence: event.chainSequence
        });
        return createHmac4("sha256", this.hmacKey).update(canonical).digest("hex");
      }
      /**
       * Canonicalize event data for consistent hashing
       */
      canonicalizeEventData(data) {
        if (data === null || data === void 0) return null;
        if (typeof data !== "object") return data;
        if (Array.isArray(data)) {
          return data.map((item) => this.canonicalizeEventData(item));
        }
        const sorted = {};
        Object.keys(data).sort().forEach((key) => {
          sorted[key] = this.canonicalizeEventData(data[key]);
        });
        return sorted;
      }
      /**
       * Get the last hash in the chain for a tenant
       */
      async getLastChainState(tenantId) {
        const result = await this.client.query(`
      SELECT chain_sequence, event_hash 
      FROM audit_chain_events
      WHERE tenant_id = $1
      ORDER BY chain_sequence DESC
      LIMIT 1
    `, [tenantId]);
        if (result.rows.length === 0) {
          const genesisHash = createHash14("sha256").update(`genesis:${tenantId}`).digest("hex");
          return { sequence: 0, hash: genesisHash };
        }
        return {
          sequence: result.rows[0].chain_sequence,
          hash: result.rows[0].event_hash
        };
      }
      /**
       * Append event to the tamper-evident chain
       */
      async appendEvent(event) {
        const lastState = await getLastChainState(event.tenantId);
        const nextSequence = lastState.sequence + 1;
        event.chainSequence = nextSequence;
        event.previousHash = lastState.hash;
        const eventHash = this.generateEventHash(event, lastState.hash);
        event.eventHash = eventHash;
        const result = await this.client.query(`
      INSERT INTO audit_chain_events (
        id, tenant_id, event_type, actor_type, actor_id,
        resource_type, resource_id, event_data, timestamp,
        previous_hash, event_hash, chain_sequence,
        created_at
      )
      VALUES (
        gen_random_uuid(), $1, $2, $3, $4,
        $5, $6, $7, $8,
        $9, $10, $11,
        now()
      )
      RETURNING id
    `, [
          event.tenantId,
          event.eventType,
          event.actorType,
          event.actorId,
          event.resourceType,
          event.resourceId,
          JSON.stringify(event.eventData),
          event.timestamp,
          event.previousHash,
          event.eventHash,
          event.chainSequence
        ]);
        return result.rows[0].id;
      }
      /**
       * Verify integrity of the audit chain
       */
      async verifyChainIntegrity(tenantId, fromSequence) {
        const startSequence = fromSequence || 1;
        const result = await this.client.query(`
      SELECT * FROM audit_chain_events
      WHERE tenant_id = $1 AND chain_sequence >= $2
      ORDER BY chain_sequence ASC
    `, [tenantId, startSequence]);
        const events = result.rows;
        if (events.length === 0) {
          return {
            intact: true,
            lastVerifiedSequence: 0,
            totalEvents: 0
          };
        }
        let lastHash = startSequence === 1 ? createHash14("sha256").update(`genesis:${tenantId}`).digest("hex") : events[0].previous_hash;
        for (let i = 0; i < events.length; i++) {
          const event = events[i];
          const expectedHash = this.generateEventHash({
            eventType: event.event_type,
            actorType: event.actor_type,
            actorId: event.actor_id,
            resourceType: event.resource_type,
            resourceId: event.resource_id,
            tenantId: event.tenant_id,
            eventData: event.event_data,
            timestamp: event.timestamp,
            chainSequence: event.chain_sequence
          }, lastHash);
          if (expectedHash !== event.event_hash) {
            return {
              intact: false,
              lastVerifiedSequence: i > 0 ? events[i - 1].chain_sequence : 0,
              brokenAt: event.chain_sequence,
              totalEvents: events.length
            };
          }
          if (i > 0 && event.previous_hash !== events[i - 1].event_hash) {
            return {
              intact: false,
              lastVerifiedSequence: events[i - 1].chain_sequence,
              brokenAt: event.chain_sequence,
              totalEvents: events.length
            };
          }
          lastHash = event.event_hash;
        }
        return {
          intact: true,
          lastVerifiedSequence: events[events.length - 1].chain_sequence,
          totalEvents: events.length
        };
      }
      /**
       * Get chain metadata for a tenant
       */
      async getChainMetadata(tenantId) {
        const lastState = await getLastChainState(tenantId);
        const verification = await this.verifyChainIntegrity(tenantId);
        return {
          tenantId,
          lastSequence: lastState.sequence,
          lastHash: lastState.hash,
          eventCount: verification.totalEvents,
          chainIntact: verification.intact,
          lastVerified: /* @__PURE__ */ new Date()
        };
      }
      /**
       * Export audit chain for compliance/legal purposes
       */
      async exportChain(tenantId, startDate, endDate) {
        let query = `
      SELECT * FROM audit_chain_events
      WHERE tenant_id = $1
    `;
        const params = [tenantId];
        if (startDate) {
          query += ` AND timestamp >= $${params.length + 1}`;
          params.push(startDate);
        }
        if (endDate) {
          query += ` AND timestamp <= $${params.length + 1}`;
          params.push(endDate);
        }
        query += ` ORDER BY chain_sequence ASC`;
        const result = await this.client.query(query, params);
        return result.rows.map((row) => ({
          id: row.id,
          eventType: row.event_type,
          actorType: row.actor_type,
          actorId: row.actor_id,
          resourceType: row.resource_type,
          resourceId: row.resource_id,
          tenantId: row.tenant_id,
          eventData: row.event_data,
          timestamp: row.timestamp,
          previousHash: row.previous_hash,
          eventHash: row.event_hash,
          chainSequence: row.chain_sequence
        }));
      }
    };
    chainManager = null;
  }
});

// src/security/routes.ts
import { Router as Router42 } from "express";
var router36, apiLimiter, authLimiter, wireTransferLimiter;
var init_routes5 = __esm({
  "src/security/routes.ts"() {
    "use strict";
    init_jwt();
    init_rbac();
    init_abac();
    init_headers();
    init_wire_fraud_protection();
    init_retention_policies();
    init_audit_chain();
    init_pii_protection();
    router36 = Router42();
    router36.use(configureSecurityHeaders());
    ({ apiLimiter, authLimiter, wireTransferLimiter } = configureRateLimiting());
    router36.use("/api/", apiLimiter);
    router36.use("/auth/", authLimiter);
    router36.post(
      "/api/wire-transfers",
      wireTransferLimiter,
      requireAuth4(),
      setTenantAndUserContext(),
      requirePerm("wire:request"),
      async (req, res) => {
        try {
          const { pool: pool17 } = await Promise.resolve().then(() => (init_db2(), db_exports2));
          const client5 = await pool17.connect();
          try {
            const wireService = new WireTransferService(client5, req.dbContext);
            const wireId = await wireService.submitRequest({
              loanId: req.body.loanId,
              amount: req.body.amount,
              recipientName: req.body.recipientName,
              recipientBank: req.body.recipientBank,
              recipientAccount: req.body.recipientAccount,
              recipientRouting: req.body.recipientRouting,
              purpose: req.body.purpose,
              requestedBy: req.user.sub,
              status: "pending",
              approvals: []
            });
            res.status(201).json({
              success: true,
              wireId,
              message: "Wire transfer request submitted for approval"
            });
          } finally {
            client5.release();
          }
        } catch (error) {
          console.error("[Security] Wire transfer request error:", error);
          res.status(500).json({ error: "Failed to submit wire transfer request" });
        }
      }
    );
    router36.post(
      "/api/wire-transfers/:wireId/approve",
      requireAuth4(),
      setTenantAndUserContext(),
      requirePerm("wire:approve"),
      async (req, res) => {
        try {
          const { pool: pool17 } = await Promise.resolve().then(() => (init_db2(), db_exports2));
          const client5 = await pool17.connect();
          try {
            const wireService = new WireTransferService(client5, req.dbContext);
            const approved = await wireService.approveTransfer(
              req.params.wireId,
              req.user.sub,
              req.user.roles?.[0] || "unknown",
              req.body.reason,
              req.ip,
              req.headers["user-agent"] || ""
            );
            res.json({
              success: true,
              approved,
              message: approved ? "Wire transfer approved and ready for execution" : "Approval recorded, waiting for additional approvals"
            });
          } finally {
            client5.release();
          }
        } catch (error) {
          console.error("[Security] Wire transfer approval error:", error);
          res.status(500).json({ error: "Failed to approve wire transfer" });
        }
      }
    );
    router36.post(
      "/api/wire-transfers/:wireId/reject",
      requireAuth4(),
      setTenantAndUserContext(),
      requirePerm("wire:approve"),
      async (req, res) => {
        try {
          const { pool: pool17 } = await Promise.resolve().then(() => (init_db2(), db_exports2));
          const client5 = await pool17.connect();
          try {
            const wireService = new WireTransferService(client5, req.dbContext);
            await wireService.rejectTransfer(
              req.params.wireId,
              req.user.sub,
              req.body.reason || "No reason provided",
              req.ip,
              req.headers["user-agent"] || ""
            );
            res.json({
              success: true,
              message: "Wire transfer rejected"
            });
          } finally {
            client5.release();
          }
        } catch (error) {
          console.error("[Security] Wire transfer rejection error:", error);
          res.status(500).json({ error: "Failed to reject wire transfer" });
        }
      }
    );
    router36.get(
      "/api/wire-transfers/:wireId",
      requireAuth4(),
      setTenantAndUserContext(),
      requirePerm("wire:request"),
      async (req, res) => {
        try {
          const { pool: pool17 } = await Promise.resolve().then(() => (init_db2(), db_exports2));
          const client5 = await pool17.connect();
          try {
            const wireService = new WireTransferService(client5, req.dbContext);
            const wire = await wireService.getWireTransfer(
              req.params.wireId,
              req.query.includePII === "true"
            );
            if (!wire) {
              return res.status(404).json({ error: "Wire transfer not found" });
            }
            res.json(wire);
          } finally {
            client5.release();
          }
        } catch (error) {
          console.error("[Security] Wire transfer retrieval error:", error);
          res.status(500).json({ error: "Failed to retrieve wire transfer" });
        }
      }
    );
    router36.post(
      "/api/loans/:loanId/pii",
      requireAuth4(),
      setTenantAndUserContext(),
      requireLoanAccess("write"),
      requirePerm("loan:write"),
      async (req, res) => {
        try {
          const { pool: pool17 } = await Promise.resolve().then(() => (init_db2(), db_exports2));
          const client5 = await pool17.connect();
          try {
            const piiRepo = new PIIRepository(client5, req.dbContext);
            await piiRepo.upsertBorrowerPII(req.params.loanId, req.body);
            res.json({
              success: true,
              message: "PII data encrypted and stored successfully"
            });
          } finally {
            client5.release();
          }
        } catch (error) {
          console.error("[Security] PII storage error:", error);
          res.status(500).json({ error: "Failed to store PII data" });
        }
      }
    );
    router36.get(
      "/api/loans/:loanId/pii",
      requireAuth4(),
      setTenantAndUserContext(),
      requireLoanAccess("read"),
      requirePerm("loan:read"),
      async (req, res) => {
        try {
          const { pool: pool17 } = await Promise.resolve().then(() => (init_db2(), db_exports2));
          const client5 = await pool17.connect();
          try {
            const piiRepo = new PIIRepository(client5, req.dbContext);
            const piiData = await piiRepo.getBorrowerPII(req.params.loanId);
            res.json({
              success: true,
              data: piiData
            });
          } finally {
            client5.release();
          }
        } catch (error) {
          console.error("[Security] PII retrieval error:", error);
          res.status(500).json({ error: "Failed to retrieve PII data" });
        }
      }
    );
    router36.get(
      "/api/retention/policies",
      requireAuth4(),
      setTenantAndUserContext(),
      requirePerm("retention:manage"),
      async (req, res) => {
        try {
          const { pool: pool17 } = await Promise.resolve().then(() => (init_db2(), db_exports2));
          const client5 = await pool17.connect();
          try {
            const retentionService = new RetentionService(client5, req.dbContext);
            const stats = await retentionService.getRetentionStats();
            res.json({
              success: true,
              data: stats
            });
          } finally {
            client5.release();
          }
        } catch (error) {
          console.error("[Security] Retention stats error:", error);
          res.status(500).json({ error: "Failed to retrieve retention statistics" });
        }
      }
    );
    router36.post(
      "/api/retention/legal-hold",
      requireAuth4(),
      setTenantAndUserContext(),
      requirePerm("retention:manage"),
      async (req, res) => {
        try {
          const { pool: pool17 } = await Promise.resolve().then(() => (init_db2(), db_exports2));
          const client5 = await pool17.connect();
          try {
            const retentionService = new RetentionService(client5, req.dbContext);
            await retentionService.applyLegalHold(
              req.body.tableName,
              req.body.reason,
              new Date(req.body.holdUntil),
              req.user.sub
            );
            res.json({
              success: true,
              message: `Legal hold applied to ${req.body.tableName}`
            });
          } finally {
            client5.release();
          }
        } catch (error) {
          console.error("[Security] Legal hold error:", error);
          res.status(500).json({ error: "Failed to apply legal hold" });
        }
      }
    );
    router36.delete(
      "/api/retention/legal-hold/:tableName",
      requireAuth4(),
      setTenantAndUserContext(),
      requirePerm("retention:manage"),
      async (req, res) => {
        try {
          const { pool: pool17 } = await Promise.resolve().then(() => (init_db2(), db_exports2));
          const client5 = await pool17.connect();
          try {
            const retentionService = new RetentionService(client5, req.dbContext);
            await retentionService.releaseLegalHold(req.params.tableName, req.user.sub);
            res.json({
              success: true,
              message: `Legal hold released for ${req.params.tableName}`
            });
          } finally {
            client5.release();
          }
        } catch (error) {
          console.error("[Security] Legal hold release error:", error);
          res.status(500).json({ error: "Failed to release legal hold" });
        }
      }
    );
    router36.get(
      "/api/audit/chain/verify",
      requireAuth4(),
      setTenantAndUserContext(),
      requirePerm("audit:read"),
      async (req, res) => {
        try {
          const auditChain = await getAuditChain();
          const verification = await auditChain.verifyChainIntegrity(req.dbContext.tenantId);
          res.json({
            success: true,
            chainIntegrity: verification
          });
        } catch (error) {
          console.error("[Security] Chain verification error:", error);
          res.status(500).json({ error: "Failed to verify audit chain" });
        }
      }
    );
    router36.get(
      "/api/audit/chain/metadata",
      requireAuth4(),
      setTenantAndUserContext(),
      requirePerm("audit:read"),
      async (req, res) => {
        try {
          const auditChain = await getAuditChain();
          const metadata = await auditChain.getChainMetadata(req.dbContext.tenantId);
          res.json({
            success: true,
            metadata
          });
        } catch (error) {
          console.error("[Security] Chain metadata error:", error);
          res.status(500).json({ error: "Failed to retrieve audit chain metadata" });
        }
      }
    );
    router36.get(
      "/api/audit/chain/export",
      requireAuth4(),
      setTenantAndUserContext(),
      requirePerm("audit:read"),
      async (req, res) => {
        try {
          const auditChain = await getAuditChain();
          const startDate = req.query.startDate ? new Date(req.query.startDate) : void 0;
          const endDate = req.query.endDate ? new Date(req.query.endDate) : void 0;
          const events = await auditChain.exportChain(req.dbContext.tenantId, startDate, endDate);
          res.json({
            success: true,
            events,
            totalCount: events.length
          });
        } catch (error) {
          console.error("[Security] Chain export error:", error);
          res.status(500).json({ error: "Failed to export audit chain" });
        }
      }
    );
    router36.get(
      "/api/security/health",
      requireAuth4(),
      setTenantAndUserContext(),
      requirePerm("security:manage"),
      async (req, res) => {
        try {
          const auditChain = await getAuditChain();
          const chainMetadata = await auditChain.getChainMetadata(req.dbContext.tenantId);
          const { pool: pool17 } = await Promise.resolve().then(() => (init_db2(), db_exports2));
          const client5 = await pool17.connect();
          try {
            const retentionService = new RetentionService(client5, req.dbContext);
            const retentionStats = await retentionService.getRetentionStats();
            res.json({
              success: true,
              security_status: {
                audit_chain_intact: chainMetadata.chainIntact,
                total_audit_events: chainMetadata.eventCount,
                retention_policies: retentionStats.totalPolicies,
                legal_holds_active: retentionStats.legalHolds,
                upcoming_retentions: retentionStats.upcomingRetentions.length,
                last_verified: chainMetadata.lastVerified
              }
            });
          } finally {
            client5.release();
          }
        } catch (error) {
          console.error("[Security] Health check error:", error);
          res.status(500).json({ error: "Failed to perform security health check" });
        }
      }
    );
  }
});

// src/security/oidc.ts
import * as openidClient from "openid-client";
async function getOidcClient() {
  if (_client) return _client;
  const issuer = await Issuer.discover(process.env.OIDC_ISSUER_URL);
  _client = new issuer.Client({
    client_id: process.env.OIDC_CLIENT_ID,
    client_secret: process.env.OIDC_CLIENT_SECRET,
    redirect_uris: [process.env.OIDC_REDIRECT_URI],
    response_types: ["code"]
  });
  return _client;
}
async function startLogin(req, res) {
  const client5 = await getOidcClient();
  const state = generators.state();
  const nonce = generators.nonce();
  req.session.oidc_state = state;
  req.session.oidc_nonce = nonce;
  const url = client5.authorizationUrl({
    scope: process.env.OIDC_SCOPES || "openid email profile",
    state,
    nonce
  });
  res.redirect(url);
}
async function callback(req, res) {
  try {
    const client5 = await getOidcClient();
    const params = client5.callbackParams(req);
    const tokenSet = await client5.callback(process.env.OIDC_REDIRECT_URI, params, {
      state: req.session.oidc_state,
      nonce: req.session.oidc_nonce
    });
    req.session.user = tokenSet.claims();
    res.redirect("/app");
  } catch (error) {
    console.error("[OIDC] Callback error:", error);
    res.status(400).json({ error: "Authentication failed" });
  }
}
var Issuer, generators, _client;
var init_oidc = __esm({
  "src/security/oidc.ts"() {
    "use strict";
    ({ Issuer, generators } = openidClient);
  }
});

// src/routes/oidc-routes.ts
import { Router as Router43 } from "express";
var oidcRouter;
var init_oidc_routes = __esm({
  "src/routes/oidc-routes.ts"() {
    "use strict";
    init_oidc();
    init_rbac();
    oidcRouter = Router43();
    oidcRouter.get("/auth/login", async (req, res) => {
      try {
        await startLogin(req, res);
      } catch (error) {
        console.error("[OIDC] Login initiation error:", error);
        res.status(500).json({
          error: "Authentication service unavailable",
          message: "Please try again later"
        });
      }
    });
    oidcRouter.get("/oauth/callback", async (req, res) => {
      try {
        await callback(req, res);
        if (req.session?.user) {
          setDefaultTenantRole(req.session.user, req.session.user.tenant_id);
        }
      } catch (error) {
        console.error("[OIDC] Callback error:", error);
        res.redirect("/login?error=authentication_failed");
      }
    });
    oidcRouter.post("/auth/logout", (req, res) => {
      if (req.session) {
        req.session.destroy((err) => {
          if (err) {
            console.error("[OIDC] Logout error:", err);
            return res.status(500).json({ error: "Logout failed" });
          }
          res.json({ success: true, message: "Logged out successfully" });
        });
      } else {
        res.json({ success: true, message: "Already logged out" });
      }
    });
    oidcRouter.get("/auth/me", (req, res) => {
      if (req.session?.user) {
        res.json({
          success: true,
          user: {
            sub: req.session.user.sub,
            email: req.session.user.email,
            name: req.session.user.name,
            roles: req.session.user.roles || [],
            tenant_id: req.session.user.tenant_id
          }
        });
      } else {
        res.status(401).json({
          error: "not_authenticated",
          message: "User not logged in"
        });
      }
    });
  }
});

// src/security/mTLS-stubs.ts
var mTLS_stubs_exports = {};
__export(mTLS_stubs_exports, {
  MTLSManager: () => MTLSManager,
  SecureServiceClient: () => SecureServiceClient,
  createDocumentServiceClient: () => createDocumentServiceClient,
  createInvestorServiceClient: () => createInvestorServiceClient,
  createPaymentServiceClient: () => createPaymentServiceClient,
  initializeMTLS: () => initializeMTLS
});
import https from "https";
import fs6 from "fs";
async function initializeMTLS(app2) {
  const mtlsManager = new MTLSManager();
  await mtlsManager.loadCertificates();
  const httpsServer = mtlsManager.createHTTPSServer(app2);
  app2.use("/api/services", mtlsManager.verifyClientCertificate());
  app2.get("/api/services/health", (req, res) => {
    res.json({
      status: "healthy",
      timestamp: /* @__PURE__ */ new Date(),
      mtls_enabled: !!req.clientCertInfo,
      client_cert: req.clientCertInfo || null
    });
  });
  console.log("[mTLS] Service-to-service communication initialized");
  return {
    httpsServer,
    mtlsManager
  };
}
var MTLSManager, SecureServiceClient, createInvestorServiceClient, createPaymentServiceClient, createDocumentServiceClient;
var init_mTLS_stubs = __esm({
  "src/security/mTLS-stubs.ts"() {
    "use strict";
    MTLSManager = class {
      config;
      ca = null;
      cert = null;
      key = null;
      constructor(config) {
        this.config = {
          caFile: process.env.MTLS_CA_FILE || "/etc/ssl/mtls/ca.crt",
          certFile: process.env.MTLS_CERT_FILE || "/etc/ssl/mtls/tls.crt",
          keyFile: process.env.MTLS_KEY_FILE || "/etc/ssl/mtls/tls.key",
          requireClientCert: true,
          verifyClientCert: true,
          ...config
        };
      }
      /**
       * Load TLS certificates
       */
      async loadCertificates() {
        try {
          if (fs6.existsSync(this.config.caFile)) {
            this.ca = fs6.readFileSync(this.config.caFile);
          }
          if (fs6.existsSync(this.config.certFile)) {
            this.cert = fs6.readFileSync(this.config.certFile);
          }
          if (fs6.existsSync(this.config.keyFile)) {
            this.key = fs6.readFileSync(this.config.keyFile);
          }
          console.log("[mTLS] Certificates loaded successfully");
        } catch (error) {
          console.warn("[mTLS] Certificate loading failed:", error);
          console.warn("[mTLS] mTLS will be disabled - ensure certificates are available for production");
        }
      }
      /**
       * Get HTTPS agent with mTLS configuration
       */
      getHTTPSAgent() {
        if (!this.cert || !this.key || !this.ca) {
          console.warn("[mTLS] Missing certificates, falling back to default HTTPS agent");
          return new https.Agent({
            rejectUnauthorized: false
            // Only for development
          });
        }
        return new https.Agent({
          cert: this.cert,
          key: this.key,
          ca: this.ca,
          rejectUnauthorized: true,
          requestCert: true,
          checkServerIdentity: (host, cert) => {
            return void 0;
          }
        });
      }
      /**
       * Express middleware for mTLS client certificate verification
       */
      verifyClientCertificate() {
        return (req, res, next) => {
          if (!this.config.requireClientCert) {
            return next();
          }
          const clientCert = req.connection?.getPeerCertificate?.();
          if (!clientCert || clientCert.subject === void 0) {
            return res.status(401).json({
              error: "client_certificate_required",
              message: "Valid client certificate required for this endpoint"
            });
          }
          req.clientCertInfo = {
            subject: clientCert.subject,
            issuer: clientCert.issuer,
            serialNumber: clientCert.serialNumber,
            fingerprint: clientCert.fingerprint,
            valid: clientCert.valid_from && clientCert.valid_to
          };
          console.log(`[mTLS] Client certificate verified: ${clientCert.subject?.CN || "unknown"}`);
          next();
        };
      }
      /**
       * Create HTTPS server with mTLS support
       */
      createHTTPSServer(app2) {
        if (!this.cert || !this.key) {
          console.warn("[mTLS] Cannot create HTTPS server - missing certificates");
          return null;
        }
        const serverOptions = {
          cert: this.cert,
          key: this.key,
          requestCert: this.config.requireClientCert,
          rejectUnauthorized: this.config.verifyClientCert
        };
        if (this.ca) {
          serverOptions.ca = this.ca;
        }
        const server = https.createServer(serverOptions, app2);
        console.log("[mTLS] HTTPS server with mTLS support created");
        return server;
      }
    };
    SecureServiceClient = class {
      mtlsManager;
      baseUrl;
      constructor(baseUrl, mtlsConfig) {
        this.baseUrl = baseUrl;
        this.mtlsManager = new MTLSManager(mtlsConfig);
      }
      /**
       * Initialize the client (load certificates)
       */
      async initialize() {
        await this.mtlsManager.loadCertificates();
      }
      /**
       * Make secure HTTP request to another service
       */
      async request(method, path11, data, headers) {
        const url = `${this.baseUrl}${path11}`;
        const agent = this.mtlsManager.getHTTPSAgent();
        const requestOptions = {
          method,
          headers: {
            "Content-Type": "application/json",
            "User-Agent": "LoanServe-Service-Client/1.0",
            ...headers
          }
        };
        if (url.startsWith("https://")) {
          requestOptions.agent = agent;
        }
        try {
          const fetch2 = (await import("node-fetch")).default;
          const response = await fetch2(url, {
            ...requestOptions,
            body: data ? JSON.stringify(data) : void 0,
            agent: url.startsWith("https://") ? agent : void 0
          });
          if (!response.ok) {
            throw new Error(`Service request failed: ${response.status} ${response.statusText}`);
          }
          const responseData = await response.json();
          return responseData;
        } catch (error) {
          console.error(`[ServiceClient] Request to ${url} failed:`, error);
          throw error;
        }
      }
      /**
       * Health check endpoint
       */
      async healthCheck() {
        try {
          const response = await this.request("GET", "/health");
          return {
            status: "healthy",
            timestamp: /* @__PURE__ */ new Date(),
            ...response
          };
        } catch (error) {
          return {
            status: "unhealthy",
            timestamp: /* @__PURE__ */ new Date(),
            error: error.message
          };
        }
      }
    };
    createInvestorServiceClient = () => new SecureServiceClient(
      process.env.INVESTOR_SERVICE_URL || "https://investor.loanserve.io"
    );
    createPaymentServiceClient = () => new SecureServiceClient(
      process.env.PAYMENT_SERVICE_URL || "https://payments.loanserve.io"
    );
    createDocumentServiceClient = () => new SecureServiceClient(
      process.env.DOCUMENT_SERVICE_URL || "https://docs.loanserve.io"
    );
  }
});

// src/security/integration.ts
var integration_exports = {};
__export(integration_exports, {
  auditSecurityEvent: () => auditSecurityEvent,
  initializeSecurity: () => initializeSecurity,
  protectSensitiveOperation: () => protectSensitiveOperation,
  validateSecurityConfig: () => validateSecurityConfig
});
async function initializeSecurity(app2) {
  console.log("[Security] Initializing comprehensive security hardening...");
  app2.use(configureSecurityHeaders());
  app2.use("/api", apiSecurityHeaders());
  app2.use(oidcRouter);
  console.log("[Security] OIDC authentication routes registered");
  app2.use(router36);
  console.log("[Security] Security API routes registered");
  console.log("[Security] Data retention integrated with ETL Scheduler (replaces node-cron)");
  try {
    const { initializeMTLS: initializeMTLS2 } = await Promise.resolve().then(() => (init_mTLS_stubs(), mTLS_stubs_exports));
    const { httpsServer, mtlsManager } = await initializeMTLS2(app2);
    console.log("[Security] mTLS service communication initialized");
  } catch (error) {
    console.warn("[Security] mTLS not available - certificates not found (normal for development)");
  }
  try {
    const { getAuditChain: getAuditChain2 } = await Promise.resolve().then(() => (init_audit_chain(), audit_chain_exports));
    await getAuditChain2();
    console.log("[Security] Tamper-evident audit chain initialized");
  } catch (error) {
    console.error("[Security] Failed to initialize audit chain:", error);
  }
  console.log("[Security] \u2705 Security hardening initialization complete");
  console.log("[Security] Features enabled:");
  console.log("[Security] - OIDC SSO authentication");
  console.log("[Security] - JWT API token verification");
  console.log("[Security] - RBAC/ABAC authorization");
  console.log("[Security] - Field-level PII encryption (KMS/Vault)");
  console.log("[Security] - Wire fraud protection with multi-approval");
  console.log("[Security] - Tamper-evident audit hash chain");
  console.log("[Security] - Data retention with legal hold support");
  console.log("[Security] - Security headers and CSP");
  console.log("[Security] - Rate limiting and DDoS protection");
}
function protectSensitiveOperation() {
  const { requireAuth: requireAuth5 } = (init_jwt(), __toCommonJS(jwt_exports));
  const { setTenantAndUserContext: setTenantAndUserContext2 } = (init_abac(), __toCommonJS(abac_exports));
  const { requirePerm: requirePerm2 } = (init_rbac(), __toCommonJS(rbac_exports));
  return [
    requireAuth5(),
    setTenantAndUserContext2(),
    requirePerm2("security:manage")
  ];
}
async function auditSecurityEvent(eventType, actorId, resourceType, resourceId, tenantId, eventData) {
  try {
    const { getAuditChain: getAuditChain2 } = await Promise.resolve().then(() => (init_audit_chain(), audit_chain_exports));
    const auditChain = await getAuditChain2();
    await auditChain.appendEvent({
      eventType: `SECURITY.${eventType}`,
      actorType: "user",
      actorId,
      resourceType,
      resourceId,
      tenantId,
      eventData,
      timestamp: /* @__PURE__ */ new Date()
    });
  } catch (error) {
    console.error("[Security] Failed to log audit event:", error);
  }
}
function validateSecurityConfig() {
  const errors = [];
  if (!process.env.OIDC_ISSUER_URL) {
    errors.push("OIDC_ISSUER_URL not configured");
  }
  if (!process.env.OIDC_CLIENT_ID) {
    errors.push("OIDC_CLIENT_ID not configured");
  }
  if (!process.env.OIDC_CLIENT_SECRET) {
    errors.push("OIDC_CLIENT_SECRET not configured");
  }
  if (!process.env.JWKS_URL) {
    errors.push("JWKS_URL not configured");
  }
  if (!process.env.JWT_AUDIENCE) {
    errors.push("JWT_AUDIENCE not configured");
  }
  if (!process.env.KMS_KEY_ARN) {
    errors.push("KMS_KEY_ARN not configured - field-level encryption disabled");
  }
  if (!process.env.VAULT_ADDR) {
    errors.push("VAULT_ADDR not configured - using fallback key storage");
  }
  if (!process.env.AUDIT_CHAIN_KEY) {
    console.warn("[Security] AUDIT_CHAIN_KEY not configured - using default key (not recommended for production)");
  }
  if (errors.length > 0) {
    console.error("[Security] Configuration errors:", errors);
  }
  return {
    valid: errors.length === 0,
    errors
  };
}
var init_integration = __esm({
  "src/security/integration.ts"() {
    "use strict";
    init_routes5();
    init_oidc_routes();
    init_headers();
  }
});

// src/repo/canonical.ts
async function loadCanonicalAndDocs(loanId) {
  try {
    const loanResult = await pool.query(`SELECT * FROM loans WHERE id = $1`, [loanId]);
    const loan = loanResult.rows[0] || {};
    let property = {};
    if (loan.property_id) {
      const propResult = await pool.query(`SELECT * FROM properties WHERE id = $1`, [loan.property_id]);
      property = propResult.rows[0] || {};
    }
    const canonical = {
      LoanNumber: loan.loan_number,
      BorrowerFullName: loan.borrower_name,
      NoteAmount: loan.original_amount,
      InterestRate: loan.interest_rate,
      AmortTermMonths: loan.amortization_term,
      PropertyStreet: property.street_address || loan.borrower_address,
      PropertyCity: property.city || loan.borrower_city,
      PropertyState: property.state || loan.borrower_state,
      PropertyZip: property.zip_code || loan.borrower_zip,
      ...loan
    };
    const docs = [];
    return { canonical, evidence: {}, docs };
  } catch (error) {
    console.error("[Canonical] Error loading canonical data:", error);
    throw error;
  }
}
async function loadQcSnapshot(loanId) {
  try {
    const rules = { rowCount: 5, rows: [
      { id: 1, code: "R001", name: "Income Verification", severity: "Warning" },
      { id: 2, code: "R002", name: "Property Appraisal", severity: "Critical" },
      { id: 3, code: "R003", name: "Credit Score Check", severity: "Warning" },
      { id: 4, code: "R004", name: "DTI Calculation", severity: "Major" },
      { id: 5, code: "R005", name: "Title Insurance", severity: "Minor" }
    ] };
    const open = { rows: [] };
    const waived = { rows: [] };
    return { rules, open, waived };
  } catch (error) {
    console.error("[QC] Error loading QC snapshot:", error);
    throw error;
  }
}
var init_canonical = __esm({
  "src/repo/canonical.ts"() {
    "use strict";
    init_db();
  }
});

// src/utils/pdf.ts
import PDFDocument3 from "pdfkit";
function renderCertificatePdf(input) {
  const doc = new PDFDocument3({ size: "LETTER", margin: 50 });
  const buffers = [];
  doc.on("data", (b) => buffers.push(b));
  doc.on("pageAdded", () => addWatermark(doc, input.watermark));
  doc.fontSize(18).text(input.header, { align: "center" }).moveDown(0.5);
  addWatermark(doc, input.watermark);
  doc.fontSize(12);
  doc.text(`Loan Number: ${input.loan?.LoanNumber || "(unknown)"}`);
  doc.text(`Borrower: ${input.canonical.BorrowerFullName || "(unknown)"}`);
  doc.text(`Property: ${[
    input.canonical.PropertyStreet,
    input.canonical.PropertyCity,
    input.canonical.PropertyState,
    input.canonical.PropertyZip
  ].filter(Boolean).join(", ") || "(unknown)"}`);
  doc.moveDown(0.5);
  doc.text(`Note Amount: ${input.canonical.NoteAmount ?? "(unknown)"}`);
  doc.text(`Interest Rate: ${input.canonical.InterestRate ?? "(unknown)"}%`);
  doc.text(`Term (months): ${input.canonical.AmortTermMonths ?? "(unknown)"}`);
  doc.moveDown();
  doc.fontSize(14).text("QC Result Summary", { underline: true }).moveDown(0.3);
  doc.fontSize(12).text(`Rules Passed: ${input.stats.passed} / ${input.stats.total}`);
  doc.text(`Issued By: ${input.issued_by}`);
  doc.moveDown(0.5);
  doc.fontSize(10).text(`Docset SHA-256: ${input.hashes.docset}`);
  doc.text(`Canonical SHA-256: ${input.hashes.canonical}`);
  doc.moveDown(0.5);
  if (input.waivers?.length) {
    doc.fontSize(12).text("Waivers", { underline: true }).moveDown(0.2);
    input.waivers.forEach((w, i) => {
      doc.fontSize(10).text(`${i + 1}. ${w.code} \u2014 ${w.name} [${w.severity}]`);
      doc.text(`   Message: ${w.message}`);
      if (w.resolved_at) doc.text(`   Waived at: ${new Date(w.resolved_at).toISOString()}`);
      doc.moveDown(0.2);
    });
  }
  doc.end();
  return new Promise((resolve) => {
    doc.on("end", () => resolve(Buffer.concat(buffers)));
  });
}
function renderDiscrepancyPdf(input) {
  const doc = new PDFDocument3({ size: "LETTER", margin: 50 });
  const buffers = [];
  doc.on("data", (b) => buffers.push(b));
  doc.fontSize(18).text(input.header, { align: "center" }).moveDown(0.5);
  doc.fontSize(12).text(`Loan Number: ${input.loan?.LoanNumber || "(unknown)"}`);
  doc.text(`Property: ${input.loan?.PropertyStreet || ""} ${input.loan?.PropertyCity || ""} ${input.loan?.PropertyState || ""} ${input.loan?.PropertyZip || ""}`);
  doc.moveDown();
  doc.fontSize(14).text("Summary", { underline: true }).moveDown(0.2);
  doc.fontSize(11).text(input.summaryText || "(No summary)").moveDown(0.5);
  doc.fontSize(14).text("Open QC Defects", { underline: true }).moveDown(0.2);
  if (input.openDefects.length === 0) {
    doc.text("None").moveDown(0.5);
  } else {
    input.openDefects.forEach((d, i) => {
      doc.fontSize(11).text(`${i + 1}. ${d.code} \u2022 ${d.severity} \u2022 ${d.name}`);
      doc.fontSize(10).text(`   ${d.message}`).moveDown(0.2);
    });
  }
  doc.fontSize(14).text("Unresolved Conflicts", { underline: true }).moveDown(0.2);
  if (input.conflicts.length === 0) {
    doc.text("None");
  } else {
    input.conflicts.forEach((c, i) => {
      doc.fontSize(11).text(`${i + 1}. ${c.key}`);
      doc.fontSize(10).text(`   Candidates: ${JSON.stringify(c.candidates).slice(0, 400)}...`).moveDown(0.2);
    });
  }
  doc.end();
  return new Promise((resolve) => {
    doc.on("end", () => resolve(Buffer.concat(buffers)));
  });
}
function addWatermark(doc, text2) {
  if (!text2) return;
  const { width, height } = doc.page;
  doc.save();
  doc.fillColor("#cccccc");
  doc.fontSize(48);
  doc.rotate(-30, { origin: [width / 2, height / 2] });
  doc.opacity(0.2).text(text2, width / 2 - 200, height / 2 - 50);
  doc.opacity(1).rotate(30, { origin: [width / 2, height / 2] });
  doc.restore();
}
var init_pdf = __esm({
  "src/utils/pdf.ts"() {
    "use strict";
  }
});

// src/utils/hash.ts
import { createHash as createHash15 } from "crypto";
function sha256Buf(buf) {
  return createHash15("sha256").update(buf).digest("hex");
}
function sha256Json(obj) {
  return sha256Buf(Buffer.from(JSON.stringify(obj)));
}
var init_hash = __esm({
  "src/utils/hash.ts"() {
    "use strict";
  }
});

// src/discrepancy/summary.ts
async function summarizeDiscrepancies(input) {
  const provider = (process.env.DR_AI_PROVIDER || "mock").toLowerCase();
  if (provider === "openai") {
    return openAiSummary(input);
  }
  const lines = [
    `Open defects: ${input.openDefects.length}`,
    `Unresolved conflicts: ${input.conflicts.length}`,
    ...input.openDefects.slice(0, 10).map((d) => `\u2022 [${d.severity}] ${d.code}: ${d.name}`),
    ...input.conflicts.slice(0, 10).map((c) => `\u2022 Conflict on ${c.key}`)
  ];
  return lines.join("\n");
}
async function openAiSummary(input) {
  const key = process.env.OPENAI_API_KEY;
  const mdl = process.env.DR_AI_MODEL || "gpt-4o-mini";
  const prompt = `Summarize these QC issues and conflicts for an investor-facing discrepancy report. Be concise and actionable.
Defects: ${JSON.stringify(input.openDefects).slice(0, 5e3)}
Conflicts: ${JSON.stringify(input.conflicts).slice(0, 5e3)}
`;
  const res = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: { "Authorization": `Bearer ${key}`, "Content-Type": "application/json" },
    body: JSON.stringify({
      model: mdl,
      temperature: 0,
      max_tokens: Number(process.env.DR_SUMMARY_MAX_TOKENS || 800),
      messages: [
        { role: "system", content: "You are a precise summarizer." },
        { role: "user", content: prompt }
      ]
    })
  });
  if (!res.ok) throw new Error(`OpenAI DR summary error ${res.status}: ${await res.text()}`);
  const json2 = await res.json();
  return json2.choices?.[0]?.message?.content?.trim() || "(summary unavailable)";
}
var init_summary = __esm({
  "src/discrepancy/summary.ts"() {
    "use strict";
  }
});

// src/servicing/amort.ts
function calcMonthlyPI(noteAmount, annualRatePct, termMonths) {
  const r = annualRatePct / 100 / 12;
  if (r === 0) return round2(noteAmount / termMonths);
  const pmt = noteAmount * (r * Math.pow(1 + r, termMonths)) / (Math.pow(1 + r, termMonths) - 1);
  return round2(pmt);
}
function buildSchedule(params) {
  const { noteAmount, annualRatePct, termMonths, firstPaymentDate, escrowMonthly } = params;
  const pi = calcMonthlyPI(noteAmount, annualRatePct, termMonths);
  const r = annualRatePct / 100 / 12;
  const rows = [];
  let bal = noteAmount;
  let d = new Date(firstPaymentDate);
  for (let n = 1; n <= termMonths; n++) {
    const interest = round2(bal * r);
    const principal = round2(pi - interest);
    const escrow = round2(escrowMonthly);
    const total = round2(principal + interest + escrow);
    bal = round2(bal - principal);
    rows.push({
      installment_no: n,
      due_date: toISO(addMonths2(d, n - 1)),
      principal_due: principal,
      interest_due: interest,
      escrow_due: escrow,
      total_due: total,
      principal_balance_after: Math.max(0, bal)
    });
  }
  return { pi, rows };
}
function estimateEscrowMonthly(inputs) {
  const inf = inputs.inflationPct ?? 0.03;
  const next = (amt) => round2((amt ?? 0) * (1 + inf));
  const buckets2 = {
    TAX: round2(next(inputs.taxAnnual) / 12),
    HOI: round2(next(inputs.hoiAnnual) / 12),
    FLOOD: round2(next(inputs.floodAnnual) / 12),
    HOA: round2((inputs.hoaAnnual ?? 0) / 12)
  };
  const monthly = round2(buckets2.TAX + buckets2.HOI + buckets2.FLOOD + buckets2.HOA);
  return { monthly, buckets: buckets2 };
}
function addMonths2(date2, months) {
  const d = new Date(date2);
  d.setMonth(d.getMonth() + months);
  return d;
}
function toISO(d) {
  return d.toISOString().slice(0, 10);
}
function round2(n) {
  return Math.round((n + Number.EPSILON) * 100) / 100;
}
var init_amort = __esm({
  "src/servicing/amort.ts"() {
    "use strict";
  }
});

// src/servicing/boarding.ts
var boarding_exports = {};
__export(boarding_exports, {
  boardLoan: () => boardLoan
});
async function boardLoan(tenantId, loanId) {
  const client5 = await pool.connect();
  try {
    const loanData = await client5.query(`
      SELECT original_amount, interest_rate, loan_term, first_payment_date, maturity_date, monthly_escrow, escrow_required
      FROM loans WHERE id = $1
    `, [loanId]);
    if (loanData.rows.length === 0) {
      throw new Error(`Loan ${loanId} not found`);
    }
    const loan = loanData.rows[0];
    const noteAmount = Number(loan.original_amount);
    const interestRate = Number(loan.interest_rate);
    const termMonths = Number(loan.loan_term);
    const firstPaymentDate = loan.first_payment_date?.toISOString().split("T")[0] || "2025-02-01";
    const maturityDate = loan.maturity_date?.toISOString().split("T")[0] || "2055-02-01";
    const escrowRequired = Boolean(loan.escrow_required);
    if (!noteAmount || !interestRate || !termMonths || !firstPaymentDate || !maturityDate) {
      throw new Error("Missing required canonical fields for boarding");
    }
    const taxAnnual = Number(loan.property_tax) * 12 || 8e3;
    const hoiAnnual = Number(loan.home_insurance) * 12 || 1200;
    const floodAnnual = void 0;
    const hoaAnnual = Number(loan.hoa_fees) * 12 || void 0;
    const esc = estimateEscrowMonthly({
      taxAnnual,
      hoiAnnual,
      floodAnnual,
      hoaAnnual,
      cushionMonths: Number(process.env.ESCROW_CUSHION_MONTHS || "2"),
      inflationPct: Number(process.env.ESCROW_ANALYSIS_INFLATION_PCT || "0.03")
    });
    const escrowMonthly = escrowRequired ? esc.monthly : 0;
    const sched = buildSchedule({
      noteAmount,
      annualRatePct: interestRate,
      termMonths,
      firstPaymentDate,
      escrowMonthly
    });
    const graceDays2 = Number(process.env.BOARDING_GRACE_DAYS_DEFAULT || "15");
    await client5.query(`
      INSERT INTO svc_accounts (tenant_id, loan_id, state, open_date, first_payment_date, maturity_date, note_amount, interest_rate,
                                amort_term_months, payment_frequency, pmt_principal_interest, grace_days, escrow_required, activated_at)
      VALUES ($1,$2,'Active', CURRENT_DATE, $3, $4, $5, $6, $7, 'Monthly', $8, $9, $10, now())
      ON CONFLICT (loan_id) DO UPDATE SET 
        state = 'Active',
        activated_at = now(),
        pmt_principal_interest = EXCLUDED.pmt_principal_interest,
        escrow_required = EXCLUDED.escrow_required
    `, [tenantId, loanId, firstPaymentDate, maturityDate, noteAmount, interestRate, termMonths, sched.pi, graceDays2, escrowRequired]);
    const buckets2 = esc.buckets;
    for (const [k, v] of Object.entries(buckets2)) {
      await client5.query(`
        INSERT INTO svc_escrow_sub (tenant_id, loan_id, bucket, monthly_accrual, cushion_months, balance)
        VALUES ($1,$2,$3,$4,$5,0)
        ON CONFLICT (loan_id, bucket) DO UPDATE SET 
          monthly_accrual=EXCLUDED.monthly_accrual, 
          cushion_months=EXCLUDED.cushion_months
      `, [tenantId, loanId, k, v, Number(process.env.ESCROW_CUSHION_MONTHS || "2")]);
    }
    const upsertVendor = async (type, name, address, phone, email) => {
      await client5.query(`
        INSERT INTO svc_vendors (tenant_id, loan_id, type, name, address, phone, email)
        VALUES ($1,$2,$3,$4,$5,$6,$7)
        ON CONFLICT (loan_id, type) DO UPDATE SET name = EXCLUDED.name
      `, [tenantId, loanId, type, name || `${type} Vendor`, address || null, phone || null, email || null]);
    };
    await upsertVendor("TAX", process.env.VENDOR_TAX_DEFAULT_NAME || "Tax Authority");
    await upsertVendor("HOI", process.env.VENDOR_HOI_DEFAULT_NAME || "HOI Carrier");
    await upsertVendor("FLOOD", process.env.VENDOR_FLOOD_DEFAULT_NAME || "NFIP");
    await upsertVendor("HOA", process.env.VENDOR_HOA_DEFAULT_NAME || "HOA");
    for (const r of sched.rows) {
      await client5.query(`
        INSERT INTO svc_schedule (tenant_id, loan_id, installment_no, due_date, principal_due, interest_due, escrow_due, total_due, principal_balance_after)
        VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9)
        ON CONFLICT (loan_id, installment_no) DO NOTHING
      `, [tenantId, loanId, r.installment_no, r.due_date, r.principal_due, r.interest_due, r.escrow_due, r.total_due, r.principal_balance_after]);
    }
    await client5.query(`
      INSERT INTO svc_txns (tenant_id, loan_id, ts, type, amount, currency, alloc_principal, memo, ref)
      VALUES ($1,$2, now(), 'BOARDING', $3, 'USD', $3, 'Boarding entry', '{}')
    `, [tenantId, loanId, noteAmount]);
    await client5.query(`
      INSERT INTO gl_entries (tenant_id, loan_id, ts, debit_acct, credit_acct, amount, memo)
      VALUES ($1,$2, now(), $3, $4, $5, 'Boarding opening principal')
    `, [tenantId, loanId, Number(process.env.GL_LOAN_PRINCIPAL_ACCT || "1100"), Number(process.env.GL_RETAINED_EARNINGS_ACCT || "3000"), noteAmount]);
    return { p_i: sched.pi, escrow_monthly: escrowMonthly, first_due_date: firstPaymentDate };
  } finally {
    client5.release();
  }
}
var init_boarding = __esm({
  "src/servicing/boarding.ts"() {
    "use strict";
    init_db();
    init_amort();
  }
});

// src/finalize/engine.ts
async function finalizeLoan(loanId, userId) {
  try {
    const loanResult = await pool.query(`SELECT state FROM loans WHERE id = $1`, [loanId]);
    if (loanResult.rows.length === 0) {
      throw new Error("Loan not found");
    }
    if (loanResult.rows[0].state === "finalized") {
      throw new Error("Loan already finalized");
    }
    const { canonical, evidence, docs } = await loadCanonicalAndDocs(loanId);
    const qc = await loadQcSnapshot(loanId);
    const conflicts = { rows: [] };
    const openDefects = qc.open.rows;
    const summaryText = await summarizeDiscrepancies({
      openDefects: openDefects.map((d) => ({ code: d.code, name: d.name, severity: d.severity, message: d.message })),
      conflicts: conflicts.rows
    });
    const docsetHash = sha256Json(docs);
    const canonicalHash = sha256Json(canonical);
    const totalRules = qc.rules.rowCount || 0;
    const openDefectCount = openDefects.length;
    const passedRules = Math.max(0, totalRules - openDefectCount);
    const certPdfData = await renderCertificatePdf({
      header: process.env.CERT_PDF_HEADER || "LoanServe \u2022 QC Certificate",
      watermark: process.env.CERT_PDF_WATERMARK || "LoanServe \u2022 DO NOT ALTER",
      loan: canonical,
      canonical,
      stats: { passed: passedRules, total: totalRules },
      hashes: { docset: docsetHash, canonical: canonicalHash },
      waivers: qc.waived.rows,
      issued_by: process.env.CERT_ISSUER_NAME || "LoanServe QC Engine"
    });
    const drPdfData = await renderDiscrepancyPdf({
      header: "Loan Discrepancy Report",
      loan: canonical,
      openDefects,
      conflicts: conflicts.rows,
      summaryText
    });
    const version = process.env.FINALIZE_VERSION || "v2025.09.03";
    const certKey = `${process.env.CERT_S3_PREFIX || "certificates"}/${loanId}/qc-cert-${version}.pdf`;
    const drKey = `${process.env.DR_S3_PREFIX || "discrepancy-reports"}/${loanId}/discrepancy-report.pdf`;
    const certUri = `file:///finalize/${certKey}`;
    const drUri = `file:///finalize/${drKey}`;
    await pool.query(`
      INSERT INTO qc_certificates (
        loan_id, version, file_uri, file_sha256, 
        docset_sha256, canonical_sha256, rules_passed, rules_total, 
        waivers, issued_by
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
    `, [
      loanId,
      version,
      certUri,
      sha256Buf(certPdfData),
      docsetHash,
      canonicalHash,
      passedRules,
      totalRules,
      JSON.stringify(qc.waived.rows),
      process.env.CERT_ISSUER_EMAIL || "qc@loanserve.io"
    ]);
    await pool.query(`
      INSERT INTO discrepancy_reports (loan_id, file_uri, file_sha256, summary)
      VALUES ($1, $2, $3, $4)
    `, [
      loanId,
      drUri,
      sha256Buf(drPdfData),
      JSON.stringify({
        openDefectCount: openDefects.length,
        conflictCount: conflicts.rows.length,
        summaryText,
        generatedAt: (/* @__PURE__ */ new Date()).toISOString()
      })
    ]);
    await pool.query(`
      UPDATE loans 
      SET state = 'finalized', finalized_at = now(), finalized_by = $2
      WHERE id = $1
    `, [loanId, userId]);
    console.log(`[Finalize] Loan ${loanId} finalized with certificate ${certUri}`);
    try {
      const { boardLoan: boardLoan2 } = await Promise.resolve().then(() => (init_boarding(), boarding_exports));
      const tenantId = "00000000-0000-0000-0000-000000000001";
      console.log(`[Finalize] Triggering boarding for loan ${loanId}`);
      const boardingResult = await boardLoan2(tenantId, loanId);
      console.log(`[Finalize] Boarding completed for loan ${loanId}:`, boardingResult);
    } catch (boardingError) {
      console.error(`[Finalize] Boarding failed for loan ${loanId}:`, boardingError);
    }
    return {
      success: true,
      certificateUri: certUri,
      discrepancyReportUri: drUri,
      stats: {
        rulesPassedTotal: `${passedRules}/${totalRules}`,
        openDefects: openDefects.length,
        conflicts: conflicts.rowCount || 0
      },
      hashes: {
        docset: docsetHash,
        canonical: canonicalHash
      }
    };
  } catch (error) {
    console.error("[Finalize] Error finalizing loan:", error);
    throw error;
  }
}
async function canFinalizeLoan(loanId) {
  try {
    const reasons = [];
    const loanResult = await pool.query(`SELECT state FROM loans WHERE id = $1`, [loanId]);
    if (loanResult.rows.length === 0) {
      reasons.push("Loan not found");
    } else if (loanResult.rows[0].state === "finalized") {
      reasons.push("Loan already finalized");
    }
    return {
      canFinalize: reasons.length === 0,
      reasons
    };
  } catch (error) {
    console.error("[Finalize] Error checking loan eligibility:", error);
    throw error;
  }
}
async function getFinalizationStatus(loanId) {
  try {
    const loanResult = await pool.query(`
      SELECT state, finalized_at, finalized_by 
      FROM loans WHERE id = $1
    `, [loanId]);
    if (loanResult.rows.length === 0) {
      throw new Error("Loan not found");
    }
    const loan = loanResult.rows[0];
    const certResult = await pool.query(`
      SELECT version, file_uri, issued_by, issued_at, rules_passed, rules_total
      FROM qc_certificates 
      WHERE loan_id = $1 
      ORDER BY issued_at DESC LIMIT 1
    `, [loanId]);
    const drResult = await pool.query(`
      SELECT file_uri, summary, generated_at
      FROM discrepancy_reports 
      WHERE loan_id = $1 
      ORDER BY generated_at DESC LIMIT 1
    `, [loanId]);
    return {
      state: loan.state,
      finalizedAt: loan.finalized_at,
      finalizedBy: loan.finalized_by,
      certificate: certResult.rows.length > 0 ? certResult.rows[0] : null,
      discrepancyReport: drResult.rows.length > 0 ? drResult.rows[0] : null
    };
  } catch (error) {
    console.error("[Finalize] Error getting finalization status:", error);
    throw error;
  }
}
var init_engine3 = __esm({
  "src/finalize/engine.ts"() {
    "use strict";
    init_db();
    init_canonical();
    init_pdf();
    init_hash();
    init_summary();
  }
});

// src/finalize/routes.ts
var routes_exports5 = {};
__export(routes_exports5, {
  finalizeRouter: () => finalizeRouter
});
import { Router as Router44 } from "express";
var finalizeRouter;
var init_routes6 = __esm({
  "src/finalize/routes.ts"() {
    "use strict";
    init_engine3();
    finalizeRouter = Router44();
    finalizeRouter.post("/api/finalize/:loanId", async (req, res) => {
      try {
        const { loanId } = req.params;
        const userId = req.user?.id || 1;
        const loanIdNum = parseInt(loanId);
        if (isNaN(loanIdNum)) {
          return res.status(400).json({ error: "Invalid loan ID" });
        }
        const eligibility = await canFinalizeLoan(loanIdNum);
        if (!eligibility.canFinalize) {
          return res.status(400).json({
            error: "Cannot finalize loan",
            reasons: eligibility.reasons
          });
        }
        const result = await finalizeLoan(loanIdNum, userId);
        res.json({
          success: true,
          message: "Loan finalized successfully",
          data: result
        });
      } catch (error) {
        console.error("[Finalize] Error finalizing loan:", error);
        res.status(500).json({
          error: "Failed to finalize loan",
          message: error instanceof Error ? error.message : "Unknown error"
        });
      }
    });
    finalizeRouter.get("/api/finalize/:loanId/status", async (req, res) => {
      try {
        const { loanId } = req.params;
        const loanIdNum = parseInt(loanId);
        if (isNaN(loanIdNum)) {
          return res.status(400).json({ error: "Invalid loan ID" });
        }
        const status = await getFinalizationStatus(loanIdNum);
        res.json({
          success: true,
          data: status
        });
      } catch (error) {
        console.error("[Finalize] Error getting finalization status:", error);
        res.status(500).json({
          error: "Failed to get finalization status",
          message: error instanceof Error ? error.message : "Unknown error"
        });
      }
    });
    finalizeRouter.get("/api/finalize/:loanId/eligibility", async (req, res) => {
      try {
        const { loanId } = req.params;
        const loanIdNum = parseInt(loanId);
        if (isNaN(loanIdNum)) {
          return res.status(400).json({ error: "Invalid loan ID" });
        }
        const eligibility = await canFinalizeLoan(loanIdNum);
        res.json({
          success: true,
          data: eligibility
        });
      } catch (error) {
        console.error("[Finalize] Error checking eligibility:", error);
        res.status(500).json({
          error: "Failed to check finalization eligibility",
          message: error instanceof Error ? error.message : "Unknown error"
        });
      }
    });
    finalizeRouter.post("/api/finalize/batch", async (req, res) => {
      try {
        const { loanIds } = req.body;
        const userId = req.user?.id || 1;
        if (!Array.isArray(loanIds) || loanIds.length === 0) {
          return res.status(400).json({
            error: "Invalid request",
            message: "loanIds must be a non-empty array"
          });
        }
        const results = [];
        for (const loanId of loanIds) {
          try {
            const loanIdNum = parseInt(loanId);
            if (isNaN(loanIdNum)) {
              results.push({
                loanId,
                status: "error",
                error: "Invalid loan ID"
              });
              continue;
            }
            const eligibility = await canFinalizeLoan(loanIdNum);
            if (eligibility.canFinalize) {
              const result = await finalizeLoan(loanIdNum, userId);
              results.push({
                loanId,
                status: "success",
                data: result
              });
            } else {
              results.push({
                loanId,
                status: "skipped",
                reasons: eligibility.reasons
              });
            }
          } catch (error) {
            results.push({
              loanId,
              status: "error",
              error: error instanceof Error ? error.message : "Unknown error"
            });
          }
        }
        const successCount = results.filter((r) => r.status === "success").length;
        const errorCount = results.filter((r) => r.status === "error").length;
        const skippedCount = results.filter((r) => r.status === "skipped").length;
        res.json({
          success: true,
          message: `Batch finalization complete: ${successCount} success, ${errorCount} errors, ${skippedCount} skipped`,
          summary: { successCount, errorCount, skippedCount },
          results
        });
      } catch (error) {
        console.error("[Finalize] Error in batch finalization:", error);
        res.status(500).json({
          error: "Failed to process batch finalization",
          message: error instanceof Error ? error.message : "Unknown error"
        });
      }
    });
  }
});

// src/routes/servicing.routes.ts
var servicing_routes_exports = {};
__export(servicing_routes_exports, {
  servicingRouter: () => servicingRouter
});
import { Router as Router45 } from "express";
var servicingRouter;
var init_servicing_routes = __esm({
  "src/routes/servicing.routes.ts"() {
    "use strict";
    init_db();
    servicingRouter = Router45();
    servicingRouter.get("/loans/:id/servicing", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const loanId = parseInt(req.params.id);
        if (isNaN(loanId)) {
          return res.status(400).json({ error: "Invalid loan ID" });
        }
        const acc = await client5.query(`
      SELECT * FROM svc_accounts WHERE loan_id=$1
    `, [loanId]);
        if (!acc.rowCount) {
          return res.status(404).json({ error: "Loan not boarded to servicing" });
        }
        const esc = await client5.query(`
      SELECT bucket, monthly_accrual, balance, cushion_months 
      FROM svc_escrow_sub WHERE loan_id=$1 
      ORDER BY bucket
    `, [loanId]);
        res.json({
          success: true,
          data: {
            account: acc.rows[0],
            escrow: esc.rows
          }
        });
      } catch (error) {
        console.error("[Servicing] Error getting account summary:", error);
        res.status(500).json({
          error: "Failed to get servicing account",
          message: error instanceof Error ? error.message : "Unknown error"
        });
      } finally {
        client5.release();
      }
    });
    servicingRouter.get("/loans/:id/schedule", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const loanId = parseInt(req.params.id);
        if (isNaN(loanId)) {
          return res.status(400).json({ error: "Invalid loan ID" });
        }
        const rows = await client5.query(`
      SELECT installment_no, due_date, principal_due, interest_due, escrow_due, 
             total_due, principal_balance_after, paid, paid_at
      FROM svc_schedule 
      WHERE loan_id=$1 
      ORDER BY installment_no 
      LIMIT 12
    `, [loanId]);
        res.json({
          success: true,
          data: {
            schedule: rows.rows
          }
        });
      } catch (error) {
        console.error("[Servicing] Error getting schedule:", error);
        res.status(500).json({
          error: "Failed to get payment schedule",
          message: error instanceof Error ? error.message : "Unknown error"
        });
      } finally {
        client5.release();
      }
    });
    servicingRouter.get("/loans/:id/transactions", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const loanId = parseInt(req.params.id);
        if (isNaN(loanId)) {
          return res.status(400).json({ error: "Invalid loan ID" });
        }
        const limit = parseInt(req.query.limit) || 50;
        const rows = await client5.query(`
      SELECT ts, type, amount, alloc_principal, alloc_interest, 
             alloc_escrow, alloc_fees, memo, ref
      FROM svc_txns 
      WHERE loan_id=$1 
      ORDER BY ts DESC 
      LIMIT $2
    `, [loanId, limit]);
        res.json({
          success: true,
          data: {
            transactions: rows.rows
          }
        });
      } catch (error) {
        console.error("[Servicing] Error getting transactions:", error);
        res.status(500).json({
          error: "Failed to get transactions",
          message: error instanceof Error ? error.message : "Unknown error"
        });
      } finally {
        client5.release();
      }
    });
    servicingRouter.get("/loans/:id/balances", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const loanId = parseInt(req.params.id);
        if (isNaN(loanId)) {
          return res.status(400).json({ error: "Invalid loan ID" });
        }
        const principalBalance = await client5.query(`
      SELECT principal_balance_after 
      FROM svc_schedule 
      WHERE loan_id=$1 AND paid=false 
      ORDER BY installment_no 
      LIMIT 1
    `, [loanId]);
        const escrowBalances = await client5.query(`
      SELECT bucket, balance, monthly_accrual 
      FROM svc_escrow_sub 
      WHERE loan_id=$1
    `, [loanId]);
        const totalEscrowBalance = escrowBalances.rows.reduce((sum3, row) => sum3 + parseFloat(row.balance), 0);
        res.json({
          success: true,
          data: {
            principalBalance: principalBalance.rows[0]?.principal_balance_after || 0,
            escrowBalance: totalEscrowBalance,
            escrowBreakdown: escrowBalances.rows
          }
        });
      } catch (error) {
        console.error("[Servicing] Error getting balances:", error);
        res.status(500).json({
          error: "Failed to get balances",
          message: error instanceof Error ? error.message : "Unknown error"
        });
      } finally {
        client5.release();
      }
    });
    servicingRouter.post("/loans/:id/board", async (req, res) => {
      try {
        const loanId = parseInt(req.params.id);
        if (isNaN(loanId)) {
          return res.status(400).json({ error: "Invalid loan ID" });
        }
        const loan = await pool.query(`
      SELECT id, state FROM loans WHERE id = $1
    `, [loanId]);
        if (!loan.rowCount) {
          return res.status(404).json({ error: "Loan not found" });
        }
        if (loan.rows[0].state !== "finalized") {
          return res.status(400).json({ error: "Loan must be finalized before boarding" });
        }
        res.json({
          success: true,
          message: "Boarding request queued",
          data: { loanId }
        });
      } catch (error) {
        console.error("[Servicing] Error triggering boarding:", error);
        res.status(500).json({
          error: "Failed to trigger boarding",
          message: error instanceof Error ? error.message : "Unknown error"
        });
      }
    });
  }
});

// server/observability/telemetry.ts
import { AsyncLocalStorage } from "async_hooks";
function createSpan(name, options) {
  return tracer.startSpan(name, options);
}
async function withSpan(name, fn, options) {
  const span = createSpan(name, options);
  try {
    const result = await fn();
    span.setStatus({ code: "OK" });
    return result;
  } catch (error) {
    span.setStatus({
      code: "ERROR",
      message: error instanceof Error ? error.message : "Unknown error"
    });
    span.recordException(error);
    throw error;
  } finally {
    span.end();
  }
}
function withCorrelationId(correlationId, fn) {
  return correlationStorage.run({ correlationId }, fn);
}
function initializeTelemetry() {
  console.log("[Telemetry] Initializing observability...");
  console.log("[Telemetry] Service:", SERVICE_NAME);
  console.log("[Telemetry] Version:", SERVICE_VERSION);
  console.log("[Telemetry] Environment:", process.env.NODE_ENV);
  if (process.env.METRICS_PORT) {
    console.log("[Telemetry] Metrics endpoint: http://localhost:" + process.env.METRICS_PORT + "/metrics");
  }
}
var correlationStorage, SERVICE_NAME, SERVICE_VERSION, metrics, tracer, meter;
var init_telemetry = __esm({
  "server/observability/telemetry.ts"() {
    "use strict";
    correlationStorage = new AsyncLocalStorage();
    SERVICE_NAME = process.env.SERVICE_NAME || "loanserve-pro";
    SERVICE_VERSION = process.env.SERVICE_VERSION || "1.0.0";
    metrics = {
      correlationIds: /* @__PURE__ */ new Map(),
      requestCount: 0,
      errorCount: 0,
      messageCount: 0
    };
    tracer = {
      startSpan: (name, options) => {
        const correlationId = correlationStorage.getStore()?.correlationId;
        const span = {
          name,
          correlationId,
          startTime: Date.now(),
          setAttribute: (key, value) => {
            if (process.env.NODE_ENV === "development") {
              console.log(`[Span ${name}] ${key}:`, value);
            }
          },
          setStatus: (status) => {
          },
          recordException: (error) => {
            console.error(`[Span ${name}] Error:`, error);
            metrics.errorCount++;
          },
          end: () => {
            const duration = Date.now() - span.startTime;
            if (process.env.NODE_ENV === "development") {
              console.log(`[Span ${name}] Completed in ${duration}ms`);
            }
          }
        };
        return span;
      }
    };
    meter = {
      createCounter: (name, options) => ({
        add: (value, labels) => {
          metrics.requestCount += value;
        }
      }),
      createHistogram: (name, options) => ({
        record: (value, labels) => {
        }
      }),
      createObservableGauge: (name, options) => ({
        addCallback: (callback2) => {
        }
      })
    };
  }
});

// server/observability/metrics.ts
import { ValueType } from "@opentelemetry/api";
function recordMetric(metric, value, labels = {}) {
  if (metric.add) {
    metric.add(value, labels);
  } else if (metric.record) {
    metric.record(value, labels);
  }
}
function initializeMetricCollectors(getQueueStats2, getOutboxStats2, getReconcileStats2) {
  queueDepthGauge.addCallback(async (observableResult) => {
    try {
      const stats = await getQueueStats2();
      for (const [queueName, depth] of Object.entries(stats.queues || {})) {
        observableResult.observe(depth, { queue: queueName });
      }
    } catch (error) {
      console.error("[Metrics] Failed to collect queue depth:", error);
    }
  });
  dlqDepthGauge.addCallback(async (observableResult) => {
    try {
      const stats = await getQueueStats2();
      for (const [queueName, depth] of Object.entries(stats.dlqs || {})) {
        observableResult.observe(depth, { queue: queueName });
      }
    } catch (error) {
      console.error("[Metrics] Failed to collect DLQ depth:", error);
    }
  });
  outboxLagGauge.addCallback(async (observableResult) => {
    try {
      const stats = await getOutboxStats2();
      if (stats.maxLag !== void 0) {
        observableResult.observe(stats.maxLag, {});
      }
    } catch (error) {
      console.error("[Metrics] Failed to collect outbox lag:", error);
    }
  });
  outboxSizeGauge.addCallback(async (observableResult) => {
    try {
      const stats = await getOutboxStats2();
      if (stats.pending !== void 0) {
        observableResult.observe(stats.pending, {});
      }
    } catch (error) {
      console.error("[Metrics] Failed to collect outbox size:", error);
    }
  });
  reconcileVarianceGauge.addCallback(async (observableResult) => {
    try {
      const stats = await getReconcileStats2();
      if (stats.totalVariance !== void 0) {
        observableResult.observe(stats.totalVariance, {});
      }
    } catch (error) {
      console.error("[Metrics] Failed to collect reconciliation variance:", error);
    }
  });
  healthCheckGauge.addCallback(async (observableResult) => {
    try {
      const queueHealth = await getQueueStats2().then(() => 1).catch(() => 0);
      const dbHealth = await getOutboxStats2().then(() => 1).catch(() => 0);
      observableResult.observe(queueHealth, { component: "rabbitmq" });
      observableResult.observe(dbHealth, { component: "database" });
    } catch (error) {
      console.error("[Metrics] Failed to collect health status:", error);
      observableResult.observe(0, { component: "overall" });
    }
  });
  console.log("[Metrics] Metric collectors initialized");
}
var queueDepthGauge, dlqDepthGauge, dlqRateCounter, processLatencyHistogram, messageProcessedCounter, messageFailedCounter, outboxLagGauge, outboxSizeGauge, reconcileVarianceGauge, reconcileExceptionsCounter, reconcileSuccessCounter, settlementAmountHistogram, settlementLatencyHistogram, notificationSentCounter, notificationFailedCounter, apiLatencyHistogram, dbQueryLatencyHistogram, paymentsProcessedCounter, paymentAmountHistogram, healthCheckGauge;
var init_metrics2 = __esm({
  "server/observability/metrics.ts"() {
    "use strict";
    init_telemetry();
    queueDepthGauge = meter.createObservableGauge("rabbitmq_queue_depth", {
      description: "Current depth of RabbitMQ queues",
      unit: "messages",
      valueType: ValueType.INT
    });
    dlqDepthGauge = meter.createObservableGauge("rabbitmq_dlq_depth", {
      description: "Current depth of Dead Letter Queues",
      unit: "messages",
      valueType: ValueType.INT
    });
    dlqRateCounter = meter.createCounter("rabbitmq_dlq_rate", {
      description: "Rate of messages sent to DLQ",
      unit: "messages",
      valueType: ValueType.INT
    });
    processLatencyHistogram = meter.createHistogram("payment_process_latency", {
      description: "Latency of payment processing",
      unit: "milliseconds",
      valueType: ValueType.DOUBLE
    });
    messageProcessedCounter = meter.createCounter("messages_processed_total", {
      description: "Total number of messages processed",
      unit: "messages",
      valueType: ValueType.INT
    });
    messageFailedCounter = meter.createCounter("messages_failed_total", {
      description: "Total number of messages that failed processing",
      unit: "messages",
      valueType: ValueType.INT
    });
    outboxLagGauge = meter.createObservableGauge("outbox_lag", {
      description: "Lag between outbox creation and processing",
      unit: "seconds",
      valueType: ValueType.DOUBLE
    });
    outboxSizeGauge = meter.createObservableGauge("outbox_size", {
      description: "Number of pending outbox messages",
      unit: "messages",
      valueType: ValueType.INT
    });
    reconcileVarianceGauge = meter.createObservableGauge("reconcile_variance_amount", {
      description: "Total variance amount in reconciliation",
      unit: "dollars",
      valueType: ValueType.DOUBLE
    });
    reconcileExceptionsCounter = meter.createCounter("reconcile_exceptions_total", {
      description: "Total number of reconciliation exceptions",
      unit: "exceptions",
      valueType: ValueType.INT
    });
    reconcileSuccessCounter = meter.createCounter("reconcile_success_total", {
      description: "Total number of successful reconciliations",
      unit: "reconciliations",
      valueType: ValueType.INT
    });
    settlementAmountHistogram = meter.createHistogram("settlement_amount", {
      description: "Distribution of settlement amounts",
      unit: "dollars",
      valueType: ValueType.DOUBLE
    });
    settlementLatencyHistogram = meter.createHistogram("settlement_latency", {
      description: "Time taken for settlements",
      unit: "milliseconds",
      valueType: ValueType.DOUBLE
    });
    notificationSentCounter = meter.createCounter("notifications_sent_total", {
      description: "Total notifications sent",
      unit: "notifications",
      valueType: ValueType.INT
    });
    notificationFailedCounter = meter.createCounter("notifications_failed_total", {
      description: "Total notifications that failed to send",
      unit: "notifications",
      valueType: ValueType.INT
    });
    apiLatencyHistogram = meter.createHistogram("api_request_latency", {
      description: "API request latency",
      unit: "milliseconds",
      valueType: ValueType.DOUBLE
    });
    dbQueryLatencyHistogram = meter.createHistogram("db_query_latency", {
      description: "Database query latency",
      unit: "milliseconds",
      valueType: ValueType.DOUBLE
    });
    paymentsProcessedCounter = meter.createCounter("payments_processed_total", {
      description: "Total payments processed",
      unit: "payments",
      valueType: ValueType.INT
    });
    paymentAmountHistogram = meter.createHistogram("payment_amount", {
      description: "Distribution of payment amounts",
      unit: "dollars",
      valueType: ValueType.DOUBLE
    });
    healthCheckGauge = meter.createObservableGauge("service_health", {
      description: "Service health status (1 = healthy, 0 = unhealthy)",
      unit: "1",
      valueType: ValueType.INT
    });
  }
});

// server/middleware/correlation-id.ts
import { randomUUID as randomUUID17 } from "crypto";
function correlationIdMiddleware(req, res, next) {
  const correlationId = req.headers["x-correlation-id"] || req.headers["x-request-id"] || req.query.correlationId || randomUUID17();
  req.correlationId = correlationId;
  res.setHeader("X-Correlation-ID", correlationId);
  if (req.log) {
    req.log = req.log.child({ correlationId });
  }
  withCorrelationId(correlationId, () => {
    next();
  });
}
function extractCorrelationId(source) {
  return source?.correlationId || source?.headers?.["x-correlation-id"] || source?.headers?.["x-request-id"] || source?.properties?.correlationId || source?.metadata?.correlationId || randomUUID17();
}
function correlationErrorHandler(err, req, res, next) {
  const correlationId = req.correlationId || "unknown";
  console.error(`[Error] Correlation ID: ${correlationId}`, err);
  if (res.headersSent) {
    return next(err);
  }
  res.status(500).json({
    error: "Internal Server Error",
    message: err.message,
    correlationId,
    timestamp: (/* @__PURE__ */ new Date()).toISOString()
  });
}
var init_correlation_id = __esm({
  "server/middleware/correlation-id.ts"() {
    "use strict";
    init_telemetry();
  }
});

// server/observability/instrumented-rabbitmq.ts
import { SpanKind, SpanStatusCode } from "@opentelemetry/api";
var InstrumentedRabbitMQService, instrumentedRabbitMQ;
var init_instrumented_rabbitmq = __esm({
  "server/observability/instrumented-rabbitmq.ts"() {
    "use strict";
    init_rabbitmq_unified();
    init_telemetry();
    init_metrics2();
    init_correlation_id();
    InstrumentedRabbitMQService = class extends RabbitMQClient {
      /**
       * Publish a message with tracing and metrics
       */
      async publishWithTracing(exchange, routingKey, message, options) {
        const correlationId = correlationStorage.getStore()?.correlationId || extractCorrelationId(options);
        return withSpan(
          `rabbitmq.publish ${exchange}/${routingKey}`,
          async () => {
            const span = createSpan("rabbitmq.publish", {
              kind: SpanKind.PRODUCER,
              attributes: {
                "messaging.system": "rabbitmq",
                "messaging.destination": exchange,
                "messaging.routing_key": routingKey,
                "correlation.id": correlationId
              }
            });
            try {
              const enhancedOptions = {
                ...options,
                correlationId,
                headers: {
                  ...options?.headers,
                  "x-correlation-id": correlationId
                }
              };
              await this.publish(exchange, routingKey, message, enhancedOptions);
              recordMetric(messageProcessedCounter, 1, {
                operation: "publish",
                exchange,
                routingKey,
                status: "success"
              });
              span.setStatus({ code: SpanStatusCode.OK });
            } catch (error) {
              recordMetric(messageFailedCounter, 1, {
                operation: "publish",
                exchange,
                routingKey,
                status: "error"
              });
              span.setStatus({
                code: SpanStatusCode.ERROR,
                message: error instanceof Error ? error.message : "Unknown error"
              });
              span.recordException(error);
              throw error;
            } finally {
              span.end();
            }
          }
        );
      }
      /**
       * Consume messages with tracing and metrics
       */
      async consumeWithTracing(queue, handler, options) {
        return this.consume(
          queue,
          async (msg) => {
            const correlationId = extractCorrelationId(msg);
            const startTime2 = Date.now();
            return withCorrelationId(correlationId, async () => {
              const span = createSpan("rabbitmq.consume", {
                kind: SpanKind.CONSUMER,
                attributes: {
                  "messaging.system": "rabbitmq",
                  "messaging.source": queue,
                  "messaging.message.id": msg.properties?.messageId,
                  "correlation.id": correlationId
                }
              });
              try {
                await handler(msg);
                const duration = Date.now() - startTime2;
                recordMetric(processLatencyHistogram, duration, {
                  queue,
                  status: "success"
                });
                recordMetric(messageProcessedCounter, 1, {
                  operation: "consume",
                  queue,
                  status: "success"
                });
                span.setStatus({ code: SpanStatusCode.OK });
              } catch (error) {
                const duration = Date.now() - startTime2;
                recordMetric(processLatencyHistogram, duration, {
                  queue,
                  status: "error"
                });
                recordMetric(messageFailedCounter, 1, {
                  operation: "consume",
                  queue,
                  status: "error"
                });
                const retryCount = msg.properties?.headers?.["x-retry-count"] || 0;
                if (retryCount >= (options?.maxRetries || 3)) {
                  recordMetric(dlqRateCounter, 1, {
                    queue,
                    reason: "max_retries"
                  });
                }
                span.setStatus({
                  code: SpanStatusCode.ERROR,
                  message: error instanceof Error ? error.message : "Unknown error"
                });
                span.recordException(error);
                throw error;
              } finally {
                span.end();
              }
            });
          },
          options
        );
      }
      /**
       * Send to DLQ with metrics
       */
      async sendToDLQWithMetrics(message, error, originalQueue) {
        const correlationId = extractCorrelationId(message);
        return withSpan(
          `rabbitmq.dlq.send ${originalQueue}`,
          async () => {
            try {
              await this.sendToDLQ(message, error, originalQueue);
              recordMetric(dlqRateCounter, 1, {
                queue: originalQueue,
                reason: error.name || "unknown"
              });
            } catch (dlqError) {
              console.error("[RabbitMQ] Failed to send to DLQ:", dlqError);
              throw dlqError;
            }
          }
        );
      }
      /**
       * Get queue statistics for metrics
       */
      async getQueueStatsForMetrics() {
        const stats = {
          queues: {},
          dlqs: {}
        };
        try {
          if (!this.channel) {
            await this.connect();
          }
          const mainQueues = [
            "q.servicing.1",
            "q.servicing.2",
            "q.servicing.3",
            "q.servicing.4",
            "q.servicing.5",
            "q.servicing.6",
            "q.servicing.7",
            "q.notifications",
            "q.daily.cycle"
          ];
          for (const queue of mainQueues) {
            try {
              const queueInfo = await this.channel.checkQueue(queue);
              stats.queues[queue] = queueInfo.messageCount;
            } catch (error) {
            }
          }
          const dlqs = mainQueues.map((q) => `dlq.${q.substring(2)}`);
          for (const dlq2 of dlqs) {
            try {
              const queueInfo = await this.channel.checkQueue(dlq2);
              stats.dlqs[dlq2] = queueInfo.messageCount;
            } catch (error) {
            }
          }
        } catch (error) {
          console.error("[RabbitMQ] Failed to get queue stats:", error);
        }
        return stats;
      }
    };
    instrumentedRabbitMQ = new InstrumentedRabbitMQService();
  }
});

// server/observability/metrics-collector.ts
var metrics_collector_exports = {};
__export(metrics_collector_exports, {
  getNotificationStats: () => getNotificationStats,
  getOutboxStats: () => getOutboxStats,
  getPaymentStats: () => getPaymentStats,
  getQueueStats: () => getQueueStats,
  getReconcileStats: () => getReconcileStats,
  startMetricsCollection: () => startMetricsCollection,
  stopMetricsCollection: () => stopMetricsCollection
});
import { sql as sql21 } from "drizzle-orm";
async function getQueueStats() {
  try {
    return await instrumentedRabbitMQ.getQueueStatsForMetrics();
  } catch (error) {
    console.error("[MetricsCollector] Failed to get queue stats:", error);
    return { queues: {}, dlqs: {} };
  }
}
async function getOutboxStats() {
  try {
    const pendingResult = await db.execute(sql21`
      SELECT COUNT(*) as count
      FROM outbox_messages
      WHERE status = 'pending'
    `);
    const pending = parseInt(pendingResult.rows[0].count) || 0;
    const lagResult = await db.execute(sql21`
      SELECT EXTRACT(EPOCH FROM (NOW() - MIN(created_at))) as max_lag
      FROM outbox_messages
      WHERE status = 'pending'
    `);
    const maxLag = parseFloat(lagResult.rows[0]?.max_lag) || 0;
    return { pending, maxLag };
  } catch (error) {
    console.error("[MetricsCollector] Failed to get outbox stats:", error);
    return { pending: 0, maxLag: 0 };
  }
}
async function getReconcileStats() {
  try {
    const varianceResult = await db.execute(sql21`
      SELECT SUM(ABS(variance_amount)) as total_variance
      FROM reconciliation_exceptions
      WHERE created_at > NOW() - INTERVAL '24 hours'
    `);
    const totalVariance = parseFloat(varianceResult.rows[0]?.total_variance) || 0;
    const exceptionResult = await db.execute(sql21`
      SELECT COUNT(*) as count
      FROM reconciliation_exceptions
      WHERE status = 'pending'
    `);
    const exceptionCount = parseInt(exceptionResult.rows[0].count) || 0;
    return { totalVariance, exceptionCount };
  } catch (error) {
    console.error("[MetricsCollector] Failed to get reconciliation stats:", error);
    return { totalVariance: 0, exceptionCount: 0 };
  }
}
async function getPaymentStats() {
  try {
    const result = await db.execute(sql21`
      SELECT 
        status,
        COUNT(*) as count,
        AVG(CAST(total_received AS NUMERIC)) as avg_amount
      FROM payments
      WHERE created_at > NOW() - INTERVAL '1 hour'
      GROUP BY status
    `);
    const stats = {
      total: 0,
      byStatus: {},
      avgAmount: 0
    };
    for (const row of result.rows) {
      const count3 = parseInt(row.count) || 0;
      stats.total += count3;
      stats.byStatus[row.status] = count3;
      if (row.avg_amount) {
        const avgAmount = parseFloat(row.avg_amount);
        recordMetric(paymentAmountHistogram, avgAmount, { status: row.status });
      }
    }
    return stats;
  } catch (error) {
    console.error("[MetricsCollector] Failed to get payment stats:", error);
    return { total: 0, byStatus: {}, avgAmount: 0 };
  }
}
async function getNotificationStats() {
  try {
    const result = await db.execute(sql21`
      SELECT 
        COUNT(CASE WHEN status = 'sent' AND channel = 'email' THEN 1 END) as emails_sent,
        COUNT(CASE WHEN status = 'sent' AND channel = 'sms' THEN 1 END) as sms_sent,
        COUNT(CASE WHEN status = 'sent' THEN 1 END) as total_sent,
        COUNT(CASE WHEN status = 'failed' THEN 1 END) as total_failed,
        COUNT(*) as total_notifications
      FROM notifications
      WHERE created_at > NOW() - INTERVAL '1 hour'
    `);
    const emailsSent = parseInt(result.rows[0]?.emails_sent) || 0;
    const smsSent = parseInt(result.rows[0]?.sms_sent) || 0;
    const totalSent = parseInt(result.rows[0]?.total_sent) || 0;
    const totalFailed = parseInt(result.rows[0]?.total_failed) || 0;
    const totalNotifications = parseInt(result.rows[0]?.total_notifications) || 0;
    if (emailsSent > 0) {
      recordMetric(notificationSentCounter, emailsSent, { type: "email" });
    }
    if (smsSent > 0) {
      recordMetric(notificationSentCounter, smsSent, { type: "sms" });
    }
    if (totalFailed > 0) {
      recordMetric(notificationFailedCounter, totalFailed, { type: "any" });
    }
    return {
      sent: totalSent,
      failed: totalFailed,
      emailsSent,
      smsSent,
      readNotifications: 0,
      // Column doesn't exist, return 0
      totalNotifications
    };
  } catch (error) {
    console.error("[MetricsCollector] Failed to get notification stats:", error);
    return { sent: 0, failed: 0, emailsSent: 0, smsSent: 0, readNotifications: 0, totalNotifications: 0 };
  }
}
function startMetricsCollection() {
  initializeMetricCollectors(
    getQueueStats,
    getOutboxStats,
    getReconcileStats
  );
  setInterval(async () => {
    try {
    } catch (error) {
      console.error("[MetricsCollector] Failed to collect queue metrics:", error);
    }
  }, 6e4);
  setInterval(async () => {
    try {
      const stats = await getPaymentStats();
      if (stats.total > 0) {
        recordMetric(paymentsProcessedCounter, stats.total, {});
      }
    } catch (error) {
      console.error("[MetricsCollector] Failed to collect payment metrics:", error);
    }
  }, 3e4);
  setInterval(async () => {
    try {
      await getNotificationStats();
    } catch (error) {
      console.error("[MetricsCollector] Failed to collect notification metrics:", error);
    }
  }, 6e4);
  console.log("[MetricsCollector] Started periodic metrics collection");
}
function stopMetricsCollection() {
  const highestIntervalId = setInterval(() => {
  }, 0);
  for (let i = 0; i < highestIntervalId; i++) {
    clearInterval(i);
  }
  console.log("[MetricsCollector] Stopped metrics collection");
}
var init_metrics_collector = __esm({
  "server/observability/metrics-collector.ts"() {
    "use strict";
    init_db();
    init_instrumented_rabbitmq();
    init_metrics2();
  }
});

// server/routes/escrow-disbursements.ts
var escrow_disbursements_exports = {};
__export(escrow_disbursements_exports, {
  default: () => escrow_disbursements_default
});
import { Router as Router46 } from "express";
import { eq as eq33 } from "drizzle-orm";
var router37, escrow_disbursements_default;
var init_escrow_disbursements = __esm({
  "server/routes/escrow-disbursements.ts"() {
    "use strict";
    init_storage();
    init_db();
    init_schema();
    init_schema();
    init_auditService();
    init_audit_helper();
    router37 = Router46();
    router37.get("/api/loans/:loanId/escrow-disbursements", async (req, res) => {
      try {
        const loanId = parseInt(req.params.loanId);
        const userId = req.user?.id || req.session?.userId;
        const disbursements = await storage.getEscrowDisbursements(loanId);
        await complianceAudit.logEvent({
          eventType: COMPLIANCE_EVENTS.ESCROW.VIEWED,
          actorType: "user",
          actorId: userId?.toString(),
          resourceType: "escrow_disbursements",
          resourceId: loanId.toString(),
          loanId,
          ipAddr: getRealUserIP(req),
          userAgent: req.headers?.["user-agent"],
          metadata: {
            action: "view_escrow_disbursements",
            disbursementCount: disbursements.length
          }
        });
        res.json(disbursements);
      } catch (error) {
        console.error("Error fetching escrow disbursements:", error);
        res.status(500).json({ error: "Failed to fetch escrow disbursements" });
      }
    });
    router37.get("/api/escrow-disbursements/:id", async (req, res) => {
      try {
        const id = parseInt(req.params.id);
        const userId = req.user?.id || req.session?.userId;
        const disbursement2 = await storage.getEscrowDisbursement(id);
        if (!disbursement2) {
          return res.status(404).json({ error: "Disbursement not found" });
        }
        await complianceAudit.logEvent({
          eventType: COMPLIANCE_EVENTS.ESCROW.VIEWED,
          actorType: "user",
          actorId: userId?.toString(),
          resourceType: "escrow_disbursement",
          resourceId: id.toString(),
          loanId: disbursement2.loanId,
          ipAddr: getRealUserIP(req),
          userAgent: req.headers?.["user-agent"],
          metadata: {
            action: "view_disbursement_detail",
            disbursementId: id,
            disbursementType: disbursement2.disbursementType,
            payeeName: disbursement2.payeeName
          }
        });
        res.json(disbursement2);
      } catch (error) {
        console.error("Error fetching disbursement:", error);
        res.status(500).json({ error: "Failed to fetch disbursement" });
      }
    });
    router37.post("/api/loans/:loanId/escrow-disbursements", async (req, res) => {
      try {
        const loanId = parseInt(req.params.loanId);
        const userId = req.user?.id || req.session?.userId;
        let escrowAccount = await storage.getEscrowAccount(loanId);
        if (!escrowAccount) {
          escrowAccount = await storage.createEscrowAccount({
            loanId,
            accountNumber: `ESC-${loanId}-${Date.now()}`,
            currentBalance: "0",
            isActive: true
          });
          await complianceAudit.logEvent({
            eventType: COMPLIANCE_EVENTS.ESCROW.ACCOUNT_CREATED,
            actorType: "user",
            actorId: userId?.toString(),
            resourceType: "escrow_account",
            resourceId: escrowAccount.id.toString(),
            loanId,
            ipAddr: getRealUserIP(req),
            userAgent: req.headers?.["user-agent"],
            metadata: {
              action: "create_escrow_account",
              loanId,
              accountNumber: escrowAccount.accountNumber
            }
          });
        }
        const cleanNumeric = (value) => {
          if (value === void 0 || value === "" || value === null) {
            return null;
          }
          return value;
        };
        const cleanString = (value) => {
          if (value === void 0 || value === "" || value === null) {
            return null;
          }
          return value;
        };
        const cleanedData = {
          // Don't spread req.body - build cleanedData from scratch
          loanId,
          escrowAccountId: escrowAccount.id,
          // Copy over required fields from body
          disbursementType: req.body.disbursementType,
          description: req.body.description,
          payeeName: req.body.payeeName,
          frequency: req.body.frequency,
          paymentMethod: req.body.paymentMethod || "check",
          status: req.body.status || "active",
          isOnHold: req.body.isOnHold || false,
          autoPayEnabled: req.body.autoPayEnabled ?? true,
          // Required date field
          nextDueDate: cleanString(req.body.nextDueDate),
          // Optional date fields - convert empty strings to null
          firstDueDate: cleanString(req.body.firstDueDate),
          lastPaidDate: cleanString(req.body.lastPaidDate),
          policyExpirationDate: cleanString(req.body.policyExpirationDate),
          holdDate: cleanString(req.body.holdDate),
          // Numeric fields - convert empty strings to null
          coverageAmount: cleanNumeric(req.body.coverageAmount),
          monthlyAmount: cleanNumeric(req.body.monthlyAmount),
          annualAmount: cleanNumeric(req.body.annualAmount),
          paymentAmount: cleanNumeric(req.body.paymentAmount),
          daysBeforeDue: cleanNumeric(req.body.daysBeforeDue),
          // Clean up string fields that might be empty
          parcelNumber: cleanString(req.body.parcelNumber),
          policyNumber: cleanString(req.body.policyNumber),
          accountNumber: cleanString(req.body.accountNumber),
          referenceNumber: cleanString(req.body.referenceNumber),
          specificDueDates: cleanString(req.body.specificDueDates),
          metadata: cleanString(req.body.metadata),
          notes: cleanString(req.body.notes),
          // Clean all address and contact fields
          payeeStreetAddress: cleanString(req.body.payeeStreetAddress),
          payeeCity: cleanString(req.body.payeeCity),
          payeeState: cleanString(req.body.payeeState),
          payeeZipCode: cleanString(req.body.payeeZipCode),
          payeeContactName: cleanString(req.body.payeeContactName),
          payeePhone: cleanString(req.body.payeePhone),
          payeeEmail: cleanString(req.body.payeeEmail),
          payeeFax: cleanString(req.body.payeeFax),
          // Insurance fields
          insuredName: cleanString(req.body.insuredName),
          insuranceCompanyName: cleanString(req.body.insuranceCompanyName),
          policyDescription: cleanString(req.body.policyDescription),
          insurancePropertyAddress: cleanString(req.body.insurancePropertyAddress),
          insurancePropertyCity: cleanString(req.body.insurancePropertyCity),
          insurancePropertyState: cleanString(req.body.insurancePropertyState),
          insurancePropertyZipCode: cleanString(req.body.insurancePropertyZipCode),
          // Agent fields
          agentName: cleanString(req.body.agentName),
          agentBusinessAddress: cleanString(req.body.agentBusinessAddress),
          agentCity: cleanString(req.body.agentCity),
          agentState: cleanString(req.body.agentState),
          agentZipCode: cleanString(req.body.agentZipCode),
          agentPhone: cleanString(req.body.agentPhone),
          agentFax: cleanString(req.body.agentFax),
          agentEmail: cleanString(req.body.agentEmail),
          // Banking fields
          bankAccountNumber: cleanString(req.body.bankAccountNumber),
          achRoutingNumber: cleanString(req.body.achRoutingNumber),
          wireRoutingNumber: cleanString(req.body.wireRoutingNumber),
          accountType: cleanString(req.body.accountType),
          bankName: cleanString(req.body.bankName),
          wireInstructions: cleanString(req.body.wireInstructions),
          // Remittance fields
          remittanceAddress: cleanString(req.body.remittanceAddress),
          remittanceCity: cleanString(req.body.remittanceCity),
          remittanceState: cleanString(req.body.remittanceState),
          remittanceZipCode: cleanString(req.body.remittanceZipCode),
          // Other fields
          category: cleanString(req.body.category),
          holdReason: cleanString(req.body.holdReason),
          holdRequestedBy: cleanString(req.body.holdRequestedBy),
          // Insurance tracking fields
          insuranceDocumentId: cleanNumeric(req.body.insuranceDocumentId),
          insuranceTracking: req.body.insuranceTracking
        };
        const cleanedDataDict = cleanedData;
        for (const key of Object.keys(cleanedDataDict)) {
          const val = cleanedDataDict[key];
          if (val === null || val === void 0) {
            delete cleanedDataDict[key];
          }
        }
        console.log("Processing escrow disbursement request");
        console.log("Data validation in progress...");
        const validatedData = insertEscrowDisbursementSchema.parse(cleanedDataDict);
        console.log("Validation complete, creating disbursement...");
        const disbursement2 = await storage.createEscrowDisbursement(validatedData);
        const disbursementDict = disbursement2;
        const createdFields = Object.keys(disbursementDict).filter((key) => {
          const val = disbursementDict[key];
          return val !== null && val !== void 0 && val !== "";
        });
        await complianceAudit.logEvent({
          eventType: COMPLIANCE_EVENTS.ESCROW.DISBURSEMENT_CREATED,
          actorType: "user",
          actorId: userId?.toString(),
          resourceType: "escrow_disbursement",
          resourceId: disbursement2.id.toString(),
          loanId,
          ipAddr: getRealUserIP(req),
          userAgent: req.headers?.["user-agent"],
          newValues: disbursement2,
          changedFields: createdFields
        });
        res.status(201).json(disbursement2);
      } catch (error) {
        console.error("Error creating disbursement:", error);
        const errorMessage = error.issues ? error.issues[0].message : error.message || "Invalid disbursement data";
        res.status(400).json({ error: errorMessage, details: error.issues || error.message });
      }
    });
    router37.patch("/api/escrow-disbursements/:id", async (req, res) => {
      try {
        const id = parseInt(req.params.id);
        const userId = req.user?.id || req.session?.userId;
        const existingDisbursement = await storage.getEscrowDisbursement(id);
        if (!existingDisbursement) {
          return res.status(404).json({ error: "Disbursement not found" });
        }
        const cleanNumeric = (value) => {
          if (value === void 0 || value === "" || value === null) {
            return void 0;
          }
          return value;
        };
        const cleanString = (value) => {
          if (value === void 0 || value === "" || value === null) {
            return void 0;
          }
          return value;
        };
        const cleanedData = {};
        if ("nextDueDate" in req.body) cleanedData.nextDueDate = cleanString(req.body.nextDueDate);
        if ("firstDueDate" in req.body) cleanedData.firstDueDate = cleanString(req.body.firstDueDate);
        if ("lastPaidDate" in req.body) cleanedData.lastPaidDate = cleanString(req.body.lastPaidDate);
        if ("policyExpirationDate" in req.body) cleanedData.policyExpirationDate = cleanString(req.body.policyExpirationDate);
        if ("holdDate" in req.body) cleanedData.holdDate = cleanString(req.body.holdDate);
        if ("coverageAmount" in req.body) cleanedData.coverageAmount = cleanNumeric(req.body.coverageAmount);
        if ("monthlyAmount" in req.body) cleanedData.monthlyAmount = cleanNumeric(req.body.monthlyAmount);
        if ("annualAmount" in req.body) cleanedData.annualAmount = cleanNumeric(req.body.annualAmount);
        if ("paymentAmount" in req.body) cleanedData.paymentAmount = cleanNumeric(req.body.paymentAmount);
        if ("daysBeforeDue" in req.body) cleanedData.daysBeforeDue = cleanNumeric(req.body.daysBeforeDue);
        Object.keys(req.body).forEach((key) => {
          if (!(key in cleanedData)) {
            const value = req.body[key];
            if (value !== void 0 && value !== "") {
              cleanedData[key] = value;
            }
          }
        });
        Object.keys(cleanedData).forEach((key) => {
          if (cleanedData[key] === void 0) {
            delete cleanedData[key];
          }
        });
        const updatedDisbursement = await storage.updateEscrowDisbursement(id, cleanedData);
        const potentialFields = Object.keys(cleanedData);
        for (const field of potentialFields) {
          const oldValue = existingDisbursement[field];
          const newValue = updatedDisbursement[field];
          if (String(oldValue) !== String(newValue)) {
            await complianceAudit.logEvent({
              eventType: COMPLIANCE_EVENTS.ESCROW.DISBURSEMENT_UPDATED,
              actorType: "user",
              actorId: userId?.toString(),
              resourceType: "escrow_disbursement",
              resourceId: id.toString(),
              loanId: existingDisbursement.loanId,
              ipAddr: getRealUserIP(req),
              userAgent: req.headers?.["user-agent"],
              description: `Escrow disbursement field '${field}' updated from '${oldValue}' to '${newValue}' on LN-2025-001`,
              previousValues: { [field]: oldValue },
              newValues: { [field]: newValue },
              changedFields: [field]
            });
          }
        }
        res.json(updatedDisbursement);
      } catch (error) {
        console.error("Error updating disbursement:", error);
        res.status(400).json({ error: "Failed to update disbursement" });
      }
    });
    router37.delete("/api/escrow-disbursements/:id", async (req, res) => {
      try {
        const id = parseInt(req.params.id);
        const userId = req.user?.id || req.session?.userId;
        const disbursement2 = await storage.getEscrowDisbursement(id);
        await storage.deleteEscrowDisbursement(id);
        if (disbursement2) {
          await complianceAudit.logEvent({
            eventType: COMPLIANCE_EVENTS.ESCROW.DISBURSEMENT_DELETED,
            actorType: "user",
            actorId: userId?.toString(),
            resourceType: "escrow_disbursement",
            resourceId: id.toString(),
            loanId: disbursement2.loanId,
            ipAddr: getRealUserIP(req),
            userAgent: req.headers?.["user-agent"],
            metadata: {
              action: "delete_escrow_disbursement",
              disbursementId: id,
              loanId: disbursement2.loanId,
              disbursementType: disbursement2.disbursementType,
              payeeName: disbursement2.payeeName,
              deletedData: disbursement2
            },
            previousValues: disbursement2
          });
        }
        res.status(204).send();
      } catch (error) {
        console.error("Error deleting disbursement:", error);
        res.status(400).json({ error: "Failed to delete disbursement" });
      }
    });
    router37.post("/api/escrow-disbursements/:id/payments", async (req, res) => {
      try {
        const disbursementId = parseInt(req.params.id);
        const userId = req.user?.id || req.session?.userId;
        const disbursement2 = await storage.getEscrowDisbursement(disbursementId);
        if (!disbursement2) {
          return res.status(404).json({ error: "Disbursement not found" });
        }
        const validatedData = insertEscrowDisbursementPaymentSchema.parse({
          ...req.body,
          disbursementId,
          loanId: disbursement2.loanId
        });
        const result = await db.transaction(async (tx) => {
          const [payment] = await tx.insert(escrowDisbursementPayments).values(validatedData).returning();
          const [ledgerEntry] = await tx.insert(loanLedger).values({
            loanId: disbursement2.loanId,
            transactionDate: validatedData.paymentDate,
            transactionId: `DISB-${payment.id}-${Date.now()}`,
            description: `Escrow disbursement: ${disbursement2.description}`,
            transactionType: "disbursement",
            debitAmount: validatedData.amount,
            creditAmount: "0",
            category: "escrow",
            notes: `Payment for ${disbursement2.disbursementType} - ${disbursement2.description}`,
            runningBalance: "0",
            // Will be calculated properly in production
            principalBalance: "0",
            interestBalance: "0",
            status: "posted"
          }).returning();
          const [updatedPayment] = await tx.update(escrowDisbursementPayments).set({ ledgerEntryId: ledgerEntry.id }).where(eq33(escrowDisbursementPayments.id, payment.id)).returning();
          const [escrowAccount] = await tx.select().from(escrowAccounts2).where(eq33(escrowAccounts2.loanId, disbursement2.loanId)).limit(1);
          if (escrowAccount) {
            const newBalance = (parseFloat(escrowAccount.balance) - parseFloat(validatedData.amount)).toFixed(2);
            await tx.update(escrowAccounts2).set({
              balance: newBalance,
              lastTransactionDate: validatedData.paymentDate
            }).where(eq33(escrowAccounts2.id, escrowAccount.id));
          }
          return { ...updatedPayment, ledgerEntryId: ledgerEntry.id };
        });
        await complianceAudit.logEvent({
          eventType: COMPLIANCE_EVENTS.ESCROW.PAYMENT_PROCESSED,
          actorType: "user",
          actorId: userId?.toString(),
          resourceType: "escrow_payment",
          resourceId: result.id.toString(),
          loanId: disbursement2.loanId,
          ipAddr: getRealUserIP(req),
          userAgent: req.headers?.["user-agent"],
          metadata: {
            action: "process_escrow_payment",
            paymentId: result.id,
            disbursementId,
            loanId: disbursement2.loanId,
            amount: validatedData.amount,
            paymentDate: validatedData.paymentDate,
            paymentMethod: validatedData.paymentMethod,
            checkNumber: validatedData.checkNumber,
            transactionNumber: validatedData.transactionNumber,
            ledgerEntryId: result.ledgerEntryId
          },
          newValues: result,
          userId,
          ipAddress: getRealUserIP(req)
        });
        res.status(201).json(result);
      } catch (error) {
        console.error("Error recording disbursement payment:", error);
        const errorMessage = error.issues ? error.issues[0].message : error.message || "Invalid payment data";
        res.status(400).json({ error: errorMessage, details: error.issues || error.message });
      }
    });
    router37.get("/api/loans/:loanId/escrow-summary", async (req, res) => {
      try {
        const loanId = parseInt(req.params.loanId);
        const userId = req.user?.id || req.session?.userId;
        const summary = await storage.getEscrowSummary(loanId);
        await complianceAudit.logEvent({
          eventType: COMPLIANCE_EVENTS.ESCROW.VIEWED,
          actorType: "user",
          actorId: userId?.toString(),
          resourceType: "escrow_summary",
          resourceId: loanId.toString(),
          loanId,
          ipAddr: getRealUserIP(req),
          userAgent: req.headers?.["user-agent"],
          metadata: {
            action: "view_escrow_summary",
            loanId,
            totalDisbursements: summary.summary.totalDisbursements,
            activeDisbursements: summary.summary.activeDisbursements,
            onHoldDisbursements: summary.summary.onHoldDisbursements,
            totalAnnualAmount: summary.summary.totalAnnualAmount
          },
          userId,
          ipAddress: getRealUserIP(req)
        });
        res.json(summary);
      } catch (error) {
        console.error("Error getting escrow summary:", error);
        res.status(500).json({ error: "Failed to get escrow summary" });
      }
    });
    router37.post("/api/escrow-disbursements/:id/hold", async (req, res) => {
      try {
        const id = parseInt(req.params.id);
        if (isNaN(id)) {
          return res.status(400).json({ error: "Invalid disbursement ID" });
        }
        const { action, reason, requestedBy } = req.body;
        const userId = req.user?.id || req.session?.userId;
        let result;
        let eventType;
        if (action === "hold") {
          result = await storage.holdEscrowDisbursement(id, reason, requestedBy);
          eventType = COMPLIANCE_EVENTS.ESCROW.DISBURSEMENT_HELD;
        } else if (action === "release") {
          result = await storage.releaseEscrowDisbursement(id);
          eventType = COMPLIANCE_EVENTS.ESCROW.DISBURSEMENT_RELEASED;
        } else {
          return res.status(400).json({ error: "Action must be 'hold' or 'release'" });
        }
        await complianceAudit.logEvent({
          eventType,
          actorType: "user",
          actorId: userId?.toString(),
          resourceType: "escrow_disbursement",
          resourceId: id.toString(),
          loanId: disbursement.loanId,
          ipAddr: getRealUserIP(req),
          userAgent: req.headers?.["user-agent"],
          metadata: {
            action: action === "hold" ? "hold_escrow_disbursement" : "release_escrow_disbursement",
            disbursementId: id,
            loanId: result.loanId,
            reason: reason || null,
            requestedBy: requestedBy || userId,
            isOnHold: result.isOnHold,
            holdReason: result.holdReason
          },
          newValues: result,
          userId,
          ipAddress: getRealUserIP(req)
        });
        res.json(result);
      } catch (error) {
        console.error("Error putting disbursement on hold:", error);
        res.status(400).json({ error: "Failed to update disbursement hold status" });
      }
    });
    escrow_disbursements_default = router37;
  }
});

// src/servicing/policy.ts
import dayjs4 from "dayjs";
import tz2 from "dayjs/plugin/timezone";
import utc2 from "dayjs/plugin/utc";
function daysPastDue(dueISO, paid, paidAt, asOfISO) {
  const asOf = dayjs4.tz(asOfISO || dayjs4().format("YYYY-MM-DD"), Z2);
  const due = dayjs4.tz(dueISO, Z2);
  if (paid && paidAt) {
    const p = dayjs4.tz(paidAt, Z2);
    return Math.max(0, p.diff(due, "day"));
  }
  return Math.max(0, asOf.diff(due, "day"));
}
function delinquencyBucket(dpd) {
  const buckets2 = (process.env.DELINQ_BUCKETS || "0,30,60,90,120").split(",").map((n) => Number(n.trim())).sort((a, b) => a - b);
  let label = `${buckets2[0]}+`;
  for (let i = buckets2.length - 1; i >= 0; i--) {
    if (dpd >= buckets2[i]) {
      label = `${buckets2[i]}+`;
      break;
    }
  }
  return label;
}
function lateFee(pi) {
  const pct = Number(process.env.LATE_FEE_PCT_OF_PI || "0.05");
  return round22(pi * pct);
}
function graceDays(loanGrace) {
  if (loanGrace && loanGrace > 0) return loanGrace;
  return Number(process.env.LATE_FEE_GRACE_DAYS || "15");
}
function round22(n) {
  return Math.round((n + Number.EPSILON) * 100) / 100;
}
var Z2;
var init_policy = __esm({
  "src/servicing/policy.ts"() {
    "use strict";
    dayjs4.extend(utc2);
    dayjs4.extend(tz2);
    Z2 = process.env.SVC_BUSINESS_TZ || "America/New_York";
  }
});

// src/servicing/statementPdf.ts
import PDFDocument4 from "pdfkit";
async function renderStatementPdf(input) {
  const doc = new PDFDocument4({ size: "LETTER", margin: 50 });
  const buffers = [];
  doc.on("data", (b) => buffers.push(b));
  doc.fontSize(18).text(input.header, { align: "center" }).moveDown(0.5);
  addWatermark2(doc, input.watermark);
  doc.fontSize(12);
  doc.text(`Statement Date: ${input.asOf}`);
  doc.text(`Loan ID: ${input.account.loan_id}`);
  doc.text(`Status: ${input.account.state}`);
  doc.text(`Due (next): ${input.schedule[0]?.due_date || "(n/a)"}`).moveDown(0.5);
  doc.fontSize(14).text("Amount Due", { underline: true }).moveDown(0.2);
  const d = input.currentDue;
  doc.fontSize(12).text(
    `Principal: $${fmt(d.principal)}   Interest: $${fmt(d.interest)}   Escrow: $${fmt(d.escrow)}   Fees: $${fmt(d.fees)}`
  );
  doc.fontSize(14).text(`Total Due: $${fmt(d.total)}`).moveDown(0.5);
  doc.fontSize(12).text(`Days Past Due: ${input.delinquency.dpd} (bucket ${input.delinquency.bucket})`).moveDown(0.5);
  doc.fontSize(14).text("Escrow", { underline: true }).moveDown(0.2);
  doc.fontSize(12).text(`Balance: $${fmt(input.escrow.balance)}   Shortage: $${fmt(input.escrow.shortage)}`);
  const eb = input.escrow.buckets;
  doc.text(
    `Monthly Accruals \u2014 TAX: $${fmt(eb.TAX || 0)} HOI: $${fmt(eb.HOI || 0)} FLOOD: $${fmt(eb.FLOOD || 0)} HOA: $${fmt(eb.HOA || 0)}`
  ).moveDown(0.5);
  doc.fontSize(14).text("Upcoming Schedule", { underline: true }).moveDown(0.2);
  doc.fontSize(12);
  input.schedule.slice(0, 3).forEach((r) => {
    doc.text(
      `${r.installment_no}. ${r.due_date}  P: $${fmt(r.principal_due)}  I: $${fmt(r.interest_due)}  Esc: $${fmt(r.escrow_due)}  Total: $${fmt(r.total_due)}`
    );
  });
  doc.moveDown(0.5);
  doc.fontSize(14).text("How to Pay", { underline: true }).moveDown(0.2);
  doc.fontSize(12).text(`Email: ${input.remitTo.email}  Phone: ${input.remitTo.phone}`);
  doc.text(`Mail: ${input.remitTo.address}`);
  doc.end();
  const pdf = await new Promise(
    (resolve) => doc.on("end", () => resolve(Buffer.concat(buffers)))
  );
  return { pdf, sha256: sha256Buf(pdf) };
}
function addWatermark2(doc, text2) {
  if (!text2) return;
  const { width, height } = doc.page;
  doc.save().fillColor("#dddddd").fontSize(40).rotate(-30, { origin: [width / 2, height / 2] }).opacity(0.2).text(text2, width / 2 - 200, height / 2 - 50).opacity(1).rotate(30, { origin: [width / 2, height / 2] }).restore();
}
function fmt(n) {
  return n.toFixed(2);
}
var init_statementPdf = __esm({
  "src/servicing/statementPdf.ts"() {
    "use strict";
    init_hash();
  }
});

// src/servicing/cycle.ts
import dayjs5 from "dayjs";
import tz3 from "dayjs/plugin/timezone";
import utc3 from "dayjs/plugin/utc";
async function runDailyCycle(tenantId, asOfISO) {
  const asOf = dayjs5.tz(asOfISO || dayjs5().format("YYYY-MM-DD"), Z3).format("YYYY-MM-DD");
  const client5 = await pool.connect();
  try {
    const exist = await client5.query(
      `SELECT 1 FROM svc_cycle_runs WHERE tenant_id=$1 AND as_of_date=$2`,
      [tenantId, asOf]
    );
    if (exist.rowCount) return { ok: true, skipped: true };
    await client5.query(
      `INSERT INTO svc_cycle_runs (tenant_id, as_of_date, status) VALUES ($1,$2,'started')`,
      [tenantId, asOf]
    );
    const acc = await client5.query(`SELECT * FROM svc_accounts WHERE state='Active'`);
    let issued = 0, lateFees = 0, billsQueued = 0;
    for (const a of acc.rows) {
      const loanId = a.loan_id;
      const sched = await client5.query(`
        SELECT * FROM svc_schedule WHERE loan_id=$1 AND paid=false ORDER BY installment_no ASC LIMIT 1
      `, [loanId]);
      const row = sched.rows[0];
      if (!row) continue;
      const dpd = daysPastDue(row.due_date, row.paid, row.paid_at);
      const bucket = delinquencyBucket(dpd);
      const grace = graceDays(a.grace_days);
      let assessedLate = false;
      if (dpd > grace) {
        const feeExists = await client5.query(`
          SELECT 1 FROM svc_txns WHERE loan_id=$1 AND type='FEE' AND fee_code='LATE' AND ref->>'installment_no' = $2::text
        `, [loanId, String(row.installment_no)]);
        if (!feeExists.rowCount) {
          const fee = lateFee(Number(a.pmt_principal_interest));
          await client5.query(`
            INSERT INTO svc_txns (tenant_id, loan_id, type, amount, alloc_fees, fee_code, memo, ref)
            VALUES ($1,$2,'FEE',$3, $3, 'LATE','Late fee after grace', $6)
          `, [tenantId, loanId, fee, row.installment_no, row.due_date, JSON.stringify({ installment_no: row.installment_no, due_date: row.due_date })]);
          await client5.query(`
            INSERT INTO gl_entries (tenant_id, loan_id, debit_acct, credit_acct, amount, memo)
            VALUES ($1,$2,$3,$4,$5,'Late fee assessment')
          `, [tenantId, loanId, Number(process.env.GL_CASH_ACCT || "1000"), Number(process.env.GL_LATE_FEE_INCOME_ACCT || "4100"), fee]);
          assessedLate = true;
          lateFees++;
        }
      }
      const isDueToday = row.due_date === asOf;
      if (isDueToday) {
        const feesRow = await client5.query(`
          SELECT COALESCE(SUM(alloc_fees),0) AS fees FROM svc_txns WHERE loan_id=$1 AND type IN ('FEE') AND ts::date <= $2::date
        `, [loanId, asOf]);
        const due = {
          principal: Number(row.principal_due),
          interest: Number(row.interest_due),
          escrow: Number(row.escrow_due),
          fees: Number(feesRow.rows[0].fees || 0)
        };
        const total = round23(due.principal + due.interest + due.escrow + due.fees);
        const escSub = await client5.query(`SELECT bucket, monthly_accrual, balance FROM svc_escrow_sub WHERE loan_id=$1`, [loanId]);
        const buckets2 = {};
        let escBal = 0;
        for (const e of escSub.rows) {
          buckets2[e.bucket] = Number(e.monthly_accrual);
          escBal += Number(e.balance);
        }
        const cushion = Number(process.env.ESCROW_CUSHION_MONTHS || "2") * (buckets2.TAX || 0 + buckets2.HOI || 0 + buckets2.FLOOD || 0 + buckets2.HOA || 0);
        const shortage = Math.max(0, round23(cushion - escBal));
        const shortageMin = Number(process.env.ESCROW_SHORTAGE_MIN_PAY || "100");
        const shortageCollectThisCycle = shortage > 0 ? Math.max(shortageMin, Math.ceil(shortage / 12)) : 0;
        const escrowBalance2 = escBal;
        const stmt = await renderStatementPdf({
          header: process.env.STMT_PDF_HEADER || "LoanServe \u2022 Monthly Statement",
          watermark: process.env.STMT_PDF_WATERMARK || "",
          account: a,
          schedule: [row],
          asOf,
          priorBalance: row.principal_balance_after + Number(row.escrow_due || 0),
          currentDue: { ...due, total },
          delinquency: { dpd, bucket: bucket2 },
          escrow: { buckets: buckets2, balance: escrowBalance2, shortage },
          remitTo: {
            email: process.env.STMT_CONTACT_EMAIL || "",
            phone: process.env.STMT_CONTACT_PHONE || "",
            address: process.env.STMT_RETURN_ADDRESS || ""
          }
        });
        const bucket2 = process.env.AWS_S3_BUCKET || "loanserve-storage";
        const key = `${process.env.S3_PREFIX || "tenants"}/${tenantId}/loans/${loanId}/${process.env.STMT_S3_PREFIX || "statements"}/STMT_${a.loan_id}_${asOf}.pdf`;
        const uri = await putBytes(bucket2, key, stmt.pdf);
        await client5.query(`
          INSERT INTO svc_statements (tenant_id, loan_id, statement_date, cycle_label, file_uri, file_sha256, summary)
          VALUES ($1,$2,$3,$4,$5,$6,$7)
        `, [tenantId, loanId, asOf, asOf.slice(0, 7), uri, stmt.sha256, JSON.stringify({
          due,
          total,
          delinquency: { dpd, bucket: bucket2 },
          escrow: { balance: escrowBalance2, shortage, buckets: buckets2 },
          shortageCollectThisCycle
        })]);
        issued++;
      }
      const bills = await client5.query(`
        SELECT v.id as vendor_id, v.type, v.name
        FROM svc_vendors v WHERE v.loan_id=$1 AND v.type IN ('TAX','HOI','FLOOD','HOA')
      `, [loanId]);
      const horizon = dayjs5.tz(asOf, Z3).add(30, "day").format("YYYY-MM-DD");
      for (const b of bills.rows) {
        const impliedDue = dayjs5.tz(asOf, Z3).add(1, "month").date(15).format("YYYY-MM-DD");
        const existBill = await client5.query(`SELECT 1 FROM svc_vendor_bills WHERE loan_id=$1 AND vendor_id=$2 AND due_date=$3`, [loanId, b.vendor_id, impliedDue]);
        if (existBill.rowCount) continue;
        const accrual = buckets[b.type] || 0;
        const amount = Math.max(50, round23(accrual * 12));
        const escBal = escrowBalance;
        const scheduled = escBal >= amount ? "Scheduled" : "Queued";
        await client5.query(`
          INSERT INTO svc_vendor_bills (tenant_id, loan_id, vendor_id, bucket, due_date, amount, status)
          VALUES ($1,$2,$3,$4,$5,$6,$7)
        `, [tenantId, loanId, b.vendor_id, b.type, impliedDue, amount, scheduled]);
        if (scheduled === "Scheduled") {
          const method = process.env.DISB_DEFAULT_METHOD || "ACH";
          await client5.query(`
            INSERT INTO svc_disbursements (tenant_id, loan_id, vendor_id, bill_id, method, scheduled_date, amount, status, meta)
            VALUES ($1,$2,$3,(SELECT id FROM svc_vendor_bills WHERE loan_id=$2 AND vendor_id=$3 AND due_date=$4 LIMIT 1),$5,$4,$6,'Requested','{}')
          `, [tenantId, loanId, b.vendor_id, impliedDue, method, amount]);
          billsQueued++;
        }
      }
    }
    await client5.query(
      `UPDATE svc_cycle_runs SET status='completed', completed_at=now(), metrics=$3 WHERE tenant_id=$1 AND as_of_date=$2`,
      [tenantId, asOf, JSON.stringify({ issued, lateFees, billsQueued })]
    );
    return { ok: true, issued, lateFees, billsQueued };
  } catch (e) {
    await pool.query(
      `UPDATE svc_cycle_runs SET status='failed', completed_at=now(), metrics=$3 WHERE tenant_id=$1 AND as_of_date=$2`,
      [tenantId, asOf, JSON.stringify({ error: String(e) })]
    ).catch(() => {
    });
    throw e;
  } finally {
    client5.release();
  }
}
function round23(n) {
  return Math.round((n + Number.EPSILON) * 100) / 100;
}
var Z3;
var init_cycle = __esm({
  "src/servicing/cycle.ts"() {
    "use strict";
    init_db();
    init_policy();
    init_statementPdf();
    init_storage2();
    dayjs5.extend(utc3);
    dayjs5.extend(tz3);
    Z3 = process.env.SVC_BUSINESS_TZ || "America/New_York";
  }
});

// src/workers/ServicingCycleWorker.ts
async function triggerDailyCycle(tenantId, asOf) {
  try {
    console.log(`[ServicingCycleWorker] Triggering daily cycle for tenant ${tenantId}`);
    const result = await runDailyCycle(tenantId, asOf);
    console.log(`[ServicingCycleWorker] Cycle completed:`, result);
    return result;
  } catch (error) {
    console.error(`[ServicingCycleWorker] Cycle failed:`, error);
    throw error;
  }
}
var init_ServicingCycleWorker = __esm({
  "src/workers/ServicingCycleWorker.ts"() {
    "use strict";
    init_cycle();
  }
});

// src/servicing/disbursements.ts
async function queueDueDisbursements(tenantId, asOfISO) {
  const client5 = await pool.connect();
  try {
    await client5.query(`SET LOCAL app.tenant_id = $1`, [tenantId]);
    const rows = await client5.query(`
      SELECT d.id, d.loan_id, d.vendor_id, d.bill_id, d.amount, d.method
      FROM svc_disbursements d
      WHERE d.scheduled_date <= $1::date AND d.status='Requested'
    `, [asOfISO]);
    return rows.rows;
  } finally {
    client5.release();
  }
}
var init_disbursements = __esm({
  "src/servicing/disbursements.ts"() {
    "use strict";
    init_db();
  }
});

// src/workers/DisbursementBridgeWorker.ts
async function processDueDisbursements(tenantId, asOf) {
  try {
    console.log(`[DisbursementBridgeWorker] Processing due disbursements for tenant ${tenantId}`);
    const dueDisbursements = await queueDueDisbursements(tenantId, asOf);
    console.log(`[DisbursementBridgeWorker] Found ${dueDisbursements.length} due disbursements`);
    dueDisbursements.forEach((d) => {
      console.log(`[DisbursementBridgeWorker] Due disbursement: ${d.id} - $${d.amount} via ${d.method}`);
    });
    return dueDisbursements;
  } catch (error) {
    console.error(`[DisbursementBridgeWorker] Failed to process disbursements:`, error);
    throw error;
  }
}
var init_DisbursementBridgeWorker = __esm({
  "src/workers/DisbursementBridgeWorker.ts"() {
    "use strict";
    init_disbursements();
  }
});

// src/servicing/cycle.simple.ts
async function testSimpleCycle(tenantId, asOfISO) {
  const asOf = asOfISO || "2025-01-15";
  const client5 = await pool.connect();
  try {
    console.log("Testing simple cycle execution...");
    console.log("Test 1: Simple tenant check");
    const test1 = await client5.query(`SELECT COUNT(*) FROM svc_accounts`);
    console.log("Accounts found:", test1.rows[0].count);
    console.log("Test 2: Parameterized query");
    const test2 = await client5.query(`SELECT COUNT(*) FROM svc_accounts WHERE state = $1`, ["Active"]);
    console.log("Active accounts:", test2.rows[0].count);
    console.log("Test 3: Complex query like in cycle");
    const test3 = await client5.query(`
      SELECT COUNT(*) FROM svc_cycle_runs WHERE tenant_id = $1 AND as_of_date = $2
    `, [tenantId, asOf]);
    console.log("Existing cycle runs:", test3.rows[0].count);
    return { ok: true, tests: 3 };
  } catch (error) {
    console.error("Simple cycle test failed:", error);
    throw error;
  } finally {
    client5.release();
  }
}
var init_cycle_simple = __esm({
  "src/servicing/cycle.simple.ts"() {
    "use strict";
    init_db();
  }
});

// src/routes/cycle.routes.ts
var cycle_routes_exports = {};
__export(cycle_routes_exports, {
  cycleRouter: () => cycleRouter
});
import { Router as Router47 } from "express";
var cycleRouter;
var init_cycle_routes = __esm({
  "src/routes/cycle.routes.ts"() {
    "use strict";
    init_db();
    init_ServicingCycleWorker();
    init_DisbursementBridgeWorker();
    init_cycle_simple();
    cycleRouter = Router47();
    cycleRouter.post("/servicing/cycle/tick", async (req, res) => {
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const asOf = req.body?.asOf;
        const result = await triggerDailyCycle(tenantId, asOf);
        res.status(202).json({
          status: "completed",
          message: "Daily cycle triggered successfully",
          result
        });
      } catch (error) {
        console.error("Cycle trigger failed:", error);
        res.status(500).json({
          error: "Failed to trigger cycle",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    cycleRouter.get("/loans/:id/statements", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        await client5.query(`SET LOCAL app.tenant_id = $1`, [tenantId]);
        const result = await client5.query(`
      SELECT statement_date, cycle_label, file_uri, file_sha256, summary
      FROM svc_statements 
      WHERE loan_id = $1 
      ORDER BY statement_date DESC
    `, [req.params.id]);
        res.json({
          loan_id: req.params.id,
          statements: result.rows
        });
      } catch (error) {
        console.error("Error fetching statements:", error);
        res.status(500).json({ error: "Failed to fetch statements" });
      } finally {
        client5.release();
      }
    });
    cycleRouter.get("/loans/:id/vendor-bills", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        await client5.query(`SET LOCAL app.tenant_id = $1`, [tenantId]);
        const result = await client5.query(`
      SELECT vb.*, v.name as vendor_name, v.type as vendor_type
      FROM svc_vendor_bills vb
      LEFT JOIN svc_vendors v ON vb.vendor_id = v.id
      WHERE vb.loan_id = $1 
      ORDER BY vb.due_date
    `, [req.params.id]);
        res.json({
          loan_id: req.params.id,
          bills: result.rows
        });
      } catch (error) {
        console.error("Error fetching vendor bills:", error);
        res.status(500).json({ error: "Failed to fetch vendor bills" });
      } finally {
        client5.release();
      }
    });
    cycleRouter.get("/loans/:id/disbursements", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        await client5.query(`SET LOCAL app.tenant_id = $1`, [tenantId]);
        const result = await client5.query(`
      SELECT d.*, v.name as vendor_name, vb.bucket
      FROM svc_disbursements d
      LEFT JOIN svc_vendors v ON d.vendor_id = v.id
      LEFT JOIN svc_vendor_bills vb ON d.bill_id = vb.id
      WHERE d.loan_id = $1 
      ORDER BY d.scheduled_date DESC
    `, [req.params.id]);
        res.json({
          loan_id: req.params.id,
          disbursements: result.rows
        });
      } catch (error) {
        console.error("Error fetching disbursements:", error);
        res.status(500).json({ error: "Failed to fetch disbursements" });
      } finally {
        client5.release();
      }
    });
    cycleRouter.get("/servicing/cycle/runs", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        await client5.query(`SET LOCAL app.tenant_id = $1`, [tenantId]);
        const result = await client5.query(`
      SELECT * FROM svc_cycle_runs 
      WHERE tenant_id = $1 
      ORDER BY as_of_date DESC 
      LIMIT 20
    `, [tenantId]);
        res.json({
          tenant_id: tenantId,
          cycle_runs: result.rows
        });
      } catch (error) {
        console.error("Error fetching cycle runs:", error);
        res.status(500).json({ error: "Failed to fetch cycle runs" });
      } finally {
        client5.release();
      }
    });
    cycleRouter.post("/servicing/cycle/test", async (req, res) => {
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const asOf = req.body?.asOf;
        const result = await testSimpleCycle(tenantId, asOf);
        res.status(200).json({
          status: "completed",
          message: "Simple cycle test passed",
          result
        });
      } catch (error) {
        console.error("Simple cycle test failed:", error);
        res.status(500).json({
          error: "Failed to run simple cycle test",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    cycleRouter.post("/servicing/disbursements/process", async (req, res) => {
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const asOf = req.body?.asOf || (/* @__PURE__ */ new Date()).toISOString().split("T")[0];
        const result = await processDueDisbursements(tenantId, asOf);
        res.status(202).json({
          status: "completed",
          message: "Disbursements processed successfully",
          disbursements: result
        });
      } catch (error) {
        console.error("Disbursement processing failed:", error);
        res.status(500).json({
          error: "Failed to process disbursements",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
  }
});

// server/routes/rabbitmq-test.ts
var rabbitmq_test_exports = {};
__export(rabbitmq_test_exports, {
  default: () => rabbitmq_test_default
});
import { Router as Router48 } from "express";
var router38, rabbitmq_test_default;
var init_rabbitmq_test = __esm({
  "server/routes/rabbitmq-test.ts"() {
    "use strict";
    init_rabbitmq_unified();
    router38 = Router48();
    router38.get("/test-connection", async (req, res) => {
      try {
        const rabbitmq2 = rabbitmqClient;
        const info = await rabbitmq2.getConnectionInfo();
        res.json({
          success: true,
          message: "RabbitMQ connection test successful",
          connectionInfo: info
        });
      } catch (error) {
        console.error("RabbitMQ connection test failed:", error);
        res.status(500).json({
          success: false,
          message: "RabbitMQ connection test failed",
          error: error.message
        });
      }
    });
    router38.post("/test-publish", async (req, res) => {
      try {
        const rabbitmq2 = rabbitmqClient;
        const { queue = "test-queue", message = "Hello from LoanServe Pro!" } = req.body;
        const success = await rabbitmq2.sendToQueue(queue, {
          message,
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          sender: "LoanServe Pro API"
        });
        res.json({
          success,
          message: `Message published to queue '${queue}'`,
          data: { queue, published: success }
        });
      } catch (error) {
        console.error("RabbitMQ publish test failed:", error);
        res.status(500).json({
          success: false,
          message: "Failed to publish message",
          error: error.message
        });
      }
    });
    router38.get("/test-consume", async (req, res) => {
      try {
        const rabbitmq2 = rabbitmqClient;
        const { queue = "test-queue" } = req.query;
        let messageReceived = null;
        let timeoutReached = false;
        const timeout = setTimeout(() => {
          timeoutReached = true;
        }, 5e3);
        const consumerTag = await rabbitmq2.consume(queue, async (message) => {
          if (!timeoutReached) {
            messageReceived = message;
            clearTimeout(timeout);
          }
        });
        await new Promise((resolve) => {
          const checkInterval = setInterval(() => {
            if (messageReceived || timeoutReached) {
              clearInterval(checkInterval);
              resolve(null);
            }
          }, 100);
        });
        if (messageReceived) {
          res.json({
            success: true,
            message: `Message consumed from queue '${queue}'`,
            data: messageReceived
          });
        } else {
          res.json({
            success: true,
            message: `No messages available in queue '${queue}' within timeout period`,
            data: null
          });
        }
      } catch (error) {
        console.error("RabbitMQ consume test failed:", error);
        res.status(500).json({
          success: false,
          message: "Failed to consume message",
          error: error.message
        });
      }
    });
    router38.get("/initialize", async (req, res) => {
      try {
        const rabbitmq2 = rabbitmqClient;
        await rabbitmq2.connect();
        await rabbitmq2.createExchange("loanserve-exchange", "direct");
        await rabbitmq2.bindQueue("test-queue", "loanserve-exchange", "test");
        res.json({
          success: true,
          message: "RabbitMQ initialized successfully",
          data: {
            exchange: "loanserve-exchange",
            queue: "test-queue",
            routingKey: "test"
          }
        });
      } catch (error) {
        console.error("RabbitMQ initialization failed:", error);
        res.status(500).json({
          success: false,
          message: "RabbitMQ initialization failed",
          error: error.message
        });
      }
    });
    rabbitmq_test_default = router38;
  }
});

// shared/messaging/envelope.ts
var init_envelope2 = __esm({
  "shared/messaging/envelope.ts"() {
    "use strict";
  }
});

// server/messaging/message-factory.ts
import { ulid as ulid7 } from "ulid";
import { randomUUID as randomUUID18 } from "crypto";
function getMessageFactory() {
  if (!defaultFactory) {
    defaultFactory = new MessageFactory({
      producer: "loanserve-api",
      producer_instance: process.env.INSTANCE_ID || ulid7()
    });
  }
  return defaultFactory;
}
var MessageFactory, defaultFactory;
var init_message_factory = __esm({
  "server/messaging/message-factory.ts"() {
    "use strict";
    init_envelope2();
    MessageFactory = class {
      options;
      producer_version;
      constructor(options) {
        this.options = options;
        this.producer_version = process.env.APP_VERSION || "1.0.0";
      }
      /**
       * Create a new message envelope
       */
      createMessage(schema, data, options) {
        const now = (/* @__PURE__ */ new Date()).toISOString();
        const envelope = {
          // Required fields
          schema,
          message_id: ulid7(),
          correlation_id: options?.correlation_id || randomUUID18(),
          causation_id: options?.causation_id || options?.correlation_id || randomUUID18(),
          occurred_at: options?.occurred_at || now,
          producer: `${this.options.producer}@${this.producer_version}`,
          version: 1,
          data,
          // Optional fields from factory options
          ...this.options.tenant_id && { tenant_id: this.options.tenant_id },
          ...this.options.user_id && { user_id: this.options.user_id },
          ...this.options.producer_instance && { producer_instance: this.options.producer_instance },
          ...this.options.trace_id && { trace_id: this.options.trace_id },
          // Optional fields from message options
          ...options?.idempotency_key && { idempotency_key: options.idempotency_key },
          ...options?.priority !== void 0 && { priority: options.priority },
          ...options?.ttl && { ttl: options.ttl },
          ...options?.retry_count !== void 0 && { retry_count: options.retry_count },
          ...options?.headers && { headers: options.headers }
        };
        return envelope;
      }
      /**
       * Create a message with high priority
       */
      createCriticalMessage(schema, data, options) {
        return this.createMessage(schema, data, {
          ...options,
          priority: 10 /* CRITICAL */
        });
      }
      /**
       * Create a reply message maintaining correlation
       */
      createReply(originalMessage, schema, data, options) {
        return this.createMessage(schema, data, {
          ...options,
          correlation_id: originalMessage.correlation_id,
          causation_id: originalMessage.message_id,
          trace_id: originalMessage.trace_id
        });
      }
      /**
       * Create an error message for dead letter queue
       */
      createErrorMessage(originalMessage, error, retryable = false) {
        return this.createMessage("loanserve.v1.error", {
          original_message: originalMessage,
          error: {
            message: error.message,
            stack: error.stack,
            name: error.name
          },
          retryable,
          failed_at: (/* @__PURE__ */ new Date()).toISOString()
        }, {
          correlation_id: originalMessage.correlation_id,
          causation_id: originalMessage.message_id,
          trace_id: originalMessage.trace_id
        });
      }
      /**
       * Generate idempotency key for business operations
       */
      static generateIdempotencyKey(...parts) {
        return parts.filter(Boolean).join("-");
      }
      /**
       * Parse message schema to extract domain and version
       */
      static parseSchema(schema) {
        const parts = schema.split(".");
        if (parts.length < 4) {
          throw new Error(`Invalid schema format: ${schema}`);
        }
        return {
          domain: parts[0],
          version: parts[1],
          entity: parts[2],
          action: parts.slice(3).join(".")
        };
      }
      /**
       * Create batch of messages with same correlation
       */
      createBatch(schema, items, options) {
        const correlation_id = randomUUID18();
        return items.map(
          (data) => this.createMessage(schema, data, {
            ...options,
            correlation_id,
            priority: options?.priority ?? 1 /* BATCH */
          })
        );
      }
      /**
       * Update factory context (e.g., after user login)
       */
      updateContext(updates) {
        Object.assign(this.options, updates);
      }
    };
  }
});

// server/messaging/idempotent-consumer.ts
import crypto15 from "crypto";
function createIdempotentHandler(consumerId, handler, options) {
  const consumer = new IdempotentConsumer({
    consumer_id: consumerId,
    ...options
  });
  return (envelope) => consumer.processMessage(envelope, handler);
}
var IdempotentConsumer;
var init_idempotent_consumer = __esm({
  "server/messaging/idempotent-consumer.ts"() {
    "use strict";
    init_db();
    IdempotentConsumer = class {
      options;
      constructor(options) {
        this.options = {
          consumer_group: "default",
          max_retries: 3,
          cleanup_after_days: 30,
          ...options
        };
      }
      /**
       * Process a message with idempotency guarantee
       */
      async processMessage(envelope, handler) {
        const startTime2 = Date.now();
        const context = {
          consumer_id: this.options.consumer_id,
          consumer_group: this.options.consumer_group,
          attempt: envelope.retry_count || 1,
          max_retries: this.options.max_retries,
          received_at: (/* @__PURE__ */ new Date()).toISOString(),
          processing_started_at: (/* @__PURE__ */ new Date()).toISOString()
        };
        try {
          const alreadyProcessed = await this.checkProcessed(envelope.message_id);
          if (alreadyProcessed) {
            console.log(`[IdempotentConsumer] Message ${envelope.message_id} already processed by ${this.options.consumer_id}`);
            return {
              success: true,
              result_hash: alreadyProcessed.result_hash
            };
          }
          const result = await handler(envelope.data, context);
          const resultHash = this.hashResult(result);
          await this.recordProcessed(envelope.message_id, resultHash, result);
          await this.recordMetrics(
            envelope.schema,
            true,
            Date.now() - startTime2,
            envelope.retry_count || 0
          );
          return {
            success: true,
            result_hash: resultHash
          };
        } catch (error) {
          console.error(`[IdempotentConsumer] Error processing message ${envelope.message_id}:`, error);
          await this.recordMetrics(
            envelope.schema,
            false,
            Date.now() - startTime2,
            envelope.retry_count || 0
          );
          const shouldRetry = this.shouldRetry(error, context.attempt);
          return {
            success: false,
            error: error.message,
            should_retry: shouldRetry,
            retry_delay_ms: this.getRetryDelay(context.attempt),
            dead_letter: !shouldRetry && context.attempt >= this.options.max_retries
          };
        }
      }
      /**
       * Check if a message was already processed
       */
      async checkProcessed(messageId) {
        const result = await db.execute(`
      SELECT result_hash, result_data 
      FROM consumer_inbox 
      WHERE consumer = $1 AND message_id = $2
    `, [this.options.consumer_id, messageId]);
        if (result.rows.length > 0) {
          return {
            result_hash: result.rows[0].result_hash || "",
            result_data: result.rows[0].result_data
          };
        }
        return null;
      }
      /**
       * Record that a message was processed
       */
      async recordProcessed(messageId, resultHash, resultData) {
        await db.execute(`
      INSERT INTO consumer_inbox (consumer, message_id, result_hash, result_data, processed_at)
      VALUES ($1, $2, $3, $4, CURRENT_TIMESTAMP)
      ON CONFLICT (consumer, message_id) DO NOTHING
    `, [
          this.options.consumer_id,
          messageId,
          resultHash,
          JSON.stringify(resultData)
        ]);
      }
      /**
       * Record processing metrics
       */
      async recordMetrics(schema, success, processingTimeMs, retryCount) {
        await db.execute(`
      INSERT INTO message_metrics (
        schema_name, consumer, processed_at, processing_time_ms, 
        success, retry_count
      )
      VALUES ($1, $2, CURRENT_TIMESTAMP, $3, $4, $5)
    `, [
          schema,
          this.options.consumer_id,
          processingTimeMs,
          success,
          retryCount
        ]);
      }
      /**
       * Generate a hash of the processing result
       */
      hashResult(result) {
        const json2 = JSON.stringify(result);
        return crypto15.createHash("sha256").update(json2).digest("hex");
      }
      /**
       * Determine if we should retry based on error type
       */
      shouldRetry(error, attempt) {
        if (attempt >= this.options.max_retries) {
          return false;
        }
        if (error.code === "VALIDATION_ERROR" || error.code === "BAD_REQUEST") {
          return false;
        }
        if (error.code === "BUSINESS_ERROR" || error.code === "INVARIANT_VIOLATION") {
          return false;
        }
        if (error.code === "NETWORK_ERROR" || error.code === "TIMEOUT" || error.code === "SERVICE_UNAVAILABLE") {
          return true;
        }
        if (error.code === "DATABASE_ERROR" || error.code === "DEADLOCK") {
          return true;
        }
        return true;
      }
      /**
       * Calculate retry delay with exponential backoff
       */
      getRetryDelay(attempt) {
        const baseDelay = 5e3;
        const maxDelay = 3e5;
        const delay = Math.min(baseDelay * Math.pow(2, attempt - 1), maxDelay);
        const jitter = Math.random() * 0.3 * delay;
        return Math.floor(delay + jitter);
      }
      /**
       * Cleanup old processed messages
       */
      async cleanup() {
        const result = await db.execute(`
      DELETE FROM consumer_inbox 
      WHERE consumer = $1 
        AND processed_at < CURRENT_TIMESTAMP - INTERVAL '${this.options.cleanup_after_days} days'
      RETURNING message_id
    `, [this.options.consumer_id]);
        const deletedCount = result.rows.length;
        if (deletedCount > 0) {
          console.log(`[IdempotentConsumer] Cleaned up ${deletedCount} old messages for ${this.options.consumer_id}`);
        }
        return deletedCount;
      }
      /**
       * Get processing statistics
       */
      async getStats(hours = 24) {
        const result = await db.execute(`
      SELECT 
        COUNT(*) as total_processed,
        SUM(CASE WHEN success THEN 1 ELSE 0 END) as success_count,
        AVG(processing_time_ms) as avg_processing_time_ms,
        SUM(CASE WHEN retry_count > 0 THEN 1 ELSE 0 END) as retry_count
      FROM message_metrics
      WHERE consumer = $1
        AND processed_at > CURRENT_TIMESTAMP - INTERVAL '${hours} hours'
    `, [this.options.consumer_id]);
        const stats = result.rows[0];
        return {
          total_processed: stats?.total_processed || 0,
          success_rate: stats?.total_processed > 0 ? stats.success_count / stats.total_processed * 100 : 0,
          avg_processing_time_ms: stats?.avg_processing_time_ms || 0,
          retry_rate: stats?.total_processed > 0 ? stats.retry_count / stats.total_processed * 100 : 0
        };
      }
    };
  }
});

// server/routes/messaging-test.ts
var messaging_test_exports = {};
__export(messaging_test_exports, {
  default: () => messaging_test_default
});
import { Router as Router49 } from "express";
var router39, messaging_test_default;
var init_messaging_test = __esm({
  "server/routes/messaging-test.ts"() {
    "use strict";
    init_message_factory();
    init_idempotent_consumer();
    init_topology2();
    init_envelope2();
    router39 = Router49();
    router39.get("/topology", async (req, res) => {
      try {
        const stats = topologyManager.getStats();
        const exchanges = topologyManager.getExchangeNames();
        const queues = topologyManager.getQueueNames();
        res.json({
          success: true,
          stats,
          exchanges,
          queues: queues.slice(0, 20),
          // Limit for display
          totalQueues: queues.length
        });
      } catch (error) {
        res.status(500).json({
          success: false,
          error: error.message
        });
      }
    });
    router39.post("/publish-test", async (req, res) => {
      try {
        const { exchange = "payments.topic", routingKey = "payment.test.received", data } = req.body;
        const rabbitmq2 = getEnhancedRabbitMQService();
        const factory = getMessageFactory();
        const envelope = factory.createMessage(
          "loanserve.v1.payment.received",
          data || {
            paymentId: "PMT-" + Date.now(),
            amount: 1e3,
            loanId: "LN-TEST-001",
            type: "ach",
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          },
          {
            priority: 5 /* NORMAL */,
            ttl: 3e5
            // 5 minutes
          }
        );
        const published = await rabbitmq2.publish(envelope, {
          exchange,
          routingKey,
          persistent: true
        });
        res.json({
          success: true,
          message: "Message published with envelope",
          messageId: envelope.message_id,
          correlationId: envelope.correlation_id,
          published
        });
      } catch (error) {
        console.error("Publish test error:", error);
        res.status(500).json({
          success: false,
          error: error.message
        });
      }
    });
    router39.post("/publish-batch", async (req, res) => {
      try {
        const { count: count3 = 10 } = req.body;
        const rabbitmq2 = getEnhancedRabbitMQService();
        const factory = getMessageFactory();
        const messages = factory.createBatch(
          "loanserve.v1.servicing.task",
          Array.from({ length: count3 }, (_, i) => ({
            taskId: `TASK-${Date.now()}-${i}`,
            loanId: `LN-${Math.floor(Math.random() * 100)}`,
            taskType: "interest_accrual",
            dueDate: (/* @__PURE__ */ new Date()).toISOString()
          }))
        );
        const results = await Promise.all(
          messages.map(async (envelope) => {
            const loanId = envelope.data.loanId;
            const shard = EnhancedRabbitMQService.calculateShard(loanId, 8);
            return rabbitmq2.publish(envelope, {
              exchange: "servicing.direct",
              routingKey: `servicing.${shard}.interest`
            });
          })
        );
        const successCount = results.filter((r) => r).length;
        res.json({
          success: true,
          message: `Published ${successCount} of ${count3} messages`,
          correlationId: messages[0].correlation_id
        });
      } catch (error) {
        console.error("Batch publish error:", error);
        res.status(500).json({
          success: false,
          error: error.message
        });
      }
    });
    router39.post("/test-idempotent", async (req, res) => {
      try {
        const { messageId = "test-" + Date.now() } = req.body;
        const handler = createIdempotentHandler(
          "test-consumer",
          async (data, context) => {
            console.log("Processing message:", data);
            await new Promise((resolve) => setTimeout(resolve, 100));
            return { processed: true, timestamp: Date.now() };
          }
        );
        const factory = getMessageFactory();
        const envelope = factory.createMessage(
          "loanserve.v1.test",
          { test: true, messageId },
          { message_id: messageId }
          // Force specific ID for testing
        );
        const result1 = await handler(envelope);
        const result2 = await handler(envelope);
        res.json({
          success: true,
          message: "Idempotency test completed",
          firstRun: result1,
          secondRun: result2,
          idempotent: result1.result_hash === result2.result_hash
        });
      } catch (error) {
        console.error("Idempotency test error:", error);
        res.status(500).json({
          success: false,
          error: error.message
        });
      }
    });
    router39.get("/queue-stats/:queue", async (req, res) => {
      try {
        const { queue } = req.params;
        const rabbitmq2 = getEnhancedRabbitMQService();
        const stats = await rabbitmq2.getQueueStats(queue);
        if (!stats) {
          return res.status(404).json({
            success: false,
            error: "Queue not found or not accessible"
          });
        }
        res.json({
          success: true,
          queue: stats.queue,
          messageCount: stats.messageCount,
          consumerCount: stats.consumerCount
        });
      } catch (error) {
        res.status(500).json({
          success: false,
          error: error.message
        });
      }
    });
    router39.get("/connection-info", async (req, res) => {
      try {
        const rabbitmq2 = getEnhancedRabbitMQService();
        const info = rabbitmq2.getConnectionInfo();
        res.json({
          success: true,
          connectionInfo: info
        });
      } catch (error) {
        res.status(500).json({
          success: false,
          error: error.message
        });
      }
    });
    router39.post("/start-test-consumer", async (req, res) => {
      try {
        const { queue = "payments.validation" } = req.body;
        const rabbitmq2 = getEnhancedRabbitMQService();
        const consumerTag = await rabbitmq2.consume(
          {
            queue,
            prefetch: 10,
            consumerTag: `test-consumer-${Date.now()}`
          },
          async (envelope, msg) => {
            console.log(`[TestConsumer] Received message:`, {
              messageId: envelope.message_id,
              schema: envelope.schema,
              data: envelope.data
            });
            await new Promise((resolve) => setTimeout(resolve, 500));
            console.log(`[TestConsumer] Processed message ${envelope.message_id}`);
          }
        );
        res.json({
          success: true,
          message: "Test consumer started",
          consumerTag,
          queue
        });
      } catch (error) {
        console.error("Start consumer error:", error);
        res.status(500).json({
          success: false,
          error: error.message
        });
      }
    });
    messaging_test_default = router39;
  }
});

// server/services/exception-case.ts
import { eq as eq34, and as and27 } from "drizzle-orm";
var ExceptionCaseService, exceptionCaseService;
var init_exception_case = __esm({
  "server/services/exception-case.ts"() {
    "use strict";
    init_db();
    init_schema();
    ExceptionCaseService = class {
      /**
       * Create a new exception case
       */
      async createException(exception) {
        const [created] = await db.insert(exceptionCases).values({
          ingestionId: exception.ingestionId,
          paymentId: exception.paymentId ? parseInt(exception.paymentId) : void 0,
          // Convert to int for DB until schema is fixed
          category: exception.category,
          subcategory: exception.subcategory,
          severity: exception.severity,
          state: exception.state || "open",
          assignedTo: exception.assignedTo,
          aiRecommendation: exception.aiRecommendation
        }).returning();
        console.log(`[ExceptionCase] Created exception ${created.id}: category=${exception.category}, severity=${exception.severity}, state=${created.state}`);
        return {
          ...created,
          paymentId: created.paymentId?.toString()
          // Convert back to string for consistency
        };
      }
      /**
       * Create an ACH return exception
       */
      async createAchReturnException(paymentId, returnCode, returnReason, amount) {
        const severity = this.determineAchReturnSeverity(returnCode);
        return this.createException({
          paymentId,
          category: "ach_return",
          subcategory: returnCode,
          severity,
          state: "open",
          aiRecommendation: {
            returnCode,
            returnReason,
            amount,
            suggestedActions: this.getAchReturnSuggestedActions(returnCode),
            autoResolve: severity === "low"
          }
        });
      }
      /**
       * Create an NSF (Non-Sufficient Funds) exception
       */
      async createNsfException(paymentId, amount, attemptCount) {
        const severity = attemptCount > 2 ? "high" : "medium";
        return this.createException({
          paymentId,
          category: "nsf",
          severity,
          state: "open",
          aiRecommendation: {
            amount,
            attemptCount,
            suggestedActions: [
              "Contact customer for updated payment method",
              "Schedule retry after payday",
              "Offer payment plan if recurring NSF",
              attemptCount > 2 ? "Consider account suspension" : "Monitor for pattern"
            ],
            recommendedRetryDate: this.calculateRetryDate(attemptCount)
          }
        });
      }
      /**
       * Create a duplicate payment exception
       */
      async createDuplicateException(ingestionId, originalPaymentId, duplicateAmount) {
        return this.createException({
          ingestionId,
          paymentId: originalPaymentId,
          category: "duplicate",
          severity: "medium",
          state: "pending",
          aiRecommendation: {
            originalPaymentId,
            duplicateAmount,
            suggestedActions: [
              "Verify duplicate payment",
              "Refund if confirmed duplicate",
              "Update reconciliation records"
            ],
            autoResolve: false
          }
        });
      }
      /**
       * Create a wire recall exception
       */
      async createWireRecallException(paymentId, recallReason, amount) {
        const severity = this.determineWireRecallSeverity(recallReason);
        return this.createException({
          paymentId,
          category: "wire_recall",
          subcategory: recallReason,
          severity,
          state: "pending",
          aiRecommendation: {
            recallReason,
            amount,
            suggestedActions: this.getWireRecallSuggestedActions(recallReason),
            requiresApproval: true
          }
        });
      }
      /**
       * Create a reconciliation variance exception
       */
      async createReconciliationVarianceException(expectedAmount, actualAmount, referenceId, source) {
        const variance = Math.abs(expectedAmount - actualAmount);
        const severity = variance > 1e3 ? "high" : variance > 100 ? "medium" : "low";
        return this.createException({
          category: "reconcile_variance",
          severity,
          state: "open",
          aiRecommendation: {
            expectedAmount,
            actualAmount,
            variance,
            referenceId,
            source,
            suggestedActions: [
              "Review transaction details",
              "Check for timing differences",
              "Verify exchange rates if applicable",
              "Contact counterparty if needed"
            ]
          }
        });
      }
      /**
       * Get exception by ID
       */
      async getException(id) {
        const [exception] = await db.select().from(exceptionCases).where(eq34(exceptionCases.id, id)).limit(1);
        if (!exception) return null;
        return {
          ...exception,
          paymentId: exception.paymentId?.toString()
          // Convert to string for consistency
        };
      }
      /**
       * Get exceptions by payment ID
       */
      async getExceptionsByPaymentId(paymentId) {
        const exceptions = await db.select().from(exceptionCases).where(eq34(exceptionCases.paymentId, parseInt(paymentId)));
        return exceptions.map((e) => ({
          ...e,
          paymentId: e.paymentId?.toString()
          // Convert back to string
        }));
      }
      /**
       * Get open exceptions
       */
      async getOpenExceptions(category, severity) {
        let query = db.select().from(exceptionCases).where(eq34(exceptionCases.state, "open"));
        if (category) {
          query = query.where(and27(
            eq34(exceptionCases.state, "open"),
            eq34(exceptionCases.category, category)
          ));
        }
        if (severity) {
          query = query.where(and27(
            eq34(exceptionCases.state, "open"),
            eq34(exceptionCases.severity, severity)
          ));
        }
        const exceptions = await query;
        return exceptions.map((e) => ({
          ...e,
          paymentId: e.paymentId?.toString()
          // Convert to string
        }));
      }
      /**
       * Resolve exception
       */
      async resolveException(id, resolution, resolvedBy) {
        await db.update(exceptionCases).set({
          state: "resolved",
          resolvedAt: /* @__PURE__ */ new Date(),
          aiRecommendation: resolution ? { resolution, resolvedBy } : void 0
        }).where(eq34(exceptionCases.id, id));
        console.log(`[ExceptionCase] Resolved exception ${id}`);
      }
      /**
       * Cancel exception
       */
      async cancelException(id, reason) {
        await db.update(exceptionCases).set({
          state: "cancelled",
          aiRecommendation: reason ? { cancellationReason: reason } : void 0
        }).where(eq34(exceptionCases.id, id));
        console.log(`[ExceptionCase] Cancelled exception ${id}`);
      }
      /**
       * Assign exception to user
       */
      async assignException(id, assignedTo) {
        await db.update(exceptionCases).set({ assignedTo }).where(eq34(exceptionCases.id, id));
        console.log(`[ExceptionCase] Assigned exception ${id} to ${assignedTo}`);
      }
      /**
       * Determine ACH return severity
       */
      determineAchReturnSeverity(returnCode) {
        const criticalCodes = ["R02", "R03", "R04", "R20"];
        const highCodes = ["R05", "R07", "R10", "R29", "R16"];
        const mediumCodes = ["R01", "R06", "R08", "R09", "R11", "R12", "R31"];
        if (criticalCodes.includes(returnCode)) return "critical";
        if (highCodes.includes(returnCode)) return "high";
        if (mediumCodes.includes(returnCode)) return "medium";
        return "low";
      }
      /**
       * Determine wire recall severity
       */
      determineWireRecallSeverity(recallReason) {
        const highSeverityReasons = ["FRAUD", "INCORRECT_BENEFICIARY", "DUPLICATE"];
        if (highSeverityReasons.includes(recallReason)) return "high";
        return "medium";
      }
      /**
       * Get ACH return suggested actions
       */
      getAchReturnSuggestedActions(returnCode) {
        const actionMap = {
          R01: ["Contact customer for updated payment method", "Schedule retry after payday"],
          R02: ["Remove account from system", "Request updated banking information"],
          R03: ["Verify account number", "Contact customer for correct information"],
          R04: ["Correct account number", "Verify with customer"],
          R05: ["Investigate authorization", "Contact customer", "File dispute response if valid"],
          R07: ["Stop future debits", "Remove authorization", "Contact customer"],
          R10: ["Provide proof of authorization", "Stop future debits if unauthorized"],
          R29: ["Verify corporate authorization", "Update authorization records"]
        };
        return actionMap[returnCode] || ["Review return reason", "Take appropriate action"];
      }
      /**
       * Get wire recall suggested actions
       */
      getWireRecallSuggestedActions(recallReason) {
        const actionMap = {
          FRAUD: ["Hold funds immediately", "Investigate transaction", "File SAR if confirmed"],
          DUPLICATE: ["Verify duplicate", "Reverse if confirmed", "Update records"],
          INCORRECT_BENEFICIARY: ["Verify beneficiary", "Return funds", "Update beneficiary records"],
          INCORRECT_AMOUNT: ["Verify correct amount", "Adjust if needed", "Document variance"],
          CUSTOMER_REQUEST: ["Verify request authenticity", "Process cancellation", "Document reason"]
        };
        return actionMap[recallReason] || ["Review recall reason", "Process according to policy"];
      }
      /**
       * Calculate retry date based on attempt count
       */
      calculateRetryDate(attemptCount) {
        const daysToAdd = Math.min(attemptCount * 3, 14);
        const retryDate = /* @__PURE__ */ new Date();
        retryDate.setDate(retryDate.getDate() + daysToAdd);
        return retryDate.toISOString().split("T")[0];
      }
    };
    exceptionCaseService = new ExceptionCaseService();
  }
});

// server/services/daily-reconciler.ts
import { eq as eq35, and as and28, between } from "drizzle-orm";
import crypto16 from "crypto";
import Decimal2 from "decimal.js";
var DailyReconcilerService, dailyReconciler;
var init_daily_reconciler = __esm({
  "server/services/daily-reconciler.ts"() {
    "use strict";
    init_db();
    init_schema();
    init_column_bank_service();
    init_exception_case();
    DailyReconcilerService = class {
      columnBankService;
      exceptionCaseService;
      constructor() {
        this.columnBankService = new ColumnBankService();
        this.exceptionCaseService = new ExceptionCaseService();
      }
      /**
       * Run daily reconciliation for a specific date
       */
      async reconcileDay(date2 = /* @__PURE__ */ new Date()) {
        console.log(`[DailyReconciler] Starting daily reconciliation for ${date2.toISOString().split("T")[0]}`);
        const periodStart = new Date(date2);
        periodStart.setHours(0, 0, 0, 0);
        const periodEnd = new Date(date2);
        periodEnd.setHours(23, 59, 59, 999);
        const results = [];
        const channels = ["ach", "wire", "column"];
        for (const channel of channels) {
          try {
            const result = await this.reconcileChannel(channel, periodStart, periodEnd);
            results.push(result);
          } catch (error) {
            console.error(`[DailyReconciler] Error reconciling ${channel}:`, error);
            await this.createReconciliationFailureException(channel, periodStart, error);
          }
        }
        return results;
      }
      /**
       * Reconcile a specific payment channel
       */
      async reconcileChannel(channel, periodStart, periodEnd) {
        console.log(`[DailyReconciler] Reconciling ${channel} for period ${periodStart.toISOString()} to ${periodEnd.toISOString()}`);
        const bankSummary = await this.getBankSettlementSummary(channel, periodStart);
        const sorSummary = await this.getSORSummary(channel, periodStart, periodEnd);
        const variance = new Decimal2(bankSummary.netTotal).minus(sorSummary.total).toNumber();
        const { missing, excess } = await this.findDiscrepancies(
          bankSummary.transactions || [],
          sorSummary.paymentIds
        );
        const result = {
          channel,
          periodStart,
          periodEnd,
          bankTotal: bankSummary.netTotal,
          sorTotal: sorSummary.total,
          variance,
          status: Math.abs(variance) < 0.01 ? "balanced" : "variance",
          missingIdentifiers: missing,
          excessIdentifiers: excess
        };
        await this.storeReconciliation(result);
        if (result.status === "variance") {
          await this.handleVariance(result);
        } else {
          await this.handleBalanced(result);
        }
        return result;
      }
      /**
       * Get bank settlement summary from Column Bank
       */
      async getBankSettlementSummary(channel, date2) {
        if (channel === "column" || channel === "ach") {
          try {
            const dateStr = date2.toISOString().split("T")[0];
            const summary = await this.columnBankService.getSettlementSummary(dateStr);
            return {
              date: dateStr,
              credits: summary.credits || 0,
              debits: summary.debits || 0,
              netTotal: (summary.credits || 0) - (summary.debits || 0),
              transactionCount: summary.transactionCount || 0,
              transactions: summary.transactions
            };
          } catch (error) {
            console.error(`[DailyReconciler] Error fetching Column settlement summary:`, error);
            return {
              date: date2.toISOString().split("T")[0],
              credits: 0,
              debits: 0,
              netTotal: 0,
              transactionCount: 0
            };
          }
        }
        return {
          date: date2.toISOString().split("T")[0],
          credits: 0,
          debits: 0,
          netTotal: 0,
          transactionCount: 0
        };
      }
      /**
       * Get SOR (System of Record) summary from database
       */
      async getSORSummary(channel, periodStart, periodEnd) {
        const sorPayments = await db.select({
          id: payments.id,
          amount: payments.totalReceived,
          status: payments.status,
          effectiveDate: payments.effectiveDate
        }).from(payments).where(
          and28(
            between(
              payments.effectiveDate,
              periodStart.toISOString().split("T")[0],
              periodEnd.toISOString().split("T")[0]
            ),
            eq35(payments.status, "completed"),
            eq35(payments.sourceChannel, channel)
          )
        );
        const total = sorPayments.reduce((sum3, payment) => {
          return sum3 + parseFloat(payment.amount || "0");
        }, 0);
        return {
          total,
          paymentIds: sorPayments.map((p) => p.id)
        };
      }
      /**
       * Find discrepancies between bank and SOR
       */
      async findDiscrepancies(bankTransactions, sorPaymentIds) {
        const bankRefs = new Set(bankTransactions.map((t) => t.reference || t.id));
        const sorRefs = new Set(sorPaymentIds);
        const missing = Array.from(bankRefs).filter((ref) => !sorRefs.has(ref));
        const excess = Array.from(sorRefs).filter((ref) => !bankRefs.has(ref));
        return { missing, excess };
      }
      /**
       * Store reconciliation result in database
       */
      async storeReconciliation(result) {
        await db.insert(reconciliations).values({
          channel: result.channel,
          periodStart: result.periodStart,
          periodEnd: result.periodEnd,
          bankTotal: result.bankTotal.toString(),
          sorTotal: result.sorTotal.toString(),
          variance: result.variance.toString(),
          status: result.status,
          metadata: {
            missingIdentifiers: result.missingIdentifiers,
            excessIdentifiers: result.excessIdentifiers,
            reconciledAt: (/* @__PURE__ */ new Date()).toISOString()
          }
        }).onConflictDoUpdate({
          target: [reconciliations.channel, reconciliations.periodStart],
          set: {
            bankTotal: result.bankTotal.toString(),
            sorTotal: result.sorTotal.toString(),
            variance: result.variance.toString(),
            status: result.status,
            metadata: {
              missingIdentifiers: result.missingIdentifiers,
              excessIdentifiers: result.excessIdentifiers,
              reconciledAt: (/* @__PURE__ */ new Date()).toISOString()
            },
            updatedAt: /* @__PURE__ */ new Date()
          }
        });
      }
      /**
       * Handle variance case - create exceptions and publish events
       */
      async handleVariance(result) {
        console.log(`[DailyReconciler] Variance detected for ${result.channel}: $${result.variance}`);
        await this.exceptionCaseService.createReconciliationVarianceException(
          result.sorTotal,
          result.bankTotal,
          `${result.channel}_${result.periodStart.toISOString().split("T")[0]}`,
          result.channel
        );
        await db.insert(outboxMessages).values({
          aggregateType: "reconciliation",
          aggregateId: crypto16.randomUUID(),
          eventType: "payment.reconciled.discrepancy",
          payload: {
            channel: result.channel,
            date: result.periodStart.toISOString().split("T")[0],
            bankTotal: result.bankTotal,
            sorTotal: result.sorTotal,
            variance: result.variance,
            missingIdentifiers: result.missingIdentifiers,
            excessIdentifiers: result.excessIdentifiers
          }
        });
        if (result.missingIdentifiers && result.missingIdentifiers.length > 0) {
          for (const missingId of result.missingIdentifiers) {
            await this.createBackfillRequest(missingId, result.channel, result.periodStart);
          }
        }
      }
      /**
       * Handle balanced case - publish success event
       */
      async handleBalanced(result) {
        console.log(`[DailyReconciler] Reconciliation balanced for ${result.channel} on ${result.periodStart.toISOString().split("T")[0]}`);
        await db.insert(outboxMessages).values({
          aggregateType: "reconciliation",
          aggregateId: crypto16.randomUUID(),
          eventType: "payment.reconciled.ok",
          payload: {
            channel: result.channel,
            date: result.periodStart.toISOString().split("T")[0],
            total: result.bankTotal,
            transactionCount: result.missingIdentifiers?.length || 0
          }
        });
      }
      /**
       * Create backfill request for missing payment
       */
      async createBackfillRequest(identifier, channel, date2) {
        console.log(`[DailyReconciler] Creating backfill request for ${identifier}`);
        await db.insert(outboxMessages).values({
          aggregateType: "backfill",
          aggregateId: identifier,
          eventType: "backfill.requested",
          payload: {
            identifier,
            channel,
            date: date2.toISOString().split("T")[0],
            reason: "missing_in_sor",
            requestedAt: (/* @__PURE__ */ new Date()).toISOString()
          }
        });
      }
      /**
       * Create exception for reconciliation failure
       */
      async createReconciliationFailureException(channel, date2, error) {
        await db.insert(exceptionCases).values({
          category: "reconcile_variance",
          subcategory: "reconciliation_failure",
          severity: "critical",
          state: "open",
          aiRecommendation: {
            channel,
            date: date2.toISOString().split("T")[0],
            error: error.message || "Unknown error",
            suggestedActions: [
              "Check bank API connectivity",
              "Verify credentials are valid",
              "Review error logs for details",
              "Manually run reconciliation when fixed"
            ]
          }
        });
      }
      /**
       * Run reconciliation for date range
       */
      async reconcileDateRange(startDate, endDate) {
        const results = [];
        const currentDate = new Date(startDate);
        while (currentDate <= endDate) {
          const dayResults = await this.reconcileDay(new Date(currentDate));
          results.push(...dayResults);
          currentDate.setDate(currentDate.getDate() + 1);
        }
        return results;
      }
      /**
       * Get reconciliation status for a date
       */
      async getReconciliationStatus(channel, date2) {
        const periodStart = new Date(date2);
        periodStart.setHours(0, 0, 0, 0);
        const periodEnd = new Date(date2);
        periodEnd.setHours(23, 59, 59, 999);
        const [record] = await db.select().from(reconciliations).where(
          and28(
            eq35(reconciliations.channel, channel),
            eq35(reconciliations.periodStart, periodStart)
          )
        ).limit(1);
        if (!record) return null;
        return {
          channel: record.channel,
          periodStart: record.periodStart,
          periodEnd: record.periodEnd,
          bankTotal: parseFloat(record.bankTotal),
          sorTotal: parseFloat(record.sorTotal),
          variance: parseFloat(record.variance),
          status: record.status,
          missingIdentifiers: record.metadata?.missingIdentifiers || [],
          excessIdentifiers: record.metadata?.excessIdentifiers || []
        };
      }
    };
    dailyReconciler = new DailyReconcilerService();
  }
});

// server/services/reconciliation-scheduler.ts
import { randomUUID as randomUUID19 } from "crypto";
var ReconciliationScheduler, reconciliationScheduler;
var init_reconciliation_scheduler = __esm({
  "server/services/reconciliation-scheduler.ts"() {
    "use strict";
    init_daily_reconciler();
    init_db();
    init_schema();
    ReconciliationScheduler = class {
      intervalId = null;
      isRunning = false;
      /**
       * Start the reconciliation scheduler
       * Runs daily at 2 AM UTC
       */
      start() {
        if (this.intervalId) {
          console.log("[ReconciliationScheduler] Already running");
          return;
        }
        console.log("[ReconciliationScheduler] Starting daily reconciliation scheduler");
        this.checkAndRunReconciliation();
        this.intervalId = setInterval(() => {
          this.checkAndRunReconciliation();
        }, 60 * 60 * 1e3);
        console.log("[ReconciliationScheduler] Scheduler started");
      }
      /**
       * Stop the reconciliation scheduler
       */
      stop() {
        if (this.intervalId) {
          clearInterval(this.intervalId);
          this.intervalId = null;
          console.log("[ReconciliationScheduler] Scheduler stopped");
        }
      }
      /**
       * Check if reconciliation should run and execute if needed
       */
      async checkAndRunReconciliation() {
        const now = /* @__PURE__ */ new Date();
        const currentHour = now.getUTCHours();
        if (currentHour === 2 && !this.isRunning) {
          await this.runDailyReconciliation();
        }
      }
      /**
       * Run daily reconciliation for yesterday's transactions
       */
      async runDailyReconciliation() {
        if (this.isRunning) {
          console.log("[ReconciliationScheduler] Reconciliation already in progress");
          return;
        }
        this.isRunning = true;
        const yesterday = /* @__PURE__ */ new Date();
        yesterday.setDate(yesterday.getDate() - 1);
        try {
          console.log(`[ReconciliationScheduler] Starting daily reconciliation for ${yesterday.toISOString().split("T")[0]}`);
          await db.insert(outboxMessages).values({
            aggregateType: "reconciliation",
            aggregateId: randomUUID19(),
            eventType: "reconciliation.started",
            payload: {
              date: yesterday.toISOString().split("T")[0],
              startedAt: (/* @__PURE__ */ new Date()).toISOString()
            }
          });
          const results = await dailyReconciler.reconcileDay(yesterday);
          const summary = {
            date: yesterday.toISOString().split("T")[0],
            totalChannels: results.length,
            balanced: results.filter((r) => r.status === "balanced").length,
            variances: results.filter((r) => r.status === "variance").length,
            totalVariance: results.reduce((sum3, r) => sum3 + Math.abs(r.variance), 0)
          };
          await db.insert(outboxMessages).values({
            aggregateType: "reconciliation",
            aggregateId: randomUUID19(),
            eventType: "reconciliation.completed",
            payload: {
              ...summary,
              completedAt: (/* @__PURE__ */ new Date()).toISOString(),
              results
            }
          });
          console.log(`[ReconciliationScheduler] Daily reconciliation completed:`, summary);
          if (summary.variances > 0) {
            await this.sendVarianceNotification(summary, results);
          }
        } catch (error) {
          console.error("[ReconciliationScheduler] Error during daily reconciliation:", error);
          await db.insert(outboxMessages).values({
            aggregateType: "reconciliation",
            aggregateId: randomUUID19(),
            eventType: "reconciliation.failed",
            payload: {
              date: yesterday.toISOString().split("T")[0],
              error: error instanceof Error ? error.message : "Unknown error",
              failedAt: (/* @__PURE__ */ new Date()).toISOString()
            }
          });
        } finally {
          this.isRunning = false;
        }
      }
      /**
       * Send notification about variance detection
       */
      async sendVarianceNotification(summary, results) {
        const varianceDetails = results.filter((r) => r.status === "variance").map((r) => ({
          channel: r.channel,
          variance: r.variance,
          bankTotal: r.bankTotal,
          sorTotal: r.sorTotal,
          missingCount: r.missingIdentifiers?.length || 0,
          excessCount: r.excessIdentifiers?.length || 0
        }));
        await db.insert(outboxMessages).values({
          aggregateType: "notification",
          aggregateId: randomUUID19(),
          eventType: "notification.variance_alert",
          payload: {
            type: "reconciliation_variance",
            date: summary.date,
            totalVariance: summary.totalVariance,
            channelsAffected: summary.variances,
            details: varianceDetails,
            message: `Reconciliation variance detected: $${summary.totalVariance.toFixed(2)} across ${summary.variances} channels`,
            severity: summary.totalVariance > 1e4 ? "critical" : "warning"
          }
        });
      }
      /**
       * Manually trigger reconciliation for a specific date
       */
      async runReconciliationForDate(date2) {
        console.log(`[ReconciliationScheduler] Manual reconciliation triggered for ${date2.toISOString().split("T")[0]}`);
        try {
          const results = await dailyReconciler.reconcileDay(date2);
          console.log(`[ReconciliationScheduler] Manual reconciliation completed for ${date2.toISOString().split("T")[0]}`);
          return {
            success: true,
            date: date2.toISOString().split("T")[0],
            results
          };
        } catch (error) {
          console.error("[ReconciliationScheduler] Manual reconciliation failed:", error);
          return {
            success: false,
            date: date2.toISOString().split("T")[0],
            error: error instanceof Error ? error.message : "Unknown error"
          };
        }
      }
      /**
       * Run reconciliation for a date range
       */
      async runReconciliationForDateRange(startDate, endDate) {
        console.log(`[ReconciliationScheduler] Batch reconciliation for ${startDate.toISOString().split("T")[0]} to ${endDate.toISOString().split("T")[0]}`);
        try {
          const results = await dailyReconciler.reconcileDateRange(startDate, endDate);
          const summary = {
            startDate: startDate.toISOString().split("T")[0],
            endDate: endDate.toISOString().split("T")[0],
            daysProcessed: results.length,
            totalVariances: results.filter((r) => r.status === "variance").length,
            totalVarianceAmount: results.reduce((sum3, r) => sum3 + Math.abs(r.variance), 0)
          };
          console.log(`[ReconciliationScheduler] Batch reconciliation completed:`, summary);
          return {
            success: true,
            ...summary,
            results
          };
        } catch (error) {
          console.error("[ReconciliationScheduler] Batch reconciliation failed:", error);
          return {
            success: false,
            startDate: startDate.toISOString().split("T")[0],
            endDate: endDate.toISOString().split("T")[0],
            error: error instanceof Error ? error.message : "Unknown error"
          };
        }
      }
    };
    reconciliationScheduler = new ReconciliationScheduler();
  }
});

// server/routes/reconciliation.ts
var reconciliation_exports = {};
__export(reconciliation_exports, {
  default: () => reconciliation_default
});
import express3 from "express";
import { z as z18 } from "zod";
function getNextRunTime() {
  const now = /* @__PURE__ */ new Date();
  const nextRun = /* @__PURE__ */ new Date();
  nextRun.setUTCHours(2, 0, 0, 0);
  if (now.getUTCHours() >= 2) {
    nextRun.setDate(nextRun.getDate() + 1);
  }
  return nextRun.toISOString();
}
var router40, reconcileDateSchema, reconcileDateRangeSchema, reconciliation_default;
var init_reconciliation2 = __esm({
  "server/routes/reconciliation.ts"() {
    "use strict";
    init_daily_reconciler();
    init_reconciliation_scheduler();
    router40 = express3.Router();
    reconcileDateSchema = z18.object({
      date: z18.string().regex(/^\d{4}-\d{2}-\d{2}$/, "Date must be in YYYY-MM-DD format")
    });
    reconcileDateRangeSchema = z18.object({
      startDate: z18.string().regex(/^\d{4}-\d{2}-\d{2}$/, "Date must be in YYYY-MM-DD format"),
      endDate: z18.string().regex(/^\d{4}-\d{2}-\d{2}$/, "Date must be in YYYY-MM-DD format")
    });
    router40.get("/status/:channel/:date", async (req, res) => {
      try {
        const { channel, date: date2 } = req.params;
        if (!/^\d{4}-\d{2}-\d{2}$/.test(date2)) {
          return res.status(400).json({ error: "Invalid date format. Use YYYY-MM-DD" });
        }
        const status = await dailyReconciler.getReconciliationStatus(
          channel,
          new Date(date2)
        );
        if (!status) {
          return res.status(404).json({
            error: "No reconciliation found for the specified channel and date"
          });
        }
        res.json(status);
      } catch (error) {
        console.error("[Reconciliation API] Error getting status:", error);
        res.status(500).json({ error: "Failed to get reconciliation status" });
      }
    });
    router40.post("/run", async (req, res) => {
      try {
        const validation = reconcileDateSchema.safeParse(req.body);
        if (!validation.success) {
          return res.status(400).json({
            error: "Invalid request",
            details: validation.error.errors
          });
        }
        const { date: date2 } = validation.data;
        res.json({
          message: "Reconciliation started",
          date: date2,
          status: "processing"
        });
        reconciliationScheduler.runReconciliationForDate(new Date(date2)).then((result) => {
          console.log("[Reconciliation API] Manual reconciliation completed:", result);
        }).catch((error) => {
          console.error("[Reconciliation API] Manual reconciliation failed:", error);
        });
      } catch (error) {
        console.error("[Reconciliation API] Error triggering reconciliation:", error);
        res.status(500).json({ error: "Failed to trigger reconciliation" });
      }
    });
    router40.post("/run-range", async (req, res) => {
      try {
        const validation = reconcileDateRangeSchema.safeParse(req.body);
        if (!validation.success) {
          return res.status(400).json({
            error: "Invalid request",
            details: validation.error.errors
          });
        }
        const { startDate, endDate } = validation.data;
        if (new Date(startDate) > new Date(endDate)) {
          return res.status(400).json({
            error: "Start date must be before or equal to end date"
          });
        }
        const start = new Date(startDate);
        const end = new Date(endDate);
        const days = Math.ceil((end.getTime() - start.getTime()) / (1e3 * 60 * 60 * 24)) + 1;
        if (days > 31) {
          return res.status(400).json({
            error: "Date range cannot exceed 31 days"
          });
        }
        res.json({
          message: "Batch reconciliation started",
          startDate,
          endDate,
          daysToProcess: days,
          status: "processing"
        });
        reconciliationScheduler.runReconciliationForDateRange(start, end).then((result) => {
          console.log("[Reconciliation API] Batch reconciliation completed:", result);
        }).catch((error) => {
          console.error("[Reconciliation API] Batch reconciliation failed:", error);
        });
      } catch (error) {
        console.error("[Reconciliation API] Error triggering batch reconciliation:", error);
        res.status(500).json({ error: "Failed to trigger batch reconciliation" });
      }
    });
    router40.get("/scheduler/status", (req, res) => {
      res.json({
        status: "active",
        schedule: "Daily at 2:00 AM UTC",
        nextRun: getNextRunTime(),
        description: "Reconciles previous day transactions automatically"
      });
    });
    router40.post("/scheduler/start", (req, res) => {
      reconciliationScheduler.start();
      res.json({
        message: "Reconciliation scheduler started",
        schedule: "Daily at 2:00 AM UTC"
      });
    });
    router40.post("/scheduler/stop", (req, res) => {
      reconciliationScheduler.stop();
      res.json({ message: "Reconciliation scheduler stopped" });
    });
    reconciliation_default = router40;
  }
});

// src/servicing/allocation.ts
function allocateStandard(inp) {
  let rem = round24(inp.pmt_amount);
  const out = {
    alloc_principal: 0,
    alloc_interest: 0,
    alloc_escrow: 0,
    alloc_fees: 0,
    leftover: 0
  };
  const ai = Math.min(rem, inp.interest_due);
  rem = round24(rem - ai);
  out.alloc_interest = ai;
  const ae = Math.min(rem, inp.escrow_due);
  rem = round24(rem - ae);
  out.alloc_escrow = ae;
  const af = Math.min(rem, inp.fees_due);
  rem = round24(rem - af);
  out.alloc_fees = af;
  const ap = Math.min(rem, inp.principal_due);
  rem = round24(rem - ap);
  out.alloc_principal = ap;
  out.leftover = rem;
  return out;
}
function round24(n) {
  return Math.round((n + Number.EPSILON) * 100) / 100;
}
var init_allocation = __esm({
  "src/servicing/allocation.ts"() {
    "use strict";
  }
});

// src/payments/allocate.ts
async function allocatePayment(i) {
  try {
    if (externalAlloc) return await externalAlloc(i);
  } catch (error) {
    console.warn("External allocator failed, falling back to standard:", error);
  }
  return allocateStandard(i);
}
var externalAlloc;
var init_allocate = __esm({
  "src/payments/allocate.ts"() {
    "use strict";
    init_allocation();
    externalAlloc = null;
  }
});

// src/payments/post.ts
import dayjs6 from "dayjs";
function nearEq(a, b, tolerance = 0.01) {
  return Math.abs(a - b) <= tolerance;
}
async function currentFees(client5, loanId) {
  const fees = await client5.query(`
    SELECT COALESCE(SUM(alloc_fees), 0) as total_fees 
    FROM svc_txns 
    WHERE loan_id = $1 AND type = 'FEE'
  `, [loanId]);
  return Number(fees.rows[0]?.total_fees || 0);
}
async function validateAndPostPayment({ tenantId, paymentId }) {
  const c = await pool.connect();
  try {
    await c.query(`BEGIN`);
    const p = await c.query(`SELECT * FROM pay_payments WHERE id=$1`, [paymentId]);
    if (!p.rowCount) throw new Error("payment not found");
    const pay = p.rows[0];
    const reject = async (reason) => {
      await c.query(`UPDATE pay_payments SET status='Rejected', error=$2 WHERE id=$1`, [paymentId, reason]);
      return { status: "Rejected", error: reason };
    };
    let loanId = pay.loan_id;
    if (!loanId && pay.loan_number) {
      const l = await c.query(`
        SELECT id FROM loans WHERE loan_number = $1 LIMIT 1
      `, [pay.loan_number]);
      loanId = l.rows[0]?.id || null;
    }
    if (!loanId) return await reject("Unroutable \u2014 no loan match");
    const acc = await c.query(`SELECT * FROM svc_accounts WHERE loan_id=$1 AND state='Active'`, [loanId]);
    if (!acc.rowCount) return await reject("Loan not active in servicing");
    const a = acc.rows[0];
    const sched = await c.query(`
      SELECT * FROM svc_schedule WHERE loan_id=$1 AND paid=false 
      ORDER BY installment_no ASC LIMIT 1
    `, [loanId]);
    const row = sched.rows[0];
    if (!row) return await reject("No unpaid schedule rows");
    const amt = Number(pay.amount);
    const threshold = Number(process.env.PAYMENT_MIN_TO_POST || "25");
    const totalCurrentDue = Number(row.principal_due) + Number(row.interest_due) + Number(row.escrow_due);
    let useSuspense = false;
    if (amt < Math.min(threshold, totalCurrentDue)) useSuspense = true;
    const fees_due = await currentFees(c, loanId);
    const alloc = await allocatePayment({
      pmt_amount: amt,
      pmt_date: dayjs6(pay.ts).format("YYYY-MM-DD"),
      installment_no: row.installment_no,
      principal_due: Number(row.principal_due),
      interest_due: Number(row.interest_due),
      escrow_due: Number(row.escrow_due),
      fees_due
    });
    if (useSuspense || alloc.leftover > 0) {
      await c.query(`UPDATE pay_payments SET status='Suspense', alloc=$2 WHERE id=$1`, [paymentId, JSON.stringify(alloc)]);
      await c.query(`
        INSERT INTO pay_suspense (tenant_id, loan_id, balance, updated_at)
        VALUES ($1,$2,$3,now())
        ON CONFLICT (tenant_id, loan_id) DO UPDATE SET 
        balance = pay_suspense.balance + EXCLUDED.balance, updated_at=now()
      `, [tenantId, loanId, amt]);
      await c.query(`
        INSERT INTO gl_entries (tenant_id, loan_id, debit_acct, credit_acct, amount, memo)
        VALUES ($1,$2,$3,$4,$5,'Payment to suspense')
      `, [tenantId, loanId, Number(process.env.GL_CASH_ACCT || "1000"), Number(process.env.GL_SUSPENSE_ACCT || "2200"), amt]);
      await c.query(`COMMIT`);
      return { status: "Suspense", alloc };
    }
    const fullyPaid = nearEq(alloc.alloc_principal, row.principal_due) && nearEq(alloc.alloc_interest, row.interest_due) && nearEq(alloc.alloc_escrow, row.escrow_due) && alloc.alloc_fees >= 0;
    const tx = await c.query(`
      INSERT INTO svc_txns (tenant_id, loan_id, type, amount, alloc_principal, alloc_interest, alloc_escrow, alloc_fees, memo, ref)
      VALUES ($1,$2,'PAYMENT',$3,$4,$5,$6,$7,'Payment posted', $8)
      RETURNING id
    `, [
      tenantId,
      loanId,
      amt,
      alloc.alloc_principal,
      alloc.alloc_interest,
      alloc.alloc_escrow,
      alloc.alloc_fees,
      JSON.stringify({ payment_id: paymentId, channel: pay.channel, reference: pay.reference || null })
    ]);
    const txnId = tx.rows[0].id;
    if (fullyPaid) {
      await c.query(`
        UPDATE svc_schedule SET paid=true, paid_at=now() 
        WHERE loan_id=$1 AND installment_no=$2
      `, [loanId, row.installment_no]);
    }
    if (alloc.alloc_escrow > 0) {
      await c.query(`
        INSERT INTO svc_escrow_sub (tenant_id, loan_id, bucket, balance, monthly_accrual, updated_at)
        VALUES ($1,$2,'TAX',$3,0,now())
        ON CONFLICT (tenant_id, loan_id, bucket) DO UPDATE SET 
        balance = svc_escrow_sub.balance + EXCLUDED.balance, updated_at=now()
      `, [tenantId, loanId, alloc.alloc_escrow]);
    }
    if (alloc.alloc_interest > 0) {
      await c.query(`
        INSERT INTO gl_entries (tenant_id, loan_id, debit_acct, credit_acct, amount, memo)
        VALUES ($1,$2,$3,$4,$5,'Payment interest')
      `, [tenantId, loanId, Number(process.env.GL_CASH_ACCT || "1000"), Number(process.env.GL_INTEREST_INCOME_ACCT || "4000"), alloc.alloc_interest]);
    }
    if (alloc.alloc_fees > 0) {
      await c.query(`
        INSERT INTO gl_entries (tenant_id, loan_id, debit_acct, credit_acct, amount, memo)
        VALUES ($1,$2,$3,$4,$5,'Payment fees')
      `, [tenantId, loanId, Number(process.env.GL_CASH_ACCT || "1000"), Number(process.env.GL_FEE_INCOME_ACCT || "4100"), alloc.alloc_fees]);
    }
    if (alloc.alloc_escrow > 0) {
      await c.query(`
        INSERT INTO gl_entries (tenant_id, loan_id, debit_acct, credit_acct, amount, memo)
        VALUES ($1,$2,$3,$4,$5,'Payment escrow')
      `, [tenantId, loanId, Number(process.env.GL_CASH_ACCT || "1000"), Number(process.env.GL_ESCROW_LIABILITY_ACCT || "2100"), alloc.alloc_escrow]);
    }
    if (alloc.alloc_principal > 0) {
      await c.query(`
        INSERT INTO gl_entries (tenant_id, loan_id, debit_acct, credit_acct, amount, memo)
        VALUES ($1,$2,$3,$4,$5,'Payment principal')
      `, [tenantId, loanId, Number(process.env.GL_CASH_ACCT || "1000"), Number(process.env.GL_LOAN_PRINCIPAL_ACCT || "1100"), alloc.alloc_principal]);
    }
    await c.query(`UPDATE pay_payments SET status='Posted', alloc=$2, posted_txn_id=$3 WHERE id=$1`, [paymentId, JSON.stringify(alloc), txnId]);
    await c.query(`COMMIT`);
    return { status: "Posted", alloc, txnId };
  } catch (e) {
    await c.query(`ROLLBACK`);
    await c.query(`UPDATE pay_payments SET status='Rejected', error=$2 WHERE id=$1`, [paymentId, String(e)]).catch(() => {
    });
    throw e;
  } finally {
    c.release();
  }
}
var init_post = __esm({
  "src/payments/post.ts"() {
    "use strict";
    init_db();
    init_allocate();
  }
});

// src/payments/receipt.ts
import dayjs7 from "dayjs";
import crypto17 from "crypto";
async function createReceiptPdf({ tenantId, paymentId, loanId, allocation }) {
  const client5 = await pool.connect();
  try {
    const payment = await client5.query(`
      SELECT p.*, l.loan_number, l.original_amount 
      FROM pay_payments p 
      LEFT JOIN loans l ON p.loan_id = l.id 
      WHERE p.id = $1
    `, [paymentId]);
    if (!payment.rowCount) throw new Error("Payment not found");
    const pay = payment.rows[0];
    const borrower = await client5.query(`
      SELECT first_name, last_name, email 
      FROM borrowers 
      WHERE loan_id = $1 
      ORDER BY is_primary DESC 
      LIMIT 1
    `, [loanId]);
    const borrowerInfo = borrower.rows[0] || { first_name: "Unknown", last_name: "Borrower", email: null };
    const receiptData = {
      header: process.env.RCPT_PDF_HEADER || "LoanServe \u2022 Payment Receipt",
      watermark: process.env.RCPT_PDF_WATERMARK || "LoanServe",
      date: dayjs7(pay.ts).format("MMMM DD, YYYY"),
      receiptNumber: `RCP-${paymentId.slice(-8).toUpperCase()}`,
      borrower: {
        name: `${borrowerInfo.first_name} ${borrowerInfo.last_name}`,
        email: borrowerInfo.email
      },
      loan: {
        number: pay.loan_number,
        originalAmount: pay.original_amount
      },
      payment: {
        amount: pay.amount,
        date: dayjs7(pay.ts).format("MM/DD/YYYY"),
        reference: pay.reference || "N/A",
        channel: pay.channel
      },
      allocation: {
        principal: allocation.alloc_principal || 0,
        interest: allocation.alloc_interest || 0,
        escrow: allocation.alloc_escrow || 0,
        fees: allocation.alloc_fees || 0,
        total: pay.amount
      }
    };
    const pdfBuffer = await renderReceiptPdf(receiptData);
    const hash = crypto17.createHash("sha256").update(pdfBuffer).digest("hex");
    const s3Key = `${process.env.RCPT_S3_PREFIX || "receipts"}/${tenantId}/${loanId}/${paymentId}.pdf`;
    const s3Uri = await putBytes(s3Key, pdfBuffer, "application/pdf");
    const receipt = await client5.query(`
      INSERT INTO pay_receipts (tenant_id, loan_id, payment_id, file_uri, file_sha256, summary)
      VALUES ($1, $2, $3, $4, $5, $6)
      RETURNING id
    `, [tenantId, loanId, paymentId, s3Uri, hash, JSON.stringify(receiptData)]);
    await client5.query(`
      UPDATE pay_payments SET receipt_id = $1 WHERE id = $2
    `, [receipt.rows[0].id, paymentId]);
    return {
      receiptId: receipt.rows[0].id,
      fileUri: s3Uri,
      hash
    };
  } finally {
    client5.release();
  }
}
async function renderReceiptPdf(data) {
  const PDFDocument5 = await import("pdfkit");
  const doc = new PDFDocument5.default();
  const chunks = [];
  doc.on("data", (chunk) => chunks.push(chunk));
  return new Promise((resolve) => {
    doc.on("end", () => resolve(Buffer.concat(chunks)));
    doc.fontSize(20).text(data.header, 50, 50);
    doc.fontSize(12).text(`Receipt #${data.receiptNumber}`, 50, 80);
    doc.text(`Date: ${data.date}`, 50, 100);
    doc.fontSize(14).text("Payment From:", 50, 140);
    doc.fontSize(12).text(data.borrower.name, 50, 160);
    if (data.borrower.email) {
      doc.text(data.borrower.email, 50, 180);
    }
    doc.fontSize(14).text("Loan Information:", 50, 220);
    doc.fontSize(12).text(`Loan Number: ${data.loan.number}`, 50, 240);
    doc.fontSize(14).text("Payment Details:", 50, 280);
    doc.fontSize(12).text(`Amount: $${Number(data.payment.amount).toFixed(2)}`, 50, 300).text(`Date: ${data.payment.date}`, 50, 320).text(`Reference: ${data.payment.reference}`, 50, 340).text(`Method: ${data.payment.channel}`, 50, 360);
    doc.fontSize(14).text("Payment Allocation:", 50, 400);
    doc.fontSize(12).text(`Principal: $${Number(data.allocation.principal).toFixed(2)}`, 50, 420).text(`Interest: $${Number(data.allocation.interest).toFixed(2)}`, 50, 440).text(`Escrow: $${Number(data.allocation.escrow).toFixed(2)}`, 50, 460).text(`Fees: $${Number(data.allocation.fees).toFixed(2)}`, 50, 480).text(`Total: $${Number(data.allocation.total).toFixed(2)}`, 50, 500);
    doc.fontSize(60).fillColor("#E0E0E0").text(data.watermark, 200, 400, { rotate: 45 });
    doc.end();
  });
}
var init_receipt = __esm({
  "src/payments/receipt.ts"() {
    "use strict";
    init_db();
    init_storage2();
  }
});

// src/payments/ingest.ts
import dayjs8 from "dayjs";
import crypto18 from "crypto";
async function ingestPayment(input) {
  const client5 = await pool.connect();
  try {
    const payment = await client5.query(`
      INSERT INTO pay_payments (
        tenant_id, batch_id, loan_id, loan_number, amount, channel, reference, memo, status
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, 'Received')
      RETURNING id
    `, [
      input.tenantId,
      input.batchId || null,
      input.loanId || null,
      input.loanNumber || null,
      input.amount,
      input.channel,
      input.reference || null,
      input.memo || null
    ]);
    const paymentId = payment.rows[0].id;
    const minAmount = Number(process.env.PAYMENT_MIN_TO_POST || "25");
    if (input.amount >= minAmount) {
      try {
        const result = await validateAndPostPayment({
          tenantId: input.tenantId,
          paymentId
        });
        if (result.status === "Posted" && input.loanId && "alloc" in result) {
          await createReceiptPdf({
            tenantId: input.tenantId,
            paymentId,
            loanId: input.loanId,
            allocation: result.alloc
          });
        }
        return { paymentId, ...result };
      } catch (error) {
        console.error("Payment posting failed:", error);
        return { paymentId, status: "Rejected", error: String(error) };
      }
    }
    return { paymentId, status: "Received" };
  } finally {
    client5.release();
  }
}
async function ingestLockboxCsv(tenantId, csvContent, fileName) {
  const client5 = await pool.connect();
  try {
    const batch = await client5.query(`
      INSERT INTO pay_batches (tenant_id, channel, batch_date, file_uri, file_sha256)
      VALUES ($1, 'LOCKBOX', $2, $3, $4)
      RETURNING id
    `, [
      tenantId,
      dayjs8().format("YYYY-MM-DD"),
      fileName,
      crypto18.createHash("sha256").update(csvContent).digest("hex")
    ]);
    const batchId = batch.rows[0].id;
    const lines = csvContent.trim().split("\n");
    const header = lines[0];
    const expectedHeader = process.env.LOCKBOX_CSV_HEADER || "PaymentDate,LoanNumber,Amount,Reference,Channel";
    if (header !== expectedHeader) {
      throw new Error(`Invalid CSV header. Expected: ${expectedHeader}`);
    }
    const results = [];
    for (let i = 1; i < lines.length; i++) {
      const [paymentDate, loanNumber, amount, reference, channel] = lines[i].split(",");
      try {
        const result = await ingestPayment({
          tenantId,
          loanNumber: loanNumber.trim(),
          amount: parseFloat(amount),
          channel: channel?.trim() || "LOCKBOX",
          reference: reference?.trim(),
          batchId
        });
        results.push({ line: i + 1, success: true, paymentId: result.paymentId });
      } catch (error) {
        results.push({ line: i + 1, success: false, error: String(error) });
      }
    }
    const successCount = results.filter((r) => r.success).length;
    const status = successCount === results.length - 1 ? "Posted" : "Failed";
    await client5.query(`
      UPDATE pay_batches SET status = $1, posted_at = now() WHERE id = $2
    `, [status, batchId]);
    return { batchId, results, successCount, totalCount: results.length };
  } finally {
    client5.release();
  }
}
async function processAchWebhook(tenantId, webhookData) {
  const { amount, loan_number, reference, status, transaction_id } = webhookData;
  if (status === "completed") {
    return await ingestPayment({
      tenantId,
      loanNumber: loan_number,
      amount: parseFloat(amount),
      channel: "ACH",
      reference: transaction_id || reference
    });
  } else if (status === "failed" || status === "returned") {
    return await processNsfChargeback(tenantId, loan_number, parseFloat(amount), reference);
  }
  return { status: "ignored", reason: `Unhandled ACH status: ${status}` };
}
async function processNsfChargeback(tenantId, loanNumber, amount, reference) {
  const client5 = await pool.connect();
  try {
    const payment = await client5.query(`
      SELECT * FROM pay_payments 
      WHERE tenant_id = $1 AND loan_number = $2 AND amount = $3 AND reference = $4
      ORDER BY ts DESC LIMIT 1
    `, [tenantId, loanNumber, amount, reference]);
    if (!payment.rowCount) {
      throw new Error("Original payment not found for NSF/chargeback");
    }
    const originalPayment = payment.rows[0];
    const reversal = await ingestPayment({
      tenantId,
      loanNumber,
      amount: -amount,
      // Negative amount for reversal
      channel: "ACH",
      reference: `NSF-REV-${reference}`,
      memo: "NSF/Chargeback reversal"
    });
    const nsfFee = Number(process.env.NSF_FEE || "35");
    if (nsfFee > 0) {
      await ingestPayment({
        tenantId,
        loanNumber,
        amount: nsfFee,
        channel: "MANUAL",
        reference: `NSF-FEE-${reference}`,
        memo: "NSF fee assessment"
      });
    }
    await client5.query(`
      UPDATE pay_payments SET status = 'Reversed' WHERE id = $1
    `, [originalPayment.id]);
    return { reversalId: reversal.paymentId, nsfFee };
  } finally {
    client5.release();
  }
}
var init_ingest = __esm({
  "src/payments/ingest.ts"() {
    "use strict";
    init_db();
    init_post();
    init_receipt();
  }
});

// src/payments/reconciliation.ts
import crypto19 from "crypto";
async function importBankStatement(input) {
  const client5 = await pool.connect();
  try {
    const hash = crypto19.createHash("sha256").update(input.fileContent).digest("hex");
    const s3Key = `${process.env.RECON_S3_PREFIX || "recon"}/${input.tenantId}/${input.stmtDate}-${input.fileName}`;
    const s3Uri = await putBytes(s3Key, input.fileContent, "application/pdf");
    const stmt = await client5.query(`
      INSERT INTO recon_bank (tenant_id, stmt_date, opening_balance, closing_balance, file_uri, file_sha256)
      VALUES ($1, $2, $3, $4, $5, $6)
      RETURNING id
    `, [input.tenantId, input.stmtDate, input.openingBalance, input.closingBalance, s3Uri, hash]);
    const bankId = stmt.rows[0].id;
    const matches = [];
    for (const txn of input.transactions) {
      const matchResult = await autoMatchTransaction(client5, input.tenantId, bankId, txn);
      matches.push(matchResult);
    }
    const totalMatched = matches.filter((m) => m.matched).length;
    const reconciliationComplete = totalMatched === input.transactions.length;
    return {
      bankId,
      fileUri: s3Uri,
      totalTransactions: input.transactions.length,
      matchedTransactions: totalMatched,
      reconciliationComplete,
      matches
    };
  } finally {
    client5.release();
  }
}
async function autoMatchTransaction(client5, tenantId, bankId, txn) {
  const matchQuery = await client5.query(`
    SELECT p.id, p.amount, p.reference, p.ts
    FROM pay_payments p
    WHERE p.tenant_id = $1 
    AND p.status = 'Posted'
    AND ABS(p.amount - $2) < 0.01
    AND p.ts >= (CURRENT_DATE - INTERVAL '2 days')
    AND p.ts <= (CURRENT_DATE + INTERVAL '2 days')
    ORDER BY ABS(p.amount - $2), ABS(EXTRACT(EPOCH FROM (p.ts - CURRENT_TIMESTAMP)))
    LIMIT 1
  `, [tenantId, txn.amount]);
  if (matchQuery.rowCount > 0) {
    const payment = matchQuery.rows[0];
    await client5.query(`
      INSERT INTO recon_matches (tenant_id, bank_id, payment_id, amount, status)
      VALUES ($1, $2, $3, $4, 'Auto')
    `, [tenantId, bankId, payment.id, txn.amount]);
    return {
      matched: true,
      paymentId: payment.id,
      matchType: "Auto",
      bankAmount: txn.amount,
      paymentAmount: payment.amount,
      reference: txn.reference
    };
  }
  await client5.query(`
    INSERT INTO recon_matches (tenant_id, bank_id, payment_id, amount, status)
    VALUES ($1, $2, NULL, $3, 'Manual')
  `, [tenantId, bankId, txn.amount]);
  return {
    matched: false,
    matchType: "Manual",
    bankAmount: txn.amount,
    reference: txn.reference,
    requiresManualReview: true
  };
}
async function getReconciliationReport(tenantId, stmtDate) {
  const client5 = await pool.connect();
  try {
    const stmt = await client5.query(`
      SELECT * FROM recon_bank WHERE tenant_id = $1 AND stmt_date = $2
    `, [tenantId, stmtDate]);
    if (!stmt.rowCount) {
      throw new Error("Bank statement not found");
    }
    const statement = stmt.rows[0];
    const matches = await client5.query(`
      SELECT m.*, p.reference as payment_reference, p.ts as payment_date
      FROM recon_matches m
      LEFT JOIN pay_payments p ON m.payment_id = p.id
      WHERE m.tenant_id = $1 AND m.bank_id = $2
      ORDER BY m.amount DESC
    `, [tenantId, statement.id]);
    const totalBankTxns = matches.rowCount;
    const matchedTxns = matches.rows.filter((m) => m.payment_id).length;
    const unmatchedTxns = totalBankTxns - matchedTxns;
    const totalBankAmount = matches.rows.reduce((sum3, m) => sum3 + Number(m.amount), 0);
    const matchedAmount = matches.rows.filter((m) => m.payment_id).reduce((sum3, m) => sum3 + Number(m.amount), 0);
    return {
      statement: {
        date: statement.stmt_date,
        openingBalance: statement.opening_balance,
        closingBalance: statement.closing_balance,
        fileUri: statement.file_uri
      },
      reconciliation: {
        totalTransactions: totalBankTxns,
        matchedTransactions: matchedTxns,
        unmatchedTransactions: unmatchedTxns,
        totalAmount: totalBankAmount,
        matchedAmount,
        unmatchedAmount: totalBankAmount - matchedAmount,
        reconciliationComplete: unmatchedTxns === 0
      },
      matches: matches.rows
    };
  } finally {
    client5.release();
  }
}
async function manualMatch(tenantId, bankMatchId, paymentId) {
  const client5 = await pool.connect();
  try {
    await client5.query(`
      UPDATE recon_matches 
      SET payment_id = $1, status = 'Manual'
      WHERE id = $2 AND tenant_id = $3
    `, [paymentId, bankMatchId, tenantId]);
    return { success: true, matchId: bankMatchId, paymentId };
  } finally {
    client5.release();
  }
}
var init_reconciliation3 = __esm({
  "src/payments/reconciliation.ts"() {
    "use strict";
    init_db();
    init_storage2();
  }
});

// src/routes/payments.routes.ts
var payments_routes_exports = {};
__export(payments_routes_exports, {
  paymentsRouter: () => paymentsRouter
});
import { Router as Router50 } from "express";
import multer3 from "multer";
import crypto20 from "crypto";
var paymentsRouter, upload3;
var init_payments_routes = __esm({
  "src/routes/payments.routes.ts"() {
    "use strict";
    init_db();
    init_ingest();
    init_post();
    init_reconciliation3();
    paymentsRouter = Router50();
    upload3 = multer3({ storage: multer3.memoryStorage() });
    paymentsRouter.post("/payments/manual", async (req, res) => {
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const { loanNumber, loanId, amount, reference, memo } = req.body;
        if (!amount || amount <= 0) {
          return res.status(400).json({ error: "Valid amount required" });
        }
        if (!loanNumber && !loanId) {
          return res.status(400).json({ error: "Loan number or loan ID required" });
        }
        const result = await ingestPayment({
          tenantId,
          loanNumber,
          loanId: loanId ? parseInt(loanId) : void 0,
          amount: parseFloat(amount),
          channel: "MANUAL",
          reference,
          memo
        });
        res.status(201).json({
          success: true,
          paymentId: result.paymentId,
          status: result.status,
          message: "Payment processed successfully"
        });
      } catch (error) {
        console.error("Manual payment error:", error);
        res.status(500).json({
          error: "Failed to process payment",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    paymentsRouter.post("/payments/lockbox", upload3.single("csvFile"), async (req, res) => {
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        if (!req.file) {
          return res.status(400).json({ error: "CSV file required" });
        }
        const csvContent = req.file.buffer.toString("utf-8");
        const fileName = req.file.originalname;
        const result = await ingestLockboxCsv(tenantId, csvContent, fileName);
        res.status(201).json({
          success: true,
          batchId: result.batchId,
          totalCount: result.totalCount,
          successCount: result.successCount,
          results: result.results,
          message: `Processed ${result.successCount} of ${result.totalCount} payments`
        });
      } catch (error) {
        console.error("Lockbox upload error:", error);
        res.status(500).json({
          error: "Failed to process lockbox file",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    paymentsRouter.post("/payments/ach-webhook", async (req, res) => {
      try {
        const signature = req.headers["x-webhook-signature"];
        const secret = process.env.ACH_WEBHOOK_SECRET;
        if (secret) {
          const expectedSignature = crypto20.createHmac("sha256", secret).update(JSON.stringify(req.body)).digest("hex");
          if (signature !== expectedSignature) {
            return res.status(401).json({ error: "Invalid webhook signature" });
          }
        }
        const tenantId = req.body.tenant_id || "00000000-0000-0000-0000-000000000001";
        const result = await processAchWebhook(tenantId, req.body);
        res.status(200).json({
          success: true,
          result,
          message: "Webhook processed successfully"
        });
      } catch (error) {
        console.error("ACH webhook error:", error);
        res.status(500).json({
          error: "Failed to process ACH webhook",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    paymentsRouter.get("/payments/:id", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const payment = await client5.query(`
      SELECT p.*, l.loan_number, b.first_name, b.last_name,
             r.file_uri as receipt_uri
      FROM pay_payments p
      LEFT JOIN loans l ON p.loan_id = l.id
      LEFT JOIN borrowers b ON l.id = b.loan_id AND b.is_primary = true
      LEFT JOIN pay_receipts r ON p.receipt_id = r.id
      WHERE p.id = $1 AND p.tenant_id = $2
    `, [req.params.id, tenantId]);
        if (!payment.rowCount) {
          return res.status(404).json({ error: "Payment not found" });
        }
        res.json({
          payment: payment.rows[0]
        });
      } catch (error) {
        console.error("Error fetching payment:", error);
        res.status(500).json({ error: "Failed to fetch payment" });
      } finally {
        client5.release();
      }
    });
    paymentsRouter.get("/loans/:loanId/payments", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const payments3 = await client5.query(`
      SELECT p.*, r.file_uri as receipt_uri
      FROM pay_payments p
      LEFT JOIN pay_receipts r ON p.receipt_id = r.id
      WHERE p.loan_id = $1 AND p.tenant_id = $2
      ORDER BY p.ts DESC
    `, [req.params.loanId, tenantId]);
        res.json({
          loanId: req.params.loanId,
          payments: payments3.rows
        });
      } catch (error) {
        console.error("Error fetching loan payments:", error);
        res.status(500).json({ error: "Failed to fetch payments" });
      } finally {
        client5.release();
      }
    });
    paymentsRouter.get("/loans/:loanId/suspense", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const suspense = await client5.query(`
      SELECT * FROM pay_suspense 
      WHERE loan_id = $1 AND tenant_id = $2
    `, [req.params.loanId, tenantId]);
        res.json({
          loanId: req.params.loanId,
          suspenseBalance: suspense.rows[0]?.balance || 0,
          lastUpdated: suspense.rows[0]?.updated_at || null
        });
      } catch (error) {
        console.error("Error fetching suspense:", error);
        res.status(500).json({ error: "Failed to fetch suspense balance" });
      } finally {
        client5.release();
      }
    });
    paymentsRouter.post("/payments/:id/post", async (req, res) => {
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const paymentId = req.params.id;
        const result = await validateAndPostPayment({ tenantId, paymentId });
        res.status(200).json({
          success: true,
          result,
          message: "Payment posted successfully"
        });
      } catch (error) {
        console.error("Payment posting error:", error);
        res.status(500).json({
          error: "Failed to post payment",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    paymentsRouter.post("/reconciliation/bank-statement", upload3.single("statementFile"), async (req, res) => {
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const { stmtDate, openingBalance, closingBalance } = req.body;
        if (!req.file) {
          return res.status(400).json({ error: "Bank statement file required" });
        }
        const transactions = JSON.parse(req.body.transactions || "[]");
        const result = await importBankStatement({
          tenantId,
          stmtDate,
          openingBalance: parseFloat(openingBalance),
          closingBalance: parseFloat(closingBalance),
          transactions,
          fileName: req.file.originalname,
          fileContent: req.file.buffer
        });
        res.status(201).json({
          success: true,
          ...result,
          message: "Bank statement imported successfully"
        });
      } catch (error) {
        console.error("Bank reconciliation error:", error);
        res.status(500).json({
          error: "Failed to import bank statement",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    paymentsRouter.get("/reconciliation/:stmtDate", async (req, res) => {
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const { stmtDate } = req.params;
        const report = await getReconciliationReport(tenantId, stmtDate);
        res.json(report);
      } catch (error) {
        console.error("Reconciliation report error:", error);
        res.status(500).json({
          error: "Failed to generate reconciliation report",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    paymentsRouter.post("/reconciliation/match", async (req, res) => {
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const { bankMatchId, paymentId } = req.body;
        if (!bankMatchId || !paymentId) {
          return res.status(400).json({ error: "Bank match ID and payment ID required" });
        }
        const result = await manualMatch(tenantId, bankMatchId, paymentId);
        res.status(200).json({
          success: true,
          ...result,
          message: "Transaction matched successfully"
        });
      } catch (error) {
        console.error("Manual match error:", error);
        res.status(500).json({
          error: "Failed to match transaction",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
  }
});

// src/investor/period.ts
import dayjs9 from "dayjs";
import tz4 from "dayjs/plugin/timezone";
import utc4 from "dayjs/plugin/utc";
function periodFor(dateISO) {
  const d = dayjs9.tz(dateISO || dayjs9().format("YYYY-MM-DD"), Z4);
  if ((process.env.REMIT_CADENCE || "MONTHLY").toUpperCase() === "WEEKLY") {
    const friday = d.day() >= 5 ? d.day(5) : d.day(-2);
    const cutoff = addBusinessDays2(friday, Number(process.env.REMIT_GRACE_DAYS_BUSINESS || "2"));
    const start = friday.subtract(6, "day").format("YYYY-MM-DD");
    return {
      start,
      end: friday.format("YYYY-MM-DD"),
      cutoff: cutoff.format("YYYY-MM-DD")
    };
  } else {
    const end = d.endOf("month").format("YYYY-MM-DD");
    const cutoff = addBusinessDays2(dayjs9.tz(end, Z4), Number(process.env.REMIT_GRACE_DAYS_BUSINESS || "2"));
    const start = d.startOf("month").format("YYYY-MM-DD");
    return { start, end, cutoff: cutoff.format("YYYY-MM-DD") };
  }
}
function addBusinessDays2(d, n) {
  let x = d;
  let c = 0;
  while (c < n) {
    x = x.add(1, "day");
    if (x.day() != 0 && x.day() != 6) c++;
  }
  return x;
}
function monthlyBpsToMonthlyAmt(bps, upb) {
  const annual = upb * (bps / 1e4);
  return Math.round((annual / 12 + Number.EPSILON) * 100) / 100;
}
var Z4;
var init_period = __esm({
  "src/investor/period.ts"() {
    "use strict";
    dayjs9.extend(utc4);
    dayjs9.extend(tz4);
    Z4 = process.env.REMIT_CUTOFF_BUSINESS_TZ || "America/New_York";
  }
});

// src/investor/engine.ts
import { createHash as createHash16 } from "crypto";
function round25(n) {
  return Math.round((n + Number.EPSILON) * 100) / 100;
}
async function runRemittance(tenantId, investorId, asOfISO) {
  const c = await pool.connect();
  try {
    const per = periodFor(asOfISO);
    const existing = await c.query(`
      SELECT id FROM inv_remit_runs 
      WHERE tenant_id=$1 AND investor_id=$2 AND period_start=$3 AND period_end=$4
    `, [tenantId, investorId, per.start, per.end]);
    if (existing.rowCount) {
      return { ok: true, skipped: true };
    }
    const run = await c.query(`
      INSERT INTO inv_remit_runs (tenant_id, investor_id, period_start, period_end) 
      VALUES ($1,$2,$3,$4) RETURNING id
    `, [tenantId, investorId, per.start, per.end]);
    const runId = run.rows[0].id;
    const holdings = await c.query(`
      SELECT h.*, i.delivery_type, 
             COALESCE(h.svc_fee_bps,$3::int) AS svc_bps, 
             COALESCE(h.strip_bps,$4::int) AS strip_bps,
             COALESCE(h.pass_escrow,$5::bool) AS pass_escrow
      FROM inv_holdings h
      JOIN inv_investors i ON i.id=h.investor_id
      WHERE h.tenant_id=$1 AND h.investor_id=$2 AND h.active=true
    `, [
      tenantId,
      investorId,
      Number(process.env.REMIT_SVC_FEE_BPS || "50"),
      Number(process.env.REMIT_STRIP_BPS || "0"),
      (process.env.REMIT_PASS_ESCROW || "false") === "true"
    ]);
    let totalNet = 0;
    for (const h of holdings.rows) {
      const tx = await c.query(`
        SELECT type, amount, alloc_principal, alloc_interest, alloc_escrow, alloc_fees
        FROM svc_txns
        WHERE loan_id=$1 AND ts::date BETWEEN $2::date AND $3::date
      `, [h.loan_id, per.start, per.end]);
      let p = 0, i = 0, e = 0, f = 0;
      for (const t of tx.rows) {
        if (t.type === "PAYMENT") {
          p += Number(t.alloc_principal || 0);
          i += Number(t.alloc_interest || 0);
          e += Number(t.alloc_escrow || 0);
          f += Number(t.alloc_fees || 0);
        } else if (t.type === "ADJUSTMENT") {
          p += Number(t.alloc_principal || 0);
          i += Number(t.alloc_interest || 0);
          e += Number(t.alloc_escrow || 0);
          f += Number(t.alloc_fees || 0);
        }
      }
      const begRow = await c.query(`
        SELECT principal_balance_after FROM svc_schedule 
        WHERE loan_id=$1 AND due_date < $2::date
        ORDER BY due_date DESC LIMIT 1
      `, [h.loan_id, per.start]);
      const endRow = await c.query(`
        SELECT principal_balance_after FROM svc_schedule 
        WHERE loan_id=$1 AND due_date <= $2::date
        ORDER BY due_date DESC LIMIT 1
      `, [h.loan_id, per.end]);
      const upbBeg = Number(begRow.rows[0]?.principal_balance_after || 0);
      const upbEnd = Number(endRow.rows[0]?.principal_balance_after || Math.max(0, upbBeg - p));
      const avgUPB = (upbBeg + upbEnd) / 2;
      const svcFee = monthlyBpsToMonthlyAmt(Number(h.svc_bps || 0), avgUPB) * Number(h.participation_pct || 1);
      const strip = monthlyBpsToMonthlyAmt(Number(h.strip_bps || 0), avgUPB) * Number(h.participation_pct || 1);
      const passEscrow = !!h.pass_escrow;
      const net2 = (p + i + (passEscrow ? e : 0)) * Number(h.participation_pct || 1) - svcFee - strip;
      await c.query(`
        INSERT INTO inv_remit_items (
          run_id, tenant_id, investor_id, loan_id, upb_beg, upb_end, 
          principal_collected, interest_collected, escrow_collected, fees_collected, 
          svc_fee, strip_io, net_remit
        ) VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13)
      `, [
        runId,
        tenantId,
        investorId,
        h.loan_id,
        upbBeg,
        upbEnd,
        p,
        i,
        e,
        f,
        round25(svcFee),
        round25(strip),
        round25(net2)
      ]);
      totalNet += net2;
    }
    const items = await c.query(`
      SELECT * FROM inv_remit_items WHERE run_id=$1 ORDER BY loan_id
    `, [runId]);
    const header = "LoanId,UPB_Beg,UPB_End,Principal,Interest,Escrow,Fees,SvcFee,StripIO,Net\n";
    const rows = items.rows.map(
      (r) => [
        r.loan_id,
        r.upb_beg,
        r.upb_end,
        r.principal_collected,
        r.interest_collected,
        r.escrow_collected,
        r.fees_collected,
        r.svc_fee,
        r.strip_io,
        r.net_remit
      ].map((v) => String(v)).join(",")
    ).join("\n");
    const csv = header + rows + "\n";
    const b = Buffer.from(csv, "utf-8");
    const sha = createHash16("sha256").update(b).digest("hex");
    const key = `${process.env.S3_PREFIX || "tenants"}/${tenantId}/${process.env.REMIT_S3_PREFIX || "remittances"}/${investorId}_${per.start}_${per.end}_loan_activity.csv`;
    const uri = `s3://test-bucket/${key}`;
    console.log(`[MockS3] Generated CSV report: ${csv.length} bytes, SHA: ${sha}`);
    const payout = await c.query(`
      INSERT INTO inv_remit_payouts (tenant_id, investor_id, run_id, amount, method, file_uri, file_sha256, status)
      VALUES ($1,$2,$3,$4,'ACH',$5,$6,'Requested') RETURNING id
    `, [tenantId, investorId, runId, round25(totalNet), uri, sha]);
    const payoutId = payout.rows[0].id;
    await c.query(`
      UPDATE inv_remit_runs SET status='Completed', completed_at=now(), metrics=$3 
      WHERE id=$1 AND tenant_id=$2
    `, [runId, tenantId, JSON.stringify({ totalNet: round25(totalNet), items: items.rowCount })]);
    if (totalNet > 0) {
      await c.query(`
        INSERT INTO gl_entries (tenant_id, debit_acct, credit_acct, amount, memo)
        VALUES ($1, $2, $3, $4, 'Investor remittance payout')
      `, [
        tenantId,
        Number(process.env.GL_INVESTOR_PAYABLE_ACCT || "2300"),
        Number(process.env.GL_CASH_ACCT || "1000"),
        totalNet
      ]);
    }
    return {
      ok: true,
      runId,
      payoutId,
      totalNet: round25(totalNet),
      period: per,
      itemCount: items.rowCount,
      fileUri: uri
    };
  } finally {
    c.release();
  }
}
var init_engine4 = __esm({
  "src/investor/engine.ts"() {
    "use strict";
    init_db();
    init_period();
  }
});

// src/investor/statement.ts
import { createHash as createHash17 } from "crypto";
import dayjs10 from "dayjs";
async function putBytes2(key, buffer, contentType) {
  const mockS3Uri = `s3://test-bucket/${key}`;
  console.log(`[MockS3] Stored ${buffer.length} bytes at ${mockS3Uri}`);
  return mockS3Uri;
}
async function generateRemittanceStatement(tenantId, runId) {
  const client5 = await pool.connect();
  try {
    const run = await client5.query(`
      SELECT r.*, i.name as investor_name, i.delivery_type
      FROM inv_remit_runs r
      JOIN inv_investors i ON r.investor_id = i.id
      WHERE r.id = $1 AND r.tenant_id = $2
    `, [runId, tenantId]);
    if (!run.rowCount) throw new Error("Remittance run not found");
    const runData = run.rows[0];
    const items = await client5.query(`
      SELECT i.*, l.loan_number
      FROM inv_remit_items i
      LEFT JOIN loans l ON i.loan_id = l.id
      WHERE i.run_id = $1
      ORDER BY i.loan_id
    `, [runId]);
    const payout = await client5.query(`
      SELECT * FROM inv_remit_payouts WHERE run_id = $1
    `, [runId]);
    const payoutData = payout.rows[0];
    const totals = items.rows.reduce((acc, item) => ({
      upb_beg: acc.upb_beg + Number(item.upb_beg),
      upb_end: acc.upb_end + Number(item.upb_end),
      principal: acc.principal + Number(item.principal_collected),
      interest: acc.interest + Number(item.interest_collected),
      escrow: acc.escrow + Number(item.escrow_collected),
      fees: acc.fees + Number(item.fees_collected),
      svc_fee: acc.svc_fee + Number(item.svc_fee),
      strip_io: acc.strip_io + Number(item.strip_io),
      net_remit: acc.net_remit + Number(item.net_remit)
    }), {
      upb_beg: 0,
      upb_end: 0,
      principal: 0,
      interest: 0,
      escrow: 0,
      fees: 0,
      svc_fee: 0,
      strip_io: 0,
      net_remit: 0
    });
    const statementData = {
      header: process.env.REMIT_PDF_HEADER || "LoanServe \u2022 Investor Remittance Statement",
      watermark: process.env.REMIT_PDF_WATERMARK || "LoanServe",
      investor: {
        name: runData.investor_name,
        id: runData.investor_id,
        deliveryType: runData.delivery_type
      },
      period: {
        start: dayjs10(runData.period_start).format("MMM DD, YYYY"),
        end: dayjs10(runData.period_end).format("MMM DD, YYYY"),
        label: `${dayjs10(runData.period_start).format("MMM YYYY")}`
      },
      summary: {
        loanCount: items.rowCount,
        upbBeginning: totals.upb_beg,
        upbEnding: totals.upb_end,
        principalCollected: totals.principal,
        interestCollected: totals.interest,
        escrowCollected: totals.escrow,
        feesCollected: totals.fees,
        servicingFee: totals.svc_fee,
        stripIO: totals.strip_io,
        netRemittance: totals.net_remit
      },
      loans: items.rows.map((item) => ({
        loanNumber: item.loan_number,
        upbBeg: Number(item.upb_beg),
        upbEnd: Number(item.upb_end),
        principal: Number(item.principal_collected),
        interest: Number(item.interest_collected),
        escrow: Number(item.escrow_collected),
        fees: Number(item.fees_collected),
        svcFee: Number(item.svc_fee),
        stripIO: Number(item.strip_io),
        netRemit: Number(item.net_remit)
      })),
      payout: {
        amount: Number(payoutData.amount),
        method: payoutData.method,
        status: payoutData.status,
        reference: payoutData.reference
      }
    };
    const pdfBuffer = await renderRemittanceStatementPdf(statementData);
    const hash = createHash17("sha256").update(pdfBuffer).digest("hex");
    const s3Key = `${process.env.S3_PREFIX || "tenants"}/${tenantId}/${process.env.REMIT_S3_PREFIX || "remittances"}/${runData.investor_id}_${runData.period_start}_${runData.period_end}_statement.pdf`;
    const s3Uri = await putBytes2(s3Key, pdfBuffer, "application/pdf");
    return {
      statementUri: s3Uri,
      hash,
      data: statementData
    };
  } finally {
    client5.release();
  }
}
async function renderRemittanceStatementPdf(data) {
  const PDFDocument5 = await import("pdfkit");
  const doc = new PDFDocument5.default();
  const chunks = [];
  doc.on("data", (chunk) => chunks.push(chunk));
  return new Promise((resolve) => {
    doc.on("end", () => resolve(Buffer.concat(chunks)));
    doc.fontSize(20).text(data.header, 50, 50);
    doc.fontSize(12).text(`Statement Period: ${data.period.start} - ${data.period.end}`, 50, 80);
    doc.text(`Generated: ${dayjs10().format("MMM DD, YYYY")}`, 50, 100);
    doc.fontSize(14).text("Investor Information:", 50, 140);
    doc.fontSize(12).text(`Name: ${data.investor.name}`, 50, 160).text(`ID: ${data.investor.id}`, 50, 180).text(`Delivery Type: ${data.investor.deliveryType}`, 50, 200);
    doc.fontSize(14).text("Remittance Summary:", 50, 240);
    doc.fontSize(12).text(`Loan Count: ${data.summary.loanCount}`, 50, 260).text(`UPB Beginning: $${Number(data.summary.upbBeginning).toFixed(2)}`, 50, 280).text(`UPB Ending: $${Number(data.summary.upbEnding).toFixed(2)}`, 50, 300).text(`Principal Collected: $${Number(data.summary.principalCollected).toFixed(2)}`, 50, 320).text(`Interest Collected: $${Number(data.summary.interestCollected).toFixed(2)}`, 50, 340).text(`Escrow Collected: $${Number(data.summary.escrowCollected).toFixed(2)}`, 50, 360).text(`Fees Collected: $${Number(data.summary.feesCollected).toFixed(2)}`, 50, 380).text(`Servicing Fee: ($${Number(data.summary.servicingFee).toFixed(2)})`, 50, 400).text(`Strip I/O: ($${Number(data.summary.stripIO).toFixed(2)})`, 50, 420);
    doc.fontSize(14).text(`Net Remittance: $${Number(data.summary.netRemittance).toFixed(2)}`, 50, 450);
    doc.fontSize(12).text("Payout Information:", 50, 480);
    doc.fontSize(11).text(`Amount: $${Number(data.payout.amount).toFixed(2)}`, 50, 500).text(`Method: ${data.payout.method}`, 50, 520).text(`Status: ${data.payout.status}`, 50, 540);
    if (data.loans.length <= 10) {
      doc.addPage();
      doc.fontSize(14).text("Loan-Level Detail:", 50, 50);
      let y = 80;
      data.loans.forEach((loan, idx) => {
        if (y > 700) {
          doc.addPage();
          y = 50;
        }
        doc.fontSize(11).text(`${idx + 1}. ${loan.loanNumber}`, 50, y).text(`Principal: $${loan.principal.toFixed(2)}`, 200, y).text(`Interest: $${loan.interest.toFixed(2)}`, 300, y).text(`Net: $${loan.netRemit.toFixed(2)}`, 400, y);
        y += 20;
      });
    }
    doc.fontSize(60).fillColor("#E0E0E0").text(data.watermark, 200, 400, { rotate: 45 });
    doc.end();
  });
}
var init_statement = __esm({
  "src/investor/statement.ts"() {
    "use strict";
    init_db();
  }
});

// src/investor/payout.ts
import { createHash as createHash18 } from "crypto";
async function processRemittancePayout(tenantId, payoutId) {
  const client5 = await pool.connect();
  try {
    await client5.query("BEGIN");
    const payout = await client5.query(`
      SELECT p.*, i.name as investor_name, i.webhook_url, i.webhook_secret
      FROM inv_remit_payouts p
      JOIN inv_investors i ON p.investor_id = i.id
      WHERE p.id = $1 AND p.tenant_id = $2
    `, [payoutId, tenantId]);
    if (!payout.rowCount) throw new Error("Payout not found");
    const payoutData = payout.rows[0];
    if (payoutData.status !== "Requested") {
      throw new Error(`Payout already processed: ${payoutData.status}`);
    }
    await client5.query(`
      UPDATE inv_remit_payouts 
      SET status = 'Sent', sent_at = now(), reference = $2
      WHERE id = $1
    `, [payoutId, `PAY-${payoutId.slice(-8).toUpperCase()}`]);
    if (Number(payoutData.amount) > 0) {
      await client5.query(`
        INSERT INTO gl_entries (tenant_id, debit_acct, credit_acct, amount, memo)
        VALUES ($1, $2, $3, $4, $5)
      `, [
        tenantId,
        Number(process.env.GL_CASH_ACCT || "1000"),
        Number(process.env.GL_INVESTOR_PAYABLE_ACCT || "2300"),
        payoutData.amount,
        `Investor payout to ${payoutData.investor_name}`
      ]);
    }
    await client5.query("COMMIT");
    if (payoutData.webhook_url) {
      try {
        await sendInvestorWebhook(payoutData);
      } catch (webhookError) {
        console.error("Webhook notification failed:", webhookError);
      }
    }
    return {
      success: true,
      payoutId,
      amount: payoutData.amount,
      reference: `PAY-${payoutId.slice(-8).toUpperCase()}`,
      method: payoutData.method,
      status: "Sent"
    };
  } catch (error) {
    await client5.query("ROLLBACK");
    await client5.query(`
      UPDATE inv_remit_payouts 
      SET status = 'Failed', error = $2
      WHERE id = $1
    `, [payoutId, String(error)]).catch(() => {
    });
    throw error;
  } finally {
    client5.release();
  }
}
async function sendInvestorWebhook(payoutData) {
  const payload = {
    event: "remittance.payout.sent",
    investor_id: payoutData.investor_id,
    payout_id: payoutData.id,
    run_id: payoutData.run_id,
    amount: payoutData.amount,
    currency: payoutData.currency,
    method: payoutData.method,
    reference: payoutData.reference,
    sent_at: (/* @__PURE__ */ new Date()).toISOString()
  };
  const headers = {
    "Content-Type": "application/json",
    "User-Agent": "LoanServe-Remittance/1.0"
  };
  if (payoutData.webhook_secret) {
    const signature = createHash18("sha256").update(JSON.stringify(payload), "utf8").digest("hex");
    headers["X-LoanServe-Signature"] = signature;
  }
  const response = await fetch(payoutData.webhook_url, {
    method: "POST",
    headers,
    body: JSON.stringify(payload),
    signal: AbortSignal.timeout(Number(process.env.INVESTOR_WEBHOOK_TIMEOUT_MS || "15000"))
  });
  if (!response.ok) {
    throw new Error(`Webhook failed: ${response.status} ${response.statusText}`);
  }
  return { success: true, status: response.status };
}
async function settleRemittancePayout(tenantId, payoutId, reference) {
  const client5 = await pool.connect();
  try {
    await client5.query(`
      UPDATE inv_remit_payouts 
      SET status = 'Settled', settled_at = now(), reference = COALESCE($3, reference)
      WHERE id = $1 AND tenant_id = $2 AND status = 'Sent'
    `, [payoutId, tenantId, reference]);
    return { success: true, payoutId, status: "Settled" };
  } finally {
    client5.release();
  }
}
var init_payout = __esm({
  "src/investor/payout.ts"() {
    "use strict";
    init_db();
  }
});

// src/routes/investor.routes.ts
var investor_routes_exports2 = {};
__export(investor_routes_exports2, {
  investorRouter: () => investorRouter
});
import { Router as Router51 } from "express";
var investorRouter;
var init_investor_routes2 = __esm({
  "src/routes/investor.routes.ts"() {
    "use strict";
    init_db();
    init_engine4();
    init_statement();
    init_payout();
    init_period();
    investorRouter = Router51();
    investorRouter.post("/investors", async (req, res) => {
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const { name, deliveryType, webhookUrl, webhookSecret, currency } = req.body;
        if (!name || !deliveryType) {
          return res.status(400).json({ error: "Name and delivery type required" });
        }
        const client5 = await pool.connect();
        try {
          const investor = await client5.query(`
        INSERT INTO inv_investors (tenant_id, name, delivery_type, webhook_url, webhook_secret, currency)
        VALUES ($1, $2, $3, $4, $5, $6)
        RETURNING *
      `, [tenantId, name, deliveryType, webhookUrl || null, webhookSecret || null, currency || "USD"]);
          res.status(201).json({
            success: true,
            investor: investor.rows[0]
          });
        } finally {
          client5.release();
        }
      } catch (error) {
        console.error("Error creating investor:", error);
        res.status(500).json({
          error: "Failed to create investor",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    investorRouter.get("/investors", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const investors2 = await client5.query(`
      SELECT i.*, 
             COUNT(h.id) as holding_count,
             COALESCE(SUM(h.participation_pct), 0) as total_participation
      FROM inv_investors i
      LEFT JOIN inv_holdings h ON i.id = h.investor_id AND h.active = true
      WHERE i.tenant_id = $1 AND i.active = true
      GROUP BY i.id
      ORDER BY i.name
    `, [tenantId]);
        res.json({
          investors: investors2.rows
        });
      } catch (error) {
        console.error("Error fetching investors:", error);
        res.status(500).json({ error: "Failed to fetch investors" });
      } finally {
        client5.release();
      }
    });
    investorRouter.post("/investors/:investorId/holdings", async (req, res) => {
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const { investorId } = req.params;
        const { loanId, participationPct, svcFeeBps, stripBps, passEscrow, accrualBasis } = req.body;
        if (!loanId || participationPct === void 0) {
          return res.status(400).json({ error: "Loan ID and participation percentage required" });
        }
        const client5 = await pool.connect();
        try {
          const holding = await client5.query(`
        INSERT INTO inv_holdings (
          tenant_id, investor_id, loan_id, participation_pct, 
          svc_fee_bps, strip_bps, pass_escrow, accrual_basis
        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
        ON CONFLICT (tenant_id, investor_id, loan_id) 
        DO UPDATE SET 
          participation_pct = EXCLUDED.participation_pct,
          svc_fee_bps = EXCLUDED.svc_fee_bps,
          strip_bps = EXCLUDED.strip_bps,
          pass_escrow = EXCLUDED.pass_escrow,
          accrual_basis = EXCLUDED.accrual_basis,
          active = true
        RETURNING *
      `, [
            tenantId,
            investorId,
            loanId,
            participationPct,
            svcFeeBps || null,
            stripBps || null,
            passEscrow || null,
            accrualBasis || "30/360"
          ]);
          res.status(201).json({
            success: true,
            holding: holding.rows[0]
          });
        } finally {
          client5.release();
        }
      } catch (error) {
        console.error("Error creating holding:", error);
        res.status(500).json({
          error: "Failed to create holding",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    investorRouter.get("/investors/:investorId/holdings", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const { investorId } = req.params;
        const holdings = await client5.query(`
      SELECT h.*, l.loan_number, l.original_amount
      FROM inv_holdings h
      LEFT JOIN loans l ON h.loan_id = l.id
      WHERE h.tenant_id = $1 AND h.investor_id = $2 AND h.active = true
      ORDER BY l.loan_number
    `, [tenantId, investorId]);
        res.json({
          investorId,
          holdings: holdings.rows
        });
      } catch (error) {
        console.error("Error fetching holdings:", error);
        res.status(500).json({ error: "Failed to fetch holdings" });
      } finally {
        client5.release();
      }
    });
    investorRouter.post("/investors/:investorId/remittances", async (req, res) => {
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const { investorId } = req.params;
        const { asOf } = req.body;
        const result = await runRemittance(tenantId, investorId, asOf);
        if (result.skipped) {
          return res.status(200).json({
            success: true,
            message: "Remittance already exists for this period",
            skipped: true
          });
        }
        res.status(201).json({
          success: true,
          message: "Remittance processed successfully",
          ...result
        });
      } catch (error) {
        console.error("Remittance processing failed:", error);
        res.status(500).json({
          error: "Failed to process remittance",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    investorRouter.get("/investors/:investorId/remittances", async (req, res) => {
      const client5 = await pool.connect();
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const { investorId } = req.params;
        const remittances = await client5.query(`
      SELECT r.*, p.amount as payout_amount, p.status as payout_status, p.method as payout_method
      FROM inv_remit_runs r
      LEFT JOIN inv_remit_payouts p ON r.id = p.run_id
      WHERE r.tenant_id = $1 AND r.investor_id = $2
      ORDER BY r.period_end DESC
    `, [tenantId, investorId]);
        res.json({
          investorId,
          remittances: remittances.rows
        });
      } catch (error) {
        console.error("Error fetching remittances:", error);
        res.status(500).json({ error: "Failed to fetch remittances" });
      } finally {
        client5.release();
      }
    });
    investorRouter.post("/remittances/:runId/statement", async (req, res) => {
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const { runId } = req.params;
        const result = await generateRemittanceStatement(tenantId, runId);
        res.status(200).json({
          success: true,
          statementUri: result.statementUri,
          hash: result.hash
        });
      } catch (error) {
        console.error("Statement generation failed:", error);
        res.status(500).json({
          error: "Failed to generate statement",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    investorRouter.post("/payouts/:payoutId/process", async (req, res) => {
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const { payoutId } = req.params;
        const result = await processRemittancePayout(tenantId, payoutId);
        res.status(200).json({
          success: true,
          message: "Payout processed successfully",
          ...result
        });
      } catch (error) {
        console.error("Payout processing failed:", error);
        res.status(500).json({
          error: "Failed to process payout",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    investorRouter.post("/payouts/:payoutId/settle", async (req, res) => {
      try {
        const tenantId = req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
        const { payoutId } = req.params;
        const { reference } = req.body;
        const result = await settleRemittancePayout(tenantId, payoutId, reference);
        res.status(200).json({
          success: true,
          message: "Payout settled successfully",
          ...result
        });
      } catch (error) {
        console.error("Payout settlement failed:", error);
        res.status(500).json({
          error: "Failed to settle payout",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    investorRouter.get("/periods/current", async (req, res) => {
      try {
        const { asOf } = req.query;
        const period = periodFor(asOf);
        res.json({
          success: true,
          period,
          cadence: process.env.REMIT_CADENCE || "MONTHLY",
          graceDays: Number(process.env.REMIT_GRACE_DAYS_BUSINESS || "2")
        });
      } catch (error) {
        console.error("Error getting period:", error);
        res.status(500).json({ error: "Failed to get period information" });
      }
    });
  }
});

// src/etl/reporting/loaders.ts
import dayjs11 from "dayjs";
var ReportingETL;
var init_loaders = __esm({
  "src/etl/reporting/loaders.ts"() {
    "use strict";
    init_db();
    ReportingETL = class {
      tenantId;
      metrics = [];
      constructor(tenantId) {
        this.tenantId = tenantId;
      }
      async loadDimLoan() {
        const start = Date.now();
        const client5 = await pool.connect();
        try {
          await client5.query("SET LOCAL app.tenant_id=$1", [this.tenantId]);
          const result = await client5.query(`
        INSERT INTO reporting.dim_loan (
          loan_id, loan_number, borrower_name, property_city, property_state, 
          property_zip, program_code, investor_id, loan_purpose, property_type, 
          occupancy_type, updated_at
        )
        SELECT 
          src.loan_id, src.loan_number, src.borrower_name, src.property_city, 
          src.property_state, src.property_zip, src.program_code, src.investor_id,
          src.loan_purpose, src.property_type, src.occupancy_type, NOW()
        FROM reporting.v_dim_loan_source src
        ON CONFLICT (loan_id) DO UPDATE SET
          loan_number = EXCLUDED.loan_number,
          borrower_name = EXCLUDED.borrower_name,
          property_city = EXCLUDED.property_city,
          property_state = EXCLUDED.property_state,
          property_zip = EXCLUDED.property_zip,
          program_code = EXCLUDED.program_code,
          investor_id = EXCLUDED.investor_id,
          loan_purpose = EXCLUDED.loan_purpose,
          property_type = EXCLUDED.property_type,
          occupancy_type = EXCLUDED.occupancy_type,
          updated_at = EXCLUDED.updated_at
      `);
          this.metrics.push({
            table: "dim_loan",
            rows_processed: result.rowCount || 0,
            processing_time_ms: Date.now() - start,
            last_updated: (/* @__PURE__ */ new Date()).toISOString()
          });
        } finally {
          client5.release();
        }
      }
      async loadDimInvestor() {
        const start = Date.now();
        const client5 = await pool.connect();
        try {
          await client5.query("SET LOCAL app.tenant_id=$1", [this.tenantId]);
          const result = await client5.query(`
        INSERT INTO reporting.dim_investor (
          investor_id, investor_name, delivery_type, active, remittance_frequency, updated_at
        )
        SELECT 
          id, name, delivery_type, active, remittance_frequency, NOW()
        FROM inv_investors
        ON CONFLICT (investor_id) DO UPDATE SET
          investor_name = EXCLUDED.investor_name,
          delivery_type = EXCLUDED.delivery_type,
          active = EXCLUDED.active,
          remittance_frequency = EXCLUDED.remittance_frequency,
          updated_at = EXCLUDED.updated_at
      `);
          this.metrics.push({
            table: "dim_investor",
            rows_processed: result.rowCount || 0,
            processing_time_ms: Date.now() - start,
            last_updated: (/* @__PURE__ */ new Date()).toISOString()
          });
        } finally {
          client5.release();
        }
      }
      async loadDimUser() {
        const start = Date.now();
        const client5 = await pool.connect();
        try {
          await client5.query("SET LOCAL app.tenant_id=$1", [this.tenantId]);
          const result = await client5.query(`
        INSERT INTO reporting.dim_user (
          user_id, username, email, role, department, active, updated_at
        )
        SELECT 
          user_id, username, email, role, department, active, NOW()
        FROM reporting.v_dim_user_source
        ON CONFLICT (user_id) DO UPDATE SET
          username = EXCLUDED.username,
          email = EXCLUDED.email,
          role = EXCLUDED.role,
          department = EXCLUDED.department,
          active = EXCLUDED.active,
          updated_at = EXCLUDED.updated_at
      `);
          this.metrics.push({
            table: "dim_user",
            rows_processed: result.rowCount || 0,
            processing_time_ms: Date.now() - start,
            last_updated: (/* @__PURE__ */ new Date()).toISOString()
          });
        } finally {
          client5.release();
        }
      }
      async loadFactTxn(sinceISO) {
        const start = Date.now();
        const client5 = await pool.connect();
        try {
          await client5.query("SET LOCAL app.tenant_id=$1", [this.tenantId]);
          const since = sinceISO || dayjs11().subtract(25, "hour").format("YYYY-MM-DD HH:mm:ss");
          const result = await client5.query(`
        INSERT INTO reporting.fact_txn (
          tenant_id, loan_id, user_id, d, type, amount, alloc_principal, 
          alloc_interest, alloc_escrow, alloc_fees, payment_method, ref
        )
        SELECT 
          t.tenant_id, t.loan_id, t.user_id, t.ts::date, t.type, t.amount, 
          t.alloc_principal, t.alloc_interest, t.alloc_escrow, t.alloc_fees,
          t.ref->>'payment_method' AS payment_method, t.ref
        FROM svc_txns t 
        WHERE t.ts >= $2
        ON CONFLICT DO NOTHING
      `, [since]);
          this.metrics.push({
            table: "fact_txn",
            rows_processed: result.rowCount || 0,
            processing_time_ms: Date.now() - start,
            last_updated: (/* @__PURE__ */ new Date()).toISOString()
          });
        } finally {
          client5.release();
        }
      }
      async loadFactQC(sinceISO) {
        const start = Date.now();
        const client5 = await pool.connect();
        try {
          await client5.query("SET LOCAL app.tenant_id=$1", [this.tenantId]);
          const since = sinceISO || dayjs11().subtract(25, "hour").format("YYYY-MM-DD HH:mm:ss");
          const result = await client5.query(`
        INSERT INTO reporting.fact_qc (
          tenant_id, loan_id, rule_code, rule_category, severity, status, 
          resolution_notes, assigned_user_id, d, resolved_at
        )
        SELECT 
          lc.tenant_id, d.loan_id, r.code, r.category, r.severity, d.status,
          d.resolution_notes, d.assigned_user_id, d.created_at::date, d.resolved_at
        FROM qc_defects d 
        JOIN qc_rules r ON r.id = d.rule_id
        JOIN loan_candidates lc ON lc.id = d.loan_id
        WHERE d.created_at >= $2
        ON CONFLICT DO NOTHING
      `, [since]);
          this.metrics.push({
            table: "fact_qc",
            rows_processed: result.rowCount || 0,
            processing_time_ms: Date.now() - start,
            last_updated: (/* @__PURE__ */ new Date()).toISOString()
          });
        } finally {
          client5.release();
        }
      }
      async loadFactExport(sinceISO) {
        const start = Date.now();
        const client5 = await pool.connect();
        try {
          await client5.query("SET LOCAL app.tenant_id=$1", [this.tenantId]);
          const since = sinceISO || dayjs11().subtract(25, "hour").format("YYYY-MM-DD HH:mm:ss");
          const result = await client5.query(`
        INSERT INTO reporting.fact_export (
          tenant_id, loan_id, template, status, file_size_bytes, 
          processing_time_ms, error_message, d
        )
        SELECT 
          tenant_id, loan_id, template, status, 
          (metadata->>'file_size')::bigint AS file_size_bytes,
          (metadata->>'processing_time_ms')::integer AS processing_time_ms,
          error_message, created_at::date
        FROM exports 
        WHERE created_at >= $2
        ON CONFLICT DO NOTHING
      `, [since]);
          this.metrics.push({
            table: "fact_export",
            rows_processed: result.rowCount || 0,
            processing_time_ms: Date.now() - start,
            last_updated: (/* @__PURE__ */ new Date()).toISOString()
          });
        } finally {
          client5.release();
        }
      }
      async loadFactNotify(sinceISO) {
        const start = Date.now();
        const client5 = await pool.connect();
        try {
          await client5.query("SET LOCAL app.tenant_id=$1", [this.tenantId]);
          const since = sinceISO || dayjs11().subtract(25, "hour").format("YYYY-MM-DD HH:mm:ss");
          const result = await client5.query(`
        INSERT INTO reporting.fact_notify (
          tenant_id, loan_id, template_code, channel, status, 
          delivery_time_ms, recipient_count, d
        )
        SELECT 
          tenant_id, loan_id, template_code, channel, status,
          (metadata->>'delivery_time_ms')::integer AS delivery_time_ms,
          COALESCE((metadata->>'recipient_count')::integer, 1) AS recipient_count,
          created_at::date
        FROM notifications 
        WHERE created_at >= $2
        ON CONFLICT DO NOTHING
      `, [since]);
          this.metrics.push({
            table: "fact_notify",
            rows_processed: result.rowCount || 0,
            processing_time_ms: Date.now() - start,
            last_updated: (/* @__PURE__ */ new Date()).toISOString()
          });
        } finally {
          client5.release();
        }
      }
      async loadFactServicing() {
        const start = Date.now();
        const client5 = await pool.connect();
        try {
          await client5.query("SET LOCAL app.tenant_id=$1", [this.tenantId]);
          const result = await client5.query(`
        INSERT INTO reporting.fact_servicing (
          tenant_id, loan_id, d, upb, escrow_balance, delinquency_dpd, 
          delinquency_bucket, payment_due, interest_rate, maturity_date, next_payment_date
        )
        SELECT 
          s.tenant_id, s.loan_id, CURRENT_DATE,
          s.principal_balance_after,
          COALESCE((
            SELECT SUM(balance) 
            FROM svc_escrow_sub e 
            WHERE e.loan_id = s.loan_id
          ), 0) AS escrow_balance,
          0 AS delinquency_dpd,  -- Would calculate from payment schedule
          '0+' AS delinquency_bucket,
          s.payment_amount AS payment_due,
          NULL AS interest_rate,  -- Would come from loan terms
          NULL AS maturity_date,  -- Would come from loan terms
          s.due_date AS next_payment_date
        FROM (
          SELECT DISTINCT ON (loan_id) * 
          FROM svc_schedule 
          ORDER BY loan_id, installment_no DESC
        ) s
        ON CONFLICT (tenant_id, loan_id, d) DO UPDATE SET
          upb = EXCLUDED.upb,
          escrow_balance = EXCLUDED.escrow_balance,
          delinquency_dpd = EXCLUDED.delinquency_dpd,
          delinquency_bucket = EXCLUDED.delinquency_bucket,
          payment_due = EXCLUDED.payment_due,
          interest_rate = EXCLUDED.interest_rate,
          maturity_date = EXCLUDED.maturity_date,
          next_payment_date = EXCLUDED.next_payment_date
      `);
          this.metrics.push({
            table: "fact_servicing",
            rows_processed: result.rowCount || 0,
            processing_time_ms: Date.now() - start,
            last_updated: (/* @__PURE__ */ new Date()).toISOString()
          });
        } finally {
          client5.release();
        }
      }
      async loadFactRemit(sinceISO) {
        const start = Date.now();
        const client5 = await pool.connect();
        try {
          await client5.query("SET LOCAL app.tenant_id=$1", [this.tenantId]);
          const since = sinceISO || dayjs11().subtract(35, "day").format("YYYY-MM-DD");
          const result = await client5.query(`
        INSERT INTO reporting.fact_remit (
          tenant_id, investor_id, loan_id, remit_period_start, remit_period_end, d,
          principal, interest, escrow, svc_fee, strip_io, net, participation_pct
        )
        SELECT 
          r.tenant_id, r.investor_id, i.loan_id, r.period_start, r.period_end, r.period_end::date,
          i.principal_collected, i.interest_collected, i.escrow_collected, 
          i.svc_fee, i.strip_io, i.net_remit,
          h.participation_pct
        FROM inv_remit_items i 
        JOIN inv_remit_runs r ON r.id = i.run_id
        LEFT JOIN inv_holdings h ON h.investor_id = r.investor_id AND h.loan_id = i.loan_id
        WHERE r.period_end >= $2
        ON CONFLICT DO NOTHING
      `, [since]);
          this.metrics.push({
            table: "fact_remit",
            rows_processed: result.rowCount || 0,
            processing_time_ms: Date.now() - start,
            last_updated: (/* @__PURE__ */ new Date()).toISOString()
          });
        } finally {
          client5.release();
        }
      }
      async loadFactDocument(sinceISO) {
        const start = Date.now();
        const client5 = await pool.connect();
        try {
          await client5.query("SET LOCAL app.tenant_id=$1", [this.tenantId]);
          const since = sinceISO || dayjs11().subtract(25, "hour").format("YYYY-MM-DD HH:mm:ss");
          const result = await client5.query(`
        INSERT INTO reporting.fact_document (
          tenant_id, loan_id, document_type, processing_status, ai_confidence_score,
          extraction_count, validation_errors, processing_time_ms, file_size_bytes, d
        )
        SELECT 
          df.tenant_id, df.loan_id, df.document_type, df.processing_status,
          (df.ai_analysis->>'confidence_score')::numeric(5,4) AS ai_confidence_score,
          COALESCE((df.ai_analysis->>'extraction_count')::integer, 0) AS extraction_count,
          COALESCE((df.ai_analysis->>'validation_errors')::integer, 0) AS validation_errors,
          (df.metadata->>'processing_time_ms')::integer AS processing_time_ms,
          (df.metadata->>'file_size')::bigint AS file_size_bytes,
          df.created_at::date
        FROM document_files df
        WHERE df.created_at >= $2
        ON CONFLICT DO NOTHING
      `, [since]);
          this.metrics.push({
            table: "fact_document",
            rows_processed: result.rowCount || 0,
            processing_time_ms: Date.now() - start,
            last_updated: (/* @__PURE__ */ new Date()).toISOString()
          });
        } finally {
          client5.release();
        }
      }
      async runIncrementalETL(sinceISO) {
        console.log(`[ETL] Starting incremental ETL for tenant ${this.tenantId}`);
        this.metrics = [];
        try {
          await this.loadDimLoan();
          await this.loadDimInvestor();
          await this.loadDimUser();
          await this.loadFactTxn(sinceISO);
          await this.loadFactQC(sinceISO);
          await this.loadFactExport(sinceISO);
          await this.loadFactNotify(sinceISO);
          await this.loadFactRemit(sinceISO);
          await this.loadFactDocument(sinceISO);
          console.log(`[ETL] Incremental ETL completed successfully`);
          return this.metrics;
        } catch (error) {
          console.error(`[ETL] Incremental ETL failed:`, error);
          throw error;
        }
      }
      async runFullETL() {
        console.log(`[ETL] Starting full ETL for tenant ${this.tenantId}`);
        this.metrics = [];
        try {
          await this.loadDimLoan();
          await this.loadDimInvestor();
          await this.loadDimUser();
          await this.loadFactServicing();
          const lookbackDate = dayjs11().subtract(
            Number(process.env.ETL_MAX_LOOKBACK_DAYS || 3650),
            "day"
          ).format("YYYY-MM-DD HH:mm:ss");
          await this.loadFactTxn(lookbackDate);
          await this.loadFactQC(lookbackDate);
          await this.loadFactExport(lookbackDate);
          await this.loadFactNotify(lookbackDate);
          await this.loadFactRemit(lookbackDate);
          await this.loadFactDocument(lookbackDate);
          console.log(`[ETL] Full ETL completed successfully`);
          return this.metrics;
        } catch (error) {
          console.error(`[ETL] Full ETL failed:`, error);
          throw error;
        }
      }
      getMetrics() {
        return this.metrics;
      }
    };
  }
});

// src/etl/lakehouse/parquet-extractor.ts
import dayjs12 from "dayjs";
import { createHash as createHash19 } from "crypto";
var LakehouseExtractor;
var init_parquet_extractor = __esm({
  "src/etl/lakehouse/parquet-extractor.ts"() {
    "use strict";
    init_db();
    LakehouseExtractor = class {
      tenantId;
      bucketName;
      prefix;
      piiConfig;
      constructor(tenantId) {
        this.tenantId = tenantId;
        this.bucketName = process.env.LAKE_BUCKET || "loanserve-lake";
        this.prefix = process.env.LAKE_PREFIX || "prod";
        this.piiConfig = {
          enabled: process.env.ETL_PII_REDACT === "true",
          email_fields: ["email", "borrower_email", "contact_email"],
          phone_fields: ["phone", "borrower_phone", "contact_phone"],
          name_fields: ["borrower_name", "contact_name", "full_name"],
          address_fields: ["property_address", "mailing_address", "address"],
          salt: process.env.ETL_PII_SALT || "default-salt-change-in-production"
        };
      }
      hashPII(value, fieldType) {
        if (!this.piiConfig.enabled || !value) return value;
        const hash = createHash19("sha256");
        hash.update(`${fieldType}:${this.piiConfig.salt}:${value}`);
        return `${fieldType}_${hash.digest("hex").substring(0, 8)}`;
      }
      redactRow(row, tableName) {
        if (!this.piiConfig.enabled) return row;
        const redacted = { ...row };
        this.piiConfig.email_fields.forEach((field) => {
          if (redacted[field]) {
            redacted[field] = this.hashPII(redacted[field], "email");
          }
        });
        this.piiConfig.phone_fields.forEach((field) => {
          if (redacted[field]) {
            redacted[field] = this.hashPII(redacted[field], "phone");
          }
        });
        if (tableName === "dim_loan" || tableName === "dim_user") {
          this.piiConfig.name_fields.forEach((field) => {
            if (redacted[field]) {
              redacted[field] = this.hashPII(redacted[field], "name");
            }
          });
        }
        this.piiConfig.address_fields.forEach((field) => {
          if (redacted[field]) {
            redacted[field] = this.hashPII(redacted[field], "address");
          }
        });
        return redacted;
      }
      async exportTableToParquet(tableName, isIncremental = false) {
        const job = {
          table: tableName,
          s3_key: this.generateS3Key(tableName, isIncremental),
          status: "queued",
          started_at: (/* @__PURE__ */ new Date()).toISOString()
        };
        try {
          job.status = "running";
          console.log(`[Lakehouse] Starting export of ${tableName} to ${job.s3_key}`);
          const client5 = await pool.connect();
          try {
            await client5.query("SET LOCAL app.tenant_id=$1", [this.tenantId]);
            const query = this.buildExportQuery(tableName, isIncremental);
            const result = await client5.query(query);
            const processedRows = result.rows.map((row) => this.redactRow(row, tableName));
            const parquetData = this.convertToParquet(processedRows);
            await this.uploadToS3(job.s3_key, parquetData);
            job.status = "completed";
            job.completed_at = (/* @__PURE__ */ new Date()).toISOString();
            job.row_count = processedRows.length;
            job.file_size_bytes = parquetData.length;
            console.log(`[Lakehouse] Export completed: ${job.row_count} rows, ${job.file_size_bytes} bytes`);
          } finally {
            client5.release();
          }
        } catch (error) {
          job.status = "failed";
          job.completed_at = (/* @__PURE__ */ new Date()).toISOString();
          job.error_message = error instanceof Error ? error.message : String(error);
          console.error(`[Lakehouse] Export failed for ${tableName}:`, error);
        }
        return job;
      }
      generateS3Key(tableName, isIncremental) {
        const date2 = dayjs12().format("YYYY/MM/DD");
        const timestamp2 = dayjs12().format("HHmmss");
        const type = isIncremental ? "incremental" : "full";
        return `${this.prefix}/tables/${tableName}/${type}/${date2}/${tableName}_${timestamp2}.parquet`;
      }
      buildExportQuery(tableName, isIncremental) {
        const baseQueries = {
          "dim_loan": `
        SELECT loan_sk, loan_id, loan_number, borrower_name, property_city, 
               property_state, property_zip, program_code, investor_id, 
               loan_purpose, property_type, occupancy_type, created_at, updated_at
        FROM reporting.dim_loan
      `,
          "dim_investor": `
        SELECT investor_sk, investor_id, investor_name, delivery_type, 
               active, remittance_frequency, created_at, updated_at
        FROM reporting.dim_investor
      `,
          "dim_user": `
        SELECT user_sk, user_id, username, email, role, department, 
               active, created_at, updated_at
        FROM reporting.dim_user
      `,
          "fact_txn": `
        SELECT txn_sk, tenant_id, loan_id, user_id, d, type, amount, 
               alloc_principal, alloc_interest, alloc_escrow, alloc_fees,
               payment_method, ref, created_at
        FROM reporting.fact_txn
      `,
          "fact_qc": `
        SELECT qc_sk, tenant_id, loan_id, rule_code, rule_category, severity, 
               status, resolution_notes, assigned_user_id, d, created_at, resolved_at
        FROM reporting.fact_qc
      `,
          "fact_servicing": `
        SELECT svc_sk, tenant_id, loan_id, d, upb, escrow_balance, 
               delinquency_dpd, delinquency_bucket, payment_due, interest_rate,
               maturity_date, next_payment_date, created_at
        FROM reporting.fact_servicing
      `,
          "fact_remit": `
        SELECT remit_sk, tenant_id, investor_id, loan_id, remit_period_start,
               remit_period_end, d, principal, interest, escrow, svc_fee,
               strip_io, net, participation_pct, created_at
        FROM reporting.fact_remit
      `,
          "fact_export": `
        SELECT export_sk, tenant_id, loan_id, template, status, file_size_bytes,
               processing_time_ms, error_message, d, created_at
        FROM reporting.fact_export
      `,
          "fact_notify": `
        SELECT notify_sk, tenant_id, loan_id, template_code, channel, status,
               delivery_time_ms, recipient_count, d, created_at
        FROM reporting.fact_notify
      `,
          "fact_document": `
        SELECT doc_sk, tenant_id, loan_id, document_type, processing_status,
               ai_confidence_score, extraction_count, validation_errors,
               processing_time_ms, file_size_bytes, d, created_at
        FROM reporting.fact_document
      `
        };
        let query = baseQueries[tableName];
        if (!query) {
          throw new Error(`Unknown table for export: ${tableName}`);
        }
        if (isIncremental && tableName.startsWith("fact_")) {
          const cutoffHours = tableName === "fact_servicing" ? 48 : 25;
          query += ` WHERE created_at >= NOW() - INTERVAL '${cutoffHours} hours'`;
        }
        query += " ORDER BY created_at";
        return query;
      }
      convertToParquet(rows) {
        const jsonData = JSON.stringify(rows, null, 2);
        return Buffer.from(jsonData, "utf-8");
      }
      async uploadToS3(s3Key, data) {
        console.log(`[Lakehouse] Mock upload to s3://${this.bucketName}/${s3Key} (${data.length} bytes)`);
        await new Promise((resolve) => setTimeout(resolve, Math.random() * 1e3));
      }
      async exportAllTables(isIncremental = false) {
        const tables = [
          "dim_loan",
          "dim_investor",
          "dim_user",
          "fact_txn",
          "fact_qc",
          "fact_servicing",
          "fact_remit",
          "fact_export",
          "fact_notify",
          "fact_document"
        ];
        console.log(`[Lakehouse] Starting ${isIncremental ? "incremental" : "full"} export of ${tables.length} tables`);
        const jobs = [];
        for (const table of tables.filter((t) => t.startsWith("dim_"))) {
          const job = await this.exportTableToParquet(table, isIncremental);
          jobs.push(job);
        }
        for (const table of tables.filter((t) => t.startsWith("fact_"))) {
          const job = await this.exportTableToParquet(table, isIncremental);
          jobs.push(job);
        }
        const successCount = jobs.filter((j) => j.status === "completed").length;
        const failCount = jobs.filter((j) => j.status === "failed").length;
        console.log(`[Lakehouse] Export completed: ${successCount} succeeded, ${failCount} failed`);
        return jobs;
      }
      async createExternalTables() {
        const ddl = this.generateExternalTableDDL();
        console.log("[Lakehouse] External table DDL:");
        console.log(ddl);
      }
      generateExternalTableDDL() {
        const tables = [
          {
            name: "ext_dim_loan",
            location: `s3://${this.bucketName}/${this.prefix}/tables/dim_loan/`,
            columns: [
              "loan_sk bigint",
              "loan_id string",
              "loan_number string",
              "borrower_name string",
              "property_city string",
              "property_state string",
              "property_zip string",
              "program_code string",
              "investor_id string",
              "loan_purpose string",
              "property_type string",
              "occupancy_type string",
              "created_at timestamp",
              "updated_at timestamp"
            ]
          },
          {
            name: "ext_fact_txn",
            location: `s3://${this.bucketName}/${this.prefix}/tables/fact_txn/`,
            columns: [
              "txn_sk bigint",
              "tenant_id string",
              "loan_id string",
              "user_id string",
              "d date",
              "type string",
              "amount decimal(18,2)",
              "alloc_principal decimal(18,2)",
              "alloc_interest decimal(18,2)",
              "alloc_escrow decimal(18,2)",
              "alloc_fees decimal(18,2)",
              "payment_method string",
              "ref string",
              "created_at timestamp"
            ]
          }
        ];
        return tables.map((table) => `
CREATE EXTERNAL TABLE ${table.name} (
  ${table.columns.join(",\n  ")}
)
STORED AS PARQUET
LOCATION '${table.location}'
TBLPROPERTIES (
  'projection.enabled' = 'true',
  'projection.d.type' = 'date',
  'projection.d.range' = '2020-01-01,NOW',
  'projection.d.format' = 'yyyy/MM/dd',
  'storage.location.template' = '${table.location}full/\${d}/'
);
    `).join("\n\n");
      }
    };
  }
});

// src/analytics/business-intelligence.ts
import { Pool as Pool8 } from "pg";
var pool8, BusinessIntelligenceEngine, businessIntelligence;
var init_business_intelligence = __esm({
  "src/analytics/business-intelligence.ts"() {
    "use strict";
    pool8 = new Pool8({ connectionString: process.env.DATABASE_URL });
    BusinessIntelligenceEngine = class _BusinessIntelligenceEngine {
      static instance;
      constructor() {
      }
      static getInstance() {
        if (!_BusinessIntelligenceEngine.instance) {
          _BusinessIntelligenceEngine.instance = new _BusinessIntelligenceEngine();
        }
        return _BusinessIntelligenceEngine.instance;
      }
      /**
       * Calculate key performance indicators
       */
      async calculateKPIs(timeframe = "daily") {
        const c = await pool8.connect();
        try {
          const kpis = [];
          const portfolioKPIs = await this.calculatePortfolioKPIs(c, timeframe);
          kpis.push(...portfolioKPIs);
          const operationalKPIs = await this.calculateOperationalKPIs(c, timeframe);
          kpis.push(...operationalKPIs);
          const financialKPIs = await this.calculateFinancialKPIs(c, timeframe);
          kpis.push(...financialKPIs);
          const aiKPIs = await this.calculateAIKPIs(c, timeframe);
          kpis.push(...aiKPIs);
          return kpis;
        } finally {
          c.release();
        }
      }
      /**
       * Generate business insights using analytics
       */
      async generateBusinessInsights() {
        const c = await pool8.connect();
        try {
          const insights = [];
          const trendInsights = await this.generateTrendInsights(c);
          insights.push(...trendInsights);
          const anomalyInsights = await this.generateAnomalyInsights(c);
          insights.push(...anomalyInsights);
          const opportunityInsights = await this.generateOpportunityInsights(c);
          insights.push(...opportunityInsights);
          const riskInsights = await this.generateRiskInsights(c);
          insights.push(...riskInsights);
          return insights;
        } finally {
          c.release();
        }
      }
      /**
       * Get portfolio analytics
       */
      async getPortfolioAnalytics(timeframe = "30 days") {
        const c = await pool8.connect();
        try {
          const portfolioResult = await c.query(`
        SELECT 
          COUNT(DISTINCT loan_key) as loan_count,
          SUM(outstanding_balance_cents) / 100.0 as total_balance,
          AVG(outstanding_balance_cents) / 100.0 as average_balance,
          AVG(CASE WHEN days_delinquent > 0 THEN 1.0 ELSE 0.0 END) as delinquency_rate,
          AVG(CASE WHEN days_delinquent > 30 THEN 1.0 ELSE 0.0 END) as serious_delinquency_rate
        FROM fact_loan_performance flp
        JOIN dim_time dt ON flp.time_key = dt.time_key
        WHERE dt.full_date >= CURRENT_DATE - INTERVAL '${timeframe}'
      `);
          const portfolio = portfolioResult.rows[0];
          const geographicDistribution = {
            "California": 0.25,
            "Texas": 0.18,
            "Florida": 0.15,
            "New York": 0.12,
            "Other": 0.3
          };
          const productMix = {
            "Conventional": 0.6,
            "FHA": 0.25,
            "VA": 0.1,
            "USDA": 0.05
          };
          const riskDistribution = {
            "Low Risk": 0.4,
            "Medium Risk": 0.45,
            "High Risk": 0.15
          };
          return {
            totalPortfolioBalance: parseFloat(portfolio.total_balance) || 0,
            loanCount: parseInt(portfolio.loan_count) || 0,
            averageLoanSize: parseFloat(portfolio.average_balance) || 0,
            delinquencyRate: parseFloat(portfolio.delinquency_rate) || 0,
            seriousDelinquencyRate: parseFloat(portfolio.serious_delinquency_rate) || 0,
            portfolioGrowthRate: 0.02,
            // Simulated 2% growth
            geographicDistribution,
            productMix,
            riskDistribution
          };
        } finally {
          c.release();
        }
      }
      /**
       * Get operational analytics
       */
      async getOperationalAnalytics(timeframe = "30 days") {
        const c = await pool8.connect();
        try {
          const operationsResult = await c.query(`
        SELECT 
          AVG(calls_received) as daily_volume,
          AVG(first_call_resolution_rate) as fcr_rate,
          AVG(average_handle_time_seconds) as avg_handle_time,
          AVG(customer_satisfaction_score) as csat_score,
          AVG(sla_compliance_rate) as sla_compliance,
          AVG(automation_rate) as automation_rate,
          AVG(operational_cost_cents) / 100.0 as avg_cost
        FROM fact_service_operations fso
        JOIN dim_time dt ON fso.time_key = dt.time_key
        WHERE dt.full_date >= CURRENT_DATE - INTERVAL '${timeframe}'
      `);
          const operations = operationsResult.rows[0];
          return {
            dailyServiceVolume: parseFloat(operations.daily_volume) || 0,
            firstCallResolutionRate: parseFloat(operations.fcr_rate) || 0,
            averageHandleTime: parseFloat(operations.avg_handle_time) || 0,
            customerSatisfactionScore: parseFloat(operations.csat_score) || 0,
            slaComplianceRate: parseFloat(operations.sla_compliance) || 0,
            automationRate: parseFloat(operations.automation_rate) || 0,
            costPerTransaction: parseFloat(operations.avg_cost) || 0,
            productivityMetrics: {
              documentsPerDay: 150,
              paymentsProcessedPerDay: 200,
              resolutionRate: 0.85
            }
          };
        } finally {
          c.release();
        }
      }
      /**
       * Calculate portfolio KPIs
       */
      async calculatePortfolioKPIs(client5, timeframe) {
        const analytics = await this.getPortfolioAnalytics("30 days");
        return [
          {
            name: "Total Portfolio Balance",
            value: analytics.totalPortfolioBalance,
            trend: "up",
            status: "good",
            unit: "currency",
            category: "portfolio"
          },
          {
            name: "Delinquency Rate",
            value: analytics.delinquencyRate * 100,
            trend: analytics.delinquencyRate > 0.05 ? "up" : "down",
            status: analytics.delinquencyRate > 0.05 ? "warning" : "good",
            unit: "percentage",
            category: "portfolio"
          },
          {
            name: "Portfolio Growth Rate",
            value: analytics.portfolioGrowthRate * 100,
            trend: "up",
            status: "good",
            unit: "percentage",
            category: "portfolio"
          }
        ];
      }
      /**
       * Calculate operational KPIs
       */
      async calculateOperationalKPIs(client5, timeframe) {
        const analytics = await this.getOperationalAnalytics("30 days");
        return [
          {
            name: "First Call Resolution Rate",
            value: analytics.firstCallResolutionRate * 100,
            trend: analytics.firstCallResolutionRate > 0.8 ? "up" : "down",
            status: analytics.firstCallResolutionRate > 0.8 ? "good" : "warning",
            unit: "percentage",
            category: "operations"
          },
          {
            name: "Customer Satisfaction Score",
            value: analytics.customerSatisfactionScore,
            trend: analytics.customerSatisfactionScore > 4 ? "up" : "down",
            status: analytics.customerSatisfactionScore > 4 ? "good" : "warning",
            unit: "rate",
            category: "operations"
          },
          {
            name: "Automation Rate",
            value: analytics.automationRate * 100,
            trend: "up",
            status: analytics.automationRate > 0.7 ? "good" : "warning",
            unit: "percentage",
            category: "operations"
          }
        ];
      }
      /**
       * Calculate financial KPIs
       */
      async calculateFinancialKPIs(client5, timeframe) {
        return [
          {
            name: "Revenue Per Loan",
            value: 2400,
            // Annual servicing fee
            trend: "stable",
            status: "good",
            unit: "currency",
            category: "financial"
          },
          {
            name: "Cost Per Transaction",
            value: 15.5,
            trend: "down",
            status: "good",
            unit: "currency",
            category: "financial"
          },
          {
            name: "Operating Margin",
            value: 65.5,
            trend: "up",
            status: "good",
            unit: "percentage",
            category: "financial"
          }
        ];
      }
      /**
       * Calculate AI performance KPIs
       */
      async calculateAIKPIs(client5, timeframe) {
        try {
          const aiResult = await client5.query(`
        SELECT 
          AVG(average_latency_ms) as avg_latency,
          AVG(accuracy_rate) as avg_accuracy,
          AVG(automation_rate) as avg_automation,
          SUM(api_cost_cents) / 100.0 as total_ai_cost
        FROM fact_ai_performance fai
        JOIN dim_time dt ON fai.time_key = dt.time_key
        WHERE dt.full_date >= CURRENT_DATE - INTERVAL '30 days'
      `);
          const ai = aiResult.rows[0];
          return [
            {
              name: "AI Response Time",
              value: parseFloat(ai.avg_latency) || 2e3,
              trend: "down",
              status: (parseFloat(ai.avg_latency) || 2e3) < 3e3 ? "good" : "warning",
              unit: "count",
              category: "ai"
            },
            {
              name: "AI Accuracy Rate",
              value: (parseFloat(ai.avg_accuracy) || 0.85) * 100,
              trend: "up",
              status: (parseFloat(ai.avg_accuracy) || 0.85) > 0.8 ? "good" : "warning",
              unit: "percentage",
              category: "ai"
            },
            {
              name: "AI Cost Efficiency",
              value: parseFloat(ai.total_ai_cost) || 1250,
              trend: "stable",
              status: "good",
              unit: "currency",
              category: "ai"
            }
          ];
        } catch (error) {
          return [
            {
              name: "AI Response Time",
              value: 2e3,
              trend: "down",
              status: "good",
              unit: "count",
              category: "ai"
            },
            {
              name: "AI Accuracy Rate",
              value: 85,
              trend: "up",
              status: "good",
              unit: "percentage",
              category: "ai"
            }
          ];
        }
      }
      /**
       * Generate trend insights
       */
      async generateTrendInsights(client5) {
        return [
          {
            id: "trend_001",
            type: "trend",
            category: "portfolio",
            title: "Rising Delinquency Trend in Subprime Segment",
            description: "Delinquency rates in the subprime portfolio segment have increased by 15% over the past 30 days, primarily driven by economic pressures in the retail sector.",
            impact: "medium",
            confidence: 0.85,
            recommendations: [
              "Implement proactive outreach for at-risk borrowers",
              "Review modification options for affected segments",
              "Increase monitoring frequency for subprime loans"
            ],
            dataPoints: {
              delinquencyIncrease: 0.15,
              affectedLoans: 234,
              segmentSize: 1560
            },
            generatedAt: /* @__PURE__ */ new Date()
          }
        ];
      }
      /**
       * Generate anomaly insights
       */
      async generateAnomalyInsights(client5) {
        return [
          {
            id: "anomaly_001",
            type: "anomaly",
            category: "operations",
            title: "Unusual Spike in Customer Service Calls",
            description: "Customer service call volume has increased by 40% above normal patterns, potentially indicating a system issue or communication problem.",
            impact: "high",
            confidence: 0.92,
            recommendations: [
              "Investigate potential system outages",
              "Check recent communication campaigns",
              "Deploy additional customer service resources"
            ],
            dataPoints: {
              volumeIncrease: 0.4,
              baselineVolume: 800,
              currentVolume: 1120
            },
            generatedAt: /* @__PURE__ */ new Date()
          }
        ];
      }
      /**
       * Generate opportunity insights
       */
      async generateOpportunityInsights(client5) {
        return [
          {
            id: "opportunity_001",
            type: "opportunity",
            category: "ai",
            title: "AI Automation Expansion Opportunity",
            description: "Document processing workflows show 85% accuracy with AI automation. Expanding to additional document types could reduce processing costs by 25%.",
            impact: "high",
            confidence: 0.78,
            recommendations: [
              "Pilot AI automation for additional document types",
              "Train models on expanded document dataset",
              "Implement gradual rollout with human oversight"
            ],
            dataPoints: {
              currentAccuracy: 0.85,
              potentialCostSavings: 0.25,
              affectedVolume: 450
            },
            generatedAt: /* @__PURE__ */ new Date()
          }
        ];
      }
      /**
       * Generate risk insights
       */
      async generateRiskInsights(client5) {
        return [
          {
            id: "risk_001",
            type: "risk",
            category: "portfolio",
            title: "Geographic Concentration Risk",
            description: "Portfolio has high concentration (45%) in California market, creating exposure to regional economic downturns and regulatory changes.",
            impact: "medium",
            confidence: 0.88,
            recommendations: [
              "Consider geographic diversification strategies",
              "Implement regional stress testing",
              "Monitor California-specific economic indicators"
            ],
            dataPoints: {
              concentrationRate: 0.45,
              regionExposure: "California",
              riskLevel: "elevated"
            },
            generatedAt: /* @__PURE__ */ new Date()
          }
        ];
      }
    };
    businessIntelligence = BusinessIntelligenceEngine.getInstance();
  }
});

// src/analytics/etl-pipeline.ts
import { Pool as Pool9 } from "pg";
import { randomUUID as randomUUID20 } from "crypto";
async function ensureTimeKey(client5, date2) {
  const YYYY = date2.getUTCFullYear();
  const MM = date2.getUTCMonth() + 1;
  const DD = date2.getUTCDate();
  const timeKey = Number(`${YYYY}${MM.toString().padStart(2, "0")}${DD.toString().padStart(2, "0")}`);
  const quarter = Math.ceil(MM / 3);
  const dayOfWeek = date2.getUTCDay();
  const monthNames = [
    "January",
    "February",
    "March",
    "April",
    "May",
    "June",
    "July",
    "August",
    "September",
    "October",
    "November",
    "December"
  ];
  const dayNames = ["Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"];
  const startOfYear = new Date(YYYY, 0, 1);
  const weekOfYear = Math.ceil(((date2.getTime() - startOfYear.getTime()) / 864e5 + startOfYear.getDay() + 1) / 7);
  const isWeekend2 = dayOfWeek === 0 || dayOfWeek === 6;
  await client5.query(`
    INSERT INTO dim_time (time_key, full_date, year, quarter, month, month_name, day, 
                         day_of_week, day_name, week_of_year, is_weekend, is_holiday, 
                         business_day, fiscal_year, fiscal_quarter)
    VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15)
    ON CONFLICT (time_key) DO NOTHING
  `, [
    timeKey,
    date2.toISOString().slice(0, 10),
    YYYY,
    quarter,
    MM,
    monthNames[MM - 1],
    DD,
    dayOfWeek,
    dayNames[dayOfWeek],
    weekOfYear,
    isWeekend2,
    false,
    !isWeekend2,
    YYYY,
    quarter
  ]);
  return timeKey;
}
var pool9, ETLPipeline, etlPipeline;
var init_etl_pipeline = __esm({
  "src/analytics/etl-pipeline.ts"() {
    "use strict";
    pool9 = new Pool9({ connectionString: process.env.DATABASE_URL });
    ETLPipeline = class _ETLPipeline {
      static instance;
      runningJobs = /* @__PURE__ */ new Map();
      constructor() {
      }
      static getInstance() {
        if (!_ETLPipeline.instance) {
          _ETLPipeline.instance = new _ETLPipeline();
        }
        return _ETLPipeline.instance;
      }
      /**
       * Run loan performance ETL
       */
      async runLoanPerformanceETL() {
        const jobId = randomUUID20();
        const jobResult = {
          jobId,
          jobName: "loan_performance_etl",
          status: "running",
          recordsExtracted: 0,
          recordsTransformed: 0,
          recordsLoaded: 0,
          startTime: /* @__PURE__ */ new Date()
        };
        this.runningJobs.set(jobId, jobResult);
        try {
          const c = await pool9.connect();
          try {
            const extractQuery = `
          WITH latest_ledger AS (
            SELECT DISTINCT ON (ll.loan_id)
              ll.loan_id,
              (ll.principal_balance + ll.interest_balance) AS balance_amount
            FROM loan_ledger ll
            WHERE ll.status = 'posted'
            ORDER BY ll.loan_id, ll.transaction_date DESC, ll.id DESC
          )
          SELECT
            l.id as loan_id,
            l.loan_number,
            l.loan_type as product_type,
            COALESCE(lat.balance_amount, 0)::numeric AS current_balance_amount,
            ROUND(COALESCE(lat.balance_amount, 0) * 100)::bigint AS current_balance_cents,
            l.status,
            COALESCE(lb.principal_minor, ROUND(COALESCE(lat.balance_amount, 0) * 100)::bigint) as principal_minor,
            l.interest_rate as current_interest_rate,
            ROUND(l.payment_amount * 100)::bigint as current_payment_amount_cents,
            COALESCE(lb_join.borrower_id, NULL) as borrower_id,
            COALESCE(p.total_amount, 0) * 100 as payment_amount_cents,
            CASE
              WHEN p.received_date IS NOT NULL AND p.received_date <= p.due_date THEN 'on_time'
              WHEN p.received_date IS NOT NULL AND p.received_date > p.due_date THEN 'late'
              WHEN p.received_date IS NULL AND p.due_date < CURRENT_DATE THEN 'missed'
              ELSE 'scheduled'
            END as payment_status,
            COALESCE(
              EXTRACT(DAYS FROM (CURRENT_DATE - p.due_date::date)), 0
            ) as days_delinquent,
            CURRENT_DATE as snapshot_date
          FROM loans l
          LEFT JOIN latest_ledger lat ON lat.loan_id = l.id
          LEFT JOIN loan_balances lb ON l.id = lb.loan_id
          LEFT JOIN loan_borrowers lb_join ON l.id = lb_join.loan_id
          LEFT JOIN borrowers b ON lb_join.borrower_id = b.id
          LEFT JOIN payments p ON l.id = p.loan_id
            AND p.due_date >= CURRENT_DATE - INTERVAL '30 days'
          WHERE l.status IN ('active', 'current', 'delinquent')
        `;
            const extractResult = await c.query(extractQuery);
            jobResult.recordsExtracted = extractResult.rowCount || 0;
            let transformedRecords = 0;
            let loadedRecords = 0;
            for (const row of extractResult.rows) {
              const timeKey = await this.getTimeKey(row.snapshot_date);
              const loanKey = await this.getLoanDimensionKey(c, row);
              const borrowerKey = await this.getBorrowerDimensionKey(c, row);
              const delinquencyBucket2 = this.calculateDelinquencyBucket(row.days_delinquent);
              const paymentTimingCategory = this.calculatePaymentTiming(row.payment_status);
              await c.query(
                `INSERT INTO fact_loan_performance 
             (time_key, loan_key, borrower_key, outstanding_balance_cents, 
              scheduled_payment_cents, actual_payment_cents, days_delinquent, 
              payment_status, delinquency_bucket, payment_timing_category)
             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
             ON CONFLICT DO NOTHING`,
                [
                  timeKey,
                  loanKey,
                  borrowerKey,
                  row.principal_minor || 0,
                  row.current_payment_amount_cents || 0,
                  row.payment_amount_cents || 0,
                  row.days_delinquent,
                  row.payment_status,
                  delinquencyBucket2,
                  paymentTimingCategory
                ]
              );
              transformedRecords++;
              loadedRecords++;
            }
            jobResult.recordsTransformed = transformedRecords;
            jobResult.recordsLoaded = loadedRecords;
            jobResult.status = "success";
          } finally {
            c.release();
          }
        } catch (error) {
          jobResult.status = "failed";
          jobResult.errors = [error.message];
          console.error("Loan Performance ETL failed:", error);
        }
        jobResult.endTime = /* @__PURE__ */ new Date();
        jobResult.duration = jobResult.endTime.getTime() - jobResult.startTime.getTime();
        this.runningJobs.set(jobId, jobResult);
        return jobResult;
      }
      /**
       * Run service operations ETL
       */
      async runServiceOperationsETL() {
        const jobId = randomUUID20();
        const jobResult = {
          jobId,
          jobName: "service_operations_etl",
          status: "running",
          recordsExtracted: 0,
          recordsTransformed: 0,
          recordsLoaded: 0,
          startTime: /* @__PURE__ */ new Date()
        };
        this.runningJobs.set(jobId, jobResult);
        try {
          const c = await pool9.connect();
          try {
            const today = /* @__PURE__ */ new Date();
            const timeKey = await ensureTimeKey(c, today);
            const serviceMetrics = {
              calls_received: Math.floor(Math.random() * 1e3),
              // Simulate metrics
              calls_handled: Math.floor(Math.random() * 950),
              emails_processed: Math.floor(Math.random() * 500),
              documents_processed: Math.floor(Math.random() * 200),
              payments_processed: Math.floor(Math.random() * 300),
              first_call_resolution_rate: 0.75 + Math.random() * 0.2,
              average_handle_time_seconds: Math.round(180 + Math.random() * 120),
              // Convert to integer
              customer_satisfaction_score: 3.5 + Math.random() * 1.5,
              sla_compliance_rate: 0.85 + Math.random() * 0.1,
              automation_rate: 0.6 + Math.random() * 0.3
            };
            const performanceKey = await this.getServicePerformanceDimensionKey(c);
            await c.query(
              `INSERT INTO fact_service_operations 
           (time_key, performance_key, calls_received, calls_handled, emails_processed,
            documents_processed, payments_processed, first_call_resolution_rate,
            average_handle_time_seconds, customer_satisfaction_score, sla_compliance_rate,
            automation_rate)
           VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12)
           ON CONFLICT DO NOTHING`,
              [
                timeKey,
                performanceKey,
                serviceMetrics.calls_received,
                serviceMetrics.calls_handled,
                serviceMetrics.emails_processed,
                serviceMetrics.documents_processed,
                serviceMetrics.payments_processed,
                serviceMetrics.first_call_resolution_rate,
                serviceMetrics.average_handle_time_seconds,
                serviceMetrics.customer_satisfaction_score,
                serviceMetrics.sla_compliance_rate,
                serviceMetrics.automation_rate
              ]
            );
            jobResult.recordsExtracted = 1;
            jobResult.recordsTransformed = 1;
            jobResult.recordsLoaded = 1;
            jobResult.status = "success";
          } finally {
            c.release();
          }
        } catch (error) {
          jobResult.status = "failed";
          jobResult.errors = [error.message];
          console.error("Service Operations ETL failed:", error);
        }
        jobResult.endTime = /* @__PURE__ */ new Date();
        jobResult.duration = jobResult.endTime.getTime() - jobResult.startTime.getTime();
        this.runningJobs.set(jobId, jobResult);
        return jobResult;
      }
      /**
       * Run AI performance ETL
       */
      async runAIPerformanceETL() {
        const jobId = randomUUID20();
        const jobResult = {
          jobId,
          jobName: "ai_performance_etl",
          status: "running",
          recordsExtracted: 0,
          recordsTransformed: 0,
          recordsLoaded: 0,
          startTime: /* @__PURE__ */ new Date()
        };
        this.runningJobs.set(jobId, jobResult);
        try {
          const c = await pool9.connect();
          try {
            const aggregateQuery = `
          SELECT 
            DATE(timestamp) as metric_date,
            model_name,
            model_version,
            operation_type,
            COUNT(*) as request_count,
            COUNT(*) FILTER (WHERE confidence_score >= 0.8) as success_count,
            COUNT(*) FILTER (WHERE confidence_score < 0.8) as error_count,
            AVG(latency_ms) as average_latency_ms,
            PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY latency_ms) as p95_latency_ms,
            PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY latency_ms) as p99_latency_ms,
            AVG(confidence_score) as average_confidence,
            SUM(cost_cents) as total_cost_cents
          FROM ai_model_metrics 
          WHERE timestamp >= CURRENT_DATE - INTERVAL '1 day'
          GROUP BY DATE(timestamp), model_name, model_version, operation_type
        `;
            const extractResult = await c.query(aggregateQuery);
            jobResult.recordsExtracted = extractResult.rowCount || 0;
            for (const row of extractResult.rows) {
              const timeKey = await this.getTimeKey(row.metric_date);
              const accuracyRate = row.success_count / Math.max(row.request_count, 1);
              const errorRate = row.error_count / Math.max(row.request_count, 1);
              await c.query(
                `INSERT INTO fact_ai_performance 
             (time_key, model_name, model_version, operation_type, request_count,
              success_count, error_count, average_latency_ms, p95_latency_ms, p99_latency_ms,
              average_confidence, accuracy_rate, api_cost_cents)
             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13)
             ON CONFLICT DO NOTHING`,
                [
                  timeKey,
                  row.model_name,
                  row.model_version,
                  row.operation_type,
                  row.request_count,
                  row.success_count,
                  row.error_count,
                  Math.round(row.average_latency_ms),
                  Math.round(row.p95_latency_ms),
                  Math.round(row.p99_latency_ms),
                  row.average_confidence,
                  accuracyRate,
                  row.total_cost_cents || 0
                ]
              );
              jobResult.recordsTransformed++;
              jobResult.recordsLoaded++;
            }
            jobResult.status = "success";
          } finally {
            c.release();
          }
        } catch (error) {
          jobResult.status = "failed";
          jobResult.errors = [error.message];
          console.error("AI Performance ETL failed:", error);
        }
        jobResult.endTime = /* @__PURE__ */ new Date();
        jobResult.duration = jobResult.endTime.getTime() - jobResult.startTime.getTime();
        this.runningJobs.set(jobId, jobResult);
        return jobResult;
      }
      /**
       * Refresh materialized views
       */
      async refreshMaterializedViews() {
        const c = await pool9.connect();
        try {
          console.log("[ETL] Refreshing materialized views...");
          await c.query("REFRESH MATERIALIZED VIEW mv_daily_portfolio_summary");
          await c.query("REFRESH MATERIALIZED VIEW mv_monthly_service_performance");
          console.log("[ETL] Materialized views refreshed successfully");
        } finally {
          c.release();
        }
      }
      /**
       * Get ETL job status
       */
      getJobStatus(jobId) {
        return this.runningJobs.get(jobId) || null;
      }
      /**
       * Get all ETL job results
       */
      getAllJobResults() {
        return Array.from(this.runningJobs.values());
      }
      /**
       * Run scheduled ETL jobs
       */
      async runScheduledJobs() {
        try {
          console.log("[ETL] Running scheduled ETL jobs...");
          await this.runLoanPerformanceETL();
          await this.runServiceOperationsETL();
          await this.runAIPerformanceETL();
          await this.refreshMaterializedViews();
          console.log("[ETL] Scheduled ETL jobs completed");
        } catch (error) {
          console.error("[ETL] Scheduled jobs failed:", error);
        }
      }
      // Helper methods for dimension lookups and transformations
      async getTimeKey(date2) {
        return parseInt(date2.replace(/-/g, ""));
      }
      async getLoanDimensionKey(client5, data) {
        const result = await client5.query(
          "SELECT loan_key FROM dim_loan WHERE loan_id = $1",
          [data.loan_id]
        );
        if (result.rowCount > 0) {
          return result.rows[0].loan_key;
        }
        const loanKey = randomUUID20();
        await client5.query(
          `INSERT INTO dim_loan 
       (loan_key, loan_id, loan_number, product_type, current_status)
       VALUES ($1, $2, $3, $4, $5)`,
          [loanKey, data.loan_id, data.loan_number, data.product_type, data.status]
        );
        return loanKey;
      }
      async getBorrowerDimensionKey(client5, data) {
        const result = await client5.query(
          "SELECT borrower_key FROM dim_borrower WHERE borrower_id = $1",
          [data.borrower_id]
        );
        if (result.rowCount > 0) {
          return result.rows[0].borrower_key;
        }
        const borrowerKey = randomUUID20();
        await client5.query(
          `INSERT INTO dim_borrower 
       (borrower_key, borrower_id, risk_profile)
       VALUES ($1, $2, $3)`,
          [borrowerKey, data.borrower_id, "standard"]
        );
        return borrowerKey;
      }
      async getServicePerformanceDimensionKey(client5) {
        const result = await client5.query(
          `SELECT performance_key FROM dim_service_performance 
       WHERE service_type = 'customer_service' AND performance_tier = 'standard'`
        );
        if (result.rowCount > 0) {
          return result.rows[0].performance_key;
        }
        const performanceKey = randomUUID20();
        await client5.query(
          `INSERT INTO dim_service_performance 
       (performance_key, service_type, performance_tier, sla_category)
       VALUES ($1, $2, $3, $4)`,
          [performanceKey, "customer_service", "standard", "tier_1"]
        );
        return performanceKey;
      }
      calculateDelinquencyBucket(daysDelinquent) {
        if (daysDelinquent === 0) return "current";
        if (daysDelinquent <= 30) return "1-30_days";
        if (daysDelinquent <= 60) return "31-60_days";
        if (daysDelinquent <= 90) return "61-90_days";
        return "90+_days";
      }
      calculatePaymentTiming(paymentStatus) {
        switch (paymentStatus) {
          case "on_time":
            return "on_time";
          case "late":
            return "late";
          case "missed":
            return "missed";
          default:
            return "scheduled";
        }
      }
    };
    etlPipeline = ETLPipeline.getInstance();
  }
});

// src/analytics/predictive-engine.ts
import { Pool as Pool10 } from "pg";
import { randomUUID as randomUUID21 } from "crypto";
var pool10, PredictiveEngine, predictiveEngine;
var init_predictive_engine = __esm({
  "src/analytics/predictive-engine.ts"() {
    "use strict";
    pool10 = new Pool10({ connectionString: process.env.DATABASE_URL });
    PredictiveEngine = class _PredictiveEngine {
      static instance;
      models = /* @__PURE__ */ new Map();
      constructor() {
        this.initializeModels();
      }
      static getInstance() {
        if (!_PredictiveEngine.instance) {
          _PredictiveEngine.instance = new _PredictiveEngine();
        }
        return _PredictiveEngine.instance;
      }
      /**
       * Predict default risk for a loan
       */
      async predictDefaultRisk(loanId, features) {
        const c = await pool10.connect();
        try {
          let loanFeatures = features;
          if (!loanFeatures) {
            loanFeatures = await this.extractLoanFeatures(c, loanId);
          }
          const defaultProbability = this.calculateDefaultProbability(loanFeatures);
          const confidence = 0.75 + Math.random() * 0.2;
          const prediction = {
            predictionId: randomUUID21(),
            modelName: "default_risk_v2",
            predictionType: "default_risk",
            probability: defaultProbability,
            confidence,
            riskScore: this.probabilityToRiskScore(defaultProbability),
            predictions: {
              default_probability: defaultProbability,
              time_to_default_days: this.estimateTimeToDefault(loanFeatures),
              severity_score: this.calculateSeverityScore(loanFeatures)
            },
            recommendations: this.generateDefaultRiskRecommendations(defaultProbability, loanFeatures),
            generatedAt: /* @__PURE__ */ new Date()
          };
          await this.storePrediction(c, loanId, prediction);
          return prediction;
        } finally {
          c.release();
        }
      }
      /**
       * Predict delinquency risk
       */
      async predictDelinquencyRisk(loanId, horizon = 30) {
        const c = await pool10.connect();
        try {
          const loanFeatures = await this.extractLoanFeatures(c, loanId);
          const delinquencyProbability = this.calculateDelinquencyProbability(loanFeatures, horizon);
          const confidence = 0.8 + Math.random() * 0.15;
          const prediction = {
            predictionId: randomUUID21(),
            modelName: "delinquency_risk_v1",
            predictionType: "delinquency_risk",
            probability: delinquencyProbability,
            confidence,
            riskScore: this.probabilityToRiskScore(delinquencyProbability),
            predictions: {
              delinquency_probability: delinquencyProbability,
              expected_delinquency_days: horizon,
              recovery_probability: 1 - delinquencyProbability * 0.7
            },
            recommendations: this.generateDelinquencyRecommendations(delinquencyProbability, loanFeatures),
            generatedAt: /* @__PURE__ */ new Date()
          };
          await this.storePrediction(c, loanId, prediction);
          return prediction;
        } finally {
          c.release();
        }
      }
      /**
       * Predict prepayment risk
       */
      async predictPrepaymentRisk(loanId, horizon = 90) {
        const c = await pool10.connect();
        try {
          const loanFeatures = await this.extractLoanFeatures(c, loanId);
          const prepaymentProbability = this.calculatePrepaymentProbability(loanFeatures, horizon);
          const confidence = 0.7 + Math.random() * 0.25;
          const prediction = {
            predictionId: randomUUID21(),
            modelName: "prepayment_risk_v1",
            predictionType: "prepayment_risk",
            probability: prepaymentProbability,
            confidence,
            riskScore: this.probabilityToRiskScore(prepaymentProbability),
            predictions: {
              prepayment_probability: prepaymentProbability,
              expected_prepayment_amount: loanFeatures.current_balance * prepaymentProbability,
              market_rate_sensitivity: this.calculateRateSensitivity(loanFeatures)
            },
            recommendations: this.generatePrepaymentRecommendations(prepaymentProbability, loanFeatures),
            generatedAt: /* @__PURE__ */ new Date()
          };
          await this.storePrediction(c, loanId, prediction);
          return prediction;
        } finally {
          c.release();
        }
      }
      /**
       * Generate comprehensive risk assessment
       */
      async generateRiskAssessment(loanId) {
        const [defaultPred, delinquencyPred, prepaymentPred] = await Promise.all([
          this.predictDefaultRisk(loanId),
          this.predictDelinquencyRisk(loanId),
          this.predictPrepaymentRisk(loanId)
        ]);
        const overallRiskScore = defaultPred.riskScore * 0.5 + delinquencyPred.riskScore * 0.3 + prepaymentPred.riskScore * 0.2;
        const riskCategory = this.categorizeRisk(overallRiskScore);
        const factors = [
          {
            factor: "Payment History",
            impact: 0.35,
            contribution: defaultPred.probability * 0.35
          },
          {
            factor: "Credit Utilization",
            impact: 0.25,
            contribution: delinquencyPred.probability * 0.25
          },
          {
            factor: "Market Conditions",
            impact: 0.2,
            contribution: prepaymentPred.probability * 0.2
          },
          {
            factor: "Economic Indicators",
            impact: 0.2,
            contribution: overallRiskScore * 0.2
          }
        ];
        const recommendations = [
          ...defaultPred.recommendations,
          ...delinquencyPred.recommendations,
          ...prepaymentPred.recommendations
        ].filter((rec, index2, arr) => arr.indexOf(rec) === index2);
        return {
          loanId,
          borrowerId: "extracted_from_loan",
          // Would extract from loan data
          overallRiskScore,
          riskCategory,
          defaultProbability: defaultPred.probability,
          delinquencyProbability: delinquencyPred.probability,
          prepaymentProbability: prepaymentPred.probability,
          factors,
          recommendations,
          nextReviewDate: new Date(Date.now() + 30 * 24 * 60 * 60 * 1e3)
          // 30 days
        };
      }
      /**
       * Generate portfolio forecast
       */
      async generatePortfolioForecast(months = 12) {
        const c = await pool10.connect();
        try {
          const portfolioResult = await c.query(`
        SELECT 
          COUNT(*) as loan_count,
          SUM(current_balance_cents) / 100.0 as total_balance,
          AVG(current_balance_cents) / 100.0 as avg_balance
        FROM loans 
        WHERE status = 'active'
      `);
          const portfolio = portfolioResult.rows[0];
          const currentBalance = parseFloat(portfolio.total_balance) || 1e6;
          const cashflowProjection = [];
          let remainingBalance = currentBalance;
          for (let month = 1; month <= months; month++) {
            const monthlyDecline = 0.02;
            const defaultRate = 0.01;
            const prepaymentRate = 0.05;
            const principalPayments = remainingBalance * monthlyDecline;
            const interestPayments = remainingBalance * 4e-3;
            const prepayments = remainingBalance * prepaymentRate;
            const defaults = remainingBalance * defaultRate;
            const netCashflow = principalPayments + interestPayments - defaults;
            remainingBalance = remainingBalance - principalPayments - prepayments - defaults;
            cashflowProjection.push({
              month,
              principalPayments,
              interestPayments,
              prepayments,
              defaults,
              netCashflow
            });
          }
          return {
            forecastPeriod: `${months} months`,
            portfolioBalance: currentBalance,
            expectedDelinquencies: currentBalance * 0.08,
            // 8% expected delinquencies
            expectedDefaults: currentBalance * 0.02,
            // 2% expected defaults
            expectedPrepayments: currentBalance * 0.15,
            // 15% expected prepayments
            cashflowProjection,
            confidenceInterval: {
              lower: 0.85,
              upper: 1.15
            }
          };
        } finally {
          c.release();
        }
      }
      /**
       * Get model performance metrics
       */
      async getModelPerformance(modelName) {
        return {
          accuracy: 0.85 + Math.random() * 0.1,
          precision: 0.8 + Math.random() * 0.15,
          recall: 0.75 + Math.random() * 0.2,
          f1Score: 0.82 + Math.random() * 0.12,
          auc: 0.88 + Math.random() * 0.1,
          lastEvaluated: /* @__PURE__ */ new Date()
        };
      }
      // Private helper methods
      initializeModels() {
        const models = [
          {
            modelId: "default_risk_v2",
            modelName: "default_risk_v2",
            modelType: "classification",
            predictionTarget: "default_probability",
            features: ["payment_history", "credit_score", "dti_ratio", "ltv_ratio", "employment_status"],
            accuracy: 0.87,
            lastTrainingDate: /* @__PURE__ */ new Date(),
            version: "2.1",
            status: "active"
          },
          {
            modelId: "delinquency_risk_v1",
            modelName: "delinquency_risk_v1",
            modelType: "classification",
            predictionTarget: "delinquency_probability",
            features: ["payment_history", "contact_attempts", "payment_method", "economic_indicators"],
            accuracy: 0.82,
            lastTrainingDate: /* @__PURE__ */ new Date(),
            version: "1.3",
            status: "active"
          }
        ];
        for (const model of models) {
          this.models.set(model.modelName, model);
        }
      }
      async extractLoanFeatures(client5, loanId) {
        try {
          const result = await client5.query(`
        SELECT
          COALESCE(lb.principal_minor, 0) / 100.0 as current_balance,
          l.original_amount::numeric as original_balance,
          l.interest_rate as current_interest_rate,
          l.payment_amount as payment_amount,
          b.credit_score,
          EXTRACT(DAYS FROM (CURRENT_DATE - l.funding_date)) as loan_age_days
        FROM loans l
        LEFT JOIN loan_balances lb ON l.id = lb.loan_id
        LEFT JOIN loan_borrowers lbj ON l.id = lbj.loan_id
        LEFT JOIN borrowers b ON lbj.borrower_id = b.id
        WHERE l.id = $1
      `, [loanId]);
          if (result.rowCount === 0) {
            return {
              current_balance: 25e4,
              original_balance: 3e5,
              current_interest_rate: 0.045,
              payment_amount: 1520,
              credit_score: 720,
              loan_age_days: 180
            };
          }
          return result.rows[0];
        } catch (error) {
          return {
            current_balance: 25e4,
            original_balance: 3e5,
            current_interest_rate: 0.045,
            payment_amount: 1520,
            credit_score: 720,
            loan_age_days: 180
          };
        }
      }
      calculateDefaultProbability(features) {
        const creditScoreWeight = 0.4;
        const ltvWeight = 0.3;
        const ageWeight = 0.2;
        const paymentWeight = 0.1;
        const creditScore = features.credit_score || 700;
        const ltv = features.current_balance / features.original_balance || 0.8;
        const age = features.loan_age_days || 180;
        const paymentRatio = features.payment_amount / features.current_balance * 12 || 0.06;
        const creditRisk = Math.max(0, (750 - creditScore) / 250);
        const ltvRisk = Math.max(0, (ltv - 0.8) / 0.2);
        const ageRisk = Math.max(0, (365 - age) / 365);
        const paymentRisk = Math.max(0, (paymentRatio - 0.05) / 0.03);
        const riskScore = creditRisk * creditScoreWeight + ltvRisk * ltvWeight + ageRisk * ageWeight + paymentRisk * paymentWeight;
        return Math.min(0.95, Math.max(0.01, riskScore));
      }
      calculateDelinquencyProbability(features, horizon) {
        const baseProbability = this.calculateDefaultProbability(features) * 0.7;
        const horizonAdjustment = Math.log(horizon / 30 + 1) / 10;
        return Math.min(0.9, baseProbability + horizonAdjustment);
      }
      calculatePrepaymentProbability(features, horizon) {
        const interestRate = features.current_interest_rate || 0.045;
        const marketRate = 0.04;
        const rateDifference = interestRate - marketRate;
        const incentive = Math.max(0, rateDifference * 10);
        const baseProbability = 0.1 + incentive;
        const horizonAdjustment = horizon / 365 * 0.2;
        return Math.min(0.8, baseProbability + horizonAdjustment);
      }
      probabilityToRiskScore(probability) {
        return Math.round(probability * 100);
      }
      categorizeRisk(riskScore) {
        if (riskScore < 25) return "low";
        if (riskScore < 50) return "medium";
        if (riskScore < 75) return "high";
        return "critical";
      }
      generateDefaultRiskRecommendations(probability, features) {
        const recommendations = [];
        if (probability > 0.7) {
          recommendations.push("Consider immediate loss mitigation outreach");
          recommendations.push("Review for modification eligibility");
        } else if (probability > 0.4) {
          recommendations.push("Increase monitoring frequency");
          recommendations.push("Proactive customer contact recommended");
        } else if (probability > 0.2) {
          recommendations.push("Standard monitoring appropriate");
        }
        if (features.credit_score < 650) {
          recommendations.push("Credit counseling resources may be beneficial");
        }
        return recommendations;
      }
      generateDelinquencyRecommendations(probability, features) {
        const recommendations = [];
        if (probability > 0.6) {
          recommendations.push("Implement early intervention strategy");
          recommendations.push("Consider payment plan options");
        } else if (probability > 0.3) {
          recommendations.push("Schedule proactive customer contact");
        }
        return recommendations;
      }
      generatePrepaymentRecommendations(probability, features) {
        const recommendations = [];
        if (probability > 0.5) {
          recommendations.push("Consider retention strategies");
          recommendations.push("Review rate lock options");
        }
        return recommendations;
      }
      estimateTimeToDefault(features) {
        const baseTime = 180;
        const creditScore = features.credit_score || 700;
        const adjustment = (creditScore - 600) / 10;
        return Math.max(30, baseTime + adjustment);
      }
      calculateSeverityScore(features) {
        const balance = features.current_balance || 25e4;
        const ltv = features.current_balance / features.original_balance || 0.8;
        const balanceFactor = Math.min(1, balance / 5e5);
        const ltvFactor = ltv;
        return Math.round((balanceFactor * 0.6 + ltvFactor * 0.4) * 100);
      }
      calculateRateSensitivity(features) {
        const currentRate = features.current_interest_rate || 0.045;
        const marketRate = 0.04;
        return Math.abs(currentRate - marketRate) * 100;
      }
      async storePrediction(client5, loanId, prediction) {
        try {
          const timeKey = parseInt((/* @__PURE__ */ new Date()).toISOString().split("T")[0].replace(/-/g, ""));
          await client5.query(
            `INSERT INTO fact_predictive_analytics 
         (time_key, model_name, prediction_type, prediction_confidence, 
          default_probability, delinquency_probability, prepayment_probability,
          recommended_action, model_accuracy)
         VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)`,
            [
              timeKey,
              prediction.modelName,
              prediction.predictionType,
              prediction.confidence,
              prediction.predictionType === "default_risk" ? prediction.probability : null,
              prediction.predictionType === "delinquency_risk" ? prediction.probability : null,
              prediction.predictionType === "prepayment_risk" ? prediction.probability : null,
              prediction.recommendations[0] || "Monitor",
              this.models.get(prediction.modelName)?.accuracy || 0.85
            ]
          );
        } catch (error) {
          console.error("Failed to store prediction:", error);
        }
      }
    };
    predictiveEngine = PredictiveEngine.getInstance();
  }
});

// src/analytics/reporting-engine.ts
import { Pool as Pool11 } from "pg";
import { randomUUID as randomUUID22 } from "crypto";
var pool11, ReportingEngine, reportingEngine;
var init_reporting_engine = __esm({
  "src/analytics/reporting-engine.ts"() {
    "use strict";
    pool11 = new Pool11({ connectionString: process.env.DATABASE_URL });
    ReportingEngine = class _ReportingEngine {
      static instance;
      reportCache = /* @__PURE__ */ new Map();
      dashboards = /* @__PURE__ */ new Map();
      constructor() {
        this.initializeDefaultDashboards();
        setInterval(() => this.refreshReportCache(), 3e5);
      }
      static getInstance() {
        if (!_ReportingEngine.instance) {
          _ReportingEngine.instance = new _ReportingEngine();
        }
        return _ReportingEngine.instance;
      }
      /**
       * Generate portfolio performance report
       */
      async generatePortfolioReport(parameters) {
        const reportId = randomUUID22();
        const startTime2 = Date.now();
        const c = await pool11.connect();
        try {
          const summaryQuery = `
        SELECT 
          COUNT(DISTINCT flp.loan_key) as total_loans,
          SUM(flp.outstanding_balance_cents) / 100.0 as total_balance,
          AVG(flp.outstanding_balance_cents) / 100.0 as average_balance,
          COUNT(*) FILTER (WHERE flp.days_delinquent > 0)::float / COUNT(*) as delinquency_rate,
          COUNT(*) FILTER (WHERE flp.days_delinquent > 30)::float / COUNT(*) as serious_delinquency_rate,
          SUM(flp.actual_payment_cents) / 100.0 as total_payments,
          SUM(flp.scheduled_payment_cents) / 100.0 as scheduled_payments
        FROM fact_loan_performance flp
        JOIN dim_time dt ON flp.time_key = dt.time_key
        WHERE dt.full_date >= $1 AND dt.full_date <= $2
      `;
          const summaryResult = await c.query(summaryQuery, [parameters.dateRange.start, parameters.dateRange.end]);
          const trendQuery = `
        SELECT 
          dt.full_date,
          COUNT(DISTINCT flp.loan_key) as loan_count,
          SUM(flp.outstanding_balance_cents) / 100.0 as balance,
          AVG(CASE WHEN flp.days_delinquent > 0 THEN 1.0 ELSE 0.0 END) as delinquency_rate,
          SUM(flp.actual_payment_cents) / 100.0 as payments
        FROM fact_loan_performance flp
        JOIN dim_time dt ON flp.time_key = dt.time_key
        WHERE dt.full_date >= $1 AND dt.full_date <= $2
        GROUP BY dt.full_date
        ORDER BY dt.full_date
      `;
          const trendResult = await c.query(trendQuery, [parameters.dateRange.start, parameters.dateRange.end]);
          const delinquencyQuery = `
        SELECT 
          flp.delinquency_bucket,
          COUNT(*) as loan_count,
          SUM(flp.outstanding_balance_cents) / 100.0 as total_balance
        FROM fact_loan_performance flp
        JOIN dim_time dt ON flp.time_key = dt.time_key
        WHERE dt.full_date >= $1 AND dt.full_date <= $2
        GROUP BY flp.delinquency_bucket
        ORDER BY 
          CASE flp.delinquency_bucket
            WHEN 'current' THEN 1
            WHEN '1-30_days' THEN 2
            WHEN '31-60_days' THEN 3
            WHEN '61-90_days' THEN 4
            WHEN '90+_days' THEN 5
          END
      `;
          const delinquencyResult = await c.query(delinquencyQuery, [parameters.dateRange.start, parameters.dateRange.end]);
          const executionTime = Date.now() - startTime2;
          const reportData = {
            reportId,
            generatedAt: /* @__PURE__ */ new Date(),
            data: {
              summary: summaryResult.rows[0] || {},
              trends: trendResult.rows || [],
              delinquencyDistribution: delinquencyResult.rows || [],
              parameters
            },
            metadata: {
              totalRecords: trendResult.rowCount || 0,
              executionTime,
              dataFreshness: /* @__PURE__ */ new Date(),
              filters: parameters
            }
          };
          this.reportCache.set(reportId, reportData);
          return reportData;
        } finally {
          c.release();
        }
      }
      /**
       * Generate operational performance report
       */
      async generateOperationsReport(parameters) {
        const reportId = randomUUID22();
        const startTime2 = Date.now();
        const c = await pool11.connect();
        try {
          const operationsQuery = `
        SELECT 
          AVG(fso.calls_received) as avg_calls_received,
          AVG(fso.calls_handled) as avg_calls_handled,
          AVG(fso.first_call_resolution_rate) as avg_fcr_rate,
          AVG(fso.customer_satisfaction_score) as avg_csat,
          AVG(fso.sla_compliance_rate) as avg_sla_compliance,
          AVG(fso.automation_rate) as avg_automation_rate,
          SUM(fso.emails_processed) as total_emails,
          SUM(fso.documents_processed) as total_documents
        FROM fact_service_operations fso
        JOIN dim_time dt ON fso.time_key = dt.time_key
        WHERE dt.full_date >= $1 AND dt.full_date <= $2
      `;
          const operationsResult = await c.query(operationsQuery, [parameters.dateRange.start, parameters.dateRange.end]);
          const trendsQuery = `
        SELECT 
          dt.full_date,
          AVG(fso.calls_received) as calls_received,
          AVG(fso.first_call_resolution_rate) as fcr_rate,
          AVG(fso.customer_satisfaction_score) as csat_score,
          AVG(fso.automation_rate) as automation_rate
        FROM fact_service_operations fso
        JOIN dim_time dt ON fso.time_key = dt.time_key
        WHERE dt.full_date >= $1 AND dt.full_date <= $2
        GROUP BY dt.full_date
        ORDER BY dt.full_date
      `;
          const trendsResult = await c.query(trendsQuery, [parameters.dateRange.start, parameters.dateRange.end]);
          let aiMetrics = {};
          if (parameters.includeAIMetrics) {
            const aiQuery = `
          SELECT 
            fai.model_name,
            AVG(fai.average_latency_ms) as avg_latency,
            AVG(fai.accuracy_rate) as avg_accuracy,
            SUM(fai.request_count) as total_requests,
            SUM(fai.api_cost_cents) / 100.0 as total_cost
          FROM fact_ai_performance fai
          JOIN dim_time dt ON fai.time_key = dt.time_key
          WHERE dt.full_date >= $1 AND dt.full_date <= $2
          GROUP BY fai.model_name
        `;
            const aiResult = await c.query(aiQuery, [parameters.dateRange.start, parameters.dateRange.end]);
            aiMetrics = { aiPerformance: aiResult.rows || [] };
          }
          const executionTime = Date.now() - startTime2;
          const reportData = {
            reportId,
            generatedAt: /* @__PURE__ */ new Date(),
            data: {
              summary: operationsResult.rows[0] || {},
              trends: trendsResult.rows || [],
              ...aiMetrics,
              parameters
            },
            metadata: {
              totalRecords: trendsResult.rowCount || 0,
              executionTime,
              dataFreshness: /* @__PURE__ */ new Date(),
              filters: parameters
            }
          };
          this.reportCache.set(reportId, reportData);
          return reportData;
        } finally {
          c.release();
        }
      }
      /**
       * Generate executive dashboard data
       */
      async generateExecutiveDashboard() {
        const c = await pool11.connect();
        try {
          const kpisQuery = `
        SELECT 
          'Total Portfolio' as name,
          SUM(outstanding_balance_cents) / 100.0 as value,
          0 as change,
          'good' as status
        FROM fact_loan_performance flp
        JOIN dim_time dt ON flp.time_key = dt.time_key
        WHERE dt.full_date = CURRENT_DATE - INTERVAL '1 day'
        
        UNION ALL
        
        SELECT 
          'Delinquency Rate' as name,
          AVG(CASE WHEN days_delinquent > 0 THEN 1.0 ELSE 0.0 END) * 100 as value,
          0 as change,
          CASE 
            WHEN AVG(CASE WHEN days_delinquent > 0 THEN 1.0 ELSE 0.0 END) > 0.05 THEN 'warning'
            ELSE 'good'
          END as status
        FROM fact_loan_performance flp
        JOIN dim_time dt ON flp.time_key = dt.time_key
        WHERE dt.full_date = CURRENT_DATE - INTERVAL '1 day'
      `;
          const kpisResult = await c.query(kpisQuery);
          const portfolioQuery = `
        SELECT * FROM mv_daily_portfolio_summary 
        WHERE full_date = (SELECT MAX(full_date) FROM mv_daily_portfolio_summary)
        LIMIT 1
      `;
          const portfolioResult = await c.query(portfolioQuery);
          const operationsQuery = `
        SELECT * FROM mv_monthly_service_performance 
        WHERE year = EXTRACT(YEAR FROM CURRENT_DATE) 
        AND month = EXTRACT(MONTH FROM CURRENT_DATE)
        LIMIT 1
      `;
          const operationsResult = await c.query(operationsQuery);
          return {
            kpis: kpisResult.rows || [],
            portfolioSummary: portfolioResult.rows[0] || {},
            operationalMetrics: operationsResult.rows[0] || {},
            riskMetrics: {
              highRiskLoans: 45,
              criticalAlerts: 3,
              averageRiskScore: 32
            },
            aiMetrics: {
              modelsActive: 4,
              averageAccuracy: 85.2,
              dailyCost: 125.5
            },
            lastUpdated: /* @__PURE__ */ new Date()
          };
        } finally {
          c.release();
        }
      }
      /**
       * Create custom dashboard
       */
      async createDashboard(dashboardConfig) {
        const dashboardId = randomUUID22();
        const dashboard = {
          ...dashboardConfig,
          dashboardId,
          createdAt: /* @__PURE__ */ new Date(),
          updatedAt: /* @__PURE__ */ new Date()
        };
        this.dashboards.set(dashboardId, dashboard);
        return dashboardId;
      }
      /**
       * Get dashboard by ID
       */
      getDashboard(dashboardId) {
        return this.dashboards.get(dashboardId) || null;
      }
      /**
       * List all dashboards
       */
      listDashboards() {
        return Array.from(this.dashboards.values());
      }
      /**
       * Get widget data
       */
      async getWidgetData(widgetId, widget) {
        const c = await pool11.connect();
        try {
          switch (widget.type) {
            case "metric":
              return this.getMetricData(c, widget);
            case "chart":
              return this.getChartData(c, widget);
            case "table":
              return this.getTableData(c, widget);
            default:
              return { error: "Unsupported widget type" };
          }
        } finally {
          c.release();
        }
      }
      /**
       * Export report to different formats
       */
      async exportReport(reportId, format2) {
        const report = this.reportCache.get(reportId);
        if (!report) {
          throw new Error("Report not found");
        }
        switch (format2) {
          case "json":
            return JSON.stringify(report.data, null, 2);
          case "csv":
            return this.convertToCSV(report.data);
          case "pdf":
            return this.generatePDF(report);
          default:
            throw new Error("Unsupported format");
        }
      }
      // Private helper methods
      initializeDefaultDashboards() {
        const executiveDashboard = {
          dashboardId: "executive-dashboard",
          name: "Executive Dashboard",
          description: "High-level business metrics and KPIs",
          widgets: [
            {
              widgetId: "portfolio-balance",
              type: "metric",
              title: "Total Portfolio Balance",
              dataSource: "fact_loan_performance",
              configuration: { metric: "total_balance", format: "currency" },
              position: { x: 0, y: 0, width: 3, height: 2 }
            },
            {
              widgetId: "delinquency-rate",
              type: "gauge",
              title: "Delinquency Rate",
              dataSource: "fact_loan_performance",
              configuration: { metric: "delinquency_rate", format: "percentage", threshold: 5 },
              position: { x: 3, y: 0, width: 3, height: 2 }
            },
            {
              widgetId: "portfolio-trends",
              type: "chart",
              title: "Portfolio Performance Trends",
              dataSource: "mv_daily_portfolio_summary",
              configuration: { chartType: "line", xAxis: "date", yAxis: "total_balance" },
              position: { x: 0, y: 2, width: 6, height: 3 }
            }
          ],
          refreshInterval: 300,
          // 5 minutes
          permissions: ["executive", "management"],
          createdAt: /* @__PURE__ */ new Date(),
          updatedAt: /* @__PURE__ */ new Date()
        };
        this.dashboards.set(executiveDashboard.dashboardId, executiveDashboard);
      }
      async getMetricData(client5, widget) {
        const config = widget.configuration;
        const query = `
      SELECT SUM(outstanding_balance_cents) / 100.0 as total_balance
      FROM fact_loan_performance flp
      JOIN dim_time dt ON flp.time_key = dt.time_key
      WHERE dt.full_date = CURRENT_DATE - INTERVAL '1 day'
    `;
        const result = await client5.query(query);
        return {
          value: result.rows[0]?.total_balance || 0,
          format: config.format || "number",
          lastUpdated: /* @__PURE__ */ new Date()
        };
      }
      async getChartData(client5, widget) {
        const query = `
      SELECT full_date as date, total_balance
      FROM mv_daily_portfolio_summary
      WHERE full_date >= CURRENT_DATE - INTERVAL '30 days'
      ORDER BY full_date
    `;
        const result = await client5.query(query);
        return {
          chartType: widget.configuration.chartType || "line",
          data: result.rows || [],
          xAxis: widget.configuration.xAxis || "date",
          yAxis: widget.configuration.yAxis || "value"
        };
      }
      async getTableData(client5, widget) {
        const query = `
      SELECT 
        dl.loan_number,
        dl.product_type,
        flp.outstanding_balance_cents / 100.0 as balance,
        flp.days_delinquent,
        flp.payment_status
      FROM fact_loan_performance flp
      JOIN dim_loan dl ON flp.loan_key = dl.loan_key
      JOIN dim_time dt ON flp.time_key = dt.time_key
      WHERE dt.full_date = CURRENT_DATE - INTERVAL '1 day'
      AND flp.days_delinquent > 30
      ORDER BY flp.days_delinquent DESC
      LIMIT 10
    `;
        const result = await client5.query(query);
        return {
          columns: ["Loan Number", "Product Type", "Balance", "Days Delinquent", "Status"],
          rows: result.rows || []
        };
      }
      convertToCSV(data) {
        if (Array.isArray(data.trends)) {
          const headers = Object.keys(data.trends[0] || {});
          const csv = [
            headers.join(","),
            ...data.trends.map((row) => headers.map((h) => row[h]).join(","))
          ];
          return csv.join("\n");
        }
        return JSON.stringify(data);
      }
      generatePDF(report) {
        const pdfContent = `
      Report: ${report.reportId}
      Generated: ${report.generatedAt.toISOString()}
      
      Data: ${JSON.stringify(report.data, null, 2)}
    `;
        return Buffer.from(pdfContent, "utf8");
      }
      async refreshReportCache() {
        const oneHourAgo = Date.now() - 60 * 60 * 1e3;
        for (const [reportId, report] of this.reportCache.entries()) {
          if (report.generatedAt.getTime() < oneHourAgo) {
            this.reportCache.delete(reportId);
          }
        }
        console.log(`[Reporting] Cache refreshed, ${this.reportCache.size} reports cached`);
      }
    };
    reportingEngine = ReportingEngine.getInstance();
  }
});

// src/analytics/streaming-processor.ts
import { Pool as Pool12 } from "pg";
import { randomUUID as randomUUID23 } from "crypto";
import { EventEmitter } from "events";
var pool12, StreamingProcessor, streamingProcessor;
var init_streaming_processor = __esm({
  "src/analytics/streaming-processor.ts"() {
    "use strict";
    pool12 = new Pool12({ connectionString: process.env.DATABASE_URL });
    StreamingProcessor = class _StreamingProcessor extends EventEmitter {
      static instance;
      processingRules = /* @__PURE__ */ new Map();
      aggregationWindows = /* @__PURE__ */ new Map();
      eventBuffer = [];
      metrics = {
        eventsProcessed: 0,
        eventsPerSecond: 0,
        averageLatency: 0,
        errorRate: 0,
        throughput: 0,
        lastProcessed: /* @__PURE__ */ new Date()
      };
      constructor() {
        super();
        this.initializeProcessingRules();
        this.initializeAggregationWindows();
        setInterval(() => this.processBatch(), 1e3);
        setInterval(() => this.updateMetrics(), 5e3);
        setInterval(() => this.cleanup(), 3e5);
      }
      static getInstance() {
        if (!_StreamingProcessor.instance) {
          _StreamingProcessor.instance = new _StreamingProcessor();
        }
        return _StreamingProcessor.instance;
      }
      /**
       * Ingest a stream event
       */
      async ingestEvent(eventData) {
        const event = {
          eventId: randomUUID23(),
          timestamp: /* @__PURE__ */ new Date(),
          ...eventData
        };
        this.eventBuffer.push(event);
        this.emit("event", event);
        return event.eventId;
      }
      /**
       * Process loan payment event
       */
      async processPaymentEvent(loanId, paymentData) {
        const event = await this.ingestEvent({
          eventType: "payment_received",
          eventSource: "payment_system",
          payload: {
            loanId,
            amount: paymentData.amount,
            paymentMethod: paymentData.paymentMethod,
            scheduledDate: paymentData.scheduledDate,
            receivedDate: paymentData.receivedDate || /* @__PURE__ */ new Date(),
            isLate: paymentData.receivedDate ? paymentData.receivedDate > paymentData.scheduledDate : false
          }
        });
        if (paymentData.amount > 5e4) {
          await this.processHighValuePayment(event);
        }
      }
      /**
       * Process document analysis event
       */
      async processDocumentEvent(documentId, analysisResult) {
        await this.ingestEvent({
          eventType: "document_analyzed",
          eventSource: "ai_processor",
          payload: {
            documentId,
            documentType: analysisResult.documentType,
            confidence: analysisResult.confidence,
            extractedData: analysisResult.extractedData,
            processingTime: analysisResult.processingTime,
            qualityScore: this.calculateDocumentQuality(analysisResult)
          }
        });
      }
      /**
       * Process customer interaction event
       */
      async processCustomerEvent(customerId, interactionData) {
        await this.ingestEvent({
          eventType: "customer_interaction",
          eventSource: "customer_service",
          payload: {
            customerId,
            interactionType: interactionData.type,
            outcome: interactionData.outcome,
            duration: interactionData.duration,
            satisfaction: interactionData.satisfaction,
            channel: interactionData.type
          }
        });
      }
      /**
       * Get real-time analytics for dashboard
       */
      async getRealTimeAnalytics() {
        const recentEvents = this.eventBuffer.slice(-50);
        const now = Date.now();
        const last5Minutes = now - 5 * 60 * 1e3;
        const recentEventCount = this.eventBuffer.filter((e) => e.timestamp.getTime() > last5Minutes).length;
        const liveMetrics = {
          eventsLast5Min: recentEventCount,
          paymentsToday: this.countEventsByType("payment_received", "today"),
          documentsProcessed: this.countEventsByType("document_analyzed", "today"),
          customerInteractions: this.countEventsByType("customer_interaction", "today"),
          averageProcessingTime: this.calculateAverageProcessingTime()
        };
        const alerts = await this.generateRealTimeAlerts();
        return {
          liveMetrics,
          recentEvents: recentEvents.slice(-10),
          // Last 10 events
          alerts,
          throughput: this.metrics.eventsPerSecond
        };
      }
      /**
       * Setup streaming aggregation
       */
      setupAggregation(config) {
        this.aggregationWindows.set(config.windowId, config);
        const interval = config.size * 1e3;
        setInterval(() => this.executeAggregation(config.windowId), interval);
        return config.windowId;
      }
      /**
       * Get streaming metrics
       */
      getStreamingMetrics() {
        return { ...this.metrics };
      }
      /**
       * Add processing rule
       */
      addProcessingRule(rule) {
        this.processingRules.set(rule.ruleId, rule);
      }
      /**
       * Get event history for analysis
       */
      async getEventHistory(eventType, timeRange) {
        let events = [...this.eventBuffer];
        if (eventType) {
          events = events.filter((e) => e.eventType === eventType);
        }
        if (timeRange) {
          events = events.filter(
            (e) => e.timestamp >= timeRange.start && e.timestamp <= timeRange.end
          );
        }
        return events.sort((a, b) => b.timestamp.getTime() - a.timestamp.getTime());
      }
      // Private methods
      async processBatch() {
        if (this.eventBuffer.length === 0) return;
        const batchSize = Math.min(100, this.eventBuffer.length);
        const batch = this.eventBuffer.splice(0, batchSize);
        const startTime2 = Date.now();
        try {
          for (const event of batch) {
            await this.processEvent(event);
          }
          this.metrics.eventsProcessed += batch.length;
          this.metrics.lastProcessed = /* @__PURE__ */ new Date();
          const latency = Date.now() - startTime2;
          this.metrics.averageLatency = (this.metrics.averageLatency + latency) / 2;
        } catch (error) {
          console.error("[Streaming] Batch processing failed:", error);
          this.metrics.errorRate = (this.metrics.errorRate + 1) / 2;
        }
      }
      async processEvent(event) {
        for (const [, rule] of this.processingRules) {
          if (!rule.enabled) continue;
          if (this.matchesPattern(event, rule.eventPattern)) {
            await this.executeRuleActions(event, rule);
          }
        }
        await this.storeEventInAnalytics(event);
      }
      matchesPattern(event, pattern) {
        return pattern === "*" || event.eventType === pattern;
      }
      async executeRuleActions(event, rule) {
        for (const action of rule.actions) {
          try {
            switch (action.type) {
              case "alert":
                await this.generateAlert(event, action.configuration);
                break;
              case "transform":
                await this.transformEvent(event, action.configuration);
                break;
              case "aggregate":
                await this.aggregateEvent(event, action.configuration);
                break;
              case "store":
                await this.storeEvent(event, action.configuration);
                break;
            }
          } catch (error) {
            console.error(`[Streaming] Action ${action.type} failed:`, error);
          }
        }
      }
      async generateAlert(event, config) {
        if (event.payload.amount > (config.threshold || 1e5)) {
          this.emit("alert", {
            type: "high_value_transaction",
            message: `High value payment of $${event.payload.amount} received`,
            event,
            timestamp: /* @__PURE__ */ new Date()
          });
        }
      }
      async transformEvent(event, config) {
        if (config.enrichment) {
          event.metadata = { ...event.metadata, enriched: true };
        }
      }
      async aggregateEvent(event, config) {
        const windowId = config.windowId;
        if (this.aggregationWindows.has(windowId)) {
          console.log(`[Streaming] Event added to aggregation window ${windowId}`);
        }
      }
      async storeEvent(event, config) {
        console.log(`[Streaming] Event stored: ${event.eventType}`);
      }
      async storeEventInAnalytics(event) {
        try {
          const c = await pool12.connect();
          if (event.eventType === "payment_received") {
            await this.storePaymentFact(c, event);
          } else if (event.eventType === "document_analyzed") {
            await this.storeAIPerformanceFact(c, event);
          } else if (event.eventType === "customer_interaction") {
            await this.storeServiceOperationFact(c, event);
          }
          c.release();
        } catch (error) {
          console.error("[Streaming] Failed to store event in analytics:", error);
        }
      }
      async storePaymentFact(client5, event) {
        const timeKey = parseInt(event.timestamp.toISOString().split("T")[0].replace(/-/g, ""));
        const loanKey = event.payload.loanId;
        const borrowerKey = "default-borrower-key";
        await client5.query(
          `INSERT INTO fact_loan_performance 
       (time_key, loan_key, borrower_key, actual_payment_cents, 
        payment_status, payment_timing_category)
       VALUES ($1, $2, $3, $4, $5, $6)
       ON CONFLICT DO NOTHING`,
          [
            timeKey,
            loanKey,
            borrowerKey,
            Math.round(event.payload.amount * 100),
            event.payload.isLate ? "late" : "on_time",
            event.payload.isLate ? "late" : "on_time"
          ]
        );
      }
      async storeAIPerformanceFact(client5, event) {
        const timeKey = parseInt(event.timestamp.toISOString().split("T")[0].replace(/-/g, ""));
        await client5.query(
          `INSERT INTO fact_ai_performance 
       (time_key, model_name, model_version, operation_type, 
        request_count, success_count, average_latency_ms, average_confidence)
       VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
       ON CONFLICT DO NOTHING`,
          [
            timeKey,
            "document_analyzer",
            "v1.0",
            "document_analysis",
            1,
            event.payload.confidence > 0.8 ? 1 : 0,
            event.payload.processingTime,
            event.payload.confidence
          ]
        );
      }
      async storeServiceOperationFact(client5, event) {
        const timeKey = parseInt(event.timestamp.toISOString().split("T")[0].replace(/-/g, ""));
        const performanceKey = "default-performance-key";
        const metricUpdates = {};
        if (event.payload.interactionType === "call") {
          metricUpdates.calls_received = 1;
          metricUpdates.calls_handled = event.payload.outcome === "resolved" ? 1 : 0;
        } else if (event.payload.interactionType === "email") {
          metricUpdates.emails_processed = 1;
        }
        if (Object.keys(metricUpdates).length > 0) {
          await client5.query(
            `INSERT INTO fact_service_operations 
         (time_key, performance_key, calls_received, calls_handled, emails_processed,
          customer_satisfaction_score)
         VALUES ($1, $2, $3, $4, $5, $6)
         ON CONFLICT DO NOTHING`,
            [
              timeKey,
              performanceKey,
              metricUpdates.calls_received || 0,
              metricUpdates.calls_handled || 0,
              metricUpdates.emails_processed || 0,
              event.payload.satisfaction || null
            ]
          );
        }
      }
      async executeAggregation(windowId) {
        const window = this.aggregationWindows.get(windowId);
        if (!window) return;
        const windowStart = new Date(Date.now() - window.size * 1e3);
        const windowEvents = this.eventBuffer.filter((e) => e.timestamp >= windowStart);
        const results = {};
        for (const agg of window.aggregations) {
          const values = windowEvents.map((e) => e.payload[agg.field]).filter((v) => v !== void 0 && v !== null);
          switch (agg.function) {
            case "sum":
              results[agg.alias] = values.reduce((sum3, val) => sum3 + Number(val), 0);
              break;
            case "avg":
              results[agg.alias] = values.length > 0 ? values.reduce((sum3, val) => sum3 + Number(val), 0) / values.length : 0;
              break;
            case "count":
              results[agg.alias] = values.length;
              break;
            case "min":
              results[agg.alias] = values.length > 0 ? Math.min(...values.map(Number)) : 0;
              break;
            case "max":
              results[agg.alias] = values.length > 0 ? Math.max(...values.map(Number)) : 0;
              break;
          }
        }
        this.emit("aggregation", {
          windowId,
          windowType: window.windowType,
          timestamp: /* @__PURE__ */ new Date(),
          results
        });
      }
      initializeProcessingRules() {
        const defaultRules = [
          {
            ruleId: "high-value-payment",
            name: "High Value Payment Alert",
            eventPattern: "payment_received",
            actions: [
              {
                type: "alert",
                configuration: { threshold: 5e4, alertType: "high_value" }
              }
            ],
            enabled: true,
            priority: 1
          },
          {
            ruleId: "document-quality-check",
            name: "Document Quality Monitoring",
            eventPattern: "document_analyzed",
            actions: [
              {
                type: "alert",
                configuration: { confidenceThreshold: 0.7, alertType: "low_confidence" }
              }
            ],
            enabled: true,
            priority: 2
          }
        ];
        for (const rule of defaultRules) {
          this.processingRules.set(rule.ruleId, rule);
        }
      }
      initializeAggregationWindows() {
        this.setupAggregation({
          windowId: "payments-5min",
          windowType: "tumbling",
          size: 300,
          // 5 minutes
          aggregations: [
            { field: "amount", function: "sum", alias: "total_payments" },
            { field: "amount", function: "count", alias: "payment_count" },
            { field: "amount", function: "avg", alias: "avg_payment" }
          ],
          groupBy: ["paymentMethod"]
        });
      }
      calculateDocumentQuality(result) {
        const confidenceScore = result.confidence * 100;
        const dataCompletenesScore = Object.keys(result.extractedData).length * 10;
        return Math.min(100, (confidenceScore + dataCompletenesScore) / 2);
      }
      countEventsByType(eventType, period) {
        const now = /* @__PURE__ */ new Date();
        const cutoff = period === "today" ? new Date(now.getFullYear(), now.getMonth(), now.getDate()) : new Date(now.getTime() - 60 * 60 * 1e3);
        return this.eventBuffer.filter(
          (e) => e.eventType === eventType && e.timestamp >= cutoff
        ).length;
      }
      calculateAverageProcessingTime() {
        const processingEvents = this.eventBuffer.filter(
          (e) => e.eventType === "document_analyzed" && e.payload.processingTime
        );
        if (processingEvents.length === 0) return 0;
        const totalTime = processingEvents.reduce((sum3, e) => sum3 + e.payload.processingTime, 0);
        return totalTime / processingEvents.length;
      }
      async generateRealTimeAlerts() {
        const alerts = [];
        const now = /* @__PURE__ */ new Date();
        if (this.metrics.errorRate > 0.05) {
          alerts.push({
            type: "error_rate",
            message: `High error rate detected: ${(this.metrics.errorRate * 100).toFixed(1)}%`,
            timestamp: now
          });
        }
        if (this.metrics.averageLatency > 5e3) {
          alerts.push({
            type: "latency",
            message: `High processing latency: ${this.metrics.averageLatency}ms`,
            timestamp: now
          });
        }
        return alerts;
      }
      async processHighValuePayment(event) {
        this.emit("high_value_payment", {
          loanId: event.payload.loanId,
          amount: event.payload.amount,
          timestamp: event.timestamp
        });
      }
      updateMetrics() {
        const now = Date.now();
        const last5Seconds = now - 5e3;
        const recentEvents = this.eventBuffer.filter((e) => e.timestamp.getTime() > last5Seconds);
        this.metrics.eventsPerSecond = recentEvents.length / 5;
        this.metrics.throughput = this.eventBuffer.length;
      }
      cleanup() {
        const oneHourAgo = Date.now() - 60 * 60 * 1e3;
        this.eventBuffer = this.eventBuffer.filter((e) => e.timestamp.getTime() > oneHourAgo);
      }
    };
    streamingProcessor = StreamingProcessor.getInstance();
  }
});

// src/routes/analytics.routes.ts
var analytics_routes_exports = {};
__export(analytics_routes_exports, {
  analyticsRouter: () => analyticsRouter
});
import { Router as Router52 } from "express";
var analyticsRouter;
var init_analytics_routes = __esm({
  "src/routes/analytics.routes.ts"() {
    "use strict";
    init_db();
    init_loaders();
    init_parquet_extractor();
    init_business_intelligence();
    init_etl_pipeline();
    init_predictive_engine();
    init_reporting_engine();
    init_streaming_processor();
    analyticsRouter = Router52();
    analyticsRouter.post("/etl/run", async (req, res) => {
      try {
        const { type = "incremental", tenant_id } = req.body;
        const tenantId = tenant_id || "00000000-0000-0000-0000-000000000001";
        const etl = new ReportingETL(tenantId);
        let metrics2;
        if (type === "full") {
          metrics2 = await etl.runFullETL();
        } else {
          const since = req.body.since_iso;
          metrics2 = await etl.runIncrementalETL(since);
        }
        res.json({
          success: true,
          type,
          tenant_id: tenantId,
          metrics: metrics2,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Analytics] ETL run failed:", error);
        res.status(500).json({
          error: "ETL execution failed",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    analyticsRouter.post("/lakehouse/export", async (req, res) => {
      try {
        const { type = "incremental", tenant_id } = req.body;
        const tenantId = tenant_id || "00000000-0000-0000-0000-000000000001";
        const extractor = new LakehouseExtractor(tenantId);
        const jobs = await extractor.exportAllTables(type !== "full");
        res.json({
          success: true,
          export_type: type,
          tenant_id: tenantId,
          jobs,
          summary: {
            total: jobs.length,
            completed: jobs.filter((j) => j.status === "completed").length,
            failed: jobs.filter((j) => j.status === "failed").length
          },
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Analytics] Lakehouse export failed:", error);
        res.status(500).json({
          error: "Lakehouse export failed",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    analyticsRouter.get("/export/csv/:table", async (req, res) => {
      try {
        const { table } = req.params;
        const { limit = 1e4, offset = 0 } = req.query;
        const allowedTables = [
          "dim_loan",
          "dim_investor",
          "dim_user",
          "fact_txn",
          "fact_qc",
          "fact_servicing",
          "fact_remit",
          "fact_export",
          "fact_notify",
          "fact_document"
        ];
        if (!allowedTables.includes(table)) {
          return res.status(400).json({ error: "Invalid table name" });
        }
        const client5 = await pool.connect();
        try {
          const result = await client5.query(`
        SELECT * FROM reporting.${table}
        ORDER BY created_at DESC
        LIMIT $1 OFFSET $2
      `, [limit, offset]);
          if (result.rows.length === 0) {
            return res.status(404).json({ error: "No data found" });
          }
          res.setHeader("Content-Type", "text/csv");
          res.setHeader("Content-Disposition", `attachment; filename="${table}_export.csv"`);
          const headers = Object.keys(result.rows[0]);
          const csvData = [
            headers.join(","),
            ...result.rows.map(
              (row) => headers.map((header) => {
                const value = row[header];
                if (value === null || value === void 0) return "";
                if (typeof value === "string" && value.includes(",")) {
                  return `"${value.replace(/"/g, '""')}"`;
                }
                return String(value);
              }).join(",")
            )
          ].join("\n");
          res.send(csvData);
        } finally {
          client5.release();
        }
      } catch (error) {
        console.error("[Analytics] CSV export failed:", error);
        res.status(500).json({
          error: "CSV export failed",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    analyticsRouter.get("/dashboard/portfolio-summary", async (req, res) => {
      try {
        const client5 = await pool.connect();
        try {
          const result = await client5.query(`
        SELECT 
          COUNT(DISTINCT loan_id) as total_loans,
          SUM(upb) as total_upb,
          SUM(escrow_balance) as total_escrow,
          COUNT(*) FILTER (WHERE delinquency_bucket != '0+') as delinquent_loans,
          AVG(upb) as avg_loan_balance
        FROM reporting.v_portfolio_summary
      `);
          res.json({
            success: true,
            data: result.rows[0],
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          });
        } finally {
          client5.release();
        }
      } catch (error) {
        console.error("[Analytics] Portfolio summary failed:", error);
        res.status(500).json({
          error: "Portfolio summary failed",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    analyticsRouter.get("/dashboard/monthly-activity", async (req, res) => {
      try {
        const { months = 12 } = req.query;
        const client5 = await pool.connect();
        try {
          const result = await client5.query(`
        SELECT * FROM reporting.v_monthly_activity
        WHERE year >= EXTRACT(year FROM NOW() - INTERVAL '${months} months')
        ORDER BY year DESC, month DESC, transaction_type
        LIMIT 100
      `);
          res.json({
            success: true,
            data: result.rows,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          });
        } finally {
          client5.release();
        }
      } catch (error) {
        console.error("[Analytics] Monthly activity failed:", error);
        res.status(500).json({
          error: "Monthly activity failed",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    analyticsRouter.get("/dashboard/qc-performance", async (req, res) => {
      try {
        const { months = 6 } = req.query;
        const client5 = await pool.connect();
        try {
          const result = await client5.query(`
        SELECT * FROM reporting.v_qc_dashboard
        WHERE year >= EXTRACT(year FROM NOW() - INTERVAL '${months} months')
        ORDER BY year DESC, month DESC, severity
        LIMIT 100
      `);
          res.json({
            success: true,
            data: result.rows,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          });
        } finally {
          client5.release();
        }
      } catch (error) {
        console.error("[Analytics] QC performance failed:", error);
        res.status(500).json({
          error: "QC performance failed",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    analyticsRouter.get("/dashboard/remittance-summary", async (req, res) => {
      try {
        const { months = 12 } = req.query;
        const client5 = await pool.connect();
        try {
          const result = await client5.query(`
        SELECT * FROM reporting.v_remittance_summary
        WHERE year >= EXTRACT(year FROM NOW() - INTERVAL '${months} months')
        ORDER BY year DESC, month DESC, investor_name
        LIMIT 100
      `);
          res.json({
            success: true,
            data: result.rows,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          });
        } finally {
          client5.release();
        }
      } catch (error) {
        console.error("[Analytics] Remittance summary failed:", error);
        res.status(500).json({
          error: "Remittance summary failed",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    analyticsRouter.post("/query/sql", async (req, res) => {
      try {
        const { sql: sql27, limit = 1e3 } = req.body;
        if (!sql27 || typeof sql27 !== "string") {
          return res.status(400).json({ error: "SQL query is required" });
        }
        const allowedPatterns = [
          /^SELECT\s+/i,
          /FROM\s+reporting\./i
        ];
        const forbiddenPatterns = [
          /INSERT\s+/i,
          /UPDATE\s+/i,
          /DELETE\s+/i,
          /DROP\s+/i,
          /CREATE\s+/i,
          /ALTER\s+/i,
          /TRUNCATE\s+/i
        ];
        if (!allowedPatterns.every((pattern) => pattern.test(sql27))) {
          return res.status(400).json({ error: "Only SELECT queries from reporting schema are allowed" });
        }
        if (forbiddenPatterns.some((pattern) => pattern.test(sql27))) {
          return res.status(400).json({ error: "DDL/DML operations are not allowed" });
        }
        const client5 = await pool.connect();
        try {
          const limitedSql = sql27.includes("LIMIT") ? sql27 : `${sql27} LIMIT ${limit}`;
          const result = await client5.query(limitedSql);
          res.json({
            success: true,
            columns: result.fields?.map((f) => f.name) || [],
            data: result.rows,
            row_count: result.rowCount,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          });
        } finally {
          client5.release();
        }
      } catch (error) {
        console.error("[Analytics] SQL query failed:", error);
        res.status(500).json({
          error: "SQL query failed",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    analyticsRouter.get("/data-quality/metrics", async (req, res) => {
      try {
        const client5 = await pool.connect();
        try {
          const metrics2 = await client5.query(`
        SELECT 
          'dim_loan' as table_name,
          COUNT(*) as total_rows,
          COUNT(*) FILTER (WHERE loan_number IS NOT NULL) as loan_number_filled,
          COUNT(*) FILTER (WHERE borrower_name IS NOT NULL) as borrower_name_filled,
          MAX(updated_at) as last_updated
        FROM reporting.dim_loan
        
        UNION ALL
        
        SELECT 
          'fact_txn' as table_name,
          COUNT(*) as total_rows,
          COUNT(*) FILTER (WHERE amount > 0) as positive_amounts,
          COUNT(*) FILTER (WHERE d >= CURRENT_DATE - INTERVAL '30 days') as recent_txns,
          MAX(created_at) as last_updated
        FROM reporting.fact_txn
        
        UNION ALL
        
        SELECT 
          'fact_servicing' as table_name,
          COUNT(*) as total_rows,
          COUNT(*) FILTER (WHERE upb > 0) as active_loans,
          COUNT(*) FILTER (WHERE d = CURRENT_DATE) as current_snapshots,
          MAX(created_at) as last_updated
        FROM reporting.fact_servicing
      `);
          res.json({
            success: true,
            metrics: metrics2.rows,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          });
        } finally {
          client5.release();
        }
      } catch (error) {
        console.error("[Analytics] Data quality metrics failed:", error);
        res.status(500).json({
          error: "Data quality metrics failed",
          message: error instanceof Error ? error.message : String(error)
        });
      }
    });
    analyticsRouter.get("/bi/kpis", async (req, res) => {
      try {
        const timeframe = req.query.timeframe || "daily";
        const kpis = await businessIntelligence.calculateKPIs(timeframe);
        res.json({
          success: true,
          data: kpis,
          timeframe,
          generatedAt: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Analytics] KPIs calculation failed:", error);
        res.status(500).json({
          success: false,
          error: "Failed to calculate KPIs",
          message: error.message
        });
      }
    });
    analyticsRouter.get("/bi/insights", async (req, res) => {
      try {
        const insights = await businessIntelligence.generateBusinessInsights();
        res.json({
          success: true,
          data: insights,
          count: insights.length,
          generatedAt: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Analytics] Business insights generation failed:", error);
        res.status(500).json({
          success: false,
          error: "Failed to generate business insights",
          message: error.message
        });
      }
    });
    analyticsRouter.get("/bi/portfolio", async (req, res) => {
      try {
        const timeframe = req.query.timeframe || "30 days";
        const analytics = await businessIntelligence.getPortfolioAnalytics(timeframe);
        res.json({
          success: true,
          data: analytics,
          timeframe,
          generatedAt: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Analytics] Portfolio analytics failed:", error);
        res.status(500).json({
          success: false,
          error: "Failed to get portfolio analytics",
          message: error.message
        });
      }
    });
    analyticsRouter.get("/bi/operations", async (req, res) => {
      try {
        const timeframe = req.query.timeframe || "30 days";
        const analytics = await businessIntelligence.getOperationalAnalytics(timeframe);
        res.json({
          success: true,
          data: analytics,
          timeframe,
          generatedAt: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Analytics] Operational analytics failed:", error);
        res.status(500).json({
          success: false,
          error: "Failed to get operational analytics",
          message: error.message
        });
      }
    });
    analyticsRouter.get("/reports/executive-dashboard", async (req, res) => {
      try {
        const dashboard = await reportingEngine.generateExecutiveDashboard();
        res.json({
          success: true,
          data: dashboard,
          generatedAt: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Analytics] Executive dashboard failed:", error);
        res.status(500).json({
          success: false,
          error: "Failed to generate executive dashboard",
          message: error.message
        });
      }
    });
    analyticsRouter.post("/reports/portfolio-performance", async (req, res) => {
      try {
        const { dateRange, groupBy, includeForecasts } = req.body;
        if (!dateRange || !dateRange.start || !dateRange.end) {
          return res.status(400).json({
            success: false,
            error: "Date range is required"
          });
        }
        const report = await reportingEngine.generatePortfolioReport({
          dateRange,
          groupBy,
          includeForecasts
        });
        res.json({
          success: true,
          data: report,
          generatedAt: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Analytics] Portfolio report generation failed:", error);
        res.status(500).json({
          success: false,
          error: "Failed to generate portfolio report",
          message: error.message
        });
      }
    });
    analyticsRouter.post("/predictions/default-risk", async (req, res) => {
      try {
        const { loanId, features } = req.body;
        if (!loanId) {
          return res.status(400).json({
            success: false,
            error: "Loan ID is required"
          });
        }
        const prediction = await predictiveEngine.predictDefaultRisk(loanId, features);
        res.json({
          success: true,
          data: prediction,
          generatedAt: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Analytics] Default risk prediction failed:", error);
        res.status(500).json({
          success: false,
          error: "Failed to predict default risk",
          message: error.message
        });
      }
    });
    analyticsRouter.post("/predictions/risk-assessment", async (req, res) => {
      try {
        const { loanId } = req.body;
        if (!loanId) {
          return res.status(400).json({
            success: false,
            error: "Loan ID is required"
          });
        }
        const assessment = await predictiveEngine.generateRiskAssessment(loanId);
        res.json({
          success: true,
          data: assessment,
          generatedAt: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Analytics] Risk assessment failed:", error);
        res.status(500).json({
          success: false,
          error: "Failed to generate risk assessment",
          message: error.message
        });
      }
    });
    analyticsRouter.post("/predictions/portfolio-forecast", async (req, res) => {
      try {
        const { months = 12 } = req.body;
        const forecast = await predictiveEngine.generatePortfolioForecast(months);
        res.json({
          success: true,
          data: forecast,
          generatedAt: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Analytics] Portfolio forecast failed:", error);
        res.status(500).json({
          success: false,
          error: "Failed to generate portfolio forecast",
          message: error.message
        });
      }
    });
    analyticsRouter.get("/streaming/real-time", async (req, res) => {
      try {
        const analytics = await streamingProcessor.getRealTimeAnalytics();
        res.json({
          success: true,
          data: analytics,
          generatedAt: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Analytics] Real-time analytics failed:", error);
        res.status(500).json({
          success: false,
          error: "Failed to get real-time analytics",
          message: error.message
        });
      }
    });
    analyticsRouter.post("/streaming/events", async (req, res) => {
      try {
        const { eventType, eventSource, payload, metadata } = req.body;
        if (!eventType || !eventSource || !payload) {
          return res.status(400).json({
            success: false,
            error: "Event type, source, and payload are required"
          });
        }
        const eventId = await streamingProcessor.ingestEvent({
          eventType,
          eventSource,
          payload,
          metadata
        });
        res.json({
          success: true,
          data: { eventId },
          generatedAt: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Analytics] Event ingestion failed:", error);
        res.status(500).json({
          success: false,
          error: "Failed to ingest event",
          message: error.message
        });
      }
    });
    analyticsRouter.post("/etl/advanced/run", async (req, res) => {
      try {
        const { jobType } = req.body;
        let result;
        switch (jobType) {
          case "loan_performance":
            result = await etlPipeline.runLoanPerformanceETL();
            break;
          case "service_operations":
            result = await etlPipeline.runServiceOperationsETL();
            break;
          case "ai_performance":
            result = await etlPipeline.runAIPerformanceETL();
            break;
          case "all":
            const [loan, service, ai] = await Promise.all([
              etlPipeline.runLoanPerformanceETL(),
              etlPipeline.runServiceOperationsETL(),
              etlPipeline.runAIPerformanceETL()
            ]);
            result = { loan, service, ai };
            break;
          default:
            return res.status(400).json({
              success: false,
              error: "Invalid job type. Use: loan_performance, service_operations, ai_performance, or all"
            });
        }
        res.json({
          success: true,
          data: result,
          jobType,
          generatedAt: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Analytics] Advanced ETL job execution failed:", error);
        res.status(500).json({
          success: false,
          error: "Failed to run advanced ETL job",
          message: error.message
        });
      }
    });
    analyticsRouter.post("/etl/refresh-views", async (req, res) => {
      try {
        await etlPipeline.refreshMaterializedViews();
        res.json({
          success: true,
          message: "Materialized views refreshed successfully",
          generatedAt: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch (error) {
        console.error("[Analytics] Materialized views refresh failed:", error);
        res.status(500).json({
          success: false,
          error: "Failed to refresh materialized views",
          message: error.message
        });
      }
    });
    analyticsRouter.get("/health/step23", async (req, res) => {
      try {
        const streamingMetrics = streamingProcessor.getStreamingMetrics();
        const etlJobs = etlPipeline.getAllJobResults();
        const health = {
          status: "healthy",
          components: {
            streaming: {
              status: streamingMetrics.errorRate < 0.1 ? "healthy" : "degraded",
              eventsPerSecond: streamingMetrics.eventsPerSecond,
              errorRate: streamingMetrics.errorRate
            },
            etl: {
              status: etlJobs.length > 0 ? "healthy" : "warning",
              totalJobs: etlJobs.length
            },
            businessIntelligence: {
              status: "healthy",
              features: ["kpis", "insights", "portfolio", "operations"]
            },
            predictiveAnalytics: {
              status: "healthy",
              models: ["default_risk_v2", "delinquency_risk_v1", "prepayment_risk_v1"]
            },
            reporting: {
              status: "healthy",
              dashboards: reportingEngine.listDashboards().length
            }
          },
          lastChecked: (/* @__PURE__ */ new Date()).toISOString()
        };
        res.json(health);
      } catch (error) {
        console.error("[Analytics] Step 23 health check failed:", error);
        res.status(500).json({
          status: "unhealthy",
          error: error.message,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      }
    });
  }
});

// src/monitoring/ai-performance.ts
import { Pool as Pool13 } from "pg";
var pool13, AIPerformanceMonitor, aiPerformanceMonitor;
var init_ai_performance = __esm({
  "src/monitoring/ai-performance.ts"() {
    "use strict";
    pool13 = new Pool13({ connectionString: process.env.DATABASE_URL });
    AIPerformanceMonitor = class _AIPerformanceMonitor {
      static instance;
      metricsBuffer = [];
      bufferSize = 100;
      flushInterval = 3e4;
      // 30 seconds
      constructor() {
        setInterval(() => this.flushMetrics(), this.flushInterval);
      }
      static getInstance() {
        if (!_AIPerformanceMonitor.instance) {
          _AIPerformanceMonitor.instance = new _AIPerformanceMonitor();
        }
        return _AIPerformanceMonitor.instance;
      }
      /**
       * Record AI model performance metric
       */
      async recordAIMetric(metric) {
        this.metricsBuffer.push(metric);
        if (this.metricsBuffer.length >= this.bufferSize) {
          await this.flushMetrics();
        }
      }
      /**
       * Record pipeline performance metric
       */
      async recordPipelineMetric(metric) {
        const c = await pool13.connect();
        try {
          await c.query(
            `INSERT INTO pipeline_performance 
         (tenant_id, pipeline_stage, operation_id, document_type, processing_time_ms, 
          queue_wait_ms, success, error_type, resource_usage)
         VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)`,
            [
              metric.tenantId,
              metric.pipelineStage,
              metric.operationId,
              metric.documentType,
              metric.processingTimeMs,
              metric.queueWaitMs,
              metric.success,
              metric.errorType,
              metric.resourceUsage ? JSON.stringify(metric.resourceUsage) : null
            ]
          );
        } finally {
          c.release();
        }
      }
      /**
       * Check for AI model drift
       */
      async checkModelDrift(tenantId, modelName, currentPredictions, baselinePredictions) {
        const driftScore = this.calculateKSStatistic(currentPredictions, baselinePredictions);
        const threshold = Number(process.env.AI_DRIFT_THRESHOLD) || 0.1;
        const driftDetected = driftScore > threshold;
        await this.recordDriftMetric({
          tenantId,
          modelName,
          driftType: "prediction",
          driftScore,
          threshold,
          sampleSize: currentPredictions.length,
          baselinePeriodStart: new Date(Date.now() - 7 * 24 * 60 * 60 * 1e3),
          // 7 days ago
          baselinePeriodEnd: /* @__PURE__ */ new Date()
        });
        return { driftDetected, driftScore };
      }
      /**
       * Get AI model performance statistics
       */
      async getModelPerformanceStats(tenantId, modelName, hoursBack = 24) {
        const c = await pool13.connect();
        try {
          const result = await c.query(
            `SELECT 
           AVG(latency_ms) as avg_latency,
           AVG(confidence_score) as avg_confidence,
           SUM(cost_cents) as total_cost,
           COUNT(*) as request_count
         FROM ai_model_metrics 
         WHERE tenant_id = $1 AND model_name = $2 
         AND timestamp >= now() - interval '${hoursBack} hours'`,
            [tenantId, modelName]
          );
          const stats = result.rows[0];
          const errorResult = await c.query(
            `SELECT 
           COUNT(*) FILTER (WHERE success = false) as errors,
           COUNT(*) as total
         FROM pipeline_performance 
         WHERE tenant_id = $1 AND timestamp >= now() - interval '${hoursBack} hours'`,
            [tenantId]
          );
          const errorStats = errorResult.rows[0];
          const errorRate = errorStats.total > 0 ? parseFloat(errorStats.errors) / parseFloat(errorStats.total) : 0;
          return {
            avgLatency: parseFloat(stats.avg_latency) || 0,
            avgConfidence: parseFloat(stats.avg_confidence) || 0,
            totalCost: parseFloat(stats.total_cost) || 0,
            requestCount: parseInt(stats.request_count) || 0,
            errorRate
          };
        } finally {
          c.release();
        }
      }
      /**
       * Get pipeline throughput metrics
       */
      async getPipelineThroughput(tenantId, hoursBack = 24) {
        const c = await pool13.connect();
        try {
          const result = await c.query(
            `SELECT 
           COUNT(*) as total_documents,
           AVG(processing_time_ms) as avg_processing_time,
           AVG(queue_wait_ms) as avg_queue_wait,
           COUNT(*) FILTER (WHERE success = true) as successful_documents
         FROM pipeline_performance 
         WHERE tenant_id = $1 AND timestamp >= now() - interval '${hoursBack} hours'`,
            [tenantId]
          );
          const stats = result.rows[0];
          const totalDocs = parseInt(stats.total_documents) || 0;
          const successfulDocs = parseInt(stats.successful_documents) || 0;
          return {
            documentsPerHour: totalDocs / hoursBack,
            avgProcessingTime: parseFloat(stats.avg_processing_time) || 0,
            avgQueueWait: parseFloat(stats.avg_queue_wait) || 0,
            successRate: totalDocs > 0 ? successfulDocs / totalDocs : 0
          };
        } finally {
          c.release();
        }
      }
      /**
       * Flush metrics buffer to database
       */
      async flushMetrics() {
        if (this.metricsBuffer.length === 0) return;
        const metricsToFlush = [...this.metricsBuffer];
        this.metricsBuffer = [];
        const c = await pool13.connect();
        try {
          for (const metric of metricsToFlush) {
            await c.query(
              `INSERT INTO ai_model_metrics 
           (tenant_id, model_name, model_version, operation_type, input_tokens, 
            output_tokens, latency_ms, confidence_score, cost_cents)
           VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)`,
              [
                metric.tenantId,
                metric.modelName,
                metric.modelVersion,
                metric.operationType,
                metric.inputTokens,
                metric.outputTokens,
                metric.latencyMs,
                metric.confidenceScore,
                metric.costCents
              ]
            );
          }
        } catch (error) {
          console.error("Failed to flush AI metrics:", error);
          this.metricsBuffer.unshift(...metricsToFlush);
        } finally {
          c.release();
        }
      }
      /**
       * Record drift metric
       */
      async recordDriftMetric(metric) {
        const c = await pool13.connect();
        try {
          await c.query(
            `INSERT INTO ai_drift_metrics 
         (tenant_id, model_name, drift_type, drift_score, threshold_exceeded, 
          sample_size, baseline_period_start, baseline_period_end)
         VALUES ($1, $2, $3, $4, $5, $6, $7, $8)`,
            [
              metric.tenantId,
              metric.modelName,
              metric.driftType,
              metric.driftScore,
              metric.driftScore > metric.threshold,
              metric.sampleSize,
              metric.baselinePeriodStart,
              metric.baselinePeriodEnd
            ]
          );
        } finally {
          c.release();
        }
      }
      /**
       * Calculate Kolmogorov-Smirnov statistic for drift detection
       */
      calculateKSStatistic(sample1, sample2) {
        const combined = [...sample1, ...sample2].sort((a, b) => a - b);
        let maxDiff = 0;
        for (const value of combined) {
          const cdf1 = sample1.filter((x) => x <= value).length / sample1.length;
          const cdf2 = sample2.filter((x) => x <= value).length / sample2.length;
          const diff = Math.abs(cdf1 - cdf2);
          maxDiff = Math.max(maxDiff, diff);
        }
        return maxDiff;
      }
    };
    aiPerformanceMonitor = AIPerformanceMonitor.getInstance();
  }
});

// src/monitoring/cache-optimizer.ts
import { Pool as Pool14 } from "pg";
import { createHash as createHash20 } from "crypto";
var pool14, CacheOptimizer, cacheOptimizer;
var init_cache_optimizer = __esm({
  "src/monitoring/cache-optimizer.ts"() {
    "use strict";
    pool14 = new Pool14({ connectionString: process.env.DATABASE_URL });
    CacheOptimizer = class _CacheOptimizer {
      static instance;
      caches = /* @__PURE__ */ new Map();
      cacheStats = /* @__PURE__ */ new Map();
      metricsBuffer = [];
      constructor() {
        setInterval(() => this.optimizeCaches(), 3e5);
        setInterval(() => this.flushMetrics(), 3e4);
      }
      static getInstance() {
        if (!_CacheOptimizer.instance) {
          _CacheOptimizer.instance = new _CacheOptimizer();
        }
        return _CacheOptimizer.instance;
      }
      /**
       * Get value from cache with performance tracking
       */
      async get(tenantId, cacheType, key) {
        const startTime2 = Date.now();
        const cacheKey = `${tenantId}:${cacheType}`;
        const cache = this.caches.get(cacheKey);
        const keyHash = this.hashKey(key);
        let value = null;
        let operation = "miss";
        if (cache?.has(key)) {
          value = cache.get(key);
          operation = "hit";
          this.incrementHits(cacheKey);
        } else {
          this.incrementMisses(cacheKey);
        }
        const latencyMs = Date.now() - startTime2;
        this.recordMetric({
          tenantId,
          cacheType,
          operation,
          keyHash,
          latencyMs
        });
        return value;
      }
      /**
       * Set value in cache with optimization
       */
      async set(tenantId, cacheType, key, value, ttlSeconds) {
        const startTime2 = Date.now();
        const cacheKey = `${tenantId}:${cacheType}`;
        const keyHash = this.hashKey(key);
        if (!this.caches.has(cacheKey)) {
          this.caches.set(cacheKey, /* @__PURE__ */ new Map());
        }
        const cache = this.caches.get(cacheKey);
        const maxSize = this.getCacheConfig(cacheType).maxSize;
        if (cache.size >= maxSize) {
          await this.evictEntries(tenantId, cacheType, 1);
        }
        const entry = {
          value,
          timestamp: Date.now(),
          ttl: ttlSeconds || this.getCacheConfig(cacheType).ttlSeconds,
          accessCount: 0
        };
        cache.set(key, entry);
        const latencyMs = Date.now() - startTime2;
        const sizeBytes = this.estimateSize(value);
        this.recordMetric({
          tenantId,
          cacheType,
          operation: "write",
          keyHash,
          latencyMs,
          sizeBytes,
          ttlSeconds: entry.ttl
        });
      }
      /**
       * Get cache hit rate
       */
      getHitRate(tenantId, cacheType) {
        const cacheKey = `${tenantId}:${cacheType}`;
        const stats = this.cacheStats.get(cacheKey);
        if (!stats || stats.hits + stats.misses === 0) {
          return 0;
        }
        return stats.hits / (stats.hits + stats.misses);
      }
      /**
       * Get cache performance analytics
       */
      async getCacheAnalytics(tenantId, hoursBack = 24) {
        const c = await pool14.connect();
        try {
          const hitRateResult = await c.query(
            `SELECT 
           cache_type,
           COUNT(*) FILTER (WHERE operation = 'hit') as hits,
           COUNT(*) FILTER (WHERE operation = 'miss') as misses
         FROM cache_metrics 
         WHERE tenant_id = $1 AND timestamp >= now() - interval '${hoursBack} hours'
         GROUP BY cache_type`,
            [tenantId]
          );
          const hitRates = {};
          for (const row of hitRateResult.rows) {
            const total = parseInt(row.hits) + parseInt(row.misses);
            hitRates[row.cache_type] = total > 0 ? parseInt(row.hits) / total : 0;
          }
          const latencyResult = await c.query(
            `SELECT cache_type, AVG(latency_ms) as avg_latency
         FROM cache_metrics 
         WHERE tenant_id = $1 AND timestamp >= now() - interval '${hoursBack} hours'
         GROUP BY cache_type`,
            [tenantId]
          );
          const avgLatency = {};
          for (const row of latencyResult.rows) {
            avgLatency[row.cache_type] = parseFloat(row.avg_latency);
          }
          const sizeResult = await c.query(
            `SELECT cache_type, SUM(size_bytes) / (1024*1024) as total_mb
         FROM cache_metrics 
         WHERE tenant_id = $1 AND operation = 'write' 
         AND timestamp >= now() - interval '${hoursBack} hours'
         GROUP BY cache_type`,
            [tenantId]
          );
          const totalSizeMB = {};
          for (const row of sizeResult.rows) {
            totalSizeMB[row.cache_type] = parseFloat(row.total_mb) || 0;
          }
          const evictionResult = await c.query(
            `SELECT cache_type, COUNT(*) as evictions
         FROM cache_metrics 
         WHERE tenant_id = $1 AND operation = 'eviction'
         AND timestamp >= now() - interval '${hoursBack} hours'
         GROUP BY cache_type`,
            [tenantId]
          );
          const evictionRates = {};
          for (const row of evictionResult.rows) {
            evictionRates[row.cache_type] = parseInt(row.evictions);
          }
          return { hitRates, avgLatency, totalSizeMB, evictionRates };
        } finally {
          c.release();
        }
      }
      /**
       * Optimize caches based on performance data
       */
      async optimizeCaches() {
        for (const [cacheKey, cache] of this.caches.entries()) {
          const [tenantId, cacheType] = cacheKey.split(":");
          const now = Date.now();
          for (const [key, entry] of cache.entries()) {
            if (now - entry.timestamp > entry.ttl * 1e3) {
              cache.delete(key);
              this.recordMetric({
                tenantId,
                cacheType,
                operation: "eviction",
                keyHash: this.hashKey(key),
                latencyMs: 0
              });
            }
          }
          const hitRate = this.getHitRate(tenantId, cacheType);
          const config = this.getCacheConfig(cacheType);
          if (hitRate < 0.5 && cache.size > config.maxSize * 0.5) {
            await this.evictEntries(tenantId, cacheType, Math.floor(cache.size * 0.2));
          }
        }
      }
      /**
       * Evict entries based on policy
       */
      async evictEntries(tenantId, cacheType, count3) {
        const cacheKey = `${tenantId}:${cacheType}`;
        const cache = this.caches.get(cacheKey);
        if (!cache) return;
        const config = this.getCacheConfig(cacheType);
        const entries = Array.from(cache.entries());
        let toEvict = [];
        switch (config.evictionPolicy) {
          case "lru":
            toEvict = entries.sort(([, a], [, b]) => a.timestamp - b.timestamp).slice(0, count3).map(([key]) => key);
            break;
          case "lfu":
            toEvict = entries.sort(([, a], [, b]) => a.accessCount - b.accessCount).slice(0, count3).map(([key]) => key);
            break;
          case "ttl":
            toEvict = entries.sort(([, a], [, b]) => a.ttl - b.ttl).slice(0, count3).map(([key]) => key);
            break;
        }
        for (const key of toEvict) {
          cache.delete(key);
          this.recordMetric({
            tenantId,
            cacheType,
            operation: "eviction",
            keyHash: this.hashKey(key),
            latencyMs: 0
          });
        }
      }
      getCacheConfig(cacheType) {
        const configs = {
          ai_response: {
            ttlSeconds: 3600,
            // 1 hour
            maxSize: 1e4,
            evictionPolicy: "lru",
            compressionEnabled: true
          },
          vendor_data: {
            ttlSeconds: 86400,
            // 24 hours
            maxSize: 5e3,
            evictionPolicy: "ttl",
            compressionEnabled: false
          },
          document_analysis: {
            ttlSeconds: 7200,
            // 2 hours
            maxSize: 1e3,
            evictionPolicy: "lfu",
            compressionEnabled: true
          }
        };
        return configs[cacheType] || configs.ai_response;
      }
      hashKey(key) {
        return createHash20("sha256").update(key).digest("hex").substring(0, 16);
      }
      estimateSize(value) {
        return JSON.stringify(value).length;
      }
      incrementHits(cacheKey) {
        const stats = this.cacheStats.get(cacheKey) || { hits: 0, misses: 0 };
        stats.hits++;
        this.cacheStats.set(cacheKey, stats);
      }
      incrementMisses(cacheKey) {
        const stats = this.cacheStats.get(cacheKey) || { hits: 0, misses: 0 };
        stats.misses++;
        this.cacheStats.set(cacheKey, stats);
      }
      recordMetric(metric) {
        this.metricsBuffer.push(metric);
      }
      async flushMetrics() {
        if (this.metricsBuffer.length === 0) return;
        const metricsToFlush = [...this.metricsBuffer];
        this.metricsBuffer = [];
        const c = await pool14.connect();
        try {
          for (const metric of metricsToFlush) {
            await c.query(
              `INSERT INTO cache_metrics 
           (tenant_id, cache_type, operation, key_hash, latency_ms, size_bytes, ttl_seconds)
           VALUES ($1, $2, $3, $4, $5, $6, $7)`,
              [
                metric.tenantId,
                metric.cacheType,
                metric.operation,
                metric.keyHash,
                metric.latencyMs,
                metric.sizeBytes,
                metric.ttlSeconds
              ]
            );
          }
        } catch (error) {
          console.error("Failed to flush cache metrics:", error);
          this.metricsBuffer.unshift(...metricsToFlush);
        } finally {
          c.release();
        }
      }
    };
    cacheOptimizer = CacheOptimizer.getInstance();
  }
});

// src/monitoring/alert-manager.ts
import { Pool as Pool15 } from "pg";
import { randomUUID as randomUUID24 } from "crypto";
var pool15, AlertManager, alertManager;
var init_alert_manager = __esm({
  "src/monitoring/alert-manager.ts"() {
    "use strict";
    pool15 = new Pool15({ connectionString: process.env.DATABASE_URL });
    AlertManager = class _AlertManager {
      static instance;
      alertRules = /* @__PURE__ */ new Map();
      activeAlerts = /* @__PURE__ */ new Map();
      pendingAlerts = /* @__PURE__ */ new Map();
      constructor() {
        setInterval(() => this.loadAlertRules(), 6e4);
        setInterval(() => this.evaluateAlerts(), 3e4);
        setInterval(() => this.autoResolveAlerts(), 3e5);
        this.loadAlertRules();
      }
      static getInstance() {
        if (!_AlertManager.instance) {
          _AlertManager.instance = new _AlertManager();
        }
        return _AlertManager.instance;
      }
      /**
       * Create a new alert
       */
      async createAlert(alert) {
        const alertId = alert.id || randomUUID24();
        const duplicateKey = `${alert.tenantId}:${alert.alertType}:${alert.title}`;
        if (this.activeAlerts.has(duplicateKey)) {
          return this.activeAlerts.get(duplicateKey).id;
        }
        const c = await pool15.connect();
        try {
          const columnCheck = await c.query(
            `SELECT column_name FROM information_schema.columns 
         WHERE table_name = 'system_alerts' AND column_name IN ('tenant_id', 'alert_type')`
          );
          const hasColumns = columnCheck.rows.map((r) => r.column_name);
          if (hasColumns.includes("tenant_id") && hasColumns.includes("alert_type")) {
            await c.query(
              `INSERT INTO system_alerts 
           (id, tenant_id, alert_type, severity, title, description, metric_value, threshold_value)
           VALUES ($1, $2, $3, $4, $5, $6, $7, $8)`,
              [
                alertId,
                alert.tenantId,
                alert.alertType,
                alert.severity,
                alert.title,
                alert.description,
                alert.metricValue,
                alert.thresholdValue
              ]
            );
          } else {
            await c.query(
              `INSERT INTO system_alerts 
           (severity, component, message, details)
           VALUES ($1, $2, $3, $4)`,
              [
                alert.severity,
                alert.alertType,
                alert.title,
                JSON.stringify({
                  description: alert.description,
                  metricValue: alert.metricValue,
                  thresholdValue: alert.thresholdValue,
                  tenantId: alert.tenantId
                })
              ]
            );
          }
          alert.id = alertId;
          this.activeAlerts.set(duplicateKey, alert);
          await this.sendNotifications(alert);
          return alertId;
        } finally {
          c.release();
        }
      }
      /**
       * Acknowledge an alert
       */
      async acknowledgeAlert(alertId, userId) {
        const c = await pool15.connect();
        try {
          await c.query(
            `UPDATE system_alerts 
         SET acknowledged = true, acknowledged_at = now()
         WHERE id = $1`,
            [alertId]
          );
          for (const [key, alert] of this.activeAlerts.entries()) {
            if (alert.id === alertId) {
              this.activeAlerts.delete(key);
              break;
            }
          }
        } finally {
          c.release();
        }
      }
      /**
       * Resolve an alert
       */
      async resolveAlert(alertId, userId) {
        const c = await pool15.connect();
        try {
          await c.query(
            `UPDATE system_alerts 
         SET resolved = true, resolved_at = now()
         WHERE id = $1`,
            [alertId]
          );
          for (const [key, alert] of this.activeAlerts.entries()) {
            if (alert.id === alertId) {
              this.activeAlerts.delete(key);
              break;
            }
          }
        } finally {
          c.release();
        }
      }
      /**
       * Get active alerts for tenant
       */
      async getActiveAlerts(tenantId) {
        const c = await pool15.connect();
        try {
          const columnCheck = await c.query(
            `SELECT column_name FROM information_schema.columns 
         WHERE table_name = 'system_alerts' AND column_name IN ('tenant_id', 'resolved')`
          );
          const hasColumns = columnCheck.rows.map((r) => r.column_name);
          if (!hasColumns.includes("tenant_id") || !hasColumns.includes("resolved")) {
            const result2 = await c.query(
              `SELECT id, severity, component as alert_type, message as title, 
           details, acknowledged, created_at
           FROM system_alerts 
           WHERE acknowledged = false
           ORDER BY created_at DESC
           LIMIT 10`
            );
            return result2.rows.map((row) => ({
              id: row.id?.toString() || "unknown",
              tenantId,
              alertType: row.alert_type || "performance",
              severity: row.severity || "info",
              title: row.title || "System Alert",
              description: row.details ? JSON.stringify(row.details) : "No description",
              acknowledged: row.acknowledged || false,
              resolved: false
            }));
          }
          const result = await c.query(
            `SELECT * FROM system_alerts 
         WHERE tenant_id = $1 AND resolved = false
         ORDER BY created_at DESC`,
            [tenantId]
          );
          return result.rows.map((row) => ({
            id: row.id,
            tenantId: row.tenant_id,
            alertType: row.alert_type,
            severity: row.severity,
            title: row.title,
            description: row.description,
            metricValue: row.metric_value,
            thresholdValue: row.threshold_value,
            acknowledged: row.acknowledged,
            resolved: row.resolved
          }));
        } finally {
          c.release();
        }
      }
      /**
       * Check metric against thresholds and create alerts
       */
      async checkMetricThreshold(tenantId, metricType, value, tags = {}) {
        const rules = this.alertRules.get(tenantId) || [];
        for (const rule of rules) {
          if (!rule.enabled || rule.metricType !== metricType) continue;
          const shouldAlert = this.evaluateCondition(value, rule.condition, rule.threshold);
          if (shouldAlert) {
            const pendingKey = `${tenantId}:${rule.id}`;
            const pending = this.pendingAlerts.get(pendingKey);
            const now = Date.now();
            if (!pending) {
              this.pendingAlerts.set(pendingKey, { count: 1, since: now });
            } else {
              pending.count++;
              if (now - pending.since >= rule.duration * 1e3) {
                await this.createAlert({
                  tenantId,
                  alertType: this.getAlertType(metricType),
                  severity: rule.severity,
                  title: `${rule.name} Threshold Exceeded`,
                  description: `${metricType} value ${value} ${rule.condition} threshold ${rule.threshold}`,
                  metricValue: value,
                  thresholdValue: rule.threshold,
                  tags
                });
                this.pendingAlerts.delete(pendingKey);
              }
            }
          } else {
            this.pendingAlerts.delete(`${tenantId}:${rule.id}`);
          }
        }
      }
      /**
       * Get alert statistics
       */
      async getAlertStats(tenantId, hoursBack = 24) {
        const c = await pool15.connect();
        try {
          const countResult = await c.query(
            `SELECT 
           COUNT(*) as total,
           COUNT(*) FILTER (WHERE severity = 'critical') as critical
         FROM system_alerts 
         WHERE tenant_id = $1 AND created_at >= now() - interval '${hoursBack} hours'`,
            [tenantId]
          );
          const counts = countResult.rows[0];
          const resolutionResult = await c.query(
            `SELECT AVG(EXTRACT(EPOCH FROM (resolved_at - created_at))) as avg_resolution_seconds
         FROM system_alerts 
         WHERE tenant_id = $1 AND resolved = true 
         AND created_at >= now() - interval '${hoursBack} hours'`,
            [tenantId]
          );
          const avgResolutionSeconds = parseFloat(resolutionResult.rows[0].avg_resolution_seconds) || 0;
          const typesResult = await c.query(
            `SELECT alert_type, COUNT(*) as count
         FROM system_alerts 
         WHERE tenant_id = $1 AND created_at >= now() - interval '${hoursBack} hours'
         GROUP BY alert_type
         ORDER BY count DESC
         LIMIT 10`,
            [tenantId]
          );
          const topAlertTypes = typesResult.rows.map((row) => ({
            type: row.alert_type,
            count: parseInt(row.count)
          }));
          return {
            totalAlerts: parseInt(counts.total),
            criticalAlerts: parseInt(counts.critical),
            averageResolutionTime: avgResolutionSeconds,
            topAlertTypes
          };
        } finally {
          c.release();
        }
      }
      /**
       * Load alert rules from database
       */
      async loadAlertRules() {
        const defaultRules = {
          "default": [
            {
              id: "ai_latency_high",
              tenantId: "default",
              name: "High AI Latency",
              metricType: "ai_latency",
              condition: "gt",
              threshold: 5e3,
              // 5 seconds
              duration: 180,
              // 3 minutes
              severity: "warning",
              enabled: true,
              notifications: ["email"]
            },
            {
              id: "error_rate_high",
              tenantId: "default",
              name: "High Error Rate",
              metricType: "error_rate",
              condition: "gt",
              threshold: 0.05,
              // 5%
              duration: 300,
              // 5 minutes
              severity: "critical",
              enabled: true,
              notifications: ["email", "slack"]
            }
          ]
        };
        for (const [tenantId, rules] of Object.entries(defaultRules)) {
          this.alertRules.set(tenantId, rules);
        }
      }
      /**
       * Evaluate alert conditions periodically
       */
      async evaluateAlerts() {
      }
      /**
       * Auto-resolve stale alerts
       */
      async autoResolveAlerts() {
        const staleThreshold = 24 * 60 * 60 * 1e3;
        const now = Date.now();
        for (const [key, alert] of this.activeAlerts.entries()) {
          if (alert.severity === "info" && alert.id) {
            await this.resolveAlert(alert.id);
          }
        }
      }
      /**
       * Send notifications for alert
       */
      async sendNotifications(alert) {
        console.log(`Alert created: ${alert.severity} - ${alert.title}`);
      }
      evaluateCondition(value, condition, threshold) {
        switch (condition) {
          case "gt":
            return value > threshold;
          case "lt":
            return value < threshold;
          case "eq":
            return value === threshold;
          case "ne":
            return value !== threshold;
          default:
            return false;
        }
      }
      getAlertType(metricType) {
        if (metricType.includes("latency") || metricType.includes("throughput")) {
          return "performance";
        } else if (metricType.includes("error")) {
          return "error_rate";
        } else if (metricType.includes("cpu") || metricType.includes("memory")) {
          return "resource";
        } else if (metricType.includes("drift")) {
          return "drift";
        }
        return "performance";
      }
    };
    alertManager = AlertManager.getInstance();
  }
});

// src/routes/monitoring.routes.ts
var monitoring_routes_exports = {};
__export(monitoring_routes_exports, {
  monitoringRouter: () => monitoringRouter
});
import { Router as Router53 } from "express";
import { Pool as Pool16 } from "pg";
function getTenantId2(req) {
  return req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
}
var pool16, monitoringRouter;
var init_monitoring_routes = __esm({
  "src/routes/monitoring.routes.ts"() {
    "use strict";
    init_ai_performance();
    init_cache_optimizer();
    init_alert_manager();
    pool16 = new Pool16({ connectionString: process.env.DATABASE_URL });
    monitoringRouter = Router53();
    monitoringRouter.get("/monitoring/ai/performance", async (req, res) => {
      try {
        const tenantId = getTenantId2(req);
        const { hours = 24, model } = req.query;
        if (model) {
          const stats = await aiPerformanceMonitor.getModelPerformanceStats(
            tenantId,
            model,
            parseInt(hours)
          );
          res.json({ model, stats });
        } else {
          const c = await pool16.connect();
          try {
            const result = await c.query(
              `SELECT DISTINCT model_name FROM ai_model_metrics 
           WHERE tenant_id = $1 AND timestamp >= now() - interval '${parseInt(hours)} hours'`,
              [tenantId]
            );
            const models = result.rows.map((row) => row.model_name);
            const allStats = {};
            for (const modelName of models) {
              allStats[modelName] = await aiPerformanceMonitor.getModelPerformanceStats(
                tenantId,
                modelName,
                parseInt(hours)
              );
            }
            res.json({ models: allStats });
          } finally {
            c.release();
          }
        }
      } catch (error) {
        console.error("AI performance monitoring error:", error);
        res.status(500).json({ error: "Failed to retrieve AI performance data" });
      }
    });
    monitoringRouter.get("/monitoring/pipeline/throughput", async (req, res) => {
      try {
        const tenantId = getTenantId2(req);
        const { hours = 24 } = req.query;
        const throughput = await aiPerformanceMonitor.getPipelineThroughput(
          tenantId,
          parseInt(hours)
        );
        res.json({ throughput });
      } catch (error) {
        console.error("Pipeline throughput error:", error);
        res.status(500).json({ error: "Failed to retrieve pipeline throughput" });
      }
    });
    monitoringRouter.get("/monitoring/cache/analytics", async (req, res) => {
      try {
        const tenantId = getTenantId2(req);
        const { hours = 24 } = req.query;
        const analytics = await cacheOptimizer.getCacheAnalytics(tenantId, parseInt(hours));
        res.json({ analytics });
      } catch (error) {
        console.error("Cache analytics error:", error);
        res.status(500).json({ error: "Failed to retrieve cache analytics" });
      }
    });
    monitoringRouter.get("/monitoring/cache/hit-rates", async (req, res) => {
      try {
        const tenantId = getTenantId2(req);
        const cacheTypes = ["ai_response", "vendor_data", "document_analysis"];
        const hitRates = {};
        for (const cacheType of cacheTypes) {
          hitRates[cacheType] = cacheOptimizer.getHitRate(tenantId, cacheType);
        }
        res.json({ hitRates });
      } catch (error) {
        console.error("Cache hit rates error:", error);
        res.status(500).json({ error: "Failed to retrieve cache hit rates" });
      }
    });
    monitoringRouter.get("/monitoring/alerts", async (req, res) => {
      try {
        const tenantId = getTenantId2(req);
        const alerts = await alertManager.getActiveAlerts(tenantId);
        res.json({ alerts });
      } catch (error) {
        console.error("Alerts retrieval error:", error);
        res.status(500).json({ error: "Failed to retrieve alerts" });
      }
    });
    monitoringRouter.post("/monitoring/alerts/:id/acknowledge", async (req, res) => {
      try {
        const { id } = req.params;
        const userId = req.user?.id || "system";
        await alertManager.acknowledgeAlert(id, userId);
        res.json({ message: "Alert acknowledged successfully" });
      } catch (error) {
        console.error("Alert acknowledgment error:", error);
        res.status(500).json({ error: "Failed to acknowledge alert" });
      }
    });
    monitoringRouter.post("/monitoring/alerts/:id/resolve", async (req, res) => {
      try {
        const { id } = req.params;
        const userId = req.user?.id || "system";
        await alertManager.resolveAlert(id, userId);
        res.json({ message: "Alert resolved successfully" });
      } catch (error) {
        console.error("Alert resolution error:", error);
        res.status(500).json({ error: "Failed to resolve alert" });
      }
    });
    monitoringRouter.get("/monitoring/alerts/stats", async (req, res) => {
      try {
        const tenantId = getTenantId2(req);
        const { hours = 24 } = req.query;
        const stats = await alertManager.getAlertStats(tenantId, parseInt(hours));
        res.json({ stats });
      } catch (error) {
        console.error("Alert stats error:", error);
        res.status(500).json({ error: "Failed to retrieve alert statistics" });
      }
    });
    monitoringRouter.get("/monitoring/resources", async (req, res) => {
      try {
        const tenantId = getTenantId2(req);
        const { hours = 1 } = req.query;
        const c = await pool16.connect();
        try {
          const result = await c.query(
            `SELECT 
           resource_type,
           AVG(measurement_value) as avg_value,
           MAX(measurement_value) as max_value,
           measurement_unit
         FROM resource_metrics 
         WHERE tenant_id = $1 AND timestamp >= now() - interval '${parseInt(hours)} hours'
         GROUP BY resource_type, measurement_unit
         ORDER BY resource_type`,
            [tenantId]
          );
          const resources = result.rows.map((row) => ({
            type: row.resource_type,
            avgValue: parseFloat(row.avg_value),
            maxValue: parseFloat(row.max_value),
            unit: row.measurement_unit
          }));
          res.json({ resources });
        } finally {
          c.release();
        }
      } catch (error) {
        console.error("Resource metrics error:", error);
        res.status(500).json({ error: "Failed to retrieve resource metrics" });
      }
    });
    monitoringRouter.get("/monitoring/dashboard", async (req, res) => {
      try {
        const tenantId = getTenantId2(req);
        const { hours = 24 } = req.query;
        const [
          aiPerformance,
          pipelineThroughput,
          cacheAnalytics,
          activeAlerts,
          alertStats
        ] = await Promise.all([
          aiPerformanceMonitor.getModelPerformanceStats(tenantId, "grok-2-1212", parseInt(hours)),
          aiPerformanceMonitor.getPipelineThroughput(tenantId, parseInt(hours)),
          cacheOptimizer.getCacheAnalytics(tenantId, parseInt(hours)),
          alertManager.getActiveAlerts(tenantId),
          alertManager.getAlertStats(tenantId, parseInt(hours))
        ]);
        res.json({
          dashboard: {
            aiPerformance,
            pipelineThroughput,
            cacheAnalytics,
            activeAlerts: activeAlerts.length,
            alertStats,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          }
        });
      } catch (error) {
        console.error("Dashboard data error:", error);
        res.status(500).json({ error: "Failed to retrieve dashboard data" });
      }
    });
    monitoringRouter.get("/monitoring/health", async (req, res) => {
      try {
        const tenantId = getTenantId2(req);
        const aiLatency = await aiPerformanceMonitor.getModelPerformanceStats(tenantId, "grok-2-1212", 1);
        const cacheHitRate = cacheOptimizer.getHitRate(tenantId, "ai_response");
        const activeAlerts = await alertManager.getActiveAlerts(tenantId);
        const health = {
          status: "healthy",
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          metrics: {
            aiLatency: aiLatency.avgLatency,
            cacheHitRate,
            activeAlerts: activeAlerts.length,
            criticalAlerts: activeAlerts.filter((a) => a.severity === "critical").length
          }
        };
        if (health.metrics.criticalAlerts > 0) {
          health.status = "critical";
        } else if (health.metrics.aiLatency > 5e3 || health.metrics.cacheHitRate < 0.5) {
          health.status = "degraded";
        }
        res.json(health);
      } catch (error) {
        console.error("Health check error:", error);
        res.status(500).json({
          status: "unhealthy",
          error: error.message,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
      }
    });
  }
});

// src/reliability/health.ts
var health_exports2 = {};
__export(health_exports2, {
  healthCheck: () => healthCheck
});
async function healthCheck(req, res) {
  const start = Date.now();
  const checks = [];
  let overallStatus = "healthy";
  try {
    const dbResult = await checkDatabase();
    checks.push(dbResult);
    if (dbResult.status === "unhealthy") overallStatus = "unhealthy";
    else if (dbResult.status === "degraded" && overallStatus === "healthy") overallStatus = "degraded";
    const mqResult = await checkMessageQueue();
    checks.push(mqResult);
    if (mqResult.status === "unhealthy") overallStatus = "unhealthy";
    else if (mqResult.status === "degraded" && overallStatus === "healthy") overallStatus = "degraded";
    const storageResult = await checkStorage();
    checks.push(storageResult);
    if (storageResult.status === "unhealthy") overallStatus = "unhealthy";
    else if (storageResult.status === "degraded" && overallStatus === "healthy") overallStatus = "degraded";
    const extResult = await checkExternalDependencies();
    checks.push(extResult);
    if (extResult.status === "unhealthy") overallStatus = "unhealthy";
    else if (extResult.status === "degraded" && overallStatus === "healthy") overallStatus = "degraded";
  } catch (error) {
    overallStatus = "unhealthy";
    checks.push({
      service: "health_check_system",
      status: "unhealthy",
      error: error instanceof Error ? error.message : String(error)
    });
  }
  const health = {
    status: overallStatus,
    timestamp: (/* @__PURE__ */ new Date()).toISOString(),
    version: process.env.npm_package_version || "1.0.0",
    deployment_color: process.env.DEPLOY_COLOR,
    rpo_minutes: Number(process.env.RPO_MINUTES || 5),
    rto_minutes: Number(process.env.RTO_MINUTES || 30),
    checks,
    uptime_seconds: Math.floor((Date.now() - startTime) / 1e3)
  };
  const statusCode = overallStatus === "healthy" ? 200 : overallStatus === "degraded" ? 200 : 503;
  res.status(statusCode).json(health);
}
async function checkDatabase() {
  const start = Date.now();
  try {
    const client5 = await pool.connect();
    try {
      await client5.query("SELECT 1");
      await client5.query("SELECT NOW()");
      const tableCheck = await client5.query(`
        SELECT COUNT(*) as table_count 
        FROM information_schema.tables 
        WHERE table_schema = 'public' 
        AND table_name IN ('loans', 'users', 'audit_logs')
      `);
      const tableCount = parseInt(tableCheck.rows[0].table_count);
      const latency = Date.now() - start;
      if (tableCount < 3) {
        return {
          service: "database",
          status: "unhealthy",
          latency_ms: latency,
          error: "Critical tables missing"
        };
      }
      return {
        service: "database",
        status: latency > 1e3 ? "degraded" : "healthy",
        latency_ms: latency,
        details: { table_count: tableCount }
      };
    } finally {
      client5.release();
    }
  } catch (error) {
    return {
      service: "database",
      status: "unhealthy",
      latency_ms: Date.now() - start,
      error: error instanceof Error ? error.message : String(error)
    };
  }
}
async function checkMessageQueue() {
  const start = Date.now();
  try {
    const mqUrl = process.env.CLOUDAMQP_URL;
    if (!mqUrl) {
      return {
        service: "message_queue",
        status: "degraded",
        latency_ms: Date.now() - start,
        error: "MQ URL not configured"
      };
    }
    new URL(mqUrl);
    return {
      service: "message_queue",
      status: "healthy",
      latency_ms: Date.now() - start
    };
  } catch (error) {
    return {
      service: "message_queue",
      status: "unhealthy",
      latency_ms: Date.now() - start,
      error: error instanceof Error ? error.message : String(error)
    };
  }
}
async function checkStorage() {
  const start = Date.now();
  try {
    const bucket = process.env.AWS_S3_BUCKET || process.env.AI_PIPELINE_BUCKET;
    if (!bucket) {
      return {
        service: "storage",
        status: "degraded",
        latency_ms: Date.now() - start,
        details: { message: "S3 bucket not configured" }
      };
    }
    return {
      service: "storage",
      status: "healthy",
      latency_ms: Date.now() - start,
      details: { bucket }
    };
  } catch (error) {
    return {
      service: "storage",
      status: "unhealthy",
      latency_ms: Date.now() - start,
      error: error instanceof Error ? error.message : String(error)
    };
  }
}
async function checkExternalDependencies() {
  const start = Date.now();
  try {
    const xaiKey = process.env.XAI_API_KEY;
    if (!xaiKey) {
      return {
        service: "external_dependencies",
        status: "degraded",
        latency_ms: Date.now() - start,
        details: { message: "AI provider not configured" }
      };
    }
    return {
      service: "external_dependencies",
      status: "healthy",
      latency_ms: Date.now() - start,
      details: { ai_provider: "configured" }
    };
  } catch (error) {
    return {
      service: "external_dependencies",
      status: "unhealthy",
      latency_ms: Date.now() - start,
      error: error instanceof Error ? error.message : String(error)
    };
  }
}
var startTime;
var init_health2 = __esm({
  "src/reliability/health.ts"() {
    "use strict";
    init_db();
    startTime = Date.now();
  }
});

// src/reliability/chaos.ts
var chaos_exports = {};
__export(chaos_exports, {
  CHAOS_TESTS: () => CHAOS_TESTS,
  ChaosEngine: () => ChaosEngine,
  chaosEngine: () => chaosEngine
});
var CHAOS_TESTS, ChaosEngine, chaosEngine;
var init_chaos = __esm({
  "src/reliability/chaos.ts"() {
    "use strict";
    init_db();
    CHAOS_TESTS = [
      {
        name: "db_connection_stress",
        description: "Stress test database connections",
        category: "database",
        severity: "medium",
        duration_seconds: 60
      },
      {
        name: "memory_pressure",
        description: "Simulate memory pressure",
        category: "memory",
        severity: "medium",
        duration_seconds: 30
      },
      {
        name: "cpu_spike",
        description: "Generate CPU load spike",
        category: "cpu",
        severity: "low",
        duration_seconds: 45
      },
      {
        name: "network_latency",
        description: "Simulate network latency",
        category: "network",
        severity: "low",
        duration_seconds: 120
      }
    ];
    ChaosEngine = class {
      activeTests = /* @__PURE__ */ new Map();
      async runChaosTest(testName) {
        const test = CHAOS_TESTS.find((t) => t.name === testName);
        if (!test) {
          throw new Error(`Unknown chaos test: ${testName}`);
        }
        if (this.activeTests.has(testName)) {
          throw new Error(`Chaos test ${testName} is already running`);
        }
        const result = {
          test: testName,
          started_at: (/* @__PURE__ */ new Date()).toISOString(),
          status: "running"
        };
        this.activeTests.set(testName, result);
        try {
          console.log(`[Chaos] Starting test: ${testName}`);
          switch (testName) {
            case "db_connection_stress":
              await this.dbConnectionStress(test.duration_seconds);
              break;
            case "memory_pressure":
              await this.memoryPressure(test.duration_seconds);
              break;
            case "cpu_spike":
              await this.cpuSpike(test.duration_seconds);
              break;
            case "network_latency":
              await this.networkLatency(test.duration_seconds);
              break;
            default:
              throw new Error(`Test implementation not found: ${testName}`);
          }
          result.status = "completed";
          result.completed_at = (/* @__PURE__ */ new Date()).toISOString();
          result.recovery_time_seconds = Math.floor(
            (new Date(result.completed_at).getTime() - new Date(result.started_at).getTime()) / 1e3
          );
          console.log(`[Chaos] Test completed: ${testName} in ${result.recovery_time_seconds}s`);
        } catch (error) {
          result.status = "failed";
          result.completed_at = (/* @__PURE__ */ new Date()).toISOString();
          result.error = error instanceof Error ? error.message : String(error);
          console.error(`[Chaos] Test failed: ${testName}`, error);
        } finally {
          this.activeTests.delete(testName);
        }
        return result;
      }
      async abortChaosTest(testName) {
        const result = this.activeTests.get(testName);
        if (result) {
          result.status = "aborted";
          result.completed_at = (/* @__PURE__ */ new Date()).toISOString();
          this.activeTests.delete(testName);
          console.log(`[Chaos] Test aborted: ${testName}`);
        }
      }
      getActiveTests() {
        return Array.from(this.activeTests.values());
      }
      async dbConnectionStress(duration) {
        const connections = [];
        const maxConnections = 10;
        try {
          for (let i = 0; i < maxConnections; i++) {
            const client5 = await pool.connect();
            connections.push(client5);
            client5.query("SELECT pg_sleep(0.1), generate_series(1, 1000)").catch(() => {
            });
          }
          await new Promise((resolve) => setTimeout(resolve, duration * 1e3));
        } finally {
          connections.forEach((client5) => {
            try {
              client5.release();
            } catch (e) {
            }
          });
        }
      }
      async memoryPressure(duration) {
        const memoryHogs = [];
        const chunkSize = 10 * 1024 * 1024;
        try {
          const endTime = Date.now() + duration * 1e3;
          while (Date.now() < endTime) {
            const chunk = Buffer.alloc(chunkSize);
            chunk.fill(0);
            memoryHogs.push(chunk);
            await new Promise((resolve) => setTimeout(resolve, 500));
            if (memoryHogs.length > 10) break;
          }
          const remainingTime = endTime - Date.now();
          if (remainingTime > 0) {
            await new Promise((resolve) => setTimeout(resolve, remainingTime));
          }
        } finally {
          memoryHogs.length = 0;
        }
      }
      async cpuSpike(duration) {
        const endTime = Date.now() + duration * 1e3;
        const workers = [];
        for (let i = 0; i < 2; i++) {
          workers.push(this.cpuIntensiveWork(endTime));
        }
        await Promise.all(workers);
      }
      async cpuIntensiveWork(endTime) {
        return new Promise((resolve) => {
          const work = () => {
            let result = 0;
            for (let i = 0; i < 1e6; i++) {
              result += Math.sqrt(i);
            }
            if (Date.now() < endTime) {
              setImmediate(work);
            } else {
              resolve();
            }
          };
          work();
        });
      }
      async networkLatency(duration) {
        const originalSetTimeout = global.setTimeout;
        const latencyMs = 100;
        global.setTimeout = function(callback2, delay, ...args) {
          return originalSetTimeout(callback2, delay + latencyMs, ...args);
        };
        try {
          await new Promise((resolve) => setTimeout(resolve, duration * 1e3));
        } finally {
          global.setTimeout = originalSetTimeout;
        }
      }
    };
    chaosEngine = new ChaosEngine();
  }
});

// server/utils/schema-validator.ts
var schema_validator_exports = {};
__export(schema_validator_exports, {
  runStartupValidations: () => runStartupValidations,
  validateEnvironmentVariables: () => validateEnvironmentVariables,
  validateSchema: () => validateSchema
});
import { sql as sql24 } from "drizzle-orm";
async function getDatabaseTables() {
  try {
    const result = await db.execute(sql24`
      SELECT table_name 
      FROM information_schema.tables 
      WHERE table_schema = 'public' 
      AND table_type = 'BASE TABLE'
      ORDER BY table_name
    `);
    return result.rows.map((row) => row.table_name);
  } catch (error) {
    logger4.error("Failed to get database tables", error);
    throw error;
  }
}
async function getTableColumns(tableName) {
  try {
    const result = await db.execute(sql24`
      SELECT 
        column_name,
        data_type,
        is_nullable,
        column_default
      FROM information_schema.columns 
      WHERE table_schema = 'public' 
      AND table_name = ${tableName}
      ORDER BY ordinal_position
    `);
    return result.rows.map((row) => ({
      column_name: row.column_name,
      data_type: row.data_type,
      is_nullable: row.is_nullable,
      column_default: row.column_default
    }));
  } catch (error) {
    logger4.error(`Failed to get columns for table ${tableName}`, error);
    throw error;
  }
}
function getSchemaTableNames() {
  const tables = [];
  for (const [key, value] of Object.entries(schema_exports)) {
    if (value && typeof value === "object" && "$" in value) {
      const tableConfig = value["$"];
      if (tableConfig && tableConfig.name) {
        tables.push(tableConfig.name);
      }
    }
  }
  return tables.sort();
}
async function validateSchema() {
  const issues = [];
  const warnings = [];
  try {
    console.log("[SchemaValidator] Starting schema validation...");
    const dbTables = await getDatabaseTables();
    const schemaTables = getSchemaTableNames();
    for (const table of schemaTables) {
      if (!dbTables.includes(table)) {
        issues.push(`Table '${table}' is defined in schema but missing in database`);
      }
    }
    for (const table of dbTables) {
      if (table.startsWith("_") || table === "drizzle" || table === "__drizzle_migrations") {
        continue;
      }
      if (!schemaTables.includes(table)) {
        warnings.push(`Table '${table}' exists in database but not defined in schema`);
      }
    }
    for (const tableName of schemaTables) {
      if (!dbTables.includes(tableName)) {
        continue;
      }
      const dbColumns = await getTableColumns(tableName);
      const dbColumnNames = dbColumns.map((c) => c.column_name);
      const schemaTable = Object.values(schema_exports).find((value) => {
        return value && typeof value === "object" && "$" in value && value["$"].name === tableName;
      });
      if (schemaTable) {
        const schemaColumns = [];
        for (const [key, value] of Object.entries(schemaTable)) {
          if (key !== "$" && value && typeof value === "object" && "name" in value) {
            schemaColumns.push(value.name);
          }
        }
        for (const col of schemaColumns) {
          if (!dbColumnNames.includes(col)) {
            issues.push(`Column '${tableName}.${col}' is defined in schema but missing in database`);
          }
        }
        for (const col of dbColumnNames) {
          if (!schemaColumns.includes(col)) {
            warnings.push(`Column '${tableName}.${col}' exists in database but not defined in schema`);
          }
        }
      }
    }
    if (issues.length > 0) {
      console.error("[SchemaValidator] Schema validation failed with issues:");
      issues.forEach((issue) => console.error(`  - ${issue}`));
    }
    if (warnings.length > 0) {
      console.warn("[SchemaValidator] Schema validation warnings:");
      warnings.forEach((warning) => console.warn(`  - ${warning}`));
    }
    if (issues.length === 0 && warnings.length === 0) {
      console.log("[SchemaValidator] Schema validation passed - all tables and columns match");
    }
    return {
      valid: issues.length === 0,
      issues,
      warnings
    };
  } catch (error) {
    logger4.error("Schema validation failed", error);
    return {
      valid: false,
      issues: [`Schema validation error: ${error instanceof Error ? error.message : "Unknown error"}`],
      warnings
    };
  }
}
function validateEnvironmentVariables() {
  const required = [
    "DATABASE_URL",
    "CLOUDAMQP_URL"
  ];
  const missing = [];
  for (const varName of required) {
    if (!process.env[varName]) {
      missing.push(varName);
    }
  }
  if (missing.length > 0) {
    console.error("[SchemaValidator] Missing required environment variables:", missing.join(", "));
  }
  return {
    valid: missing.length === 0,
    missing
  };
}
async function runStartupValidations() {
  console.log("[SchemaValidator] Starting validation process...");
  console.log("[SchemaValidator] Running startup validations...");
  const envValidation = validateEnvironmentVariables();
  if (!envValidation.valid) {
    console.error("[SchemaValidator] Environment validation failed - missing variables:", envValidation.missing.join(", "));
    return false;
  }
  console.log("[SchemaValidator] Environment variables validated");
  const schemaValidation = await validateSchema();
  if (!schemaValidation.valid) {
    console.error("[SchemaValidator] Schema validation failed - see issues above");
  }
  console.log("[SchemaValidator] Startup validations complete");
  return true;
}
var logger4;
var init_schema_validator = __esm({
  "server/utils/schema-validator.ts"() {
    "use strict";
    init_db();
    init_schema();
    init_logger();
    logger4 = new Logger("SchemaValidator");
  }
});

// server/migrations.ts
var migrations_exports = {};
__export(migrations_exports, {
  runMigrations: () => runMigrations
});
import { migrate } from "drizzle-orm/neon-http/migrator";
import path8 from "path";
async function runMigrations() {
  console.log("[Migration] Starting database migrations...");
  try {
    const migrationsFolder = path8.join(process.cwd(), "migrations");
    await migrate(db, {
      migrationsFolder,
      migrationsTable: "__drizzle_migrations"
      // Track applied migrations
    });
    console.log("[Migration] Database migrations completed successfully");
    await verifyDatabaseTables();
    console.log("[Migration] Running schema validation...");
    const { runStartupValidations: runStartupValidations2 } = await Promise.resolve().then(() => (init_schema_validator(), schema_validator_exports));
    await runStartupValidations2();
  } catch (error) {
    console.error("[Migration] Error running migrations:", error);
    if (error?.code === "42710") {
      console.warn("[Migration] Duplicate object detected (enum/type); continuing:", error.message);
      return;
    }
    if (process.env.NODE_ENV === "production") {
      console.error("[Migration] CRITICAL: Production migrations failed!");
    }
  }
}
async function verifyDatabaseTables() {
  try {
    const criticalTables = [
      "users",
      "roles",
      "user_roles",
      "auth_events",
      "login_attempts",
      "user_ip_allowlist",
      "sessions"
    ];
    for (const table of criticalTables) {
      const result = await db.execute(`
        SELECT EXISTS (
          SELECT FROM information_schema.tables 
          WHERE table_name = '${table}'
        );
      `);
      if (!result.rows[0]?.exists) {
        console.warn(`[Migration] Warning: Table '${table}' does not exist`);
      }
    }
    console.log("[Migration] Database table verification completed");
  } catch (error) {
    console.error("[Migration] Error verifying tables:", error);
  }
}
var init_migrations = __esm({
  "server/migrations.ts"() {
    "use strict";
    init_db();
  }
});

// src/monitoring/rmqPoller.ts
var rmqPoller_exports = {};
__export(rmqPoller_exports, {
  startRmqPoller: () => startRmqPoller
});
async function startRmqPoller(intervalMs = 15e3) {
  if (!process.env.RMQ_MGMT_URL) return;
  setInterval(async () => {
    try {
      const res = await fetch(`${process.env.RMQ_MGMT_URL}/queues/${encodeURIComponent(process.env.RMQ_VHOST || "/")}`, {
        headers: { "Authorization": "Basic " + Buffer.from(`${process.env.RMQ_MGMT_USER}:${process.env.RMQ_MGMT_PASS}`).toString("base64") }
      });
      if (!res.ok) return;
      const data = await res.json();
      for (const q of queuesToWatch) {
        const m = data.find((d2) => d2.name === q);
        if (m) {
          rmqQueueDepth.labels(q).set(m.messages ?? 0);
        }
        const dlq2 = `${q}.dlq`;
        const d = data.find((d0) => d0.name === dlq2);
        if (d) {
          rmqQueueDlqDepth.labels(q).set(d.messages ?? 0);
        }
      }
    } catch {
    }
  }, intervalMs).unref();
}
var queuesToWatch;
var init_rmqPoller = __esm({
  "src/monitoring/rmqPoller.ts"() {
    "use strict";
    init_metrics();
    queuesToWatch = [
      "loan.docs.uploaded.q",
      "loan.docs.chunked.q",
      "loan.ocr.completed.q",
      "loan.extract.completed.q",
      "loan.qc.start.q",
      "loan.qc.completed.q",
      "loan.export.request.q",
      "loan.export.start.q",
      "loan.export.completed.q",
      "notify.request.q",
      "notify.send.q",
      "notify.sent.q",
      "notify.failed.q"
    ];
  }
});

// server/crm/notification-service.ts
import { sql as sql25 } from "drizzle-orm";
import sgMail4 from "@sendgrid/mail";
import { ulid as ulid8 } from "ulid";
var CRMNotificationService;
var init_notification_service = __esm({
  "server/crm/notification-service.ts"() {
    "use strict";
    init_db();
    init_repo();
    init_render_service();
    if (process.env.SENDGRID_API_KEY) {
      sgMail4.setApiKey(process.env.SENDGRID_API_KEY);
    }
    CRMNotificationService = class {
      repo;
      renderer;
      constructor() {
        this.repo = new DocsRepo();
        this.renderer = new RenderService();
      }
      /**
       * Send or schedule a CRM notification
       */
      async sendNotification(request) {
        try {
          const template = await this.getOrCreateTemplate(request.type);
          if (!template) {
            throw new Error(`No template found for notification type: ${request.type}`);
          }
          const payload = this.buildPayload(request);
          if (request.scheduleFor && request.scheduleFor > /* @__PURE__ */ new Date()) {
            const noticeId = await this.scheduleNotice(request, template.template_id);
            return { success: true, noticeId };
          }
          const rendered = await this.renderer.renderDocument(
            {
              type: `crm_${request.type}`,
              template_id: template.template_id,
              payload
            },
            template
          );
          const docId = await this.repo.insertArtifact({
            type: `crm_${request.type}`,
            loan_id: request.loanId,
            template_id: template.template_id,
            payload_json: payload,
            inputs_hash: rendered.inputs_hash,
            pdf_hash: rendered.pdf_hash,
            pdf_bytes: rendered.pdf_bytes,
            size_bytes: rendered.size_bytes,
            event_id: ulid8()
          });
          await this.sendEmail(request, rendered.html, request.attachments);
          return { success: true, docId };
        } catch (error) {
          console.error("[CRM Notification] Error:", error);
          return {
            success: false,
            error: error instanceof Error ? error.message : "Unknown error"
          };
        }
      }
      /**
       * Build notification payload
       */
      buildPayload(request) {
        const basePayload = {
          loan_id: request.loanId,
          recipient: {
            email: request.recipientEmail,
            name: request.recipientName || request.recipientEmail
          },
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          ...request.data
        };
        switch (request.type) {
          case "task_assignment":
            return {
              ...basePayload,
              task: request.data.task,
              assignedBy: request.data.assignedBy,
              dueDate: request.data.dueDate,
              priority: request.data.priority
            };
          case "appointment_reminder":
            return {
              ...basePayload,
              appointment: request.data.appointment,
              location: request.data.location,
              startTime: request.data.startTime,
              endTime: request.data.endTime
            };
          case "task_overdue":
            return {
              ...basePayload,
              task: request.data.task,
              daysOverdue: request.data.daysOverdue,
              originalDueDate: request.data.originalDueDate
            };
          default:
            return basePayload;
        }
      }
      /**
       * Schedule a future notice
       */
      async scheduleNotice(request, templateId) {
        const noticeTemplateResult = await db.execute(sql25`
      INSERT INTO notice_template_v2 (
        name,
        trigger_code,
        html_template,
        subject_template,
        priority,
        delivery_channels
      )
      VALUES (
        ${`CRM ${request.type.replace("_", " ")}`},
        ${`crm.${request.type}`},
        ${this.getDefaultHtmlTemplate(request.type)},
        ${this.getDefaultSubject(request.type)},
        ${request.type === "task_overdue" ? "high" : "normal"},
        ${JSON.stringify(["email"])}
      )
      ON CONFLICT (trigger_code) 
      DO UPDATE SET updated_at = NOW()
      RETURNING notice_template_id
    `);
        const noticeTemplateId = noticeTemplateResult.rows[0].notice_template_id;
        const noticeId = await this.repo.scheduleNotice({
          loan_id: request.loanId,
          notice_template_id: noticeTemplateId,
          trigger_code: `crm.${request.type}`,
          params: request.data,
          scheduled_for: request.scheduleFor
        });
        return noticeId;
      }
      /**
       * Send email via SendGrid
       */
      async sendEmail(request, htmlContent, attachments) {
        const msg = {
          to: request.recipientEmail,
          from: process.env.SENDGRID_FROM_EMAIL || "noreply@loanserve.pro",
          subject: this.getDefaultSubject(request.type),
          html: htmlContent,
          attachments: attachments || []
        };
        await sgMail4.send(msg);
      }
      /**
       * Get or create template for notification type
       */
      async getOrCreateTemplate(type) {
        let template = await this.repo.getLatestTemplate(`crm_${type}`);
        if (!template) {
          await db.execute(sql25`
        INSERT INTO document_template (template_id, type, jurisdiction, version, engine, html_source, css_source)
        VALUES (
          ${`tmpl_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`},
          ${`crm_${type}`},
          NULL,
          1,
          'handlebars-html',
          ${this.getDefaultHtmlTemplate(type)},
          ${this.getDefaultCSS()}
        )
        ON CONFLICT DO NOTHING
      `);
          template = await this.repo.getLatestTemplate(`crm_${type}`);
        }
        return template;
      }
      /**
       * Get default HTML template for notification type
       */
      getDefaultHtmlTemplate(type) {
        const templates = {
          task_assignment: `<!DOCTYPE html>
<html>
<head><title>Task Assignment</title></head>
<body>
  <div class="container">
    <h1>New Task Assigned</h1>
    <p>Hello {{recipient.name}},</p>
    <p>A new task has been assigned to you:</p>
    <div class="task-details">
      <h2>{{task.title}}</h2>
      <p>{{task.description}}</p>
      <p><strong>Due Date:</strong> {{dueDate}}</p>
      <p><strong>Priority:</strong> {{priority}}</p>
      <p><strong>Assigned By:</strong> {{assignedBy}}</p>
    </div>
    <p>Loan ID: {{loan_id}}</p>
  </div>
</body>
</html>`,
          appointment_reminder: `<!DOCTYPE html>
<html>
<head><title>Appointment Reminder</title></head>
<body>
  <div class="container">
    <h1>Appointment Reminder</h1>
    <p>Hello {{recipient.name}},</p>
    <p>This is a reminder about your upcoming appointment:</p>
    <div class="appointment-details">
      <h2>{{appointment.title}}</h2>
      <p>{{appointment.description}}</p>
      <p><strong>Date:</strong> {{startTime}}</p>
      <p><strong>Location:</strong> {{location}}</p>
    </div>
    <p>Loan ID: {{loan_id}}</p>
  </div>
</body>
</html>`,
          task_overdue: `<!DOCTYPE html>
<html>
<head><title>Task Overdue</title></head>
<body>
  <div class="container">
    <h1>\u26A0\uFE0F Task Overdue</h1>
    <p>Hello {{recipient.name}},</p>
    <p>The following task is now <strong>{{daysOverdue}} days overdue</strong>:</p>
    <div class="task-details">
      <h2>{{task.title}}</h2>
      <p>{{task.description}}</p>
      <p><strong>Original Due Date:</strong> {{originalDueDate}}</p>
    </div>
    <p>Please complete this task as soon as possible.</p>
    <p>Loan ID: {{loan_id}}</p>
  </div>
</body>
</html>`,
          email_notification: `<!DOCTYPE html>
<html>
<head><title>{{subject}}</title></head>
<body>
  <div class="container">
    {{{content}}}
    <hr>
    <p class="footer">Loan ID: {{loan_id}}</p>
  </div>
</body>
</html>`,
          deal_update: `<!DOCTYPE html>
<html>
<head><title>Deal Update</title></head>
<body>
  <div class="container">
    <h1>Deal Status Update</h1>
    <p>Hello {{recipient.name}},</p>
    <p>There has been an update to your deal:</p>
    <div class="deal-details">
      <h2>{{deal.title}}</h2>
      <p><strong>Stage:</strong> {{deal.stage}}</p>
      <p><strong>Value:</strong> {{deal.value}}</p>
      <p><strong>Update:</strong> {{updateMessage}}</p>
    </div>
    <p>Loan ID: {{loan_id}}</p>
  </div>
</body>
</html>`
        };
        return templates[type] || templates.email_notification;
      }
      /**
       * Get default subject for notification type
       */
      getDefaultSubject(type) {
        const subjects = {
          task_assignment: "New Task Assigned",
          appointment_reminder: "Appointment Reminder",
          task_overdue: "\u26A0\uFE0F Task Overdue",
          email_notification: "Notification",
          deal_update: "Deal Status Update"
        };
        return subjects[type] || "CRM Notification";
      }
      /**
       * Get default CSS for CRM notifications
       */
      getDefaultCSS() {
        return `
body { 
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; 
  line-height: 1.6; 
  color: #333; 
  margin: 0; 
  padding: 0;
}
.container { 
  max-width: 600px; 
  margin: 0 auto; 
  padding: 20px;
}
h1 { 
  color: #2c3e50; 
  border-bottom: 2px solid #3498db; 
  padding-bottom: 10px;
}
h2 { 
  color: #34495e; 
  margin-top: 20px;
}
.task-details, .appointment-details, .deal-details {
  background: #f8f9fa;
  border-left: 4px solid #3498db;
  padding: 15px;
  margin: 20px 0;
}
.footer {
  margin-top: 30px;
  padding-top: 20px;
  border-top: 1px solid #ddd;
  color: #666;
  font-size: 0.9em;
}
strong { 
  color: #2c3e50; 
}`;
      }
    };
  }
});

// server/crm/check-overdue-tasks.ts
var check_overdue_tasks_exports = {};
__export(check_overdue_tasks_exports, {
  checkOverdueTasks: () => checkOverdueTasks,
  runCRMNotificationChecks: () => runCRMNotificationChecks,
  scheduleAppointmentReminders: () => scheduleAppointmentReminders
});
import { sql as sql26 } from "drizzle-orm";
async function checkOverdueTasks() {
  try {
    const now = /* @__PURE__ */ new Date();
    const yesterday = new Date(now.getTime() - 24 * 60 * 60 * 1e3);
    const overdueTasksResult = await db.execute(sql26`
      SELECT 
        t.id,
        t.title,
        t.description,
        t.loan_id,
        t.assigned_to,
        t.due_date,
        u.email as assignee_email,
        u.username as assignee_name,
        l.loan_number,
        EXTRACT(DAY FROM (NOW() - t.due_date::timestamp)) as days_overdue
      FROM crm_tasks t
      LEFT JOIN users u ON t.assigned_to = u.id
      LEFT JOIN loans l ON t.loan_id = l.id
      WHERE t.status = 'pending'
        AND t.due_date < NOW()
        AND t.assigned_to IS NOT NULL
        AND (
          NOT EXISTS (
            SELECT 1 FROM crm_activity a 
            WHERE a.related_id = t.id
              AND a.activity_type = 'overdue_notification'
              AND a.created_at > ${yesterday}
          )
        )
    `);
    console.log(`[CRM] Found ${overdueTasksResult.rows.length} overdue tasks to notify`);
    for (const task of overdueTasksResult.rows) {
      try {
        const notificationResult = await notificationService.sendNotification({
          type: "task_overdue",
          loanId: task.loan_id,
          recipientEmail: task.assignee_email,
          recipientName: task.assignee_name,
          data: {
            task: {
              title: task.title,
              description: task.description || "No description"
            },
            daysOverdue: task.days_overdue,
            originalDueDate: new Date(task.due_date).toISOString().split("T")[0],
            loanNumber: task.loan_number
          }
        });
        if (notificationResult.success) {
          await db.execute(sql26`
            INSERT INTO crm_activity (
              loan_id, 
              user_id, 
              activity_type, 
              activity_data, 
              related_id
            )
            VALUES (
              ${task.loan_id},
              ${task.assigned_to},
              'overdue_notification',
              ${JSON.stringify({
            description: `Overdue notification sent for task: ${task.title}`,
            daysOverdue: task.days_overdue,
            documentId: notificationResult.docId
          })},
              ${task.id}
            )
          `);
          console.log(`[CRM] Sent overdue notification for task ${task.id} to ${task.assignee_email}`);
        }
      } catch (error) {
        console.error(`[CRM] Failed to send overdue notification for task ${task.id}:`, error);
      }
    }
  } catch (error) {
    console.error("[CRM] Error checking overdue tasks:", error);
  }
}
async function scheduleAppointmentReminders() {
  try {
    const tomorrow = /* @__PURE__ */ new Date();
    tomorrow.setDate(tomorrow.getDate() + 1);
    tomorrow.setHours(0, 0, 0, 0);
    const dayAfter = new Date(tomorrow);
    dayAfter.setDate(dayAfter.getDate() + 1);
    const appointmentsResult = await db.execute(sql26`
      SELECT 
        a.id,
        a.title,
        a.description,
        a.location,
        a.start_time,
        a.end_time,
        a.loan_id,
        a.attendees,
        l.loan_number
      FROM crm_appointments a
      LEFT JOIN loans l ON a.loan_id = l.id
      WHERE a.start_time >= ${tomorrow}
        AND a.start_time < ${dayAfter}
        AND NOT EXISTS (
          SELECT 1 FROM crm_activity act 
          WHERE act.related_id = a.id
            AND act.activity_type = 'appointment_reminder'
        )
    `);
    console.log(`[CRM] Found ${appointmentsResult.rows.length} appointments to remind`);
    for (const appointment of appointmentsResult.rows) {
      try {
        const attendees = appointment.attendees || [];
        if (attendees.length > 0) {
          const usersResult = await db.execute(sql26`
            SELECT id, email, username 
            FROM users 
            WHERE id = ANY(${attendees.map(Number)})
          `);
          for (const user of usersResult.rows) {
            const reminderTime = new Date(tomorrow);
            reminderTime.setHours(9, 0, 0, 0);
            const notificationResult = await notificationService.sendNotification({
              type: "appointment_reminder",
              loanId: appointment.loan_id,
              recipientEmail: user.email,
              recipientName: user.username,
              data: {
                appointment: {
                  title: appointment.title,
                  description: appointment.description || "No description"
                },
                location: appointment.location || "TBD",
                startTime: new Date(appointment.start_time).toLocaleString(),
                endTime: appointment.end_time ? new Date(appointment.end_time).toLocaleString() : null,
                loanNumber: appointment.loan_number
              },
              scheduleFor: reminderTime
            });
            if (notificationResult.success) {
              await db.execute(sql26`
                INSERT INTO crm_activity (
                  loan_id, 
                  user_id, 
                  activity_type, 
                  activity_data, 
                  related_id
                )
                VALUES (
                  ${appointment.loan_id},
                  ${user.id},
                  'appointment_reminder',
                  ${JSON.stringify({
                description: `Reminder scheduled for appointment: ${appointment.title}`,
                scheduledFor: reminderTime.toISOString(),
                noticeId: notificationResult.noticeId
              })},
                  ${appointment.id}
                )
              `);
              console.log(`[CRM] Scheduled appointment reminder for ${user.email}`);
            }
          }
        }
      } catch (error) {
        console.error(`[CRM] Failed to schedule reminder for appointment ${appointment.id}:`, error);
      }
    }
  } catch (error) {
    console.error("[CRM] Error scheduling appointment reminders:", error);
  }
}
async function runCRMNotificationChecks() {
  console.log("[CRM] Running notification checks...");
  await Promise.all([
    checkOverdueTasks(),
    scheduleAppointmentReminders()
  ]);
  console.log("[CRM] Notification checks complete");
}
var notificationService;
var init_check_overdue_tasks = __esm({
  "server/crm/check-overdue-tasks.ts"() {
    "use strict";
    init_db();
    init_notification_service();
    notificationService = new CRMNotificationService();
  }
});

// src/metrics/metrics.ts
import client4 from "prom-client";
function collectMetrics(queue, status, durationMs) {
  queueProcessedTotal.labels(queue, status).inc();
  queueDuration.labels(queue, status).observe(durationMs / 1e3);
}
var queueProcessedTotal, queueDuration;
var init_metrics3 = __esm({
  "src/metrics/metrics.ts"() {
    "use strict";
    queueProcessedTotal = new client4.Counter({
      name: "queue_messages_processed_total",
      help: "Total number of messages processed by queue and status",
      labelNames: ["queue", "status"]
    });
    queueDuration = new client4.Histogram({
      name: "queue_processing_duration_seconds",
      help: "Processing duration for messages",
      labelNames: ["queue", "status"],
      buckets: [0.01, 0.1, 0.5, 1, 2, 5, 10]
    });
  }
});

// src/queues/consumer-utils.ts
async function startConsumer(conn, opts) {
  const channel = await conn.createConfirmChannel();
  await channel.prefetch(5);
  channel.consume(opts.queue, async (msg) => {
    if (!msg) return;
    const startTime2 = Date.now();
    let status = "success";
    try {
      const content = JSON.parse(msg.content.toString());
      const messageId = content.messageId ?? msg.properties?.messageId;
      const tenantId = content.tenantId ?? msg.properties?.headers?.tenantId;
      if (!messageId || !tenantId) throw new Error("Missing messageId/tenantId");
      console.log(`[${opts.queue}] Processing message ${messageId} for tenant ${tenantId}`);
      await withTenantClient(tenantId, async (client5) => {
        await opts.handler(content, { client: client5, msg });
      });
      channel.ack(msg);
    } catch (err) {
      console.error(`[${opts.queue}] error`, err);
      const isFatal = err.message?.includes("schema") || err.message?.includes("invalid");
      status = isFatal ? "fatal" : "transient";
      const route = isFatal ? dlq(opts.queue) : retry(opts.queue, "10s");
      channel.publish("", route, msg.content, { persistent: true });
      channel.nack(msg, false, false);
    } finally {
      collectMetrics(opts.queue, status, Date.now() - startTime2);
    }
  });
}
var init_consumer_utils = __esm({
  "src/queues/consumer-utils.ts"() {
    "use strict";
    init_withTenantClient();
    init_topology();
    init_metrics3();
  }
});

// src/workers/BoardingWorker.ts
var BoardingWorker_exports = {};
__export(BoardingWorker_exports, {
  setConnection: () => setConnection,
  startBoardingWorker: () => startBoardingWorker
});
function setConnection(conn) {
  connection = conn;
}
async function startBoardingWorker() {
  console.log("[BoardingWorker] Starting boarding worker...");
  if (!connection) {
    throw new Error("[BoardingWorker] Connection not set. Call setConnection() first.");
  }
  await startConsumer(connection, {
    queue: "loan.finalize.completed.q",
    handler: async (payload, helpers) => {
      try {
        const { tenantId, loanId, error } = payload;
        console.log(`[BoardingWorker] Processing finalize completion for loan ${loanId}`);
        if (!error) {
          const out = await boardLoan(tenantId, loanId);
          console.log(`[BoardingWorker] Loan ${loanId} boarded successfully:`, out);
        } else {
          console.log(`[BoardingWorker] Skipping boarding for loan ${loanId} due to finalize error:`, error);
        }
      } catch (e) {
        console.error(`[BoardingWorker] Error boarding loan:`, e);
        throw e;
      }
    }
  });
  await startConsumer(connection, {
    queue: "loan.board.request.q",
    handler: async (payload, helpers) => {
      try {
        const { tenantId, loanId } = payload;
        console.log(`[BoardingWorker] Processing manual boarding request for loan ${loanId}`);
        const out = await boardLoan(tenantId, loanId);
        console.log(`[BoardingWorker] Manual boarding for loan ${loanId} completed:`, out);
      } catch (e) {
        console.error(`[BoardingWorker] Error in manual boarding:`, e);
        throw e;
      }
    }
  });
  await startConsumer(connection, {
    queue: "status.update.v1",
    handler: async (payload, helpers) => {
      console.log("[BoardingWorker] Processed status update:", payload.type || "unknown");
    }
  });
  console.log("[BoardingWorker] Boarding worker started successfully");
}
var connection;
var init_BoardingWorker = __esm({
  "src/workers/BoardingWorker.ts"() {
    "use strict";
    init_consumer_utils();
    init_boarding();
  }
});

// src/queues/etl/etl-consumer.ts
async function initEtlConsumers(conn, publishFn) {
  console.log("[ETL Consumer] Initializing ETL consumers...");
  await startConsumer(conn, {
    queue: Queues.EtlSchedule,
    handler: async (envelope, deps) => {
      const { tenantId, payload, correlationId } = envelope;
      console.log(`[ETL Schedule] Processing schedule for tenant ${tenantId}, window: ${payload.window}`);
      try {
        const jobTypes = payload.jobTypes || ["loan_performance", "service_operations", "ai_performance"];
        for (const jobType of jobTypes) {
          const jobEnvelope = createEnvelope({
            tenantId,
            causationId: correlationId,
            idempotencyKey: createEtlIdempotencyKey(tenantId, jobType, (/* @__PURE__ */ new Date()).toISOString()),
            payload: {
              shardKey: `${jobType}:${tenantId}:${Date.now()}`,
              jobType,
              timeWindow: {
                start: new Date(Date.now() - 5 * 60 * 1e3).toISOString(),
                // 5 minutes ago
                end: (/* @__PURE__ */ new Date()).toISOString()
              },
              parameters: {}
            },
            actor: { service: "etl-scheduler" }
          });
          const routingKey = createRoutingKey(tenantId, "etl.job");
          await publishFn(Exchanges.Commands, routingKey, jobEnvelope);
          console.log(`[ETL Schedule] Queued ${jobType} job for tenant ${tenantId}`);
        }
      } catch (error) {
        console.error(`[ETL Schedule] Failed to process schedule for tenant ${tenantId}:`, error);
        throw error;
      }
    }
  });
  await startConsumer(conn, {
    queue: Queues.EtlJob,
    handler: async (envelope, deps) => {
      const { tenantId, payload, correlationId } = envelope;
      console.log(`[ETL Job] Processing ${payload.jobType} job for tenant ${tenantId}`);
      try {
        const etlPipeline2 = ETLPipeline.getInstance();
        let result;
        switch (payload.jobType) {
          case "loan_performance":
            result = await etlPipeline2.runLoanPerformanceETL();
            break;
          case "service_operations":
            result = await etlPipeline2.runServiceOperationsETL();
            break;
          case "ai_performance":
            result = await etlPipeline2.runAIPerformanceETL();
            break;
          default:
            throw new Error(`Unknown ETL job type: ${payload.jobType}`);
        }
        console.log(`[ETL Job] Completed ${payload.jobType} for tenant ${tenantId}:`, {
          status: result.status,
          recordsProcessed: result.recordsLoaded,
          duration: result.duration
        });
        const statusEnvelope = createEnvelope({
          tenantId,
          causationId: correlationId,
          payload: {
            resourceType: "etl_job",
            resourceId: payload.shardKey,
            status: result.status,
            progress: 100,
            message: `ETL job ${payload.jobType} completed`,
            metadata: {
              recordsExtracted: result.recordsExtracted,
              recordsTransformed: result.recordsTransformed,
              recordsLoaded: result.recordsLoaded,
              duration: result.duration
            }
          },
          actor: { service: "etl-consumer" }
        });
        const statusRoutingKey = createRoutingKey(tenantId, "status.etl.completed");
        await publishFn(Exchanges.Events, statusRoutingKey, statusEnvelope);
      } catch (error) {
        console.error(`[ETL Job] Failed ${payload.jobType} for tenant ${tenantId}:`, error);
        const errorEnvelope = createEnvelope({
          tenantId,
          causationId: correlationId,
          payload: {
            resourceType: "etl_job",
            resourceId: payload.shardKey,
            status: "failed",
            progress: 0,
            message: `ETL job ${payload.jobType} failed: ${error.message}`,
            metadata: { error: error.message }
          },
          actor: { service: "etl-consumer" }
        });
        const errorRoutingKey = createRoutingKey(tenantId, "status.etl.failed");
        await publishFn(Exchanges.Events, errorRoutingKey, errorEnvelope);
        throw error;
      }
    }
  });
  console.log("[ETL Consumer] ETL consumers initialized successfully");
}
var init_etl_consumer = __esm({
  "src/queues/etl/etl-consumer.ts"() {
    "use strict";
    init_consumer_utils();
    init_topology();
    init_envelope_helpers();
    init_etl_pipeline();
  }
});

// src/queues/etl/etl-scheduler.ts
function startEtlScheduler(publishFn) {
  if (globalScheduler) {
    console.log("[ETL] Scheduler already started");
    return globalScheduler;
  }
  globalScheduler = new EtlScheduler(publishFn);
  globalScheduler.start();
  return globalScheduler;
}
function stopEtlScheduler() {
  if (globalScheduler) {
    globalScheduler.stop();
    globalScheduler = null;
  }
}
var NIL3, DEFAULT_TENANT2, EtlScheduler, globalScheduler;
var init_etl_scheduler = __esm({
  "src/queues/etl/etl-scheduler.ts"() {
    "use strict";
    init_envelope_helpers();
    init_topology();
    NIL3 = "00000000-0000-0000-0000-000000000000";
    DEFAULT_TENANT2 = process.env.DEFAULT_TENANT_ID ?? NIL3;
    EtlScheduler = class {
      publishFunction;
      intervalId = null;
      lastMaintenanceRun = null;
      constructor(publishFn) {
        this.publishFunction = publishFn;
      }
      /**
       * Start the ETL scheduler (replaces setInterval timer)
       */
      start(intervalMs = 3e5) {
        if (this.intervalId) {
          console.log("[ETL Scheduler] Already running");
          return;
        }
        console.log(`[ETL Scheduler] Starting with ${intervalMs}ms interval`);
        this.intervalId = setInterval(async () => {
          await this.tickSchedule();
        }, intervalMs);
        this.tickSchedule().catch(console.error);
      }
      /**
       * Stop the ETL scheduler
       */
      stop() {
        if (this.intervalId) {
          clearInterval(this.intervalId);
          this.intervalId = null;
          console.log("[ETL Scheduler] Stopped");
        }
      }
      /**
       * Publish ETL schedule tick for all tenants
       */
      async tickSchedule() {
        try {
          console.log("[ETL Scheduler] Publishing schedule tick");
          const tenantId = "default";
          const dateKey = createDateKey();
          const etlEnvelope = createEnvelope({
            tenantId,
            idempotencyKey: createEtlIdempotencyKey(tenantId, "schedule", dateKey),
            payload: {
              window: "last_5m",
              jobTypes: ["loan_performance", "service_operations", "ai_performance"]
            },
            actor: { service: "etl-scheduler" }
          });
          const etlRoutingKey = createRoutingKey(tenantId, "etl.schedule");
          await this.publishFunction(Exchanges.Schedules, etlRoutingKey, etlEnvelope);
          console.log(`[ETL Scheduler] Published ETL schedule for tenant ${tenantId}`);
          if (this.shouldRunMaintenance()) {
            const maintenanceEnvelope = createEnvelope({
              tenantId,
              idempotencyKey: createEtlIdempotencyKey(tenantId, "maintenance", dateKey),
              payload: {
                window: "daily",
                jobTypes: ["retention_cleanup", "audit_maintenance"]
              },
              actor: { service: "etl-scheduler" }
            });
            const maintenanceRoutingKey = createRoutingKey(tenantId, "maintenance.schedule");
            await this.publishFunction(Exchanges.Schedules, maintenanceRoutingKey, maintenanceEnvelope);
            this.lastMaintenanceRun = /* @__PURE__ */ new Date();
            console.log(`[ETL Scheduler] Published maintenance schedule for tenant ${tenantId}`);
          }
        } catch (error) {
          console.error("[ETL Scheduler] Failed to publish schedule:", error);
        }
      }
      /**
       * Check if we should run daily maintenance tasks
       * Runs once per day at 2:00 AM server time
       */
      shouldRunMaintenance() {
        const now = /* @__PURE__ */ new Date();
        const currentHour = now.getHours();
        const currentMinute = now.getMinutes();
        const isMaintenanceWindow = currentHour === 2 && currentMinute < 5;
        if (!isMaintenanceWindow) return false;
        if (this.lastMaintenanceRun) {
          const today = now.toDateString();
          const lastRunDay = this.lastMaintenanceRun.toDateString();
          if (today === lastRunDay) return false;
        }
        return true;
      }
    };
    globalScheduler = null;
  }
});

// src/queues/payment/payment-consumer.ts
var payment_consumer_exports = {};
__export(payment_consumer_exports, {
  PaymentProcessingSchema: () => PaymentProcessingSchema,
  initPaymentConsumer: () => initPaymentConsumer
});
import { z as z19 } from "zod";
import { eq as eq36 } from "drizzle-orm";
import { ulid as ulid9 } from "ulid";
async function allocatePayment2(loanId, amountCents, paymentId) {
  console.log(`[Payment] Allocating payment ${paymentId} for loan ${loanId}: $${amountCents / 100}`);
  const allocation = {
    late_fees: Math.min(amountCents, 2500),
    // Max $25 late fees
    interest: Math.min(amountCents - 2500, Math.round(amountCents * 0.3)),
    principal: Math.max(0, amountCents - 2500 - Math.round(amountCents * 0.3) - Math.round(amountCents * 0.1)),
    escrow: Math.round(amountCents * 0.1)
  };
  const ledgerEntries2 = [];
  if (allocation.late_fees > 0) {
    ledgerEntries2.push({
      id: ulid9(),
      loanId,
      entryType: "payment_late_fees",
      amount: (allocation.late_fees / 100).toString(),
      description: `Late fee payment - ${paymentId}`,
      paymentId,
      createdAt: /* @__PURE__ */ new Date(),
      balance: "0"
      // Will be calculated
    });
  }
  if (allocation.interest > 0) {
    ledgerEntries2.push({
      id: ulid9(),
      loanId,
      entryType: "payment_interest",
      amount: (allocation.interest / 100).toString(),
      description: `Interest payment - ${paymentId}`,
      paymentId,
      createdAt: /* @__PURE__ */ new Date(),
      balance: "0"
    });
  }
  if (allocation.principal > 0) {
    ledgerEntries2.push({
      id: ulid9(),
      loanId,
      entryType: "payment_principal",
      amount: (allocation.principal / 100).toString(),
      description: `Principal payment - ${paymentId}`,
      paymentId,
      createdAt: /* @__PURE__ */ new Date(),
      balance: "0"
    });
  }
  if (allocation.escrow > 0) {
    ledgerEntries2.push({
      id: ulid9(),
      loanId,
      entryType: "escrow_credit",
      amount: (allocation.escrow / 100).toString(),
      description: `Escrow credit - ${paymentId}`,
      paymentId,
      createdAt: /* @__PURE__ */ new Date(),
      balance: "0"
    });
    await db.update(escrowAccounts2).set({
      currentBalance: (Number((await db.select().from(escrowAccounts2).where(eq36(escrowAccounts2.loanId, loanId)))[0]?.currentBalance || "0") + allocation.escrow / 100).toString()
    }).where(eq36(escrowAccounts2.loanId, loanId));
  }
  if (ledgerEntries2.length > 0) {
    await db.insert(loanLedger).values(ledgerEntries2);
  }
  console.log(`[Payment] Allocation complete:`, allocation);
  return allocation;
}
async function processPaymentMessage(message, publishEvent2) {
  console.log(`[Payment Consumer] Processing payment: ${message.payment_id}`);
  try {
    const payment = {
      id: message.payment_id,
      loanId: message.loan_id,
      amount: (message.amount_cents / 100).toString(),
      source: message.source,
      status: "processing",
      externalRef: message.external_ref,
      processorRef: message.processor_ref,
      submittedAt: message.submitted_at ? new Date(message.submitted_at) : /* @__PURE__ */ new Date(),
      submittedBy: message.submitted_by || 1,
      // Default system user
      // Source-specific fields
      accountNumberMasked: message.account_number_masked,
      routingNumberMasked: message.routing_number_masked,
      accountType: message.account_type,
      secCode: message.sec_code,
      traceNumber: message.trace_number,
      wireRef: message.wire_ref,
      senderRef: message.sender_ref,
      checkNumber: message.check_number,
      payerAccount: message.payer_account,
      cardLastFour: message.card_last_four,
      cardType: message.card_type,
      authCode: message.auth_code
    };
    await db.insert(payments).values(payment);
    console.log(`[Payment Consumer] Payment record created: ${message.payment_id}`);
    await allocatePayment2(message.loan_id, message.amount_cents, message.payment_id);
    await db.update(payments).set({ status: "processed", processedAt: /* @__PURE__ */ new Date() }).where(eq36(payments.id, message.payment_id));
    console.log(`[Payment Consumer] Payment processed successfully: ${message.payment_id}`);
    const processedEvent = createEnvelope({
      tenantId: "default",
      correlationId: ulid9(),
      payload: {
        eventType: "payment.processed",
        payment_id: message.payment_id,
        loan_id: message.loan_id,
        amount_cents: message.amount_cents,
        source: message.source,
        processed_at: (/* @__PURE__ */ new Date()).toISOString()
      }
    });
    await publishEvent2(Exchanges.Events, "payment.processed", processedEvent);
  } catch (error) {
    console.error(`[Payment Consumer] Error processing payment ${message.payment_id}:`, error);
    await db.update(payments).set({ status: "failed", errorMessage: error.message }).where(eq36(payments.id, message.payment_id));
    const failedEvent = createEnvelope({
      tenantId: "default",
      correlationId: ulid9(),
      payload: {
        eventType: "payment.failed",
        payment_id: message.payment_id,
        loan_id: message.loan_id,
        error: error.message,
        failed_at: (/* @__PURE__ */ new Date()).toISOString()
      }
    });
    await publishEvent2(Exchanges.Events, "payment.failed", failedEvent);
    throw error;
  }
}
async function initPaymentConsumer(connection2, publishEvent2) {
  const channel = await connection2.createChannel();
  await channel.prefetch(1);
  console.log("[Payment Consumer] Initializing payment processing consumer...");
  await channel.consume(ROUTING_KEYS.PAYMENT_PROCESS, async (msg) => {
    if (!msg) return;
    try {
      const envelope = JSON.parse(msg.content.toString());
      const message = validateMessage(envelope, PaymentProcessingSchema);
      console.log(`[Payment Consumer] Received payment processing message:`, {
        correlationId: envelope.correlationId,
        paymentId: message.payment_id,
        loanId: message.loan_id,
        amount: message.amount_cents
      });
      await processPaymentMessage(message, publishEvent2);
      channel.ack(msg);
      console.log(`[Payment Consumer] Payment processing completed: ${message.payment_id}`);
    } catch (error) {
      console.error("[Payment Consumer] Error processing message:", error);
      const retryCount = msg.properties.headers?.["x-retry-count"] || 0;
      if (retryCount < 3) {
        channel.nack(msg, false, false);
        console.log(`[Payment Consumer] Message rejected for retry (attempt ${retryCount + 1})`);
      } else {
        channel.nack(msg, false, false);
        console.log(`[Payment Consumer] Message sent to DLQ after ${retryCount + 1} attempts`);
      }
    }
  });
  console.log("[Payment Consumer] \u2705 Payment processing consumer initialized");
}
var PaymentProcessingSchema;
var init_payment_consumer = __esm({
  "src/queues/payment/payment-consumer.ts"() {
    "use strict";
    init_envelope_helpers();
    init_topology();
    init_db();
    init_schema();
    PaymentProcessingSchema = z19.object({
      payment_id: z19.string(),
      loan_id: z19.number(),
      source: z19.enum(["ach", "wire", "check", "card", "cash"]),
      amount_cents: z19.number().positive(),
      currency: z19.string().default("USD"),
      // ACH-specific fields
      account_number_masked: z19.string().optional(),
      routing_number_masked: z19.string().optional(),
      account_type: z19.enum(["checking", "savings"]).optional(),
      sec_code: z19.enum(["PPD", "CCD", "WEB", "TEL"]).optional(),
      trace_number: z19.string().optional(),
      // Wire fields
      wire_ref: z19.string().optional(),
      sender_ref: z19.string().optional(),
      // Check fields
      check_number: z19.string().optional(),
      payer_account: z19.string().optional(),
      // Card fields
      card_last_four: z19.string().optional(),
      card_type: z19.string().optional(),
      auth_code: z19.string().optional(),
      // Common fields
      external_ref: z19.string().optional(),
      processor_ref: z19.string().optional(),
      submitted_by: z19.number().optional(),
      // User ID
      submitted_at: z19.string().optional()
    });
  }
});

// server/services/grok-ai-service.ts
var grok_ai_service_exports = {};
__export(grok_ai_service_exports, {
  GrokAIService: () => GrokAIService,
  grokAIService: () => grokAIService
});
import Groq from "groq-sdk";
import crypto21 from "crypto";
import { randomUUID as randomUUID25 } from "crypto";
var GROQ_API_KEY, GrokAIService, grokAIService;
var init_grok_ai_service = __esm({
  "server/services/grok-ai-service.ts"() {
    "use strict";
    init_db();
    init_schema();
    GROQ_API_KEY = process.env.GROQ_API_KEY || "";
    GrokAIService = class {
      groq;
      modelName = "llama-3.3-70b-versatile";
      // Fast, accurate model
      constructor() {
        if (!GROQ_API_KEY) {
          console.warn("[GrokAI] API key not configured - AI features disabled");
        }
        this.groq = new Groq({
          apiKey: GROQ_API_KEY
        });
      }
      /**
       * Analyze a payment document using Grok AI
       */
      async analyzeDocument(documentContent, documentType) {
        console.log("[GrokAI] Analyzing document...");
        if (!GROQ_API_KEY) {
          return this.getFallbackAnalysis();
        }
        try {
          const content = Buffer.isBuffer(documentContent) ? documentContent.toString("base64") : documentContent;
          const prompt = this.buildDocumentAnalysisPrompt(content, documentType);
          const completion = await this.groq.chat.completions.create({
            messages: [
              {
                role: "system",
                content: "You are a financial document analysis expert specializing in mortgage loan servicing. Analyze documents to extract payment information with extreme precision. Always return valid JSON."
              },
              {
                role: "user",
                content: prompt
              }
            ],
            model: this.modelName,
            temperature: 0.1,
            // Low temperature for consistency
            max_tokens: 2e3,
            response_format: { type: "json_object" }
          });
          const response = completion.choices[0]?.message?.content;
          if (!response) {
            throw new Error("No response from Grok AI");
          }
          const result = JSON.parse(response);
          result.validationIssues = this.validateExtractedData(result.extractedData);
          console.log("[GrokAI] Document analysis complete:", {
            type: result.documentType,
            confidence: result.confidence,
            amount: result.extractedData.amount
          });
          return result;
        } catch (error) {
          console.error("[GrokAI] Document analysis failed:", error);
          return this.getFallbackAnalysis();
        }
      }
      /**
       * Classify a payment and determine processing path
       */
      async classifyPayment(amount, loanId, paymentData) {
        console.log(`[GrokAI] Classifying payment for loan ${loanId}`);
        if (!GROQ_API_KEY) {
          return this.getDefaultClassification();
        }
        try {
          const loanContext = await this.getLoanContext(loanId);
          const prompt = this.buildClassificationPrompt(amount, loanContext, paymentData);
          const completion = await this.groq.chat.completions.create({
            messages: [
              {
                role: "system",
                content: "You are a mortgage payment classification expert. Analyze payments to determine their category, risk level, and processing requirements. Consider compliance, fraud risk, and servicing rules. Return valid JSON."
              },
              {
                role: "user",
                content: prompt
              }
            ],
            model: this.modelName,
            temperature: 0.2,
            max_tokens: 1e3,
            response_format: { type: "json_object" }
          });
          const response = completion.choices[0]?.message?.content;
          if (!response) {
            throw new Error("No response from Grok AI");
          }
          const classification = JSON.parse(response);
          console.log("[GrokAI] Payment classified:", {
            category: classification.category,
            risk: classification.riskScore,
            recommendation: classification.processingRecommendation
          });
          return classification;
        } catch (error) {
          console.error("[GrokAI] Payment classification failed:", error);
          return this.getDefaultClassification();
        }
      }
      /**
       * Generate payment allocation recommendations
       */
      async recommendPaymentAllocation(amount, loanId, dueAmounts) {
        console.log(`[GrokAI] Generating allocation for loan ${loanId}`);
        if (!GROQ_API_KEY) {
          return this.getDefaultAllocation(amount, dueAmounts);
        }
        try {
          const prompt = `
        Allocate payment of $${amount.toFixed(2)} for a mortgage loan with:
        - Principal Due: $${dueAmounts.principal.toFixed(2)}
        - Interest Due: $${dueAmounts.interest.toFixed(2)}
        - Escrow Due: $${(dueAmounts.escrow || 0).toFixed(2)}
        - Fees Due: $${(dueAmounts.fees || 0).toFixed(2)}
        - Late Fees: $${(dueAmounts.lateFees || 0).toFixed(2)}
        
        Follow standard mortgage servicing waterfall:
        1. Late fees first
        2. Other fees
        3. Interest
        4. Escrow
        5. Principal
        
        Return as JSON with 'recommended' allocation, 'reasoning', and optional 'alternativeOptions'.
      `;
          const completion = await this.groq.chat.completions.create({
            messages: [
              {
                role: "system",
                content: "You are a mortgage servicing expert. Apply payment allocation rules precisely following regulatory requirements."
              },
              {
                role: "user",
                content: prompt
              }
            ],
            model: this.modelName,
            temperature: 0.1,
            max_tokens: 1e3,
            response_format: { type: "json_object" }
          });
          const response = completion.choices[0]?.message?.content;
          if (!response) {
            throw new Error("No response from Grok AI");
          }
          return JSON.parse(response);
        } catch (error) {
          console.error("[GrokAI] Allocation recommendation failed:", error);
          return this.getDefaultAllocation(amount, dueAmounts);
        }
      }
      /**
       * Detect anomalies in payment patterns
       */
      async detectAnomalies(loanId, currentPayment) {
        console.log(`[GrokAI] Detecting anomalies for loan ${loanId}`);
        if (!GROQ_API_KEY) {
          return { anomalies: [], overallRisk: 0 };
        }
        try {
          const paymentHistory = await this.getPaymentHistory(loanId);
          const prompt = `
        Analyze this payment for anomalies:
        Current Payment: ${JSON.stringify(currentPayment)}
        Payment History (last 12): ${JSON.stringify(paymentHistory)}
        
        Look for:
        - Unusual amounts (too high/low)
        - Suspicious timing patterns
        - Account changes
        - Potential fraud indicators
        - Compliance violations
        
        Return JSON with 'anomalies' array and 'overallRisk' score (0-100).
      `;
          const completion = await this.groq.chat.completions.create({
            messages: [
              {
                role: "system",
                content: "You are a fraud detection and compliance expert for mortgage servicing. Identify payment anomalies and assess risk."
              },
              {
                role: "user",
                content: prompt
              }
            ],
            model: this.modelName,
            temperature: 0.3,
            max_tokens: 1500,
            response_format: { type: "json_object" }
          });
          const response = completion.choices[0]?.message?.content;
          if (!response) {
            throw new Error("No response from Grok AI");
          }
          const result = JSON.parse(response);
          if (result.anomalies.length > 0) {
            console.warn("[GrokAI] Anomalies detected:", result.anomalies);
            await this.recordAnomalies(loanId, currentPayment, result.anomalies);
          }
          return result;
        } catch (error) {
          console.error("[GrokAI] Anomaly detection failed:", error);
          return { anomalies: [], overallRisk: 0 };
        }
      }
      /**
       * Process document with AI and create payment artifacts
       */
      async processDocumentForPayment(documentPath, documentContent, channel) {
        console.log("[GrokAI] Processing document for payment ingestion");
        const analysis = await this.analyzeDocument(documentContent);
        const ingestionId = randomUUID25();
        const idempotencyKey = `ai-doc-${crypto21.createHash("sha256").update(documentContent).digest("hex").substring(0, 16)}`;
        const loanId = analysis.extractedData.loanIdentifier || "unknown";
        const amount = analysis.extractedData.amount || 0;
        const classification = await this.classifyPayment(
          amount,
          loanId,
          analysis.extractedData
        );
        const anomalies = await this.detectAnomalies(loanId, {
          amount,
          ...analysis.extractedData
        });
        const envelope = {
          message_id: randomUUID25(),
          correlation_id: randomUUID25(),
          idempotency_key: idempotencyKey,
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          source: {
            channel,
            document: documentPath
          },
          payment: {
            amount_cents: Math.round(amount * 100),
            reference: analysis.extractedData.referenceNumber,
            value_date: analysis.extractedData.transactionDate
          },
          borrower: {
            loan_id: loanId,
            name: analysis.extractedData.payerName
          },
          ai_analysis: {
            document_type: analysis.documentType,
            confidence: analysis.confidence,
            payment_intent: analysis.paymentIntent,
            classification: classification.category,
            risk_score: classification.riskScore,
            anomaly_score: anomalies.overallRisk,
            processing_recommendation: classification.processingRecommendation
          }
        };
        await db.insert(paymentIngestions).values({
          id: ingestionId,
          idempotencyKey,
          channel,
          sourceReference: documentPath,
          rawPayloadHash: crypto21.createHash("sha256").update(documentContent).digest("hex"),
          artifactUri: [`file://${documentPath}`],
          artifactHash: [crypto21.createHash("sha256").update(documentContent).digest("hex")],
          receivedAt: /* @__PURE__ */ new Date(),
          normalizedEnvelope: envelope,
          status: classification.processingRecommendation === "auto_process" ? "normalized" : "received"
        });
        const artifactId = randomUUID25();
        await db.insert(paymentArtifacts).values({
          id: artifactId,
          ingestionId,
          type: analysis.documentType === "unknown" ? "document" : analysis.documentType,
          uri: `file://${documentPath}`,
          sha256: crypto21.createHash("sha256").update(documentContent).digest("hex"),
          sizeBytes: documentContent.length,
          mime: "application/pdf",
          sourceMetadata: {
            ai_analysis: analysis,
            classification,
            anomalies: anomalies.anomalies
          }
        });
        if (classification.processingRecommendation === "auto_process") {
          await db.insert(outboxMessages).values({
            id: randomUUID25(),
            aggregateType: "payments",
            aggregateId: ingestionId,
            eventType: "payment.ai.processed",
            payload: envelope,
            createdAt: /* @__PURE__ */ new Date(),
            publishedAt: null,
            attemptCount: 0,
            lastError: null
          });
          console.log("[GrokAI] Payment auto-processed and published to pipeline");
        } else {
          console.log(`[GrokAI] Payment held for ${classification.processingRecommendation}: ${classification.reasoning}`);
        }
        return {
          ingestionId,
          artifactId,
          analysis,
          classification
        };
      }
      /**
       * Build document analysis prompt
       */
      buildDocumentAnalysisPrompt(content, documentType) {
        return `
      Analyze this financial document${documentType ? ` (type: ${documentType})` : ""} and extract payment information.
      
      Document content: ${content.substring(0, 1e4)} // Limit for token efficiency
      
      Extract and return as JSON:
      {
        "documentType": "check|wire_receipt|ach_confirmation|invoice|statement|unknown",
        "confidence": 0.0-1.0,
        "extractedData": {
          "amount": numeric value in dollars,
          "payerName": "name of payer",
          "payerAccount": "account number if visible",
          "payeeAccount": "destination account",
          "referenceNumber": "transaction reference",
          "transactionDate": "YYYY-MM-DD",
          "loanIdentifier": "loan number or ID",
          "paymentMethod": "ach|wire|check|card",
          "metadata": { any additional relevant data }
        },
        "paymentIntent": {
          "type": "principal|interest|escrow|fees|mixed",
          "allocation": { breakdown if determinable }
        },
        "aiInsights": ["relevant observations about the document"]
      }
    `;
      }
      /**
       * Build payment classification prompt
       */
      buildClassificationPrompt(amount, loanContext, paymentData) {
        return `
      Classify this mortgage payment:
      Amount: $${amount.toFixed(2)}
      Loan Context: ${JSON.stringify(loanContext)}
      Payment Data: ${JSON.stringify(paymentData)}
      
      Determine:
      {
        "category": "regular|prepayment|payoff|partial|overpayment",
        "urgency": "standard|expedited|critical",
        "riskScore": 0-100 (fraud/compliance risk),
        "complianceFlags": ["any compliance concerns"],
        "processingRecommendation": "auto_process|manual_review|hold|reject",
        "reasoning": "explanation of classification"
      }
      
      Consider:
      - Is amount consistent with regular payment?
      - Any fraud indicators?
      - Compliance requirements (RESPA, TILA, etc.)
      - Processing urgency based on due dates
    `;
      }
      /**
       * Get loan context for AI analysis
       */
      async getLoanContext(loanId) {
        try {
          const loanQuery = await db.query(`
        SELECT 
          l.id,
          l.loan_number,
          l.current_balance,
          l.monthly_payment,
          l.interest_rate,
          l.next_due_date,
          l.days_past_due,
          l.status,
          l.created_at,
          p.street_address,
          p.city,
          p.state,
          p.zip_code,
          b.first_name,
          b.last_name,
          b.email,
          b.phone
        FROM loans l
        LEFT JOIN properties p ON l.property_id = p.id
        LEFT JOIN borrowers b ON l.primary_borrower_id = b.id
        WHERE l.loan_number = $1 OR l.id = $2
        LIMIT 1
      `, [loanId, parseInt(loanId) || 0]);
          if (loanQuery.rows.length > 0) {
            const loan = loanQuery.rows[0];
            return {
              loanId: loan.loan_number || loan.id,
              regularPaymentAmount: parseFloat(loan.monthly_payment) || 0,
              currentBalance: parseFloat(loan.current_balance) || 0,
              interestRate: parseFloat(loan.interest_rate) || 0,
              nextDueDate: loan.next_due_date,
              isDelinquent: loan.days_past_due > 0,
              daysPastDue: loan.days_past_due || 0,
              status: loan.status,
              borrowerName: `${loan.first_name || ""} ${loan.last_name || ""}`.trim(),
              propertyAddress: `${loan.street_address || ""} ${loan.city || ""} ${loan.state || ""} ${loan.zip_code || ""}`.trim()
            };
          }
        } catch (error) {
          console.warn(`[GrokAI] Failed to fetch loan context for ${loanId}:`, error);
        }
        return {
          loanId,
          regularPaymentAmount: 0,
          currentBalance: 0,
          nextDueDate: null,
          isDelinquent: false,
          daysPastDue: 0,
          status: "unknown",
          error: "Could not fetch loan data from database"
        };
      }
      /**
       * Get payment history for pattern analysis
       */
      async getPaymentHistory(loanId) {
        try {
          const paymentQuery = await db.query(`
        SELECT 
          p.payment_date,
          p.amount_cents,
          p.payment_method,
          p.reference_number,
          p.status,
          p.created_at
        FROM payments p
        JOIN loans l ON p.loan_id = l.id
        WHERE l.loan_number = $1 OR l.id = $2
        ORDER BY p.payment_date DESC
        LIMIT 12
      `, [loanId, parseInt(loanId) || 0]);
          if (paymentQuery.rows.length > 0) {
            return paymentQuery.rows.map((payment) => ({
              date: payment.payment_date,
              amount: parseFloat(payment.amount_cents) / 100,
              method: payment.payment_method,
              reference: payment.reference_number,
              status: payment.status,
              created_at: payment.created_at
            }));
          }
        } catch (error) {
          console.warn(`[GrokAI] Failed to fetch payment history for ${loanId}:`, error);
        }
        return [];
      }
      /**
       * Record detected anomalies
       */
      async recordAnomalies(loanId, payment, anomalies) {
        for (const anomaly of anomalies) {
          const correlationId = randomUUID25();
          const eventData = {
            type: anomaly.type,
            severity: anomaly.severity,
            description: anomaly.description,
            recommendation: anomaly.recommendation,
            loanId
          };
          const eventHash = crypto21.createHash("sha256").update(JSON.stringify(eventData)).digest("hex");
          await db.insert(paymentEvents).values({
            paymentId: payment.id || null,
            ingestionId: payment.ingestionId || null,
            type: "anomaly_detected",
            eventTime: /* @__PURE__ */ new Date(),
            actorType: "ai",
            actorId: "grok-ai-service",
            correlationId,
            data: eventData,
            prevEventHash: null,
            eventHash
          });
        }
      }
      /**
       * Validate extracted data
       */
      validateExtractedData(data) {
        const issues = [];
        if (!data.amount || data.amount <= 0) {
          issues.push("Invalid or missing payment amount");
        }
        if (!data.loanIdentifier) {
          issues.push("Cannot identify associated loan");
        }
        if (!data.transactionDate) {
          issues.push("Missing transaction date");
        }
        if (!data.paymentMethod) {
          issues.push("Payment method not identified");
        }
        return issues;
      }
      /**
       * Get fallback analysis when AI is unavailable
       */
      getFallbackAnalysis() {
        return {
          documentType: "unknown",
          confidence: 0,
          extractedData: {},
          validationIssues: ["AI service unavailable - manual review required"]
        };
      }
      /**
       * Get default classification when AI is unavailable
       */
      getDefaultClassification() {
        return {
          category: "regular",
          urgency: "standard",
          riskScore: 50,
          // Medium risk when uncertain
          processingRecommendation: "manual_review",
          reasoning: "AI service unavailable - defaulting to manual review"
        };
      }
      /**
       * Get default allocation using standard waterfall
       */
      getDefaultAllocation(amount, dueAmounts) {
        const allocation = {};
        let remaining = amount;
        const waterfall = [
          { key: "lateFees", amount: dueAmounts.lateFees || 0 },
          { key: "fees", amount: dueAmounts.fees || 0 },
          { key: "interest", amount: dueAmounts.interest || 0 },
          { key: "escrow", amount: dueAmounts.escrow || 0 },
          { key: "principal", amount: dueAmounts.principal || 0 }
        ];
        for (const item of waterfall) {
          if (remaining <= 0) break;
          const allocated = Math.min(remaining, item.amount);
          if (allocated > 0) {
            allocation[item.key] = allocated;
            remaining -= allocated;
          }
        }
        if (remaining > 0) {
          allocation.principal = (allocation.principal || 0) + remaining;
        }
        return {
          recommended: allocation,
          reasoning: "Standard mortgage servicing waterfall applied"
        };
      }
      /**
       * Health check for AI service
       */
      async healthCheck() {
        if (!GROQ_API_KEY) {
          return {
            status: "unhealthy",
            model: this.modelName,
            apiConfigured: false
          };
        }
        try {
          const start = Date.now();
          await this.groq.chat.completions.create({
            messages: [
              {
                role: "user",
                content: 'Return JSON: {"status": "ok"}'
              }
            ],
            model: this.modelName,
            temperature: 0,
            max_tokens: 10,
            response_format: { type: "json_object" }
          });
          const responseTime = Date.now() - start;
          return {
            status: "healthy",
            model: this.modelName,
            apiConfigured: true,
            lastResponseTime: responseTime
          };
        } catch (error) {
          console.error("[GrokAI] Health check failed:", error);
          return {
            status: "degraded",
            model: this.modelName,
            apiConfigured: true
          };
        }
      }
    };
    grokAIService = new GrokAIService();
  }
});

// src/queues/document/document-consumer.ts
var document_consumer_exports = {};
__export(document_consumer_exports, {
  DocumentProcessingSchema: () => DocumentProcessingSchema,
  initDocumentConsumer: () => initDocumentConsumer,
  performAIAnalysis: () => performAIAnalysis,
  performOCR: () => performOCR
});
import { z as z20 } from "zod";
import { eq as eq37 } from "drizzle-orm";
import { ulid as ulid10 } from "ulid";
async function performOCR(message) {
  console.log(`[Document OCR] Processing OCR for document: ${message.document_id}`);
  const { TextractClient, DetectDocumentTextCommand } = await import("@aws-sdk/client-textract");
  const { readFileSync: readFileSync2 } = await import("fs");
  try {
    const documentBuffer = readFileSync2(message.file_path);
    const textractClient = new TextractClient({
      region: process.env.AWS_REGION || "us-east-1",
      credentials: {
        accessKeyId: process.env.AWS_ACCESS_KEY_ID,
        secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY
      }
    });
    const command = new DetectDocumentTextCommand({
      Document: {
        Bytes: documentBuffer
      }
    });
    const result = await textractClient.send(command);
    let extractedText = "";
    let totalConfidence = 0;
    let blockCount = 0;
    for (const block of result.Blocks || []) {
      if (block.BlockType === "LINE") {
        extractedText += block.Text + "\n";
        totalConfidence += block.Confidence || 0;
        blockCount++;
      }
    }
    const averageConfidence = blockCount > 0 ? totalConfidence / blockCount / 100 : 0;
    console.log(`[Document OCR] Textract OCR completed for ${message.document_id}`);
    return {
      text: extractedText.trim(),
      confidence: averageConfidence
    };
  } catch (error) {
    console.warn(`[Document OCR] Textract failed for ${message.document_id}:`, error.message);
    if (error.name === "UnsupportedDocumentException" || error.message.includes("unsupported")) {
      console.log(`[Document OCR] Falling back to Grok AI for ${message.document_id}`);
      const { grokAIService: grokAIService2 } = await Promise.resolve().then(() => (init_grok_ai_service(), grok_ai_service_exports));
      const documentBuffer = readFileSync2(message.file_path);
      const grokResult = await grokAIService2.analyzeDocument(documentBuffer);
      const grokText = [
        grokResult.extractedData.payerName,
        grokResult.extractedData.amount?.toString(),
        grokResult.extractedData.referenceNumber,
        grokResult.extractedData.transactionDate,
        ...grokResult.aiInsights || []
      ].filter(Boolean).join("\n");
      return {
        text: grokText || "Document processed by AI but text extraction failed",
        confidence: grokResult.confidence
      };
    }
    throw new Error(`OCR processing failed: ${error.message}`);
  }
}
async function performAIAnalysis(message, ocrText) {
  console.log(`[Document AI] Analyzing document: ${message.document_id}`);
  const { grokAIService: grokAIService2 } = await Promise.resolve().then(() => (init_grok_ai_service(), grok_ai_service_exports));
  const { readFileSync: readFileSync2 } = await import("fs");
  try {
    const documentBuffer = readFileSync2(message.file_path);
    const grokResult = await grokAIService2.analyzeDocument(documentBuffer, message.file_name);
    const classification = grokResult.documentType === "unknown" ? "unclassified_document" : grokResult.documentType;
    const extractedData = {
      borrower_name: grokResult.extractedData.payerName || null,
      loan_amount: grokResult.extractedData.amount || null,
      loan_identifier: grokResult.extractedData.loanIdentifier || null,
      transaction_date: grokResult.extractedData.transactionDate || null,
      reference_number: grokResult.extractedData.referenceNumber || null,
      payment_method: grokResult.extractedData.paymentMethod || null,
      account_number: grokResult.extractedData.payerAccount || null,
      ...grokResult.extractedData.metadata
    };
    const summary = grokResult.aiInsights?.join(". ") || `Document classified as ${classification} with ${grokResult.confidence * 100}% confidence. OCR text length: ${ocrText.length} characters.`;
    console.log(`[Document AI] Grok AI analysis completed for ${message.document_id}:`, {
      classification,
      confidence: grokResult.confidence,
      extractedFields: Object.keys(extractedData).length
    });
    return {
      classification,
      confidence: grokResult.confidence,
      extracted_data: extractedData,
      summary
    };
  } catch (error) {
    console.error(`[Document AI] Grok AI analysis failed for ${message.document_id}:`, error);
    const classification = message.file_name.toLowerCase().includes("bank") ? "bank_statement" : message.file_name.toLowerCase().includes("tax") ? "tax_document" : message.file_name.toLowerCase().includes("pay") ? "payment_document" : "unclassified_document";
    return {
      classification,
      confidence: 0.3,
      // Low confidence for fallback
      extracted_data: {
        ocr_text_length: ocrText.length,
        filename: message.file_name,
        processing_error: error.message
      },
      summary: `AI analysis failed, classified by filename as ${classification}. Error: ${error.message}`
    };
  }
}
async function processDocumentMessage(message, publishEvent2) {
  console.log(`[Document Consumer] Processing document: ${message.document_id}`);
  try {
    await db.update(documents).set({ status: "processing", updatedAt: /* @__PURE__ */ new Date() }).where(eq37(documents.id, message.document_id));
    let ocrText = "";
    let ocrConfidence = 0;
    let classification = "";
    let aiConfidence = 0;
    let extractedData = {};
    let summary = "";
    if (["ocr", "full"].includes(message.processing_type)) {
      const ocrResult = await performOCR(message);
      ocrText = ocrResult.text;
      ocrConfidence = ocrResult.confidence;
      await db.update(documents).set({
        ocrText,
        ocrConfidence,
        updatedAt: /* @__PURE__ */ new Date()
      }).where(eq37(documents.id, message.document_id));
      console.log(`[Document Consumer] OCR completed for ${message.document_id}`);
    }
    if (["ai_analysis", "classification", "full"].includes(message.processing_type)) {
      const aiResult = await performAIAnalysis(message, ocrText);
      classification = aiResult.classification;
      aiConfidence = aiResult.confidence;
      extractedData = aiResult.extracted_data;
      summary = aiResult.summary;
      await db.update(documents).set({
        classification,
        aiConfidence,
        extractedData: JSON.stringify(extractedData),
        summary,
        updatedAt: /* @__PURE__ */ new Date()
      }).where(eq37(documents.id, message.document_id));
      console.log(`[Document Consumer] AI analysis completed for ${message.document_id}`);
    }
    await db.update(documents).set({
      status: "processed",
      processedAt: /* @__PURE__ */ new Date(),
      updatedAt: /* @__PURE__ */ new Date()
    }).where(eq37(documents.id, message.document_id));
    console.log(`[Document Consumer] Document processed successfully: ${message.document_id}`);
    const processedEvent = createEnvelope({
      tenantId: "default",
      correlationId: ulid10(),
      payload: {
        eventType: "document.processed",
        document_id: message.document_id,
        loan_id: message.loan_id,
        processing_type: message.processing_type,
        classification,
        ai_confidence: aiConfidence,
        ocr_confidence: ocrConfidence,
        has_extracted_data: Object.keys(extractedData).length > 0,
        processed_at: (/* @__PURE__ */ new Date()).toISOString()
      }
    });
    await publishEvent2(Exchanges.Events, "document.processed", processedEvent);
  } catch (error) {
    console.error(`[Document Consumer] Error processing document ${message.document_id}:`, error);
    await db.update(documents).set({
      status: "failed",
      errorMessage: error.message,
      updatedAt: /* @__PURE__ */ new Date()
    }).where(eq37(documents.id, message.document_id));
    const failedEvent = createEnvelope({
      tenantId: "default",
      correlationId: ulid10(),
      payload: {
        eventType: "document.failed",
        document_id: message.document_id,
        loan_id: message.loan_id,
        error: error.message,
        failed_at: (/* @__PURE__ */ new Date()).toISOString()
      }
    });
    await publishEvent2(Exchanges.Events, "document.failed", failedEvent);
    throw error;
  }
}
async function initDocumentConsumer(connection2, publishEvent2) {
  const channel = await connection2.createChannel();
  await channel.prefetch(2);
  console.log("[Document Consumer] Initializing document processing consumer...");
  const DOCUMENT_QUEUE = "document.process.v1";
  await channel.assertQueue(DOCUMENT_QUEUE, {
    durable: true,
    arguments: {
      "x-dead-letter-exchange": Exchanges.Dlq,
      "x-queue-type": "quorum"
    }
  });
  await channel.bindQueue(DOCUMENT_QUEUE, Exchanges.Commands, "tenant.*.document.process");
  await channel.consume(DOCUMENT_QUEUE, async (msg) => {
    if (!msg) return;
    try {
      const envelope = JSON.parse(msg.content.toString());
      const message = validateMessage(envelope, DocumentProcessingSchema);
      console.log(`[Document Consumer] Received document processing message:`, {
        correlationId: envelope.correlationId,
        documentId: message.document_id,
        loanId: message.loan_id,
        processingType: message.processing_type
      });
      await processDocumentMessage(message, publishEvent2);
      channel.ack(msg);
      console.log(`[Document Consumer] Document processing completed: ${message.document_id}`);
    } catch (error) {
      console.error("[Document Consumer] Error processing message:", error);
      const retryCount = msg.properties.headers?.["x-retry-count"] || 0;
      if (retryCount < 3) {
        channel.nack(msg, false, false);
        console.log(`[Document Consumer] Message rejected for retry (attempt ${retryCount + 1})`);
      } else {
        channel.nack(msg, false, false);
        console.log(`[Document Consumer] Message sent to DLQ after ${retryCount + 1} attempts`);
      }
    }
  });
  console.log("[Document Consumer] \u2705 Document processing consumer initialized");
}
var DocumentProcessingSchema;
var init_document_consumer = __esm({
  "src/queues/document/document-consumer.ts"() {
    "use strict";
    init_envelope_helpers();
    init_topology();
    init_db();
    init_schema();
    DocumentProcessingSchema = z20.object({
      document_id: z20.string(),
      loan_id: z20.number(),
      file_path: z20.string(),
      file_name: z20.string(),
      mime_type: z20.string(),
      file_size: z20.number(),
      processing_type: z20.enum(["ocr", "ai_analysis", "classification", "full"]),
      uploaded_by: z20.number().optional(),
      folder_id: z20.string().optional(),
      // OCR specific options
      ocr_language: z20.string().default("en"),
      extract_tables: z20.boolean().default(false),
      // AI analysis options
      analyze_content: z20.boolean().default(true),
      classify_document: z20.boolean().default(true),
      extract_datapoints: z20.boolean().default(true)
    });
  }
});

// src/db/auditService.ts
async function auditAction(client5, params) {
  await client5.query(
    `INSERT INTO audits (tenant_id, target_type, target_id, action, changes, created_at)
       VALUES ($1, $2, $3, $4, $5, now())`,
    [params.tenantId, params.targetType, params.targetId, params.action, params.changes]
  );
}
var init_auditService2 = __esm({
  "src/db/auditService.ts"() {
    "use strict";
  }
});

// src/db/eventOutboxService.ts
async function publishEvent(client5, params) {
  await client5.query(
    `INSERT INTO event_outbox (tenant_id, aggregate_id, aggregate_type, event_type, payload, version, created_at)
       VALUES ($1,$2,$3,$4,$5,$6,now())`,
    [
      params.tenantId,
      params.aggregateId,
      params.aggregateType,
      params.eventType,
      params.payload,
      params.version || 1
    ]
  );
}
var init_eventOutboxService = __esm({
  "src/db/eventOutboxService.ts"() {
    "use strict";
  }
});

// src/queues/escrow/escrow-consumer.ts
var escrow_consumer_exports = {};
__export(escrow_consumer_exports, {
  initEscrowConsumer: () => initEscrowConsumer
});
import { drizzle as drizzle3 } from "drizzle-orm/postgres-js";
async function initEscrowConsumer(conn) {
  await startConsumer(conn, {
    queue: Queues.Escrow,
    handler: async (payload, { client: client5 }) => {
      const { loanId, escrowAction, tenantId } = payload;
      const db2 = drizzle3(client5);
      switch (escrowAction.type) {
        case "analysis":
          await performEscrowAnalysis(loanId, tenantId, client5);
          break;
        case "disbursement":
          await processEscrowDisbursement(loanId, escrowAction.disbursementId, tenantId, client5);
          break;
        case "shortage_detection":
          await detectEscrowShortage(loanId, tenantId, client5);
          break;
        default:
          throw new Error(`Unknown escrow action: ${escrowAction.type}`);
      }
    }
  });
}
async function performEscrowAnalysis(loanId, tenantId, client5) {
  const db2 = drizzle3(client5);
  const [escrowAccount] = await db2.select().from(escrowAccounts).where(eq(escrowAccounts.loanId, loanId));
  if (!escrowAccount) {
    throw new Error(`No escrow account found for loan ${loanId}`);
  }
  const escrowItems = await db2.select().from(escrowItems).where(eq(escrowItems.escrowAccountId, escrowAccount.id));
  const annualRequired = escrowItems.reduce((total, item) => total + (item.annualAmount || 0), 0);
  const currentBalance = escrowAccount.balance || 0;
  const monthlyPayment = escrowAccount.monthlyPayment || 0;
  const targetBalance = annualRequired / 12 * 2;
  const shortage = Math.max(0, targetBalance - currentBalance);
  const surplus = Math.max(0, currentBalance - targetBalance);
  await db2.insert(escrowAnalysis).values({
    escrowAccountId: escrowAccount.id,
    analysisDate: /* @__PURE__ */ new Date(),
    annualRequired,
    currentBalance,
    targetBalance,
    shortage,
    surplus,
    recommendedMonthlyPayment: (annualRequired + shortage) / 12
  });
  await publishEvent(client5, {
    tenantId,
    aggregateId: loanId,
    aggregateType: "loan",
    eventType: "EscrowAnalysisCompleted",
    payload: {
      shortage,
      surplus,
      currentBalance,
      recommendedPayment: (annualRequired + shortage) / 12
    }
  });
  await auditAction(client5, {
    tenantId,
    targetType: "escrow_accounts",
    targetId: escrowAccount.id,
    action: "escrow_analysis_completed",
    changes: { shortage, surplus, analysisDate: /* @__PURE__ */ new Date() }
  });
}
async function processEscrowDisbursement(loanId, disbursementId, tenantId, client5) {
  const db2 = drizzle3(client5);
  const [disbursement2] = await db2.select().from(escrowDisbursements).where(eq(escrowDisbursements.id, disbursementId));
  if (!disbursement2) {
    throw new Error(`Disbursement ${disbursementId} not found`);
  }
  await db2.update(escrowAccounts).set({
    balance: sql`balance - ${disbursement2.amount}`,
    lastDisbursementDate: /* @__PURE__ */ new Date()
  }).where(eq(escrowAccounts.loanId, loanId));
  await db2.update(escrowDisbursements).set({
    status: "processed",
    processedAt: /* @__PURE__ */ new Date()
  }).where(eq(escrowDisbursements.id, disbursementId));
  await publishEvent(client5, {
    tenantId,
    aggregateId: loanId,
    aggregateType: "loan",
    eventType: "EscrowDisbursementProcessed",
    payload: {
      disbursementId,
      amount: disbursement2.amount,
      payee: disbursement2.payee,
      purpose: disbursement2.purpose
    }
  });
  await auditAction(client5, {
    tenantId,
    targetType: "escrow_disbursements",
    targetId: disbursementId,
    action: "disbursement_processed",
    changes: { amount: disbursement2.amount, processedAt: /* @__PURE__ */ new Date() }
  });
}
async function detectEscrowShortage(loanId, tenantId, client5) {
}
var init_escrow_consumer = __esm({
  "src/queues/escrow/escrow-consumer.ts"() {
    "use strict";
    init_consumer_utils();
    init_topology();
    init_auditService2();
    init_eventOutboxService();
  }
});

// src/queues/maintenance/maintenance-consumer.ts
var maintenance_consumer_exports = {};
__export(maintenance_consumer_exports, {
  initMaintenanceConsumer: () => initMaintenanceConsumer
});
async function handleRetentionCleanup(tenantId, client5) {
  console.log(`[Maintenance] Starting retention cleanup for tenant ${tenantId}`);
  try {
    const retentionOps = new RetentionOperations(client5);
    const results = await retentionOps.runRetentionForAllTenants();
    const sessionResult = await client5.query(`
      DELETE FROM sessions 
      WHERE expires_at < CURRENT_TIMESTAMP
    `);
    const thirtyDaysAgo = /* @__PURE__ */ new Date();
    thirtyDaysAgo.setDate(thirtyDaysAgo.getDate() - 30);
    const messageResult = await client5.query(`
      DELETE FROM processed_messages 
      WHERE processed_at < $1
    `, [thirtyDaysAgo]);
    console.log(`[Maintenance] Retention cleanup completed:`, {
      ...results,
      expiredSessions: sessionResult.rowCount || 0,
      oldMessages: messageResult.rowCount || 0
    });
  } catch (error) {
    console.error(`[Maintenance] Retention cleanup failed:`, error);
    throw error;
  }
}
async function handleAuditMaintenance(tenantId, client5) {
  console.log(`[Maintenance] Starting audit maintenance for tenant ${tenantId}`);
  try {
    const chainResult = await client5.query(`
      SELECT COUNT(*) as broken_chains
      FROM audit_logs a1
      LEFT JOIN audit_logs a2 ON a2.id = a1.id + 1
      WHERE a1.next_hash != a2.previous_hash
        AND a2.id IS NOT NULL
    `);
    const brokenChains = chainResult.rows[0]?.broken_chains || 0;
    if (brokenChains > 0) {
      console.warn(`[Maintenance] Detected ${brokenChains} broken audit chain links`);
    }
    const statsResult = await client5.query(`
      INSERT INTO audit_statistics (tenant_id, date, total_events, integrity_status)
      VALUES ($1, CURRENT_DATE, 
        (SELECT COUNT(*) FROM audit_logs WHERE DATE(created_at) = CURRENT_DATE),
        CASE WHEN $2 = 0 THEN 'valid' ELSE 'compromised' END
      )
      ON CONFLICT (tenant_id, date) DO UPDATE SET
        total_events = EXCLUDED.total_events,
        integrity_status = EXCLUDED.integrity_status
    `, [tenantId, brokenChains]);
    console.log(`[Maintenance] Audit maintenance completed - integrity status: ${brokenChains === 0 ? "valid" : "compromised"}`);
  } catch (error) {
    console.error(`[Maintenance] Audit maintenance failed:`, error);
    throw error;
  }
}
async function initMaintenanceConsumer(conn, publishFn) {
  console.log("[Maintenance Consumer] Initializing maintenance consumer...");
  await startConsumer(conn, {
    queue: "maintenance.schedule.v1",
    handler: async (payload, helpers) => {
      const { tenantId } = payload;
      const { jobTypes = [] } = payload.payload || {};
      console.log(`[Maintenance Consumer] Processing maintenance jobs:`, jobTypes);
      for (const jobType of jobTypes) {
        try {
          await withTenantClient(tenantId, async (client5) => {
            switch (jobType) {
              case "retention_cleanup":
                await handleRetentionCleanup(tenantId, client5);
                break;
              case "audit_maintenance":
                await handleAuditMaintenance(tenantId, client5);
                break;
              default:
                console.warn(`[Maintenance Consumer] Unknown job type: ${jobType}`);
            }
          });
        } catch (error) {
          console.error(`[Maintenance Consumer] Job ${jobType} failed:`, error);
        }
      }
      console.log(`[Maintenance Consumer] Completed maintenance jobs for tenant ${tenantId}`);
    }
  });
  console.log("[Maintenance Consumer] \u2705 Maintenance consumer initialized");
}
var init_maintenance_consumer = __esm({
  "src/queues/maintenance/maintenance-consumer.ts"() {
    "use strict";
    init_consumer_utils();
    init_withTenantClient();
    init_retention_policies();
  }
});

// src/services/service-registry.ts
import { ulid as ulid11 } from "ulid";
var ServiceRegistry, globalServiceRegistry;
var init_service_registry = __esm({
  "src/services/service-registry.ts"() {
    "use strict";
    init_envelope_helpers();
    init_topology();
    ServiceRegistry = class {
      services = /* @__PURE__ */ new Map();
      healthCheckInterval = null;
      connection = null;
      /**
       * Initialize service registry
       */
      async initialize(connection2) {
        this.connection = connection2;
        console.log("[Service Registry] Initializing microservice registry...");
        this.startHealthMonitoring();
        console.log("[Service Registry] \u2705 Service registry initialized");
      }
      /**
       * Register a microservice instance
       */
      async registerService(definition) {
        const serviceId = ulid11();
        const instance = {
          serviceId,
          serviceName: definition.name,
          version: definition.version,
          host: "localhost",
          // In production, this would be the actual host
          port: definition.port,
          healthEndpoint: definition.healthEndpoint,
          status: "starting",
          lastHealthCheck: (/* @__PURE__ */ new Date()).toISOString(),
          registeredAt: (/* @__PURE__ */ new Date()).toISOString(),
          metadata: {
            capabilities: definition.capabilities,
            environment: process.env.NODE_ENV || "development",
            instanceId: serviceId,
            processId: process.pid.toString()
          }
        };
        this.services.set(serviceId, instance);
        console.log(`[Service Registry] Registered service: ${definition.name}@${definition.version}`, {
          serviceId,
          port: definition.port,
          capabilities: definition.capabilities
        });
        if (this.connection) {
          const registrationEvent = createEnvelope({
            tenantId: "system",
            correlationId: ulid11(),
            payload: {
              eventType: "service.registered",
              service_id: serviceId,
              service_name: definition.name,
              version: definition.version,
              host: instance.host,
              port: instance.port,
              capabilities: definition.capabilities,
              registered_at: instance.registeredAt
            }
          });
          const channel = await this.connection.createConfirmChannel();
          await channel.publish(Exchanges.Events, "service.registered", Buffer.from(JSON.stringify(registrationEvent)));
          await channel.close();
        }
        return instance;
      }
      /**
       * Deregister a service instance
       */
      async deregisterService(serviceId) {
        const service = this.services.get(serviceId);
        if (!service) {
          throw new Error(`Service not found: ${serviceId}`);
        }
        service.status = "stopping";
        this.services.delete(serviceId);
        console.log(`[Service Registry] Deregistered service: ${service.serviceName}`, {
          serviceId,
          serviceName: service.serviceName
        });
        if (this.connection) {
          const deregistrationEvent = createEnvelope({
            tenantId: "system",
            correlationId: ulid11(),
            payload: {
              eventType: "service.deregistered",
              service_id: serviceId,
              service_name: service.serviceName,
              deregistered_at: (/* @__PURE__ */ new Date()).toISOString()
            }
          });
          const channel = await this.connection.createConfirmChannel();
          await channel.publish(Exchanges.Events, "service.deregistered", Buffer.from(JSON.stringify(deregistrationEvent)));
          await channel.close();
        }
      }
      /**
       * Get all healthy instances of a service
       */
      getHealthyInstances(serviceName) {
        return Array.from(this.services.values()).filter(
          (service) => service.serviceName === serviceName && service.status === "healthy"
        );
      }
      /**
       * Get service instance by capability
       */
      getServicesByCapability(capability) {
        return Array.from(this.services.values()).filter(
          (service) => service.metadata.capabilities.includes(capability) && service.status === "healthy"
        );
      }
      /**
       * Get all registered services
       */
      getAllServices() {
        return Array.from(this.services.values());
      }
      /**
       * Update service health status
       */
      updateServiceHealth(serviceId, status) {
        const service = this.services.get(serviceId);
        if (service) {
          service.status = status;
          service.lastHealthCheck = (/* @__PURE__ */ new Date()).toISOString();
        }
      }
      /**
       * Start periodic health monitoring
       */
      startHealthMonitoring() {
        if (this.healthCheckInterval) {
          clearInterval(this.healthCheckInterval);
        }
        this.healthCheckInterval = setInterval(async () => {
          await this.performHealthChecks();
        }, 3e4);
      }
      /**
       * Perform health checks on all registered services
       */
      async performHealthChecks() {
        const services = Array.from(this.services.values());
        for (const service of services) {
          try {
            const isHealthy = Math.random() > 0.1;
            this.updateServiceHealth(service.serviceId, isHealthy ? "healthy" : "unhealthy");
            if (!isHealthy) {
              console.warn(`[Service Registry] Health check failed for ${service.serviceName}:${service.serviceId}`);
            }
          } catch (error) {
            console.error(`[Service Registry] Health check error for ${service.serviceName}:`, error);
            this.updateServiceHealth(service.serviceId, "unhealthy");
          }
        }
      }
      /**
       * Get service registry statistics
       */
      getStats() {
        const services = Array.from(this.services.values());
        const servicesByName = {};
        services.forEach((service) => {
          servicesByName[service.serviceName] = (servicesByName[service.serviceName] || 0) + 1;
        });
        return {
          totalServices: services.length,
          healthyServices: services.filter((s) => s.status === "healthy").length,
          unhealthyServices: services.filter((s) => s.status === "unhealthy").length,
          servicesByName
        };
      }
      /**
       * Stop monitoring and cleanup
       */
      stop() {
        if (this.healthCheckInterval) {
          clearInterval(this.healthCheckInterval);
          this.healthCheckInterval = null;
        }
        this.services.clear();
        console.log("[Service Registry] Service registry stopped");
      }
    };
    globalServiceRegistry = new ServiceRegistry();
  }
});

// src/services/payment-service.ts
import express5 from "express";
import { z as z21 } from "zod";
import { ulid as ulid12 } from "ulid";
var CreatePaymentSchema2, AllocatePaymentSchema, PaymentService, paymentService;
var init_payment_service = __esm({
  "src/services/payment-service.ts"() {
    "use strict";
    init_service_registry();
    init_envelope_helpers();
    init_topology();
    CreatePaymentSchema2 = z21.object({
      loan_id: z21.number(),
      payment_method: z21.enum(["ach", "wire", "check", "card", "manual"]),
      amount_cents: z21.number().positive(),
      payment_date: z21.string(),
      reference_number: z21.string().optional(),
      bank_account_id: z21.string().optional(),
      notes: z21.string().optional()
    });
    AllocatePaymentSchema = z21.object({
      payment_id: z21.string(),
      allocation_rules: z21.object({
        fees_first: z21.boolean().default(true),
        interest_before_principal: z21.boolean().default(true),
        escrow_percentage: z21.number().min(0).max(100).optional()
      }).optional()
    });
    PaymentService = class {
      app;
      connection = null;
      publishChannel = null;
      serviceInstance = null;
      constructor() {
        this.app = express5();
        this.app.use(express5.json());
        this.setupRoutes();
      }
      /**
       * Initialize payment service
       */
      async initialize(connection2) {
        this.connection = connection2;
        this.publishChannel = await connection2.createConfirmChannel();
        console.log("[Payment Service] Initializing independent payment microservice...");
        const definition = {
          name: "payment-service",
          version: "1.0.0",
          port: 5001,
          healthEndpoint: "/health",
          capabilities: [
            "payment.processing",
            "payment.allocation",
            "payment.validation",
            "payment.reporting"
          ],
          dependencies: ["loan-service", "database"],
          queueBindings: {
            consumes: ["tenant.*.payment.process", "tenant.*.payment.allocate"],
            publishes: ["payment.processed", "payment.allocated", "payment.failed"]
          }
        };
        this.serviceInstance = await globalServiceRegistry.registerService(definition);
        await this.startConsumers();
        console.log("[Payment Service] \u2705 Payment microservice initialized on port 5001");
      }
      /**
       * Setup REST API routes
       */
      setupRoutes() {
        this.app.get("/health", (req, res) => {
          res.json({
            status: "healthy",
            service: "payment-service",
            version: "1.0.0",
            timestamp: (/* @__PURE__ */ new Date()).toISOString(),
            uptime: process.uptime(),
            capabilities: [
              "payment.processing",
              "payment.allocation",
              "payment.validation",
              "payment.reporting"
            ]
          });
        });
        this.app.post("/payments", async (req, res) => {
          try {
            const paymentData = CreatePaymentSchema2.parse(req.body);
            const paymentId = ulid12();
            const correlationId = ulid12();
            const paymentMessage = {
              payment_id: paymentId,
              loan_id: paymentData.loan_id,
              source: paymentData.payment_method,
              amount_cents: paymentData.amount_cents,
              payment_date: paymentData.payment_date,
              reference_number: paymentData.reference_number,
              bank_account_id: paymentData.bank_account_id,
              notes: paymentData.notes,
              processing_options: {
                validate_loan: true,
                check_balances: true,
                apply_waterfall: true,
                update_escrow: true
              }
            };
            const envelope = createEnvelope({
              tenantId: "default",
              correlationId,
              payload: paymentMessage
            });
            await this.publishChannel.publish(
              Exchanges.Commands,
              "tenant.default.payment.process",
              Buffer.from(JSON.stringify(envelope))
            );
            res.status(202).json({
              success: true,
              payment_id: paymentId,
              correlation_id: correlationId,
              status: "processing",
              message: "Payment submitted for processing"
            });
          } catch (error) {
            console.error("[Payment Service] Error creating payment:", error);
            res.status(400).json({
              success: false,
              error: error instanceof Error ? error.message : "Unknown error"
            });
          }
        });
        this.app.post("/payments/:paymentId/allocate", async (req, res) => {
          try {
            const { paymentId } = req.params;
            const allocationData = AllocatePaymentSchema.parse(req.body);
            const correlationId = ulid12();
            const allocationMessage = {
              payment_id: paymentId,
              allocation_rules: allocationData.allocation_rules || {
                fees_first: true,
                interest_before_principal: true
              },
              correlation_id: correlationId
            };
            const envelope = createEnvelope({
              tenantId: "default",
              correlationId,
              payload: allocationMessage
            });
            await this.publishChannel.publish(
              Exchanges.Commands,
              "tenant.default.payment.allocate",
              Buffer.from(JSON.stringify(envelope))
            );
            res.status(202).json({
              success: true,
              payment_id: paymentId,
              correlation_id: correlationId,
              status: "allocating",
              message: "Payment allocation submitted for processing"
            });
          } catch (error) {
            console.error("[Payment Service] Error allocating payment:", error);
            res.status(400).json({
              success: false,
              error: error instanceof Error ? error.message : "Unknown error"
            });
          }
        });
        this.app.get("/payments/:paymentId/status", async (req, res) => {
          try {
            const { paymentId } = req.params;
            res.json({
              success: true,
              payment_id: paymentId,
              status: "processed",
              allocation_status: "completed",
              processed_at: (/* @__PURE__ */ new Date()).toISOString()
            });
          } catch (error) {
            console.error("[Payment Service] Error getting payment status:", error);
            res.status(500).json({
              success: false,
              error: error instanceof Error ? error.message : "Unknown error"
            });
          }
        });
      }
      /**
       * Start queue consumers for payment processing
       */
      async startConsumers() {
        if (!this.connection) return;
        console.log("[Payment Service] Queue consumers delegation to payment-consumer");
      }
      /**
       * Start the payment service server
       */
      async start() {
        const port = 5001;
        this.app.listen(port, "0.0.0.0", () => {
          console.log(`[Payment Service] \u{1F680} Payment microservice running on port ${port}`);
          if (this.serviceInstance) {
            globalServiceRegistry.updateServiceHealth(this.serviceInstance.serviceId, "healthy");
          }
        });
      }
      /**
       * Stop the payment service
       */
      async stop() {
        if (this.publishChannel) {
          await this.publishChannel.close();
        }
        if (this.serviceInstance) {
          await globalServiceRegistry.deregisterService(this.serviceInstance.serviceId);
        }
        console.log("[Payment Service] Payment microservice stopped");
      }
    };
    paymentService = new PaymentService();
  }
});

// src/services/document-service.ts
import express6 from "express";
import multer5 from "multer";
import { z as z22 } from "zod";
import { ulid as ulid13 } from "ulid";
import path9 from "path";
import fs9 from "fs/promises";
var UploadDocumentSchema, ProcessDocumentSchema, uploadStorage2, upload5, DocumentService, documentService;
var init_document_service = __esm({
  "src/services/document-service.ts"() {
    "use strict";
    init_service_registry();
    init_envelope_helpers();
    init_topology();
    UploadDocumentSchema = z22.object({
      loan_id: z22.number(),
      folder_id: z22.string().optional(),
      processing_type: z22.enum(["ocr", "ai_analysis", "classification", "full"]).default("full"),
      uploaded_by: z22.number().optional(),
      // OCR options
      ocr_language: z22.string().default("en"),
      extract_tables: z22.boolean().default(false),
      // AI analysis options
      analyze_content: z22.boolean().default(true),
      classify_document: z22.boolean().default(true),
      extract_datapoints: z22.boolean().default(true)
    });
    ProcessDocumentSchema = z22.object({
      document_id: z22.string(),
      processing_type: z22.enum(["ocr", "ai_analysis", "classification", "full"]),
      processing_options: z22.object({
        ocr_language: z22.string().default("en"),
        extract_tables: z22.boolean().default(false),
        analyze_content: z22.boolean().default(true),
        classify_document: z22.boolean().default(true),
        extract_datapoints: z22.boolean().default(true)
      }).optional()
    });
    uploadStorage2 = multer5.diskStorage({
      destination: async function(req, file, cb) {
        const uploadDir = "services/document-service/uploads";
        try {
          await fs9.mkdir(uploadDir, { recursive: true });
        } catch (error) {
          console.error("Error creating upload directory:", error);
        }
        cb(null, uploadDir);
      },
      filename: function(req, file, cb) {
        const timestamp2 = Date.now();
        const randomSuffix = Math.round(Math.random() * 1e9);
        const ext = path9.extname(file.originalname);
        const basename = path9.basename(file.originalname, ext);
        const sanitized = basename.replace(/[^a-zA-Z0-9.-]/g, "_");
        cb(null, `${timestamp2}_${randomSuffix}_${sanitized}${ext}`);
      }
    });
    upload5 = multer5({
      storage: uploadStorage2,
      limits: {
        fileSize: 50 * 1024 * 1024,
        // 50MB limit for documents
        files: 10
        // Multiple files per upload
      },
      fileFilter: function(req, file, cb) {
        const allowedMimeTypes = [
          "application/pdf",
          "image/jpeg",
          "image/png",
          "image/tiff",
          "application/msword",
          "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
          "text/plain"
        ];
        if (allowedMimeTypes.includes(file.mimetype)) {
          cb(null, true);
        } else {
          cb(new Error(`Unsupported file type: ${file.mimetype}`));
        }
      }
    });
    DocumentService = class {
      app;
      connection = null;
      publishChannel = null;
      serviceInstance = null;
      constructor() {
        this.app = express6();
        this.app.use(express6.json());
        this.setupRoutes();
      }
      /**
       * Initialize document service
       */
      async initialize(connection2) {
        this.connection = connection2;
        this.publishChannel = await connection2.createChannel();
        console.log("[Document Service] Initializing independent document microservice...");
        const definition = {
          name: "document-service",
          version: "1.0.0",
          port: 5002,
          healthEndpoint: "/health",
          capabilities: [
            "document.upload",
            "document.processing",
            "document.ocr",
            "document.ai_analysis",
            "document.classification",
            "document.storage"
          ],
          dependencies: ["storage", "ai-service"],
          queueBindings: {
            consumes: ["tenant.*.document.process"],
            publishes: ["document.processed", "document.failed", "document.uploaded"]
          }
        };
        this.serviceInstance = await globalServiceRegistry.registerService(definition);
        console.log("[Document Service] \u2705 Document microservice initialized on port 5002");
      }
      /**
       * Setup REST API routes
       */
      setupRoutes() {
        this.app.get("/health", (req, res) => {
          res.json({
            status: "healthy",
            service: "document-service",
            version: "1.0.0",
            timestamp: (/* @__PURE__ */ new Date()).toISOString(),
            uptime: process.uptime(),
            capabilities: [
              "document.upload",
              "document.processing",
              "document.ocr",
              "document.ai_analysis",
              "document.classification",
              "document.storage"
            ]
          });
        });
        this.app.post("/documents/upload", upload5.array("documents", 10), async (req, res) => {
          try {
            const uploadData = UploadDocumentSchema.parse(req.body);
            const files = req.files;
            if (!files || files.length === 0) {
              return res.status(400).json({
                success: false,
                error: "No files uploaded"
              });
            }
            const uploadResults = [];
            for (const file of files) {
              const documentId = ulid13();
              const correlationId = ulid13();
              const documentMessage = {
                document_id: documentId,
                loan_id: uploadData.loan_id,
                file_path: file.path,
                file_name: file.originalname,
                mime_type: file.mimetype,
                file_size: file.size,
                processing_type: uploadData.processing_type,
                uploaded_by: uploadData.uploaded_by,
                folder_id: uploadData.folder_id,
                ocr_language: uploadData.ocr_language,
                extract_tables: uploadData.extract_tables,
                analyze_content: uploadData.analyze_content,
                classify_document: uploadData.classify_document,
                extract_datapoints: uploadData.extract_datapoints
              };
              const envelope = createEnvelope({
                tenantId: "default",
                correlationId,
                payload: documentMessage
              });
              await this.publishChannel.publish(
                Exchanges.Commands,
                "tenant.default.document.process",
                Buffer.from(JSON.stringify(envelope))
              );
              uploadResults.push({
                document_id: documentId,
                correlation_id: correlationId,
                filename: file.originalname,
                size: file.size,
                status: "processing"
              });
            }
            res.status(202).json({
              success: true,
              message: `${files.length} documents uploaded and queued for processing`,
              documents: uploadResults
            });
          } catch (error) {
            console.error("[Document Service] Error uploading documents:", error);
            res.status(400).json({
              success: false,
              error: error.message
            });
          }
        });
        this.app.post("/documents/:documentId/process", async (req, res) => {
          try {
            const { documentId } = req.params;
            const processData = ProcessDocumentSchema.parse(req.body);
            const correlationId = ulid13();
            const documentMessage = {
              document_id: documentId,
              processing_type: processData.processing_type,
              ...processData.processing_options
            };
            const envelope = createEnvelope({
              tenantId: "default",
              correlationId,
              payload: documentMessage
            });
            await this.publishChannel.publish(
              Exchanges.Commands,
              "tenant.default.document.process",
              Buffer.from(JSON.stringify(envelope))
            );
            res.status(202).json({
              success: true,
              document_id: documentId,
              correlation_id: correlationId,
              processing_type: processData.processing_type,
              status: "processing",
              message: "Document queued for processing"
            });
          } catch (error) {
            console.error("[Document Service] Error processing document:", error);
            res.status(400).json({
              success: false,
              error: error.message
            });
          }
        });
        this.app.get("/documents/:documentId/status", async (req, res) => {
          try {
            const { documentId } = req.params;
            res.json({
              success: true,
              document_id: documentId,
              status: "processed",
              processing_status: {
                ocr: "completed",
                ai_analysis: "completed",
                classification: "completed"
              },
              results: {
                classification: "loan_application",
                confidence: 0.95,
                extracted_data: {
                  borrower_name: "John Doe",
                  loan_amount: 25e4
                }
              },
              processed_at: (/* @__PURE__ */ new Date()).toISOString()
            });
          } catch (error) {
            console.error("[Document Service] Error getting document status:", error);
            res.status(500).json({
              success: false,
              error: error.message
            });
          }
        });
        this.app.get("/documents", async (req, res) => {
          try {
            const { loan_id, status, classification } = req.query;
            res.json({
              success: true,
              documents: [],
              total: 0,
              filters: {
                loan_id,
                status,
                classification
              }
            });
          } catch (error) {
            console.error("[Document Service] Error listing documents:", error);
            res.status(500).json({
              success: false,
              error: error.message
            });
          }
        });
      }
      /**
       * Start the document service server
       */
      async start() {
        const port = 5002;
        this.app.listen(port, "0.0.0.0", () => {
          console.log(`[Document Service] \u{1F680} Document microservice running on port ${port}`);
          if (this.serviceInstance) {
            globalServiceRegistry.updateServiceHealth(this.serviceInstance.serviceId, "healthy");
          }
        });
      }
      /**
       * Stop the document service
       */
      async stop() {
        if (this.publishChannel) {
          await this.publishChannel.close();
        }
        if (this.serviceInstance) {
          await globalServiceRegistry.deregisterService(this.serviceInstance.serviceId);
        }
        console.log("[Document Service] Document microservice stopped");
      }
    };
    documentService = new DocumentService();
  }
});

// src/services/escrow-service.ts
import express7 from "express";
import { z as z23 } from "zod";
import { ulid as ulid14 } from "ulid";
var CreateDisbursementSchema2, EscrowAnalysisSchema, ApproveDisbursementSchema, EscrowService, escrowService;
var init_escrow_service = __esm({
  "src/services/escrow-service.ts"() {
    "use strict";
    init_service_registry();
    init_envelope_helpers();
    init_topology();
    CreateDisbursementSchema2 = z23.object({
      loan_id: z23.number(),
      disbursement_type: z23.enum(["property_tax", "homeowners_insurance", "flood_insurance", "pmi", "hoa_fee", "other"]),
      payee_name: z23.string(),
      payee_address: z23.string().optional(),
      amount_cents: z23.number().positive(),
      due_date: z23.string(),
      account_number: z23.string().optional(),
      reference_number: z23.string().optional(),
      notes: z23.string().optional(),
      requires_approval: z23.boolean().default(false)
    });
    EscrowAnalysisSchema = z23.object({
      loan_id: z23.number(),
      analysis_type: z23.enum(["annual", "shortage", "surplus", "projection"]).default("annual"),
      projection_months: z23.number().min(1).max(24).default(12)
    });
    ApproveDisbursementSchema = z23.object({
      disbursement_id: z23.string(),
      approved_by: z23.number(),
      approval_notes: z23.string().optional()
    });
    EscrowService = class {
      app;
      connection = null;
      publishChannel = null;
      serviceInstance = null;
      constructor() {
        this.app = express7();
        this.app.use(express7.json());
        this.setupRoutes();
      }
      /**
       * Initialize escrow service
       */
      async initialize(connection2) {
        this.connection = connection2;
        this.publishChannel = await connection2.createChannel();
        console.log("[Escrow Service] Initializing independent escrow microservice...");
        const definition = {
          name: "escrow-service",
          version: "1.0.0",
          port: 5003,
          healthEndpoint: "/health",
          capabilities: [
            "escrow.disbursement",
            "escrow.analysis",
            "escrow.balance_management",
            "escrow.forecasting",
            "escrow.reporting"
          ],
          dependencies: ["loan-service", "payment-service", "database"],
          queueBindings: {
            consumes: ["tenant.*.escrow.disburse", "tenant.*.escrow.analyze"],
            publishes: ["escrow.disbursement.processed", "escrow.disbursement.failed", "escrow.analysis.completed"]
          }
        };
        this.serviceInstance = await globalServiceRegistry.registerService(definition);
        console.log("[Escrow Service] \u2705 Escrow microservice initialized on port 5003");
      }
      /**
       * Setup REST API routes
       */
      setupRoutes() {
        this.app.get("/health", (req, res) => {
          res.json({
            status: "healthy",
            service: "escrow-service",
            version: "1.0.0",
            timestamp: (/* @__PURE__ */ new Date()).toISOString(),
            uptime: process.uptime(),
            capabilities: [
              "escrow.disbursement",
              "escrow.analysis",
              "escrow.balance_management",
              "escrow.forecasting",
              "escrow.reporting"
            ]
          });
        });
        this.app.post("/disbursements", async (req, res) => {
          try {
            const disbursementData = CreateDisbursementSchema2.parse(req.body);
            const disbursementId = ulid14();
            const correlationId = ulid14();
            const escrowMessage = {
              disbursement_id: disbursementId,
              loan_id: disbursementData.loan_id,
              disbursement_type: disbursementData.disbursement_type,
              payee_name: disbursementData.payee_name,
              payee_address: disbursementData.payee_address,
              amount_cents: disbursementData.amount_cents,
              due_date: disbursementData.due_date,
              account_number: disbursementData.account_number,
              reference_number: disbursementData.reference_number,
              notes: disbursementData.notes,
              requires_approval: disbursementData.requires_approval,
              requested_by: 1,
              // TODO: Get from authenticated user
              requested_at: (/* @__PURE__ */ new Date()).toISOString()
            };
            const envelope = createEnvelope({
              tenantId: "default",
              correlationId,
              payload: escrowMessage
            });
            await this.publishChannel.publish(
              Exchanges.Commands,
              "tenant.default.escrow.disburse",
              Buffer.from(JSON.stringify(envelope))
            );
            res.status(202).json({
              success: true,
              disbursement_id: disbursementId,
              correlation_id: correlationId,
              status: "processing",
              message: "Escrow disbursement submitted for processing",
              requires_approval: disbursementData.requires_approval
            });
          } catch (error) {
            console.error("[Escrow Service] Error creating disbursement:", error);
            res.status(400).json({
              success: false,
              error: error.message
            });
          }
        });
        this.app.post("/disbursements/:disbursementId/approve", async (req, res) => {
          try {
            const { disbursementId } = req.params;
            const approvalData = ApproveDisbursementSchema.parse(req.body);
            const correlationId = ulid14();
            const approvalMessage = {
              disbursement_id: disbursementId,
              approved_by: approvalData.approved_by,
              approved_at: (/* @__PURE__ */ new Date()).toISOString(),
              approval_notes: approvalData.approval_notes,
              action: "approve"
            };
            const envelope = createEnvelope({
              tenantId: "default",
              correlationId,
              payload: approvalMessage
            });
            await this.publishChannel.publish(
              Exchanges.Events,
              "escrow.disbursement.approved",
              Buffer.from(JSON.stringify(envelope))
            );
            res.json({
              success: true,
              disbursement_id: disbursementId,
              correlation_id: correlationId,
              status: "approved",
              message: "Disbursement approved and queued for processing"
            });
          } catch (error) {
            console.error("[Escrow Service] Error approving disbursement:", error);
            res.status(400).json({
              success: false,
              error: error.message
            });
          }
        });
        this.app.post("/analysis", async (req, res) => {
          try {
            const analysisData = EscrowAnalysisSchema.parse(req.body);
            const analysisId = ulid14();
            const correlationId = ulid14();
            const analysisMessage = {
              analysis_id: analysisId,
              loan_id: analysisData.loan_id,
              analysis_type: analysisData.analysis_type,
              projection_months: analysisData.projection_months,
              requested_at: (/* @__PURE__ */ new Date()).toISOString()
            };
            const envelope = createEnvelope({
              tenantId: "default",
              correlationId,
              payload: analysisMessage
            });
            await this.publishChannel.publish(
              Exchanges.Commands,
              "tenant.default.escrow.analyze",
              Buffer.from(JSON.stringify(envelope))
            );
            res.status(202).json({
              success: true,
              analysis_id: analysisId,
              correlation_id: correlationId,
              status: "processing",
              message: "Escrow analysis submitted for processing"
            });
          } catch (error) {
            console.error("[Escrow Service] Error running analysis:", error);
            res.status(400).json({
              success: false,
              error: error.message
            });
          }
        });
        this.app.get("/accounts/:loanId/balance", async (req, res) => {
          try {
            const { loanId } = req.params;
            res.json({
              success: true,
              loan_id: parseInt(loanId),
              balance: {
                current_balance: 2500,
                required_balance: 2200,
                shortage: 0,
                surplus: 300,
                monthly_payment: 183.33,
                last_updated: (/* @__PURE__ */ new Date()).toISOString()
              },
              next_disbursements: [
                {
                  type: "property_tax",
                  amount: 850,
                  due_date: "2025-02-15",
                  payee: "County Tax Assessor"
                },
                {
                  type: "homeowners_insurance",
                  amount: 1200,
                  due_date: "2025-03-01",
                  payee: "Insurance Company"
                }
              ]
            });
          } catch (error) {
            console.error("[Escrow Service] Error getting balance:", error);
            res.status(500).json({
              success: false,
              error: error.message
            });
          }
        });
        this.app.get("/disbursements/:disbursementId/status", async (req, res) => {
          try {
            const { disbursementId } = req.params;
            res.json({
              success: true,
              disbursement_id: disbursementId,
              status: "processed",
              disbursement_type: "property_tax",
              payee_name: "County Tax Assessor",
              amount: 850,
              processed_at: (/* @__PURE__ */ new Date()).toISOString(),
              payment_method: "ach",
              reference_number: "ESC-" + disbursementId.slice(-8)
            });
          } catch (error) {
            console.error("[Escrow Service] Error getting disbursement status:", error);
            res.status(500).json({
              success: false,
              error: error.message
            });
          }
        });
        this.app.get("/disbursements", async (req, res) => {
          try {
            const { loan_id, status, disbursement_type } = req.query;
            res.json({
              success: true,
              disbursements: [],
              total: 0,
              filters: {
                loan_id,
                status,
                disbursement_type
              }
            });
          } catch (error) {
            console.error("[Escrow Service] Error listing disbursements:", error);
            res.status(500).json({
              success: false,
              error: error.message
            });
          }
        });
      }
      /**
       * Start the escrow service server
       */
      async start() {
        const port = 5003;
        this.app.listen(port, "0.0.0.0", () => {
          console.log(`[Escrow Service] \u{1F680} Escrow microservice running on port ${port}`);
          if (this.serviceInstance) {
            globalServiceRegistry.updateServiceHealth(this.serviceInstance.serviceId, "healthy");
          }
        });
      }
      /**
       * Stop the escrow service
       */
      async stop() {
        if (this.publishChannel) {
          await this.publishChannel.close();
        }
        if (this.serviceInstance) {
          await globalServiceRegistry.deregisterService(this.serviceInstance.serviceId);
        }
        console.log("[Escrow Service] Escrow microservice stopped");
      }
    };
    escrowService = new EscrowService();
  }
});

// src/services/api-gateway.ts
import express8 from "express";
import { createProxyMiddleware } from "http-proxy-middleware";
var SERVICE_ROUTES, ApiGateway, apiGateway;
var init_api_gateway = __esm({
  "src/services/api-gateway.ts"() {
    "use strict";
    init_service_registry();
    SERVICE_ROUTES = {
      "/api/v3/payments": {
        serviceName: "payment-service",
        capability: "payment.processing",
        target: "http://localhost:5001"
      },
      "/api/v3/documents": {
        serviceName: "document-service",
        capability: "document.processing",
        target: "http://localhost:5002"
      },
      "/api/v3/escrow": {
        serviceName: "escrow-service",
        capability: "escrow.disbursement",
        target: "http://localhost:5003"
      },
      "/api/v3/loans": {
        serviceName: "loan-service",
        capability: "loan.management",
        target: "http://localhost:5004"
        // Future loan service
      }
    };
    ApiGateway = class {
      app;
      connection = null;
      serviceRoutes = /* @__PURE__ */ new Map();
      constructor() {
        this.app = express8();
        this.setupMiddleware();
        this.setupRoutes();
      }
      /**
       * Initialize API gateway
       */
      async initialize(connection2) {
        this.connection = connection2;
        console.log("[API Gateway] Initializing microservice API gateway...");
        this.setupServiceProxies();
        console.log("[API Gateway] \u2705 API gateway initialized");
      }
      /**
       * Setup middleware
       */
      setupMiddleware() {
        this.app.use((req, res, next) => {
          res.header("Access-Control-Allow-Origin", "*");
          res.header("Access-Control-Allow-Methods", "GET,PUT,POST,DELETE,OPTIONS");
          res.header("Access-Control-Allow-Headers", "Origin, X-Requested-With, Content-Type, Accept, Authorization");
          if (req.method === "OPTIONS") {
            res.sendStatus(200);
          } else {
            next();
          }
        });
        this.app.use((req, _res, next) => {
          console.log(`[API Gateway] ${req.method} ${req.path} -> ${this.getTargetService(req.path)}`);
          next();
        });
        this.app.use("/api/v3/*/health", (req, res, next) => {
          const serviceName = this.getServiceNameFromPath(req.path);
          const healthyInstances = globalServiceRegistry.getHealthyInstances(serviceName);
          if (healthyInstances.length === 0) {
            return res.status(503).json({
              error: "Service unavailable",
              service: serviceName,
              message: "No healthy instances available"
            });
          }
          next();
        });
      }
      /**
       * Setup API gateway routes
       */
      setupRoutes() {
        this.app.get("/api/v3/gateway/health", (_req, res) => {
          const stats = globalServiceRegistry.getStats();
          const services = globalServiceRegistry.getAllServices();
          res.json({
            status: "healthy",
            gateway: "api-gateway",
            version: "1.0.0",
            timestamp: (/* @__PURE__ */ new Date()).toISOString(),
            uptime: process.uptime(),
            services: {
              total: stats.totalServices,
              healthy: stats.healthyServices,
              unhealthy: stats.unhealthyServices,
              by_name: stats.servicesByName
            },
            instances: services.map((service) => ({
              service_name: service.serviceName,
              service_id: service.serviceId,
              status: service.status,
              capabilities: service.metadata.capabilities,
              last_health_check: service.lastHealthCheck
            }))
          });
        });
        this.app.get("/api/v3/gateway/services", (req, res) => {
          const { capability, service_name } = req.query;
          let services;
          if (capability) {
            services = globalServiceRegistry.getServicesByCapability(capability);
          } else if (service_name) {
            services = globalServiceRegistry.getHealthyInstances(service_name);
          } else {
            services = globalServiceRegistry.getAllServices();
          }
          res.json({
            success: true,
            services: services.map((service) => ({
              service_id: service.serviceId,
              service_name: service.serviceName,
              version: service.version,
              host: service.host,
              port: service.port,
              status: service.status,
              capabilities: service.metadata.capabilities,
              registered_at: service.registeredAt,
              last_health_check: service.lastHealthCheck
            })),
            total: services.length
          });
        });
        this.app.get("/api/v3/gateway/load-balancer", (_req, res) => {
          const routeStats = Array.from(this.serviceRoutes.entries()).map(([route]) => ({
            route,
            target: SERVICE_ROUTES[route]?.target,
            service_name: SERVICE_ROUTES[route]?.serviceName,
            healthy_instances: globalServiceRegistry.getHealthyInstances(
              SERVICE_ROUTES[route]?.serviceName || ""
            ).length
          }));
          res.json({
            success: true,
            routes: routeStats,
            load_balancing: "round_robin",
            // Future enhancement
            circuit_breaker: "enabled"
            // Future enhancement
          });
        });
        this.app.use("*", (req, res, next) => {
          if (req.path.startsWith("/api/v3/")) {
            return next();
          }
          const url = new URL(req.originalUrl, `http://${req.headers.host ?? "localhost"}`);
          const coreServerUrl = `http://localhost:4000${url.pathname}${url.search}`;
          console.log(`[API Gateway] Redirecting frontend request to: ${coreServerUrl}`);
          res.redirect(302, coreServerUrl);
        });
      }
      /**
       * Setup service proxy middleware
       */
      setupServiceProxies() {
        Object.entries(SERVICE_ROUTES).forEach(([route, config]) => {
          const proxyMiddleware = createProxyMiddleware({
            target: config.target,
            changeOrigin: true,
            pathRewrite: {
              [`^${route}`]: ""
              // Remove route prefix when forwarding
            },
            onProxyReq: (proxyReq, req, _res) => {
              proxyReq.setHeader("X-Gateway-Route", route);
              proxyReq.setHeader("X-Service-Name", config.serviceName);
              proxyReq.setHeader("X-Request-ID", this.generateRequestId());
            },
            onProxyRes: (proxyRes, _req, _res) => {
              proxyRes.headers["X-Gateway"] = "api-gateway-v1";
              proxyRes.headers["X-Service-Route"] = route;
            },
            onError: (err, _req, res) => {
              console.error(`[API Gateway] Proxy error for ${route}:`, err.message);
              if (res && !res.headersSent) {
                res.status(503).json({
                  error: "Service temporarily unavailable",
                  service: config.serviceName,
                  route,
                  message: err.message,
                  retry_after: 30
                });
              }
            }
          });
          this.app.use(route, proxyMiddleware);
          this.serviceRoutes.set(route, proxyMiddleware);
          console.log(`[API Gateway] Registered route: ${route} -> ${config.target} (${config.serviceName})`);
        });
      }
      /**
       * Get target service name from request path
       */
      getTargetService(path11) {
        for (const [route, config] of Object.entries(SERVICE_ROUTES)) {
          if (path11.startsWith(route)) {
            return config.serviceName;
          }
        }
        return "unknown";
      }
      /**
       * Get service name from health check path
       */
      getServiceNameFromPath(path11) {
        const parts = path11.split("/");
        if (parts.length >= 4 && parts[1] === "api" && parts[2] === "v3") {
          const servicePath = parts[3];
          switch (servicePath) {
            case "payments":
              return "payment-service";
            case "documents":
              return "document-service";
            case "escrow":
              return "escrow-service";
            case "loans":
              return "loan-service";
            default:
              return "unknown";
          }
        }
        return "unknown";
      }
      /**
       * Generate unique request ID
       */
      generateRequestId() {
        return `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
      }
      /**
       * Start the API gateway server
       */
      async start() {
        const port = 5e3;
        this.app.listen(port, "0.0.0.0", () => {
          console.log(`[API Gateway] \u{1F680} API Gateway running on port ${port}`);
          console.log("[API Gateway] Available routes:");
          Object.entries(SERVICE_ROUTES).forEach(([route, config]) => {
            console.log(`  ${route} -> ${config.serviceName} (${config.target})`);
          });
        });
      }
      /**
       * Stop the API gateway
       */
      async stop() {
        console.log("[API Gateway] API Gateway stopped");
      }
    };
    apiGateway = new ApiGateway();
  }
});

// src/services/microservice-orchestrator.ts
var microservice_orchestrator_exports = {};
__export(microservice_orchestrator_exports, {
  MicroserviceOrchestrator: () => MicroserviceOrchestrator,
  microserviceOrchestrator: () => microserviceOrchestrator
});
var MicroserviceOrchestrator, microserviceOrchestrator;
var init_microservice_orchestrator = __esm({
  "src/services/microservice-orchestrator.ts"() {
    "use strict";
    init_service_registry();
    init_payment_service();
    init_document_service();
    init_escrow_service();
    init_api_gateway();
    MicroserviceOrchestrator = class {
      connection = null;
      services = [];
      /**
       * Initialize all microservices
       */
      async initialize(connection2) {
        this.connection = connection2;
        console.log("[Orchestrator] \u{1F680} Starting microservice decomposition (Phase 3)...");
        await globalServiceRegistry.initialize(connection2);
        this.services = [
          {
            name: "payment-service",
            service: paymentService,
            port: 5001,
            initialized: false
          },
          {
            name: "document-service",
            service: documentService,
            port: 5002,
            initialized: false
          },
          {
            name: "escrow-service",
            service: escrowService,
            port: 5003,
            initialized: false
          }
        ];
        for (const serviceConfig of this.services) {
          try {
            console.log(`[Orchestrator] Initializing ${serviceConfig.name}...`);
            await serviceConfig.service.initialize(connection2);
            serviceConfig.initialized = true;
            console.log(`[Orchestrator] \u2705 ${serviceConfig.name} initialized`);
          } catch (error) {
            console.error(`[Orchestrator] \u274C Failed to initialize ${serviceConfig.name}:`, error);
            serviceConfig.initialized = false;
          }
        }
        console.log("[Orchestrator] Initializing API Gateway...");
        await apiGateway.initialize(connection2);
        await this.startAllServices();
        this.displayServiceStatus();
        console.log("[Orchestrator] \u{1F389} Phase 3: Microservice decomposition complete!");
      }
      /**
       * Start all initialized services
       */
      async startAllServices() {
        console.log("[Orchestrator] Starting microservice servers...");
        for (const serviceConfig of this.services) {
          if (serviceConfig.initialized) {
            try {
              await serviceConfig.service.start();
              console.log(`[Orchestrator] \u2705 ${serviceConfig.name} server started on port ${serviceConfig.port}`);
            } catch (error) {
              console.error(`[Orchestrator] \u274C Failed to start ${serviceConfig.name}:`, error);
            }
          }
        }
        try {
          await apiGateway.start();
          console.log("[Orchestrator] \u2705 API Gateway started on port 5000");
        } catch (error) {
          console.error("[Orchestrator] \u274C Failed to start API Gateway:", error);
        }
      }
      /**
       * Display comprehensive service status
       */
      displayServiceStatus() {
        console.log("\n[Orchestrator] \u{1F4CA} MICROSERVICE STATUS DASHBOARD");
        console.log("================================================");
        const registryStats = globalServiceRegistry.getStats();
        console.log(`Total Services: ${registryStats.totalServices}`);
        console.log(`Healthy Services: ${registryStats.healthyServices}`);
        console.log(`Unhealthy Services: ${registryStats.unhealthyServices}`);
        console.log("");
        console.log("\u{1F3AF} SERVICE ENDPOINTS:");
        console.log("  API Gateway:       http://localhost:5000/api/v3/gateway/health");
        console.log("  Payment Service:   http://localhost:5001/health");
        console.log("  Document Service:  http://localhost:5002/health");
        console.log("  Escrow Service:    http://localhost:5003/health");
        console.log("");
        console.log("\u{1F517} API ROUTES (via Gateway):");
        console.log("  POST /api/v3/payments        -> Payment processing");
        console.log("  POST /api/v3/documents/upload -> Document upload & processing");
        console.log("  POST /api/v3/escrow/disbursements -> Escrow disbursements");
        console.log("  GET  /api/v3/gateway/services -> Service discovery");
        console.log("");
        console.log("\u26A1 QUEUE INTEGRATION:");
        console.log("  \u2705 Payment processing queue consumers active");
        console.log("  \u2705 Document processing queue consumers active");
        console.log("  \u2705 Escrow disbursement queue consumers active");
        console.log("  \u2705 Service registry event publishing active");
        console.log("");
        console.log("\u{1F50D} MONITORING:");
        console.log("  Queue Health:      GET /api/queue-health");
        console.log("  Service Registry:  GET /api/v3/gateway/services");
        console.log("  Load Balancer:     GET /api/v3/gateway/load-balancer");
        console.log("================================================\n");
      }
      /**
       * Get orchestrator status
       */
      getStatus() {
        const registryServices = globalServiceRegistry.getAllServices();
        return {
          total_services: this.services.length,
          initialized_services: this.services.filter((s) => s.initialized).length,
          running_services: registryServices.filter((s) => s.status === "healthy").length,
          service_details: this.services.map((service) => ({
            name: service.name,
            port: service.port,
            initialized: service.initialized,
            status: service.initialized ? "running" : "stopped"
          }))
        };
      }
      /**
       * Graceful shutdown of all services
       */
      async shutdown() {
        console.log("[Orchestrator] Initiating graceful shutdown...");
        await apiGateway.stop();
        for (const serviceConfig of this.services) {
          if (serviceConfig.initialized) {
            try {
              await serviceConfig.service.stop();
              console.log(`[Orchestrator] \u2705 ${serviceConfig.name} stopped`);
            } catch (error) {
              console.error(`[Orchestrator] Error stopping ${serviceConfig.name}:`, error);
            }
          }
        }
        globalServiceRegistry.stop();
        console.log("[Orchestrator] \u2705 Graceful shutdown complete");
      }
    };
    microserviceOrchestrator = new MicroserviceOrchestrator();
  }
});

// src/init-queues.ts
var init_queues_exports = {};
__export(init_queues_exports, {
  initQueues: () => initQueues
});
import amqp from "amqplib";
import { randomUUID as randomUUID26 } from "node:crypto";
async function initQueues() {
  const rabbitmqUrl = process.env.CLOUDAMQP_URL || process.env.RABBITMQ_URL || "amqp://localhost";
  const conn = await amqp.connect(rabbitmqUrl);
  globalConnection = conn;
  const channel = await conn.createChannel();
  console.log("[Queue Init] Initializing legacy queue system...");
  await channel.assertExchange(Exchanges.COMMANDS, "direct", { durable: true });
  await channel.assertExchange(Exchanges.EVENTS, "topic", { durable: true });
  const legacyQueues = [
    Queues.Import,
    Queues.Ocr,
    Queues.Datapoint,
    Queues.Conflict,
    Queues.Disbursement,
    Queues.Escrow,
    Queues.Ucdp,
    Queues.Flood,
    Queues.Hoi,
    Queues.Title
  ];
  for (const queue of legacyQueues) {
    await channel.assertQueue(queue, {
      durable: true,
      arguments: {
        "x-dead-letter-exchange": "",
        "x-dead-letter-routing-key": dlq(queue)
      }
    });
    await channel.bindQueue(queue, Exchanges.COMMANDS, queue);
    for (const delay of retryDelays) {
      const [value, unit] = delay.match(/(\d+)(s|m)/).slice(1);
      const ttl = Number(value) * (unit === "s" ? 1e3 : 6e4);
      const retryQueue = retry(queue, delay);
      await channel.assertQueue(retryQueue, {
        durable: true,
        arguments: {
          "x-dead-letter-exchange": "",
          "x-dead-letter-routing-key": queue,
          "x-message-ttl": ttl
        }
      });
    }
    await channel.assertQueue(dlq(queue), { durable: true });
  }
  console.log("[Queue Init] Legacy queues initialized");
  console.log("[Queue Init] Initializing modern queue system...");
  await declareTopology(channel);
  console.log("[Queue Init] Modern topology declared");
  const publishFunction = async (exchange, routingKey, message) => {
    const messageBuffer = Buffer.from(JSON.stringify(message));
    const msgId = message.correlationId || randomUUID26();
    await channel.publish(exchange, routingKey, messageBuffer, {
      persistent: true,
      contentType: "application/json",
      messageId: msgId,
      correlationId: msgId,
      timestamp: Date.now(),
      headers: {
        tenantId: message.tenantId || process.env.DEFAULT_TENANT_ID || "default",
        schemaVersion: message.schemaVersion || 1
      }
    });
  };
  await initEtlConsumers(conn, publishFunction);
  console.log("[Queue Init] ETL consumers initialized");
  const { initPaymentConsumer: initPaymentConsumer2 } = await Promise.resolve().then(() => (init_payment_consumer(), payment_consumer_exports));
  await initPaymentConsumer2(conn, publishFunction);
  console.log("[Queue Init] Payment consumers initialized");
  const { initDocumentConsumer: initDocumentConsumer2 } = await Promise.resolve().then(() => (init_document_consumer(), document_consumer_exports));
  await initDocumentConsumer2(conn, publishFunction);
  console.log("[Queue Init] Document consumers initialized");
  const { initEscrowConsumer: initEscrowConsumer2 } = await Promise.resolve().then(() => (init_escrow_consumer(), escrow_consumer_exports));
  await initEscrowConsumer2(conn, publishFunction);
  console.log("[Queue Init] Escrow consumers initialized");
  const { setConnection: setConnection2, startBoardingWorker: startBoardingWorker2 } = await Promise.resolve().then(() => (init_BoardingWorker(), BoardingWorker_exports));
  setConnection2(conn);
  await startBoardingWorker2();
  console.log("[Queue Init] Boarding worker initialized");
  const { initMaintenanceConsumer: initMaintenanceConsumer2 } = await Promise.resolve().then(() => (init_maintenance_consumer(), maintenance_consumer_exports));
  await initMaintenanceConsumer2(conn, publishFunction);
  console.log("[Queue Init] Maintenance consumer initialized");
  const { setPublishFunction: setPublishFunction2 } = await Promise.resolve().then(() => (init_payment_async(), payment_async_exports));
  setPublishFunction2(publishFunction);
  console.log("[Queue Init] Payment route publisher configured");
  const { globalQueueMonitor: globalQueueMonitor2 } = await Promise.resolve().then(() => (init_queue_monitor(), queue_monitor_exports));
  await globalQueueMonitor2.initialize(conn);
  console.log("[Queue Init] Queue monitoring initialized");
  const { microserviceOrchestrator: microserviceOrchestrator2 } = await Promise.resolve().then(() => (init_microservice_orchestrator(), microservice_orchestrator_exports));
  await microserviceOrchestrator2.initialize(conn);
  console.log("[Queue Init] \u2705 Microservice orchestration initialized");
  startEtlScheduler(publishFunction);
  console.log("[Queue Init] ETL scheduler started");
  console.log("[Queue Init] \u2705 Both legacy and modern queue systems initialized");
  process.on("SIGINT", async () => {
    console.log("[Queue Init] Shutting down gracefully...");
    stopEtlScheduler();
    if (channel) await channel.close();
    if (conn) await conn.close();
    process.exit(0);
  });
  process.on("SIGTERM", async () => {
    console.log("[Queue Init] Shutting down gracefully...");
    stopEtlScheduler();
    if (channel) await channel.close();
    if (conn) await conn.close();
    process.exit(0);
  });
}
var NIL4, DEFAULT_TENANT3, retryDelays, globalConnection;
var init_init_queues = __esm({
  "src/init-queues.ts"() {
    "use strict";
    init_topology();
    init_etl_consumer();
    init_etl_scheduler();
    NIL4 = "00000000-0000-0000-0000-000000000000";
    DEFAULT_TENANT3 = process.env.DEFAULT_TENANT_ID ?? NIL4;
    retryDelays = ["10s", "1m", "5m"];
    globalConnection = null;
    if (import.meta.url === `file://${process.argv[1]}`) {
      initQueues().catch((err) => {
        console.error(err);
        process.exit(1);
      });
    }
  }
});

// server/index.ts
import express9 from "express";

// server/routes.ts
init_storage();
import { createServer } from "http";

// server/auth.ts
init_storage();
import passport from "passport";
import { Strategy as LocalStrategy } from "passport-local";
import session from "express-session";
import { scrypt, timingSafeEqual } from "crypto";
import { promisify } from "util";
import argon2 from "argon2";
var scryptAsync = promisify(scrypt);
async function hashPassword(password) {
  return await argon2.hash(password);
}
async function comparePasswords(supplied, stored) {
  if (stored.startsWith("$argon2")) {
    return await argon2.verify(stored, supplied);
  } else if (stored.includes(".")) {
    const [hashed, salt] = stored.split(".");
    const hashedBuf = Buffer.from(hashed, "hex");
    const suppliedBuf = await scryptAsync(supplied, salt, 64);
    return timingSafeEqual(hashedBuf, suppliedBuf);
  }
  return false;
}
function setupAuth(app2) {
  const isProduction = process.env.NODE_ENV === "production" || app2.get("env") === "production";
  if (isProduction && (!process.env.SESSION_SECRET || process.env.SESSION_SECRET === "dev-session-secret-change-in-production")) {
    console.error("WARNING: SESSION_SECRET must be set in production!");
    throw new Error("SESSION_SECRET must be set in production");
  }
  const sessionSettings = {
    secret: process.env.SESSION_SECRET || "dev-session-secret-change-in-production",
    resave: false,
    saveUninitialized: false,
    store: storage.sessionStore,
    cookie: {
      secure: isProduction,
      // Require HTTPS in production
      httpOnly: true,
      maxAge: 24 * 60 * 60 * 1e3,
      // 24 hours
      sameSite: isProduction ? "none" : "strict",
      // 'none' for production to work with HTTPS
      domain: process.env.COOKIE_DOMAIN || void 0
      // Allow setting custom domain
    },
    name: "connect.sid",
    // Explicit session name
    proxy: isProduction
    // Trust proxy headers in production
  };
  app2.set("trust proxy", 1);
  app2.use(session(sessionSettings));
  app2.use(passport.initialize());
  app2.use(passport.session());
  passport.use(
    new LocalStrategy(async (username, password, done) => {
      const user = await storage.getUserByUsername(username);
      if (!user || !await comparePasswords(password, user.password)) {
        return done(null, false);
      } else {
        return done(null, user);
      }
    })
  );
  passport.serializeUser((user, done) => {
    if (!user || !user.id) {
      return done(new Error("Invalid user object"));
    }
    done(null, user.id);
  });
  passport.deserializeUser(async (id, done) => {
    try {
      const userId = typeof id === "string" ? parseInt(id, 10) : id;
      if (isNaN(userId)) {
        return done(new Error("Invalid user ID"));
      }
      const user = await storage.getUser(userId);
      done(null, user);
    } catch (error) {
      console.error("Failed to deserialize user:", error);
      done(error, null);
    }
  });
  app2.post("/api/register", async (req, res, next) => {
    const existingUser = await storage.getUserByUsername(req.body.username);
    if (existingUser) {
      return res.status(400).send("Username already exists");
    }
    const user = await storage.createUser({
      ...req.body,
      password: await hashPassword(req.body.password)
    });
    req.login(user, (err) => {
      if (err) return next(err);
      res.status(201).json(user);
    });
  });
  app2.post("/api/login", (req, res, next) => {
    console.log("Login attempt received");
    console.log("Session ID before auth:", req.sessionID);
    console.log("Session cookie settings:", sessionSettings.cookie);
    passport.authenticate("local", (err, user, info) => {
      if (err) {
        console.error("Login authentication error:", err);
        return res.status(500).json({ error: "Internal server error" });
      }
      if (!user) {
        return res.status(401).json({ error: "Invalid username or password" });
      }
      req.login(user, async (err2) => {
        if (err2) {
          console.error("Login session error:", err2);
          return res.status(500).json({ error: "Login failed" });
        }
        const { db: db2 } = await Promise.resolve().then(() => (init_db(), db_exports));
        const { userRoles: userRoles2, roles: roles2 } = await Promise.resolve().then(() => (init_schema(), schema_exports));
        const { eq: eq38 } = await import("drizzle-orm");
        const userRolesList = await db2.select({
          roleId: roles2.id,
          roleName: roles2.name,
          roleDescription: roles2.description
        }).from(userRoles2).innerJoin(roles2, eq38(userRoles2.roleId, roles2.id)).where(eq38(userRoles2.userId, user.id));
        const roleNames = userRolesList.map((r) => r.roleName);
        const { password, ...userWithoutPassword } = user;
        const userWithRoles = {
          ...userWithoutPassword,
          roles: userRolesList,
          roleNames,
          // Add backward-compatible role field - prioritize borrower role
          role: roleNames.includes("borrower") ? "borrower" : roleNames.includes("admin") ? "admin" : roleNames[0] || "user"
        };
        console.log(`User ${user.username} logged in successfully with role: ${userWithRoles.role}`);
        console.log("Session ID after login:", req.sessionID);
        console.log("Session data:", req.session);
        console.log("Response headers about to be sent");
        req.session.save((saveErr) => {
          if (saveErr) {
            console.error("Session save error:", saveErr);
          }
          console.log("Session saved, sending response");
          return res.status(200).json(userWithRoles);
        });
      });
    })(req, res, next);
  });
  app2.post("/api/logout", (req, res, next) => {
    const username = req.user?.username || "unknown";
    req.logout((err) => {
      if (err) {
        console.error("Logout error:", err);
        return next(err);
      }
      req.session.destroy((err2) => {
        if (err2) {
          console.error("Session destroy error:", err2);
        }
        console.log(`User ${username} logged out successfully`);
        res.clearCookie("connect.sid");
        res.sendStatus(200);
      });
    });
  });
  app2.get("/api/user", async (req, res) => {
    const userId = req.user?.id || req.session?.userId;
    if (!userId) {
      return res.sendStatus(401);
    }
    try {
      const { db: db2 } = await Promise.resolve().then(() => (init_db(), db_exports));
      const { users: users2, userRoles: userRoles2, roles: roles2 } = await Promise.resolve().then(() => (init_schema(), schema_exports));
      const { eq: eq38 } = await import("drizzle-orm");
      const [user] = await db2.select().from(users2).where(eq38(users2.id, userId)).limit(1);
      if (!user) {
        return res.sendStatus(401);
      }
      const userRolesList = await db2.select({
        roleId: roles2.id,
        roleName: roles2.name,
        roleDescription: roles2.description
      }).from(userRoles2).innerJoin(roles2, eq38(userRoles2.roleId, roles2.id)).where(eq38(userRoles2.userId, userId));
      const roleNames = userRolesList.map((r) => r.roleName);
      const { password, ...userWithoutPassword } = user;
      const userWithRoles = {
        ...userWithoutPassword,
        roles: userRolesList,
        roleNames,
        // Add a backward-compatible role field - prioritize borrower role
        role: roleNames.includes("borrower") ? "borrower" : roleNames.includes("admin") ? "admin" : roleNames[0] || "user"
      };
      res.json(userWithRoles);
    } catch (error) {
      console.error("Error fetching user:", error);
      res.sendStatus(500);
    }
  });
}

// server/routes.ts
init_auditService();
init_db();
init_audit_helper();
import { sql as sql23 } from "drizzle-orm";
import multer4 from "multer";
import path5 from "path";
import fs7 from "fs/promises";

// server/utils/file-security.ts
import path from "path";
import crypto2 from "crypto";
function sanitizeFilename(originalName) {
  if (!originalName || typeof originalName !== "string") {
    throw new Error("Invalid filename provided");
  }
  let sanitized = originalName.replace(/[<>:"|?*\x00-\x1F]/g, "").replace(/\.{2,}/g, ".").replace(/^\.+|\.+$/g, "").replace(/[/\\]/g, "").replace(/[\x00-\x1F\x7F]/g, "").trim();
  const windowsReserved = [
    "CON",
    "PRN",
    "AUX",
    "NUL",
    "COM1",
    "COM2",
    "COM3",
    "COM4",
    "COM5",
    "COM6",
    "COM7",
    "COM8",
    "COM9",
    "LPT1",
    "LPT2",
    "LPT3",
    "LPT4",
    "LPT5",
    "LPT6",
    "LPT7",
    "LPT8",
    "LPT9"
  ];
  const nameWithoutExt = path.parse(sanitized).name.toUpperCase();
  if (windowsReserved.includes(nameWithoutExt)) {
    sanitized = `file_${sanitized}`;
  }
  if (!sanitized || sanitized.length === 0) {
    sanitized = "uploaded_file";
  }
  const ext = path.extname(sanitized);
  const baseName = path.basename(sanitized, ext);
  if (baseName.length > 200) {
    const truncated = baseName.substring(0, 200);
    sanitized = truncated + ext;
  }
  return sanitized;
}
function generateSecureFilename(originalName) {
  const sanitizedName = sanitizeFilename(originalName);
  const ext = path.extname(sanitizedName);
  const baseName = path.basename(sanitizedName, ext);
  const timestamp2 = Date.now();
  const randomBytes4 = crypto2.randomBytes(4).toString("hex");
  return `${baseName}_${timestamp2}_${randomBytes4}${ext}`;
}
function validateFileExtension(filename) {
  const allowedExtensions = [
    ".pdf",
    ".doc",
    ".docx",
    ".xls",
    ".xlsx",
    ".txt",
    ".csv",
    ".png",
    ".jpg",
    ".jpeg",
    ".gif",
    ".tiff",
    ".bmp",
    ".zip",
    ".rar",
    ".7z"
  ];
  const ext = path.extname(filename).toLowerCase();
  return {
    valid: allowedExtensions.includes(ext),
    extension: ext
  };
}
function validateFileSize(size, maxSizeMB = 10) {
  const maxSizeBytes = maxSizeMB * 1024 * 1024;
  return size <= maxSizeBytes;
}
function isPasswordProtectedPDF(buffer) {
  try {
    if (buffer.subarray(0, 4).toString() !== "%PDF") {
      return false;
    }
    const pdfContent = buffer.toString("latin1");
    const encryptionIndicators = [
      "/Encrypt",
      // Direct encryption dictionary reference
      "/Filter/Standard",
      // Standard security handler
      "/Filter/PublicKey",
      // Public key security handler
      "/V 1",
      "/V 2",
      "/V 4",
      "/V 5",
      // Encryption algorithm versions
      "/R 2",
      "/R 3",
      "/R 4",
      "/R 5",
      "/R 6",
      // Revision numbers for encryption
      "/UserPassword",
      // User password entry
      "/OwnerPassword"
      // Owner password entry
    ];
    for (const indicator of encryptionIndicators) {
      if (pdfContent.includes(indicator)) {
        return true;
      }
    }
    const encryptTrailerPattern = /\/Encrypt\s+\d+\s+\d+\s+R/;
    if (encryptTrailerPattern.test(pdfContent)) {
      return true;
    }
    if (pdfContent.includes("Adobe.PPKMS") || pdfContent.includes("Adobe.PubSec")) {
      return true;
    }
    return false;
  } catch (error) {
    console.warn("Error checking PDF encryption:", error);
    return true;
  }
}
function validateUploadedFile(originalName, buffer, mimeType, size, options = {}) {
  const errors = [];
  const { maxSizeMB = 10, allowPasswordProtectedPDFs = false } = options;
  let sanitizedFilename;
  try {
    sanitizedFilename = sanitizeFilename(originalName);
  } catch (error) {
    errors.push(`Invalid filename: ${error.message}`);
    return { valid: false, errors };
  }
  const { valid: validExtension, extension } = validateFileExtension(sanitizedFilename);
  if (!validExtension) {
    errors.push(`File type '${extension}' is not allowed`);
  }
  if (!validateFileSize(size, maxSizeMB)) {
    errors.push(`File size exceeds maximum limit of ${maxSizeMB}MB`);
  }
  const expectedMimeTypes = {
    ".pdf": ["application/pdf"],
    ".doc": ["application/msword"],
    ".docx": ["application/vnd.openxmlformats-officedocument.wordprocessingml.document"],
    ".xls": ["application/vnd.ms-excel"],
    ".xlsx": ["application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"],
    ".txt": ["text/plain"],
    ".csv": ["text/csv", "application/csv"],
    ".png": ["image/png"],
    ".jpg": ["image/jpeg"],
    ".jpeg": ["image/jpeg"],
    ".gif": ["image/gif"],
    ".tiff": ["image/tiff"],
    ".bmp": ["image/bmp"],
    ".zip": ["application/zip"],
    ".rar": ["application/x-rar-compressed"],
    ".7z": ["application/x-7z-compressed"]
  };
  const expectedMimes = expectedMimeTypes[extension] || [];
  if (expectedMimes.length > 0 && !expectedMimes.includes(mimeType)) {
    errors.push(`MIME type '${mimeType}' doesn't match file extension '${extension}'`);
  }
  if (extension === ".pdf" && !allowPasswordProtectedPDFs) {
    if (isPasswordProtectedPDF(buffer)) {
      errors.push("Password-protected PDFs are not allowed");
    }
  }
  if (buffer.length === 0) {
    errors.push("File appears to be empty");
  }
  const suspiciousSignatures = [
    Buffer.from([77, 90]),
    // PE/EXE files
    Buffer.from([80, 75, 3, 4])
    // ZIP (could be malicious if unexpected)
  ];
  if (![".zip", ".rar", ".7z"].includes(extension)) {
    for (const signature of suspiciousSignatures) {
      if (buffer.subarray(0, signature.length).equals(signature)) {
        errors.push("File contains suspicious binary signature");
        break;
      }
    }
  }
  const secureFilename = generateSecureFilename(sanitizedFilename);
  return {
    valid: errors.length === 0,
    errors,
    sanitizedFilename,
    secureFilename
  };
}
function createFileUploadAuditLog(originalName, validation, fileSize, mimeType, uploadedBy, clientIP, userAgent) {
  return {
    originalFilename: originalName,
    sanitizedFilename: validation.sanitizedFilename || "unknown",
    secureFilename: validation.secureFilename || "unknown",
    fileSize,
    mimeType,
    validationErrors: validation.errors,
    isPasswordProtectedPDF: mimeType === "application/pdf" && validation.errors.some((e) => e.includes("Password-protected")),
    uploadedBy,
    uploadTimestamp: Date.now(),
    clientIP,
    userAgent
  };
}

// server/openai.ts
import fs from "fs/promises";
import axios from "axios";
import { setTimeout as promiseSetTimeout } from "timers/promises";
import { setTimeout as nodeSetTimeout, clearTimeout as clearTimeout2 } from "timers";
import { v4 as uuidv4 } from "uuid";
var fromPath;
var getDocument;
try {
  ({ fromPath } = await import("pdf2pic"));
  console.log("[INFO] Successfully loaded pdf2pic module");
} catch (error) {
  console.error("[FATAL] Failed to load pdf2pic module", {
    error: error.message
  });
  throw new Error("pdf2pic module is not installed. Run `npm install pdf2pic`");
}
try {
  ({ getDocument } = await import("pdfjs-dist/legacy/build/pdf.js"));
  console.log("[INFO] Successfully loaded pdfjs-dist module");
} catch (error) {
  console.error("[FATAL] Failed to load pdfjs-dist module", {
    error: error.message
  });
  throw new Error(
    "pdfjs-dist module is not installed. Run `npm install pdfjs-dist@3.11.338`"
  );
}
var DocumentAnalysisService = class {
  config;
  apiKey;
  logger;
  constructor() {
    const apiKey = process.env.XAI_API_KEY_NEW || process.env.XAI_API_KEY;
    if (!apiKey || apiKey.trim() === "") {
      throw new Error("XAI_API_KEY or XAI_API_KEY_NEW is missing or invalid");
    }
    this.apiKey = apiKey;
    this.config = {
      baseURL: "https://api.x.ai/v1",
      timeout: 18e4,
      maxRetries: 3,
      initialRetryDelay: 500,
      maxFileSize: 10 * 1024 * 1024,
      // 10MB
      maxPagesToConvert: 5,
      maxJsonContentSize: 1e6
      // 1MB
    };
    this.logger = {
      info: (message, meta = {}) => console.log(`[INFO] ${message}`, meta),
      warn: (message, meta = {}) => console.warn(`[WARN] ${message}`, meta),
      error: (message, meta = {}) => console.error(`[ERROR] ${message}`, meta)
    };
    this.logger.info("DocumentAnalysisService initialized", {
      apiKeyLength: apiKey.length,
      config: this.config
    });
  }
  validateFile(fileName, fileBuffer) {
    if (!fileName) {
      throw new Error("File name is required");
    }
    if (!fileBuffer || fileBuffer.length === 0) {
      throw new Error("File buffer is empty or invalid");
    }
    if (fileBuffer.length > this.config.maxFileSize) {
      throw new Error(
        `File size exceeds maximum limit of ${this.config.maxFileSize / (1024 * 1024)}MB`
      );
    }
    if (!/\.(pdf|jpg|jpeg|png|gif|webp)$/i.test(fileName)) {
      throw new Error(
        "Unsupported file type. Supported types: PDF, JPG, JPEG, PNG, GIF, WEBP"
      );
    }
  }
  buildDocumentAnalysisPrompt(fileName, fileBuffer, documentText) {
    const isImage = /\.(jpg|jpeg|png|gif|webp)$/i.test(fileName);
    const isPDF = /\.pdf$/i.test(fileName);
    const promptParts = [
      `Analyze this ${isImage ? "image" : "PDF document"} named "${fileName}" completely and extract all relevant mortgage loan information.`,
      "",
      "=== DOCUMENT ANALYSIS ===",
      `Document: ${fileName}`,
      `Size: ${Math.round(fileBuffer.length / 1024)}KB`,
      `Type: ${isImage ? "Image" : "PDF"}`,
      documentText ? `Content: ${documentText}` : "",
      // Removed 5000 character limit
      "",
      "=== EXTRACTION REQUIREMENTS ===",
      "First, identify what type of document this is (e.g., loan application, property deed, insurance policy, tax return, income statement, credit report, appraisal, settlement statement, etc.).",
      "",
      "SPECIAL HANDLING FOR CREDIT REPORTS:",
      "If this is a credit report, ONLY extract the following limited information:",
      "- Borrower's SSN",
      "- Borrower's current address (street, city, state, zip)",
      "- Credit scores from all three bureaus (Equifax, Experian, TransUnion)",
      "- Co-borrower's SSN (if present)",
      "- Co-borrower's current address (if present)",
      "- Co-borrower's credit scores (if present)",
      "DO NOT extract loan information, beneficiary/servicer details, or any other data from credit reports.",
      "",
      "For all other document types, extract ALL relevant information from the COMPLETE document including:",
      "- Property details: Extract complete address (street, city, state, zip separately), property type, property value/appraisal value, purchase price if available, APN (Assessor's Parcel Number) or Parcel Number",
      "- Loan information: Extract loan amount, interest rate (as percentage), loan term IN MONTHS (convert years to months), loan type, prepayment penalty terms and expiration date, late charge (amount or percentage), grace period (number of days)",
      "- Fee responsibility: Who pays monthly fees - B (Borrower), S (Beneficiary/Servicer), SP (Split between parties)",
      "- Down payment: Calculate from purchase price minus loan amount if not explicitly stated",
      "- Borrower information: Full name (individual and/or company), phone, email, SSN/EIN/TIN if present, annual income, complete mailing address (may differ from property), credit scores from all three bureaus (Equifax, Experian, TransUnion) if available",
      "- Co-Borrower information: Full name, phone, email, SSN/EIN/TIN if present, annual income, complete mailing address, credit scores from all three bureaus if available",
      "- Payment details: Monthly payment amount (principal + interest), monthly escrow amount, HOA fees if applicable",
      "- Financial details: Property value, down payment amount, closing costs, PMI amount, property taxes (annual), hazard insurance (annual)",
      "- Important dates: Closing/origination date, first payment due date, maturity date (calculate from origination + term), prepayment penalty expiration date",
      "- Trustee/Title Company: Company name, contact name if available, phone, email, complete street address (street, city, state, zip)",
      "- Beneficiary/Lender: Company name, contact name if available, phone, email, complete street address (street, city, state, zip)",
      "- Escrow Company: Company name, ESCROW NUMBER (very important), phone, email, complete street address (street, city, state, zip)",
      "- Investor information: Investor name, bank name, ABA/routing number, account number, account type (checking/savings)",
      "- Loan documents referenced: List all documents mentioned (Note, Deed of Trust, etc.)",
      "- Default conditions: Extract and summarize key events that constitute default",
      "- Insurance requirements: Specific types required and minimum coverage amounts",
      "- Cross-default parties: List any entities mentioned in cross-default clauses",
      "",
      "IMPORTANT EXTRACTION RULES:",
      "- For credit reports: ONLY extract SSN, current address, and credit scores - ignore all other information",
      "- Extract addresses with separate components (street, city, state, zip) - never combine into single field",
      "- The borrower's mailing address may be different from the property address - extract both",
      "- CALCULATE missing values when possible:",
      "  * If loan term is in years, convert to months (years \xD7 12)",
      "  * If down payment not stated but purchase price and loan amount are present: down payment = purchase price - loan amount",
      "  * If maturity date not stated but origination date and term are present: maturity date = origination date + term",
      "  * If property value not stated, use purchase price or appraisal value if available",
      "- Extract ALL numeric values as numbers, not strings (e.g., 250000 not '250000')",
      "- Extract percentages as numbers (e.g., 5.5 for 5.5%, not '5.5%')",
      "- Extract dates in YYYY-MM-DD format",
      "- Extract the ESCROW NUMBER if present anywhere in the document (may be labeled as 'Escrow #', 'File #', 'Order #', etc.)",
      "- Only return null if information is truly not present and cannot be calculated",
      "- For credit reports: Return null for ALL fields except SSN, addresses, and credit scores",
      "- For PDF documents, use both text content and images to ensure nothing is missed",
      "",
      "Return a JSON object with extracted data: {",
      '  "documentType": "document_category_here",',
      '  "extractedData": {',
      '    "propertyStreetAddress": "street_address_only_or_null",',
      '    "propertyCity": "city_only_or_null",',
      '    "propertyState": "state_only_or_null",',
      '    "propertyZipCode": "zip_code_only_or_null",',
      '    "propertyType": "extracted_value_or_null",',
      '    "propertyValue": number_or_null,',
      '    "apnNumber": "assessor_parcel_number_or_null",',
      '    "borrowerName": "extracted_value_or_null",',
      '    "borrowerCompanyName": "company_name_or_null",',
      '    "borrowerPhone": "phone_or_null",',
      '    "borrowerEmail": "email_or_null",',
      '    "borrowerSSN": "ssn_or_null",',
      '    "borrowerIncome": number_or_null,',
      '    "borrowerStreetAddress": "borrower_street_address_or_null",',
      '    "borrowerCity": "borrower_city_or_null",',
      '    "borrowerState": "borrower_state_or_null",',
      '    "borrowerZipCode": "borrower_zip_code_or_null",',
      '    "creditScoreEquifax": number_or_null,',
      '    "creditScoreExperian": number_or_null,',
      '    "creditScoreTransunion": number_or_null,',
      '    "coBorrowerName": "co_borrower_name_or_null",',
      '    "coBorrowerCompanyName": "co_borrower_company_or_null",',
      '    "coBorrowerPhone": "co_borrower_phone_or_null",',
      '    "coBorrowerEmail": "co_borrower_email_or_null",',
      '    "coBorrowerSSN": "co_borrower_ssn_or_null",',
      '    "coBorrowerIncome": number_or_null,',
      '    "coBorrowerStreetAddress": "co_borrower_street_or_null",',
      '    "coBorrowerCity": "co_borrower_city_or_null",',
      '    "coBorrowerState": "co_borrower_state_or_null",',
      '    "coBorrowerZipCode": "co_borrower_zip_or_null",',
      '    "coBorrowerCreditScoreEquifax": number_or_null,',
      '    "coBorrowerCreditScoreExperian": number_or_null,',
      '    "coBorrowerCreditScoreTransunion": number_or_null,',
      '    "loanAmount": number_or_null,',
      '    "interestRate": number_or_null,',
      '    "loanTermMonths": number_in_months_or_null,',
      '    "loanType": "extracted_value_or_null",',
      '    "lateCharge": "late_charge_amount_or_percentage_or_null",',
      '    "gracePeriod": number_of_days_or_null,',
      '    "feePayer": "B_or_S_or_SP_or_null",',
      '    "monthlyPayment": number_or_null,',
      '    "escrowAmount": number_or_null,',
      '    "hoaFees": number_or_null,',
      '    "downPayment": number_or_null,',
      '    "closingCosts": number_or_null,',
      '    "pmi": number_or_null,',
      '    "taxes": number_or_null,',
      '    "insurance": number_or_null,',
      '    "closingDate": "YYYY-MM-DD_or_null",',
      '    "firstPaymentDate": "YYYY-MM-DD_or_null",',
      '    "maturityDate": "YYYY-MM-DD_or_null",',
      '    "prepaymentExpirationDate": "YYYY-MM-DD_or_null",',
      '    "trusteeName": "extracted_value_or_null",',
      '    "trusteeCompanyName": "company_name_or_null",',
      '    "trusteePhone": "phone_or_null",',
      '    "trusteeEmail": "email_or_null",',
      '    "trusteeStreetAddress": "street_address_only_or_null",',
      '    "trusteeCity": "city_only_or_null",',
      '    "trusteeState": "state_only_or_null",',
      '    "trusteeZipCode": "zip_code_only_or_null",',
      '    "beneficiaryName": "extracted_value_or_null",',
      '    "beneficiaryCompanyName": "company_name_or_null",',
      '    "beneficiaryPhone": "phone_or_null",',
      '    "beneficiaryEmail": "email_or_null",',
      '    "beneficiaryStreetAddress": "street_address_only_or_null",',
      '    "beneficiaryCity": "city_only_or_null",',
      '    "beneficiaryState": "state_only_or_null",',
      '    "beneficiaryZipCode": "zip_code_only_or_null",',
      '    "escrowCompanyName": "name_or_null",',
      '    "escrowNumber": "escrow_number_or_null",',
      '    "escrowCompanyPhone": "phone_or_null",',
      '    "escrowCompanyEmail": "email_or_null",',
      '    "escrowCompanyStreetAddress": "street_or_null",',
      '    "escrowCompanyCity": "city_or_null",',
      '    "escrowCompanyState": "state_or_null",',
      '    "escrowCompanyZipCode": "zip_or_null",',
      '    "investorName": "investor_name_or_null",',
      '    "investorBankName": "bank_name_or_null",',
      '    "investorABANumber": "aba_routing_number_or_null",',
      '    "investorAccountNumber": "account_number_or_null",',
      '    "investorAccountType": "checking_or_savings_or_null",',
      '    "loanDocuments": ["array_of_documents_or_null"],',
      '    "defaultConditions": ["array_of_conditions_or_null"],',
      '    "insuranceRequirements": ["array_of_requirements_or_null"],',
      '    "crossDefaultParties": ["array_of_entities_or_null"]',
      "  },",
      '  "confidence": 0.85',
      "}",
      "",
      "IMPORTANT: Include the complete document context in the analysis and ensure accuracy with provided text."
    ];
    const prompt = promptParts.join("\n");
    this.logger.info("Generated document analysis prompt", {
      length: prompt.length
    });
    return prompt;
  }
  async extractPDFText(fileBuffer) {
    try {
      const uint8Array = new Uint8Array(fileBuffer);
      const pdf = await getDocument({ data: uint8Array }).promise;
      let text2 = "";
      const numPages = pdf.numPages;
      this.logger.info("Extracting text from PDF", { numPages });
      for (let i = 1; i <= numPages && i <= this.config.maxPagesToConvert; i++) {
        const page = await pdf.getPage(i);
        const content = await page.getTextContent();
        const pageText = content.items.map((item) => item.str).join(" ").trim();
        text2 += pageText + "\n";
        this.logger.info(`Extracted text from page ${i}`, {
          length: pageText.length
        });
      }
      text2 = text2.trim();
      if (text2.length > 0) {
        this.logger.info("Successfully extracted text from PDF", {
          length: text2.length
        });
        return text2;
      } else {
        this.logger.warn("Extracted PDF text is empty");
        return void 0;
      }
    } catch (error) {
      this.logger.error("PDF text extraction failed", { error: error.message });
      return void 0;
    }
  }
  async convertPDFToImages(fileBuffer) {
    const tempPdfPath = `/tmp/temp_${uuidv4()}.pdf`;
    const base64Images = [];
    let extractedText;
    try {
      extractedText = await this.extractPDFText(fileBuffer);
      this.logger.info("Attempting PDF to image conversion", {
        fileSize: fileBuffer.length
      });
      await fs.writeFile(tempPdfPath, fileBuffer);
      const convert = fromPath(tempPdfPath, {
        density: 300,
        saveFilename: "page",
        savePath: "/tmp/",
        format: "png",
        width: 2e3,
        height: 2800
      });
      for (let i = 1; i <= this.config.maxPagesToConvert; i++) {
        try {
          const page = await convert(i, { responseType: "buffer" });
          if (page.buffer && page.buffer.length > 1e3) {
            const base64Image = page.buffer.toString("base64");
            base64Images.push(base64Image);
            this.logger.info(`Converted PDF page ${i}`, {
              size: base64Image.length
            });
          } else {
            this.logger.warn(`PDF page ${i} has insufficient data`, {
              size: page.buffer?.length || 0
            });
          }
        } catch (pageError) {
          this.logger.warn(`Failed to convert PDF page ${i}`, {
            error: pageError.message
          });
          break;
        }
      }
    } catch (error) {
      this.logger.error("PDF image conversion failed", {
        error: error.message
      });
      if (!extractedText) {
        extractedText = await this.extractPDFText(fileBuffer);
      }
    } finally {
      await fs.unlink(tempPdfPath).catch(() => this.logger.warn("Failed to clean up temp PDF file"));
    }
    if (!extractedText && base64Images.length === 0) {
      throw new Error("Failed to extract text or images from PDF");
    }
    return { images: base64Images, text: extractedText };
  }
  async analyzeDocumentWithGrok(fileName, fileBuffer) {
    try {
      this.validateFile(fileName, fileBuffer);
      this.logger.info(`Processing document`, {
        fileName,
        size: fileBuffer.length
      });
      const isImage = /\.(jpg|jpeg|png|gif|webp)$/i.test(fileName);
      const isPDF = /\.pdf$/i.test(fileName);
      let documentText;
      if (isPDF) {
        const { text: text2 } = await this.convertPDFToImages(fileBuffer);
        documentText = text2;
      }
      const prompt = this.buildDocumentAnalysisPrompt(
        fileName,
        fileBuffer,
        documentText
      );
      const result = await this.generateDocumentAnalysisWithStreaming(
        prompt,
        fileName,
        fileBuffer
      );
      return {
        documentType: result.documentType || "unknown",
        extractedData: result.extractedData || {},
        confidence: result.confidence || 0.5
      };
    } catch (error) {
      this.logger.error("Failed to analyze document", { error: error.message });
      return {
        documentType: "unknown",
        extractedData: {},
        confidence: 0
      };
    }
  }
  async generateDocumentAnalysisWithStreaming(prompt, fileName, fileBuffer) {
    const modelsToTry = ["grok-4-0709"];
    let lastError = null;
    for (const model of modelsToTry) {
      this.logger.info(`Attempting analysis with model`, { model });
      for (let retryCount = 0; retryCount < this.config.maxRetries; retryCount++) {
        try {
          const startTime2 = Date.now();
          const isImage = /\.(jpg|jpeg|png|gif|webp)$/i.test(fileName);
          const isPDF = /\.pdf$/i.test(fileName);
          const content = [{ type: "text", text: prompt }];
          if (isImage) {
            content.push({
              type: "image_url",
              image_url: {
                url: `data:image/jpeg;base64,${fileBuffer.toString("base64")}`
              }
            });
          } else if (isPDF) {
            const { images } = await this.convertPDFToImages(fileBuffer);
            if (images.length > 0) {
              images.forEach((base64Image) => {
                if (base64Image && base64Image.length > 1e3) {
                  content.push({
                    type: "image_url",
                    image_url: { url: `data:image/png;base64,${base64Image}` }
                  });
                }
              });
              this.logger.info(`Added images to request`, {
                count: images.length
              });
            } else {
              this.logger.warn(
                "No valid images extracted, using text-only prompt"
              );
            }
          }
          const response = await axios({
            url: `${this.config.baseURL}/chat/completions`,
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              Authorization: `Bearer ${this.apiKey}`
            },
            data: {
              model,
              messages: [
                {
                  role: "system",
                  content: "You are an expert mortgage document analysis AI. Extract all relevant loan, property, borrower, trustee, beneficiary, and related information from the provided document with high accuracy. Do not generate fictitious data; return null for missing information."
                },
                {
                  role: "user",
                  content
                }
              ],
              response_format: { type: "json_object" },
              temperature: 0.1,
              max_tokens: 8e3,
              // Increased to avoid truncation
              stream: true
            },
            responseType: "stream",
            timeout: this.config.timeout,
            validateStatus: (status) => status === 200
          });
          this.logger.info(`API call initiated`, {
            model,
            duration: Date.now() - startTime2,
            promptLength: prompt.length,
            contentItems: content.length
          });
          const result = await this.processDocumentStream(response);
          if (!result || !result.documentType && !result.extractedData) {
            throw new Error("No valid data in response");
          }
          this.logger.info(`Document analyzed successfully`, {
            model,
            documentType: result.documentType
          });
          return result;
        } catch (error) {
          lastError = error;
          const axiosError = error;
          this.logger.error(`Analysis attempt failed`, {
            model,
            retry: retryCount + 1,
            error: lastError.message
          });
          if (axiosError.response?.status === 429) {
            const delay2 = this.config.initialRetryDelay * Math.pow(2, retryCount);
            this.logger.warn(`Rate limited, retrying after ${delay2}ms`, {
              model,
              retry: retryCount + 1
            });
            await promiseSetTimeout(delay2);
            continue;
          }
          if (axiosError.response?.status === 400 || axiosError.response?.status === 404) {
            this.logger.warn(`Model ${model} not available, trying next model`);
            break;
          }
          if (axiosError.code === "ECONNABORTED") {
            this.logger.warn(
              `Timeout for ${model} attempt ${retryCount + 1}. Retrying in ${delay2}ms`
            );
            const delay2 = this.config.initialRetryDelay * Math.pow(2, retryCount);
            await promiseSetTimeout(delay2);
            continue;
          }
          if (retryCount === this.config.maxRetries - 1) {
            this.logger.warn(
              `Retries exhausted for ${model}, trying next model`
            );
            break;
          }
          const delay = this.config.initialRetryDelay * Math.pow(2, retryCount);
          await promiseSetTimeout(delay);
        }
      }
    }
    this.logger.error("All models failed", { lastError: lastError?.message });
    throw new Error(lastError?.message || "All model attempts failed");
  }
  async processDocumentStream(response) {
    let jsonContent = "";
    let buffer = "";
    let hasData = false;
    let chunkCount = 0;
    return new Promise((resolve, reject) => {
      const timeoutId = nodeSetTimeout(() => {
        if (!hasData) {
          this.logger.error(
            "No data received within 20 seconds, treating as failure"
          );
          reject(new Error("No data received from API within timeout"));
        }
      }, 2e4);
      response.data.on("data", (chunk) => {
        if (!hasData) clearTimeout2(timeoutId);
        hasData = true;
        chunkCount++;
        const chunkStr = chunk.toString();
        buffer += chunkStr;
        if (chunkStr.trim()) hasData = true;
        this.logger.info(`Received chunk`, {
          length: chunkStr.length,
          chunkCount
        });
        if (jsonContent.length + chunkStr.length > this.config.maxJsonContentSize) {
          this.logger.error("JSON content size exceeds maximum limit", {
            currentSize: jsonContent.length,
            maxSize: this.config.maxJsonContentSize
          });
          reject(new Error("JSON content size exceeds maximum limit"));
          return;
        }
        const lines = buffer.split("\n");
        buffer = lines.pop() || "";
        for (const line of lines) {
          if (line.startsWith("data: ")) {
            const data = line.slice(6);
            if (data === "[DONE]") {
              this.logger.info(
                `Stream completed. JSON content length: ${jsonContent.length}`
              );
              if (!jsonContent || jsonContent.length === 0) {
                this.logger.error("Empty response received from API");
                reject(new Error("Empty response from API"));
                return;
              }
              try {
                const cleanContent = jsonContent.replace(
                  /data: \[DONE\]\s*$/,
                  ""
                );
                const result = JSON.parse(cleanContent);
                if (result && (result.documentType || result.extractedData)) {
                  this.logger.info("Stream processing completed", {
                    resultLength: cleanContent.length
                  });
                  resolve(result);
                } else {
                  this.logger.error(
                    "Response lacks valid document analysis data",
                    {
                      contentSnippet: cleanContent.substring(0, 200)
                    }
                  );
                  reject(new Error("Invalid response format"));
                }
                return;
              } catch (e) {
                this.logger.error("JSON parse error in stream", {
                  error: e.message,
                  contentSnippet: jsonContent.substring(
                    Math.max(0, jsonContent.length - 200)
                  )
                });
                this.extractResultFromPartialJSON(jsonContent, resolve, reject);
                return;
              }
            }
            try {
              const parsed = JSON.parse(data);
              const content = parsed.choices?.[0]?.delta?.content;
              if (content) {
                jsonContent += content;
              }
            } catch (e) {
              this.logger.warn("Non-JSON data in stream", {
                data: data.substring(0, 100)
              });
            }
          }
        }
      });
      response.data.on("end", () => {
        clearTimeout2(timeoutId);
        if (!hasData || !jsonContent) {
          this.logger.error("Stream ended with no meaningful data");
          reject(new Error("No data received from API"));
          return;
        }
        try {
          const cleanContent = jsonContent.replace(/data: \[DONE\]\s*$/, "");
          const result = JSON.parse(cleanContent);
          if (result && (result.documentType || result.extractedData)) {
            this.logger.info("Stream completed", {
              resultLength: cleanContent.length
            });
            resolve(result);
          } else {
            this.logger.error(
              "Final response lacks valid document analysis data",
              {
                contentSnippet: cleanContent.substring(0, 200)
              }
            );
            reject(new Error("Invalid response format"));
          }
        } catch (e) {
          this.logger.error("Final JSON parse error", {
            error: e.message,
            contentSnippet: jsonContent.substring(
              Math.max(0, jsonContent.length - 200)
            )
          });
          this.extractResultFromPartialJSON(jsonContent, resolve, reject);
        }
      });
      response.data.on("error", (error) => {
        clearTimeout2(timeoutId);
        this.logger.error("Stream error", { error: error.message });
        reject(new Error(`Stream error: ${error.message}`));
      });
    });
  }
  extractResultFromPartialJSON(content, resolve, reject) {
    if (!content.trim()) {
      this.logger.warn("No content to parse in partial JSON");
      reject(new Error("No content to parse in partial JSON"));
      return;
    }
    try {
      const jsonStart = content.indexOf("{");
      const jsonEnd = content.lastIndexOf("}");
      if (jsonStart >= 0 && jsonEnd > jsonStart) {
        const jsonStr = content.substring(jsonStart, jsonEnd + 1);
        const result = JSON.parse(jsonStr);
        if (result && (result.documentType || result.extractedData)) {
          this.logger.info("Recovered result from partial JSON", {
            resultLength: jsonStr.length
          });
          resolve(result);
        } else {
          this.logger.error("Partial JSON lacks valid document analysis data", {
            contentSnippet: jsonStr.substring(0, 200)
          });
          reject(new Error("Invalid partial JSON format"));
        }
      } else {
        this.logger.error("No valid JSON structure in partial content", {
          contentSnippet: content.substring(0, 200)
        });
        reject(new Error("No valid JSON structure in partial content"));
      }
    } catch (e) {
      this.logger.error("Failed to extract result from partial JSON", {
        error: e.message,
        contentSnippet: content.substring(0, 200)
      });
      reject(new Error(`Failed to parse partial JSON: ${e.message}`));
    }
  }
};
async function analyzeDocument(filePath, fileName) {
  const service = new DocumentAnalysisService();
  try {
    const fileBuffer = await fs.readFile(filePath);
    return await service.analyzeDocumentWithGrok(fileName, fileBuffer);
  } catch (error) {
    service.logger.error("Error reading document file", {
      error: error.message
    });
    return {
      documentType: "unknown",
      extractedData: {},
      confidence: 0
    };
  }
}

// server/routes/fees.ts
init_db();
init_schema();
import { Router } from "express";
import { eq as eq4, and as and3, desc as desc2 } from "drizzle-orm";
var router = Router();
function requireAuth(req, res, next) {
  if (req.isAuthenticated()) {
    return next();
  }
  res.status(401).json({ error: "Unauthorized" });
}
router.get("/templates", requireAuth, async (req, res) => {
  try {
    const templates = await db.select().from(feeTemplates).where(eq4(feeTemplates.lenderId, req.user.id)).orderBy(desc2(feeTemplates.isDefault), desc2(feeTemplates.createdAt));
    res.json(templates);
  } catch (error) {
    console.error("Error fetching fee templates:", error);
    res.status(500).json({ error: "Failed to fetch fee templates" });
  }
});
router.get("/templates/default", requireAuth, async (req, res) => {
  try {
    const [template] = await db.select().from(feeTemplates).where(and3(
      eq4(feeTemplates.lenderId, req.user.id),
      eq4(feeTemplates.isDefault, true)
    )).limit(1);
    res.json(template || null);
  } catch (error) {
    console.error("Error fetching default template:", error);
    res.status(500).json({ error: "Failed to fetch default template" });
  }
});
router.post("/templates", requireAuth, async (req, res) => {
  try {
    const { templateName, description, fees, isDefault } = req.body;
    if (isDefault) {
      await db.update(feeTemplates).set({ isDefault: false }).where(eq4(feeTemplates.lenderId, req.user.id));
    }
    const [template] = await db.insert(feeTemplates).values({
      lenderId: req.user.id,
      templateName,
      description,
      fees,
      isDefault: isDefault || false
    }).returning();
    res.json(template);
  } catch (error) {
    console.error("Error creating fee template:", error);
    res.status(500).json({ error: "Failed to create fee template" });
  }
});
router.put("/templates/:id", requireAuth, async (req, res) => {
  try {
    const { templateName, description, fees, isDefault } = req.body;
    const templateId = parseInt(req.params.id);
    if (isDefault) {
      await db.update(feeTemplates).set({ isDefault: false }).where(and3(
        eq4(feeTemplates.lenderId, req.user.id),
        eq4(feeTemplates.id, templateId)
      ));
    }
    const [template] = await db.update(feeTemplates).set({
      templateName,
      description,
      fees,
      isDefault,
      updatedAt: /* @__PURE__ */ new Date()
    }).where(and3(
      eq4(feeTemplates.id, templateId),
      eq4(feeTemplates.lenderId, req.user.id)
    )).returning();
    res.json(template);
  } catch (error) {
    console.error("Error updating fee template:", error);
    res.status(500).json({ error: "Failed to update fee template" });
  }
});
router.delete("/templates/:id", requireAuth, async (req, res) => {
  try {
    await db.delete(feeTemplates).where(and3(
      eq4(feeTemplates.id, parseInt(req.params.id)),
      eq4(feeTemplates.lenderId, req.user.id)
    ));
    res.json({ success: true });
  } catch (error) {
    console.error("Error deleting fee template:", error);
    res.status(500).json({ error: "Failed to delete fee template" });
  }
});
router.get("/loan/:loanId", requireAuth, async (req, res) => {
  try {
    const fees = await db.select().from(loanFees).where(eq4(loanFees.loanId, parseInt(req.params.loanId))).orderBy(desc2(loanFees.createdAt));
    res.json(fees);
  } catch (error) {
    console.error("Error fetching loan fees:", error);
    res.status(500).json({ error: "Failed to fetch loan fees" });
  }
});
router.post("/loan/:loanId", requireAuth, async (req, res) => {
  try {
    const { feeType, feeName, feeAmount, feePercentage, frequency, chargeDate, dueDate, notes } = req.body;
    const [fee] = await db.insert(loanFees).values({
      loanId: parseInt(req.params.loanId),
      feeType,
      feeName,
      feeAmount,
      feePercentage,
      frequency,
      chargeDate,
      dueDate,
      notes
    }).returning();
    res.json(fee);
  } catch (error) {
    console.error("Error adding loan fee:", error);
    res.status(500).json({ error: "Failed to add loan fee" });
  }
});
router.put("/loan-fee/:id", requireAuth, async (req, res) => {
  try {
    const { feeAmount, dueDate, paidDate, waived, waivedReason, notes } = req.body;
    const [fee] = await db.update(loanFees).set({
      feeAmount,
      dueDate,
      paidDate,
      waived,
      waivedBy: waived ? req.user.id : null,
      waivedReason,
      notes,
      updatedAt: /* @__PURE__ */ new Date()
    }).where(eq4(loanFees.id, parseInt(req.params.id))).returning();
    res.json(fee);
  } catch (error) {
    console.error("Error updating loan fee:", error);
    res.status(500).json({ error: "Failed to update loan fee" });
  }
});
router.delete("/loan-fee/:id", requireAuth, async (req, res) => {
  try {
    await db.delete(loanFees).where(eq4(loanFees.id, parseInt(req.params.id)));
    res.json({ success: true });
  } catch (error) {
    console.error("Error deleting loan fee:", error);
    res.status(500).json({ error: "Failed to delete loan fee" });
  }
});
router.post("/loan/:loanId/apply-template/:templateId", requireAuth, async (req, res) => {
  try {
    const loanId = parseInt(req.params.loanId);
    const templateId = parseInt(req.params.templateId);
    const [template] = await db.select().from(feeTemplates).where(eq4(feeTemplates.id, templateId)).limit(1);
    if (!template) {
      return res.status(404).json({ error: "Template not found" });
    }
    const [loan] = await db.select().from(loans).where(eq4(loans.id, loanId)).limit(1);
    if (!loan) {
      return res.status(404).json({ error: "Loan not found" });
    }
    const feesData = template.fees;
    const createdFees = [];
    for (const fee of feesData) {
      let feeAmount = fee.amount;
      if (fee.isPercentage && fee.percentage) {
        feeAmount = (parseFloat(loan.originalAmount) * fee.percentage / 100).toFixed(2);
      }
      const [createdFee] = await db.insert(loanFees).values({
        loanId,
        feeType: fee.type,
        feeName: fee.name,
        feeAmount: feeAmount.toString(),
        feePercentage: fee.percentage?.toString(),
        frequency: fee.frequency,
        chargeDate: fee.chargeDate,
        dueDate: fee.dueDate,
        notes: `Applied from template: ${template.templateName}`
      }).returning();
      createdFees.push(createdFee);
    }
    res.json({ success: true, fees: createdFees });
  } catch (error) {
    console.error("Error applying template to loan:", error);
    res.status(500).json({ error: "Failed to apply template to loan" });
  }
});
var fees_default = router;

// server/routes/ledger.ts
init_db();
init_schema();
import { eq as eq5, desc as desc3 } from "drizzle-orm";
import { sql as sql5 } from "drizzle-orm";
import { parse } from "json2csv";
import PDFDocument from "pdfkit";
import sgMail from "@sendgrid/mail";
if (process.env.SENDGRID_API_KEY) {
  sgMail.setApiKey(process.env.SENDGRID_API_KEY);
}
async function getLoanLedger(req, res) {
  try {
    const { loanId } = req.params;
    console.log("[Ledger] Fetching double-entry ledger for loan:", loanId);
    const events = await db.select({
      eventId: generalLedgerEvents.eventId,
      eventDate: generalLedgerEvents.eventDate,
      eventType: generalLedgerEvents.eventType,
      description: generalLedgerEvents.description,
      correlationId: generalLedgerEvents.correlationId,
      metadata: generalLedgerEvents.metadata,
      createdAt: generalLedgerEvents.createdAt
    }).from(generalLedgerEvents).where(eq5(generalLedgerEvents.loanId, parseInt(loanId))).orderBy(desc3(generalLedgerEvents.eventDate), desc3(generalLedgerEvents.createdAt));
    if (events.length > 0) {
      const eventIds = events.map((e) => e.eventId);
      const entriesData = await db.select().from(generalLedgerEntries).where(sql5`${generalLedgerEntries.eventId} = ANY(${eventIds})`).orderBy(generalLedgerEntries.accountCode);
      const entriesByEvent = entriesData.reduce((acc, entry) => {
        if (!acc[entry.eventId]) {
          acc[entry.eventId] = [];
        }
        acc[entry.eventId].push(entry);
        return acc;
      }, {});
      const formattedEntries = [];
      let runningBalance = 0;
      const reversedEvents = [...events].reverse();
      for (const event of reversedEvents) {
        const eventEntries = entriesByEvent[event.eventId] || [];
        let netDebit = 0;
        let netCredit = 0;
        for (const entry of eventEntries) {
          const debitAmount = Number(entry.debitMinor) / 100;
          const creditAmount = Number(entry.creditMinor) / 100;
          if (entry.accountCode.startsWith("LOAN")) {
            netDebit += debitAmount;
            netCredit += creditAmount;
          }
        }
        runningBalance += netCredit - netDebit;
        for (const entry of eventEntries) {
          const debitAmount = Number(entry.debitMinor) / 100;
          const creditAmount = Number(entry.creditMinor) / 100;
          formattedEntries.push({
            id: entry.entryId,
            transactionDate: event.eventDate,
            transactionId: event.correlationId || `EVT-${event.eventId.slice(0, 8)}`,
            description: `${event.description} - ${entry.accountName}`,
            transactionType: event.eventType,
            category: entry.accountCode,
            debitAmount: debitAmount > 0 ? debitAmount.toFixed(2) : null,
            creditAmount: creditAmount > 0 ? creditAmount.toFixed(2) : null,
            runningBalance: runningBalance.toFixed(2),
            principalBalance: runningBalance.toFixed(2),
            // Simplified for now
            interestBalance: "0.00",
            // Would need separate tracking
            status: "posted",
            createdAt: event.createdAt,
            accountCode: entry.accountCode,
            accountName: entry.accountName,
            memo: entry.memo
          });
        }
      }
      formattedEntries.reverse();
      console.log("[Ledger] Found double-entry events:", events.length, "with entries:", formattedEntries.length);
      res.json(formattedEntries);
    } else {
      console.log("[Ledger] No double-entry data found, falling back to single-entry ledger");
      const entries = await db.select().from(loanLedger).where(eq5(loanLedger.loanId, parseInt(loanId))).orderBy(desc3(loanLedger.transactionDate), desc3(loanLedger.id));
      console.log("[Ledger] Found single-entry entries:", entries.length);
      res.json(entries);
    }
  } catch (error) {
    console.error("Error fetching loan ledger:", error);
    res.status(500).json({ error: "Failed to fetch ledger entries" });
  }
}
async function createDoubleEntryTransaction({
  loanId,
  eventType,
  eventDate,
  description,
  entries,
  correlationId,
  metadata
}) {
  const [event] = await db.insert(generalLedgerEvents).values({
    loanId,
    eventType,
    eventDate,
    effectiveDate: eventDate,
    description,
    correlationId: correlationId || `TXN-${Date.now()}`,
    metadata
  }).returning();
  let totalDebits = 0;
  let totalCredits = 0;
  for (const entry of entries) {
    totalDebits += entry.debit;
    totalCredits += entry.credit;
  }
  if (Math.abs(totalDebits - totalCredits) > 0.01) {
    throw new Error(`Double-entry imbalance: Debits ${totalDebits} != Credits ${totalCredits}`);
  }
  const ledgerEntries2 = [];
  for (const entry of entries) {
    const [ledgerEntry] = await db.insert(generalLedgerEntries).values({
      eventId: event.eventId,
      accountCode: entry.accountCode,
      accountName: entry.accountName,
      debitMinor: BigInt(Math.round(entry.debit * 100)),
      creditMinor: BigInt(Math.round(entry.credit * 100)),
      currency: "USD",
      memo: entry.memo
    }).returning();
    ledgerEntries2.push(ledgerEntry);
  }
  return { event, entries: ledgerEntries2 };
}
async function addLedgerTransaction(req, res) {
  try {
    const { loanId } = req.params;
    const transaction = req.body;
    const userId = req.user?.id;
    console.log("Adding ledger transaction:", { loanId, transaction, userId });
    const transactionId = `TXN-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
    const lastEntry = await db.select().from(loanLedger).where(eq5(loanLedger.loanId, parseInt(loanId))).orderBy(desc3(loanLedger.transactionDate), desc3(loanLedger.id)).limit(1);
    const lastBalance = lastEntry[0]?.runningBalance || "0";
    const lastPrincipalBalance = lastEntry[0]?.principalBalance || "0";
    const lastInterestBalance = lastEntry[0]?.interestBalance || "0";
    const debit = parseFloat(transaction.debitAmount || "0");
    const credit = parseFloat(transaction.creditAmount || "0");
    const newBalance = parseFloat(lastBalance) + credit - debit;
    let newPrincipalBalance = parseFloat(lastPrincipalBalance);
    let newInterestBalance = parseFloat(lastInterestBalance);
    if (transaction.transactionType === "principal") {
      if (credit > 0) {
        newPrincipalBalance += credit;
      } else if (debit > 0) {
        newPrincipalBalance -= debit;
      }
    } else if (transaction.transactionType === "interest") {
      if (credit > 0) {
        newInterestBalance += credit;
      } else if (debit > 0) {
        newInterestBalance -= debit;
      }
    }
    const approvalRequired = transaction.transactionType === "reversal" || debit > 1e4 || credit > 1e4;
    if (transaction.transactionType === "payment" && (debit > 0 || credit > 0)) {
      try {
        const paymentAmount = debit > 0 ? debit : credit;
        await createDoubleEntryTransaction({
          loanId: parseInt(loanId),
          eventType: "payment",
          eventDate: new Date(transaction.transactionDate),
          description: transaction.description || `Payment received`,
          correlationId: transactionId,
          entries: [
            {
              accountCode: "CASH.PAYMENTS",
              accountName: "Cash - Customer Payments",
              debit: paymentAmount,
              credit: 0,
              memo: "Payment received from borrower"
            },
            {
              accountCode: "LOAN.PRINCIPAL",
              accountName: "Loan Principal Receivable",
              debit: 0,
              credit: paymentAmount,
              memo: "Principal reduction"
            }
          ],
          metadata: {
            paymentMethod: transaction.category,
            notes: transaction.notes
          }
        });
      } catch (error) {
        console.error("Failed to create double-entry records:", error);
      }
    }
    const [newEntry] = await db.insert(loanLedger).values({
      loanId: parseInt(loanId),
      transactionDate: new Date(transaction.transactionDate),
      transactionId,
      description: transaction.description,
      transactionType: transaction.transactionType,
      category: transaction.category,
      debitAmount: transaction.debitAmount ? transaction.debitAmount.toString() : null,
      creditAmount: transaction.creditAmount ? transaction.creditAmount.toString() : null,
      runningBalance: newBalance.toFixed(2),
      principalBalance: newPrincipalBalance.toFixed(2),
      interestBalance: newInterestBalance.toFixed(2),
      status: approvalRequired ? "pending_approval" : "posted",
      approvalRequired,
      createdBy: userId,
      notes: transaction.notes,
      reversalOf: transaction.reversalOf
    }).returning();
    console.log("Transaction added successfully:", newEntry);
    res.json(newEntry);
  } catch (error) {
    console.error("Error adding ledger transaction:", error);
    res.status(500).json({ error: "Failed to add transaction" });
  }
}
async function approveLedgerTransaction(req, res) {
  try {
    const { transactionId } = req.params;
    const { approvalNotes } = req.body;
    const userId = req.user?.id;
    const [transaction] = await db.select().from(loanLedger).where(eq5(loanLedger.id, parseInt(transactionId))).limit(1);
    if (!transaction) {
      return res.status(404).json({ error: "Transaction not found" });
    }
    if (transaction.status !== "pending_approval") {
      return res.status(400).json({ error: "Transaction is not pending approval" });
    }
    const [updated] = await db.update(loanLedger).set({
      status: "posted",
      approvedBy: userId,
      approvalDate: /* @__PURE__ */ new Date(),
      approvalNotes,
      updatedAt: /* @__PURE__ */ new Date()
    }).where(eq5(loanLedger.id, parseInt(transactionId))).returning();
    res.json(updated);
  } catch (error) {
    console.error("Error approving transaction:", error);
    res.status(500).json({ error: "Failed to approve transaction" });
  }
}
async function exportLedgerToCSV(req, res) {
  try {
    const { loanId } = req.params;
    const entries = await db.select().from(loanLedger).where(eq5(loanLedger.loanId, parseInt(loanId))).orderBy(desc3(loanLedger.transactionDate), desc3(loanLedger.id));
    const formattedEntries = entries.map((entry) => ({
      transactionDate: new Date(entry.transactionDate).toLocaleDateString("en-US", {
        year: "numeric",
        month: "2-digit",
        day: "2-digit"
      }),
      transactionId: entry.transactionId,
      description: entry.description,
      transactionType: entry.transactionType,
      debitAmount: entry.debitAmount ? parseFloat(entry.debitAmount).toLocaleString("en-US", { minimumFractionDigits: 2, maximumFractionDigits: 2 }) : "",
      creditAmount: entry.creditAmount ? parseFloat(entry.creditAmount).toLocaleString("en-US", { minimumFractionDigits: 2, maximumFractionDigits: 2 }) : "",
      runningBalance: parseFloat(entry.runningBalance).toLocaleString("en-US", { minimumFractionDigits: 2, maximumFractionDigits: 2 }),
      principalBalance: parseFloat(entry.principalBalance).toLocaleString("en-US", { minimumFractionDigits: 2, maximumFractionDigits: 2 }),
      status: entry.status
    }));
    const fields = [
      "transactionDate",
      "transactionId",
      "description",
      "transactionType",
      "debitAmount",
      "creditAmount",
      "runningBalance",
      "principalBalance",
      "status"
    ];
    const csv = parse(formattedEntries, { fields });
    res.setHeader("Content-Type", "text/csv");
    res.setHeader("Content-Disposition", `attachment; filename="loan-${loanId}-ledger.csv"`);
    res.send(csv);
  } catch (error) {
    console.error("Error exporting ledger:", error);
    res.status(500).json({ error: "Failed to export ledger" });
  }
}
async function exportLedgerToPDF(req, res) {
  try {
    const { loanId } = req.params;
    const entries = await db.select().from(loanLedger).where(eq5(loanLedger.loanId, parseInt(loanId))).orderBy(desc3(loanLedger.transactionDate), desc3(loanLedger.id));
    const loanData = await db.select().from(loans).where(eq5(loans.id, parseInt(loanId))).limit(1);
    const doc = new PDFDocument();
    const buffers = [];
    doc.on("data", buffers.push.bind(buffers));
    doc.on("end", () => {
      const pdfData = Buffer.concat(buffers);
      res.setHeader("Content-Type", "application/pdf");
      res.setHeader("Content-Disposition", `attachment; filename="loan-${loanId}-ledger.pdf"`);
      res.send(pdfData);
    });
    doc.fontSize(20).text("Loan Ledger Report", { align: "center" });
    doc.fontSize(12).text(`Loan Number: ${loanData[0]?.loanNumber || "N/A"}`, { align: "center" });
    doc.moveDown();
    doc.fontSize(10);
    doc.text("Date | Transaction | Description | Debit | Credit | Balance", { underline: true });
    doc.moveDown();
    entries.forEach((entry) => {
      const date2 = new Date(entry.transactionDate).toLocaleDateString("en-US", {
        year: "numeric",
        month: "2-digit",
        day: "2-digit"
      });
      const debit = entry.debitAmount ? parseFloat(entry.debitAmount).toLocaleString("en-US", { minimumFractionDigits: 2, maximumFractionDigits: 2 }) : "-";
      const credit = entry.creditAmount ? parseFloat(entry.creditAmount).toLocaleString("en-US", { minimumFractionDigits: 2, maximumFractionDigits: 2 }) : "-";
      const balance = parseFloat(entry.runningBalance).toLocaleString("en-US", { minimumFractionDigits: 2, maximumFractionDigits: 2 });
      doc.text(`${date2} | ${entry.transactionId} | ${entry.description} | ${debit} | ${credit} | ${balance}`);
    });
    doc.end();
  } catch (error) {
    console.error("Error exporting ledger to PDF:", error);
    res.status(500).json({ error: "Failed to export ledger" });
  }
}
async function emailLedger(req, res) {
  try {
    const { loanId } = req.params;
    const { recipientEmail, recipientName, format: format2 } = req.body;
    if (!process.env.SENDGRID_API_KEY) {
      return res.status(400).json({ error: "Email service not configured" });
    }
    const entries = await db.select().from(loanLedger).where(eq5(loanLedger.loanId, parseInt(loanId))).orderBy(desc3(loanLedger.transactionDate), desc3(loanLedger.id));
    const loanData = await db.select().from(loans).where(eq5(loans.id, parseInt(loanId))).limit(1);
    let attachment;
    let filename;
    if (format2 === "csv") {
      const fields = [
        "transactionDate",
        "transactionId",
        "description",
        "transactionType",
        "debitAmount",
        "creditAmount",
        "runningBalance",
        "principalBalance",
        "status"
      ];
      const csv = parse(entries, { fields });
      attachment = Buffer.from(csv).toString("base64");
      filename = `loan-${loanId}-ledger.csv`;
    } else {
      const doc = new PDFDocument();
      const buffers = [];
      doc.on("data", buffers.push.bind(buffers));
      doc.fontSize(20).text("Loan Ledger Report", { align: "center" });
      doc.fontSize(12).text(`Loan Number: ${loanData[0]?.loanNumber || "N/A"}`, { align: "center" });
      doc.moveDown();
      entries.forEach((entry) => {
        const date2 = new Date(entry.transactionDate).toLocaleDateString();
        doc.fontSize(10).text(`${date2} - ${entry.description}: Debit: ${entry.debitAmount || "-"}, Credit: ${entry.creditAmount || "-"}, Balance: ${entry.runningBalance}`);
      });
      doc.end();
      await new Promise((resolve) => doc.on("end", resolve));
      attachment = Buffer.concat(buffers).toString("base64");
      filename = `loan-${loanId}-ledger.pdf`;
    }
    const msg = {
      to: recipientEmail,
      from: process.env.SENDGRID_FROM_EMAIL || "noreply@loanservepro.com",
      subject: `Loan Ledger Report - ${loanData[0]?.loanNumber || "Loan #" + loanId}`,
      text: `Dear ${recipientName},

Please find attached the loan ledger report for loan ${loanData[0]?.loanNumber || "#" + loanId}.

Best regards,
LoanServe Pro`,
      html: `<p>Dear ${recipientName},</p><p>Please find attached the loan ledger report for loan ${loanData[0]?.loanNumber || "#" + loanId}.</p><p>Best regards,<br>LoanServe Pro</p>`,
      attachments: [
        {
          content: attachment,
          filename,
          type: format2 === "csv" ? "text/csv" : "application/pdf",
          disposition: "attachment"
        }
      ]
    };
    await sgMail.send(msg);
    res.json({ success: true, message: "Ledger report sent successfully" });
  } catch (error) {
    console.error("Error emailing ledger:", error);
    res.status(500).json({ error: "Failed to email ledger report" });
  }
}
function isAuthenticated(req, res, next) {
  if (req.isAuthenticated && req.isAuthenticated()) {
    return next();
  }
  res.status(401).json({ error: "Unauthorized" });
}
function registerLedgerRoutes(app2) {
  app2.get("/api/loans/:loanId/ledger", isAuthenticated, getLoanLedger);
  app2.post("/api/loans/:loanId/ledger", isAuthenticated, addLedgerTransaction);
  app2.post("/api/ledger/:transactionId/approve", isAuthenticated, approveLedgerTransaction);
  app2.get("/api/loans/:loanId/ledger/export/csv", isAuthenticated, exportLedgerToCSV);
  app2.get("/api/loans/:loanId/ledger/export/pdf", isAuthenticated, exportLedgerToPDF);
  app2.post("/api/loans/:loanId/ledger/email", isAuthenticated, emailLedger);
  app2.get("/api/ledger/:transactionId/approve", isAuthenticated, (req, res) => {
    res.json({ message: "Use POST method for approval" });
  });
}

// server/routes/auth.ts
init_auth_service();
init_db();
init_schema();
init_response_utils();
import { Router as Router2 } from "express";
import { eq as eq8 } from "drizzle-orm";
var router2 = Router2();
router2.post("/login", async (req, res) => {
  try {
    const { email, password } = req.body;
    if (!email || !password) {
      return ErrorResponses.badRequest(res, "Email and password are required");
    }
    const ip = req.ip || "unknown";
    const userAgent = req.get("user-agent");
    const ipLimit = await ipRateLimiter.checkLimit(`ip-${ip}`);
    if (!ipLimit.allowed) {
      return ErrorResponses.tooManyRequests(res, "Too many login attempts from this IP", ipLimit.retryAfter);
    }
    const emailLimit = await emailRateLimiter.checkLimit(`email-${email.toLowerCase()}`);
    if (!emailLimit.allowed) {
      return ErrorResponses.tooManyRequests(res, "Too many login attempts for this email", emailLimit.retryAfter);
    }
    const result = await login(email, password, ip, userAgent);
    if (!result.success) {
      await db.insert(authEvents).values({
        eventType: "login_failed",
        ip,
        userAgent,
        details: { email, error: result.error },
        eventKey: `login-failed-${email}-${Date.now()}`
      });
      return ErrorResponses.unauthorized(res, result.error || "Invalid credentials");
    }
    if (req.session) {
      req.session.userId = result.user.id;
      req.session.sessionId = result.sessionId;
      req.session.ip = ip;
      req.session.userAgent = userAgent;
    }
    return sendSuccess(res, {
      user: result.user,
      sessionId: result.sessionId
    }, "Login successful");
  } catch (error) {
    console.error("Login endpoint error:", error);
    return ErrorResponses.internalError(res, "An error occurred during login", error);
  }
});
router2.post("/logout", async (req, res) => {
  try {
    const userId = req.session?.userId || req?.user?.id;
    const sessionId = req.session?.sessionId;
    if (!userId) {
      return res.status(400).json({
        error: "No active session",
        code: "NO_SESSION"
      });
    }
    if (sessionId) {
      await logout(sessionId, userId);
    }
    if (req.session) {
      req.session.destroy((err) => {
        if (err) {
          console.error("Session destroy error:", err);
        }
      });
    }
    res.json({
      success: true,
      message: "Logged out successfully"
    });
  } catch (error) {
    console.error("Logout endpoint error:", error);
    res.status(500).json({
      error: "An error occurred during logout",
      code: "INTERNAL_ERROR"
    });
  }
});
router2.get("/session", async (req, res) => {
  try {
    const sessionId = req.session?.sessionId;
    if (!sessionId) {
      return res.json({
        authenticated: false
      });
    }
    const session2 = await validateSession(sessionId);
    if (!session2.valid) {
      if (req.session) {
        req.session.destroy(() => {
        });
      }
      return res.json({
        authenticated: false
      });
    }
    const [user] = await db.select({
      id: users.id,
      username: users.username,
      email: users.email,
      firstName: users.firstName,
      lastName: users.lastName
      // role field removed - using RBAC system
    }).from(users).where(eq8(users.id, session2.userId)).limit(1);
    res.json({
      authenticated: true,
      user: user || null,
      sessionId
    });
  } catch (error) {
    console.error("Session check error:", error);
    res.status(500).json({
      error: "An error occurred checking session",
      code: "INTERNAL_ERROR"
    });
  }
});
router2.post("/change-password", async (req, res) => {
  try {
    const userId = req.session?.userId;
    if (!userId) {
      return res.status(401).json({
        error: "Authentication required",
        code: "AUTH_REQUIRED"
      });
    }
    const { currentPassword, newPassword } = req.body;
    if (!currentPassword || !newPassword) {
      return res.status(400).json({
        error: "Current and new passwords are required",
        code: "MISSING_PASSWORDS"
      });
    }
    const [user] = await db.select({
      id: users.id,
      password: users.password
    }).from(users).where(eq8(users.id, userId)).limit(1);
    if (!user) {
      return res.status(404).json({
        error: "User not found",
        code: "USER_NOT_FOUND"
      });
    }
    const { verifyPassword: verifyPassword2 } = await Promise.resolve().then(() => (init_auth_service(), auth_service_exports));
    const isValid = await verifyPassword2(currentPassword, user.password);
    if (!isValid) {
      return res.status(401).json({
        error: "Current password is incorrect",
        code: "INVALID_CURRENT_PASSWORD"
      });
    }
    const validation = await validatePassword(newPassword, userId);
    if (!validation.valid) {
      return res.status(400).json({
        error: "New password does not meet requirements",
        code: "INVALID_PASSWORD",
        errors: validation.errors
      });
    }
    const hashedPassword = await hashPassword2(newPassword);
    await db.update(users).set({
      password: hashedPassword,
      passwordUpdatedAt: /* @__PURE__ */ new Date(),
      updatedAt: /* @__PURE__ */ new Date()
    }).where(eq8(users.id, userId));
    await addPasswordToHistory(userId, hashedPassword);
    await db.insert(authEvents).values({
      actorUserId: userId,
      targetUserId: userId,
      eventType: "password_reset_completed",
      ip: req.ip,
      userAgent: req.get("user-agent"),
      details: { method: "change_password" },
      eventKey: `password-change-${userId}-${Date.now()}`
    });
    res.json({
      success: true,
      message: "Password changed successfully"
    });
  } catch (error) {
    console.error("Password change error:", error);
    res.status(500).json({
      error: "An error occurred changing password",
      code: "INTERNAL_ERROR"
    });
  }
});
router2.post("/validate-password", async (req, res) => {
  const { password, userId } = req.body;
  if (!password) {
    return res.status(400).json({
      error: "Password is required",
      code: "MISSING_PASSWORD"
    });
  }
  const validation = await validatePassword(password, userId);
  res.json({
    valid: validation.valid,
    errors: validation.errors
  });
});
router2.post("/password-reset/request", async (req, res) => {
  try {
    const { email } = req.body;
    if (!email) {
      return res.status(400).json({
        error: "Email is required",
        code: "MISSING_EMAIL"
      });
    }
    const {
      createPasswordResetToken: createPasswordResetToken2,
      sendPasswordResetEmail: sendPasswordResetEmail2,
      sendGenericResponseEmail: sendGenericResponseEmail2
    } = await Promise.resolve().then(() => (init_auth_service(), auth_service_exports));
    const emailService = await Promise.resolve().then(() => (init_email_service(), email_service_exports));
    const result = await createPasswordResetToken2(email);
    if (result.token) {
      await emailService.sendPasswordResetEmail(email, result.token);
    } else {
      await emailService.sendGenericResponseEmail(email);
    }
    res.json({
      success: true,
      message: "If an account exists with this email, you will receive password reset instructions."
    });
  } catch (error) {
    console.error("Password reset request error:", error);
    res.status(500).json({
      error: "An error occurred processing your request",
      code: "INTERNAL_ERROR"
    });
  }
});
router2.post("/password-reset/confirm", async (req, res) => {
  try {
    const { token, newPassword } = req.body;
    if (!token || !newPassword) {
      return res.status(400).json({
        error: "Token and new password are required",
        code: "MISSING_PARAMS"
      });
    }
    const { resetPasswordWithToken: resetPasswordWithToken2 } = await Promise.resolve().then(() => (init_auth_service(), auth_service_exports));
    const result = await resetPasswordWithToken2(token, newPassword);
    if (!result.success) {
      return res.status(400).json({
        error: result.error || "Password reset failed",
        code: "RESET_FAILED",
        errors: result.errors
      });
    }
    res.json({
      success: true,
      message: "Password reset successfully. Please login with your new password."
    });
  } catch (error) {
    console.error("Password reset confirm error:", error);
    res.status(500).json({
      error: "An error occurred resetting your password",
      code: "INTERNAL_ERROR"
    });
  }
});
router2.post("/validate-token", async (req, res) => {
  try {
    const { token, type = "invitation" } = req.body;
    if (!token) {
      return res.status(400).json({
        error: "Token is required",
        code: "MISSING_TOKEN"
      });
    }
    const { passwordResetTokens: passwordResetTokens2, users: users2 } = await Promise.resolve().then(() => (init_schema(), schema_exports));
    const crypto22 = await import("crypto");
    const hashedToken = crypto22.createHash("sha256").update(token).digest("hex");
    const [tokenRecord] = await db.select({
      userId: passwordResetTokens2.userId,
      expiresAt: passwordResetTokens2.expiresAt,
      usedAt: passwordResetTokens2.usedAt
    }).from(passwordResetTokens2).where(eq8(passwordResetTokens2.tokenHash, hashedToken)).limit(1);
    if (!tokenRecord) {
      return res.status(400).json({
        error: "Invalid or expired token",
        code: "INVALID_TOKEN"
      });
    }
    if (tokenRecord.usedAt) {
      return res.status(400).json({
        error: "Token has already been used",
        code: "TOKEN_ALREADY_USED"
      });
    }
    if (new Date(tokenRecord.expiresAt) < /* @__PURE__ */ new Date()) {
      return res.status(400).json({
        error: "Token has expired",
        code: "EXPIRED_TOKEN"
      });
    }
    const [user] = await db.select({
      id: users2.id,
      email: users2.email,
      username: users2.username,
      firstName: users2.firstName,
      lastName: users2.lastName
    }).from(users2).where(eq8(users2.id, tokenRecord.userId)).limit(1);
    if (!user) {
      return res.status(400).json({
        error: "User not found",
        code: "USER_NOT_FOUND"
      });
    }
    res.json({
      success: true,
      valid: true,
      user: {
        email: user.email,
        username: user.username,
        firstName: user.firstName,
        lastName: user.lastName
      }
    });
  } catch (error) {
    console.error("Token validation error:", error);
    res.status(500).json({
      error: "An error occurred validating the token",
      code: "INTERNAL_ERROR"
    });
  }
});
router2.post("/activate", async (req, res) => {
  try {
    const { token, username, password, firstName, lastName } = req.body;
    if (!token || !username || !password || !firstName || !lastName) {
      return res.status(400).json({
        error: "All fields are required",
        code: "MISSING_FIELDS"
      });
    }
    const { activateAccountWithToken: activateAccountWithToken2 } = await Promise.resolve().then(() => (init_auth_service(), auth_service_exports));
    const result = await activateAccountWithToken2(
      token,
      username,
      password,
      firstName,
      lastName
    );
    if (!result.success) {
      return res.status(400).json({
        error: result.error || "Account activation failed",
        code: "ACTIVATION_FAILED",
        errors: result.errors
      });
    }
    res.json({
      success: true,
      message: "Account activated successfully. You can now login.",
      user: result.user
    });
  } catch (error) {
    console.error("Account activation error:", error);
    res.status(500).json({
      error: "An error occurred activating your account",
      code: "INTERNAL_ERROR"
    });
  }
});
var auth_default = router2;

// server/routes/admin-users.ts
init_middleware();
init_db();
init_schema();
init_auth_service();
init_email_service();
init_response_utils();
import { Router as Router3 } from "express";
import { eq as eq10, and as and8, or as or3, like, sql as sql9, desc as desc5, inArray as inArray3, isNull as isNull3 } from "drizzle-orm";
import { z as z2 } from "zod";
import * as crypto4 from "crypto";
var router3 = Router3();
var requireAdmin = async (req, res, next) => {
  if (!req.user) {
    return ErrorResponses.unauthorized(res);
  }
  const userRoleRecords = await db.select({
    roleName: roles.name
  }).from(userRoles).innerJoin(roles, eq10(userRoles.roleId, roles.id)).where(eq10(userRoles.userId, req.user.id));
  const hasAdminRole = userRoleRecords.some((r) => r.roleName === "admin");
  if (!hasAdminRole) {
    return ErrorResponses.forbidden(res, "Admin access required");
  }
  next();
};
router3.use(requireAuth2);
router3.use(requireAdmin);
router3.get("/", async (req, res) => {
  try {
    const {
      page = 1,
      limit = 20,
      search = "",
      role = "",
      isActive
    } = req.query;
    const offset = (Number(page) - 1) * Number(limit);
    let baseConditions = [];
    if (search) {
      baseConditions.push(
        or3(
          like(users.username, `%${search}%`),
          like(users.email, `%${search}%`),
          like(users.firstName, `%${search}%`),
          like(users.lastName, `%${search}%`)
        )
      );
    }
    if (isActive !== void 0) {
      baseConditions.push(eq10(users.isActive, isActive === "true"));
    }
    const whereClause = baseConditions.length > 0 ? and8(...baseConditions) : void 0;
    const countQuery = db.select({ count: sql9`COUNT(*)` }).from(users);
    if (whereClause) {
      countQuery.where(whereClause);
    }
    const countResult = await countQuery;
    const totalCount = Number(countResult[0].count);
    const usersQuery = db.select().from(users);
    if (whereClause) {
      usersQuery.where(whereClause);
    }
    const usersList = await usersQuery.orderBy(desc5(users.createdAt)).limit(Number(limit)).offset(offset);
    const userIds = usersList.map((u) => u.id);
    let userRolesMap = {};
    if (userIds.length > 0) {
      const userRolesList = await db.select({
        userId: userRoles.userId,
        roleName: roles.name
      }).from(userRoles).innerJoin(roles, eq10(userRoles.roleId, roles.id)).where(inArray3(userRoles.userId, userIds));
      userRolesList.forEach((ur) => {
        if (!userRolesMap[ur.userId]) {
          userRolesMap[ur.userId] = [];
        }
        userRolesMap[ur.userId].push(ur.roleName);
      });
    }
    let filteredUsers = usersList;
    if (role && role !== "all") {
      filteredUsers = usersList.filter(
        (u) => userRolesMap[u.id]?.includes(role)
      );
    }
    const results = filteredUsers.map((user) => ({
      ...user,
      roles: userRolesMap[user.id] || []
    }));
    res.json({
      users: results,
      pagination: {
        page: Number(page),
        limit: Number(limit),
        total: totalCount,
        pages: Math.ceil(totalCount / Number(limit))
      }
    });
  } catch (error) {
    handleError(error, res);
  }
});
router3.get("/roles", async (req, res) => {
  try {
    const rolesList = await db.select().from(roles).orderBy(roles.name);
    res.json({ roles: rolesList });
  } catch (error) {
    console.error("Error fetching roles:", error);
    res.status(500).json({ error: "Failed to fetch roles" });
  }
});
router3.get("/:id", async (req, res) => {
  try {
    const userId = parseInt(req.params.id);
    const user = await db.select().from(users).where(eq10(users.id, userId)).limit(1);
    if (user.length === 0) {
      return res.status(404).json({ error: "User not found" });
    }
    const userRolesList = await db.select({
      roleId: roles.id,
      roleName: roles.name,
      roleDescription: roles.description
    }).from(userRoles).innerJoin(roles, eq10(userRoles.roleId, roles.id)).where(eq10(userRoles.userId, userId));
    const recentLogins = await db.select().from(loginAttempts).where(eq10(loginAttempts.userId, userId)).orderBy(desc5(loginAttempts.attemptedAt)).limit(10);
    const allSessions = await db.select().from(sessions);
    const activeSessions = allSessions.filter((session2) => {
      try {
        const sessData = typeof session2.sess === "string" ? JSON.parse(session2.sess) : session2.sess;
        return sessData.userId === userId || sessData.passport?.user === userId;
      } catch {
        return false;
      }
    }).map((session2) => ({
      sid: session2.sid,
      expire: session2.expire
    }));
    let ipAllowlist = [];
    try {
      ipAllowlist = await db.select().from(userIpAllowlist).where(eq10(userIpAllowlist.userId, userId));
    } catch (error) {
      console.error("Error fetching IP allowlist:", error);
    }
    res.json({
      user: user[0],
      roles: userRolesList,
      recentLogins,
      activeSessions,
      ipAllowlist
    });
  } catch (error) {
    console.error("Error fetching user details:", error);
    res.status(500).json({ error: "Failed to fetch user details" });
  }
});
var updateUserSchema = z2.object({
  username: z2.string().optional(),
  email: z2.string().email().optional(),
  firstName: z2.string().optional(),
  lastName: z2.string().optional(),
  phone: z2.string().optional(),
  isActive: z2.boolean().optional(),
  emailVerified: z2.boolean().optional()
});
router3.patch("/:id", async (req, res) => {
  try {
    const userId = parseInt(req.params.id);
    const updates = updateUserSchema.parse(req.body);
    const result = await db.update(users).set(updates).where(eq10(users.id, userId)).returning();
    if (result.length === 0) {
      return res.status(404).json({ error: "User not found" });
    }
    await db.insert(authEvents).values({
      eventType: "user_updated",
      actorUserId: req.user.id,
      targetUserId: userId,
      ip: req.ip,
      userAgent: req.headers["user-agent"] || null,
      details: { updates }
    });
    res.json({ user: result[0] });
  } catch (error) {
    console.error("Error updating user:", error);
    res.status(500).json({ error: "Failed to update user" });
  }
});
router3.post("/:id/lock", async (req, res) => {
  try {
    const userId = parseInt(req.params.id);
    const { duration = 30 } = req.body;
    const lockedUntil = /* @__PURE__ */ new Date();
    lockedUntil.setMinutes(lockedUntil.getMinutes() + duration);
    const result = await db.update(users).set({
      lockedUntil,
      failedLoginCount: 0
    }).where(eq10(users.id, userId)).returning();
    if (result.length === 0) {
      return res.status(404).json({ error: "User not found" });
    }
    await db.insert(authEvents).values({
      eventType: "account_locked",
      actorUserId: req.user.id,
      targetUserId: userId,
      ip: req.ip,
      userAgent: req.headers["user-agent"] || null,
      details: { lockedUntil, duration }
    });
    res.json({
      message: "User locked successfully",
      lockedUntil,
      user: result[0]
    });
  } catch (error) {
    console.error("Error locking user:", error);
    res.status(500).json({ error: "Failed to lock user" });
  }
});
router3.post("/:id/unlock", async (req, res) => {
  try {
    const userId = parseInt(req.params.id);
    const result = await db.update(users).set({
      lockedUntil: null,
      failedLoginCount: 0
    }).where(eq10(users.id, userId)).returning();
    if (result.length === 0) {
      return res.status(404).json({ error: "User not found" });
    }
    await db.insert(authEvents).values({
      eventType: "account_unlocked",
      actorUserId: req.user.id,
      targetUserId: userId,
      ip: req.ip,
      userAgent: req.headers["user-agent"] || null,
      details: {}
    });
    res.json({
      message: "User unlocked successfully",
      user: result[0]
    });
  } catch (error) {
    console.error("Error unlocking user:", error);
    res.status(500).json({ error: "Failed to unlock user" });
  }
});
router3.post("/:id/suspend", async (req, res) => {
  try {
    const userId = parseInt(req.params.id);
    const { reason } = req.body;
    const result = await db.update(users).set({ isActive: false }).where(eq10(users.id, userId)).returning();
    if (result.length === 0) {
      return res.status(404).json({ error: "User not found" });
    }
    await db.update(sessions).set({ revokedAt: /* @__PURE__ */ new Date() }).where(and8(
      eq10(sessions.userId, userId),
      isNull3(sessions.revokedAt)
    ));
    await db.insert(authEvents).values({
      eventType: "user_updated",
      actorUserId: req.user.id,
      targetUserId: userId,
      ip: req.ip,
      userAgent: req.headers["user-agent"] || null,
      details: { reason }
    });
    res.json({
      message: "User suspended successfully",
      user: result[0]
    });
  } catch (error) {
    console.error("Error suspending user:", error);
    res.status(500).json({ error: "Failed to suspend user" });
  }
});
router3.post("/:id/activate", async (req, res) => {
  try {
    const userId = parseInt(req.params.id);
    const result = await db.update(users).set({ isActive: true }).where(eq10(users.id, userId)).returning();
    if (result.length === 0) {
      return res.status(404).json({ error: "User not found" });
    }
    await db.insert(authEvents).values({
      eventType: "user_updated",
      actorUserId: req.user.id,
      targetUserId: userId,
      ip: req.ip,
      userAgent: req.headers["user-agent"] || null,
      details: {}
    });
    res.json({
      message: "User activated successfully",
      user: result[0]
    });
  } catch (error) {
    console.error("Error activating user:", error);
    res.status(500).json({ error: "Failed to activate user" });
  }
});
router3.post("/:id/roles", async (req, res) => {
  try {
    const userId = parseInt(req.params.id);
    const { roleId } = req.body;
    if (!roleId) {
      return res.status(400).json({ error: "Role ID is required" });
    }
    const role = await db.select().from(roles).where(eq10(roles.id, roleId)).limit(1);
    if (role.length === 0) {
      return res.status(404).json({ error: "Role not found" });
    }
    const existing = await db.select({
      userId: userRoles.userId,
      roleId: userRoles.roleId
    }).from(userRoles).where(and8(
      eq10(userRoles.userId, userId),
      eq10(userRoles.roleId, roleId)
    )).limit(1);
    if (existing.length > 0) {
      return res.status(400).json({ error: "User already has this role" });
    }
    await db.insert(userRoles).values({
      userId,
      roleId,
      assignedBy: req.user?.id || null
    });
    await db.insert(authEvents).values({
      eventType: "role_assigned",
      actorUserId: req.user.id,
      targetUserId: userId,
      ip: req.ip,
      userAgent: req.headers["user-agent"] || null,
      details: { roleId, roleName: role[0].name }
    });
    res.json({
      message: "Role assigned successfully",
      role: role[0]
    });
  } catch (error) {
    console.error("Error assigning role:", error);
    res.status(500).json({ error: "Failed to assign role" });
  }
});
router3.delete("/:id/roles/:roleId", async (req, res) => {
  try {
    const userId = parseInt(req.params.id);
    const { roleId } = req.params;
    const role = await db.select().from(roles).where(eq10(roles.id, roleId)).limit(1);
    await db.delete(userRoles).where(and8(
      eq10(userRoles.userId, userId),
      eq10(userRoles.roleId, roleId)
    ));
    await db.insert(authEvents).values({
      eventType: "user_updated",
      actorUserId: req.user.id,
      targetUserId: userId,
      ip: req.ip,
      userAgent: req.headers["user-agent"] || null,
      details: { action: "role_removed", roleId, roleName: role[0]?.name }
    });
    res.json({ message: "Role removed successfully" });
  } catch (error) {
    console.error("Error removing role:", error);
    res.status(500).json({ error: "Failed to remove role" });
  }
});
router3.get("/:id/sessions", async (req, res) => {
  try {
    const userId = parseInt(req.params.id);
    const userSessions = await db.select().from(sessions).where(eq10(sessions.userId, userId)).orderBy(desc5(sessions.lastSeenAt));
    res.json({ sessions: userSessions });
  } catch (error) {
    console.error("Error fetching sessions:", error);
    res.status(500).json({ error: "Failed to fetch sessions" });
  }
});
router3.post("/:id/sessions/:sessionId/revoke", async (req, res) => {
  try {
    const userId = parseInt(req.params.id);
    const { sessionId } = req.params;
    const result = await db.update(sessions).set({ revokedAt: /* @__PURE__ */ new Date() }).where(and8(
      eq10(sessions.id, sessionId),
      eq10(sessions.userId, userId)
    )).returning();
    if (result.length === 0) {
      return res.status(404).json({ error: "Session not found" });
    }
    await db.insert(authEvents).values({
      eventType: "session_revoked",
      actorUserId: req.user.id,
      targetUserId: userId,
      ip: req.ip,
      userAgent: req.headers["user-agent"] || null,
      details: { sessionId }
    });
    res.json({ message: "Session revoked successfully" });
  } catch (error) {
    console.error("Error revoking session:", error);
    res.status(500).json({ error: "Failed to revoke session" });
  }
});
router3.get("/:id/audit-logs", async (req, res) => {
  try {
    const userId = parseInt(req.params.id);
    const { page = 1, limit = 50 } = req.query;
    const offset = (Number(page) - 1) * Number(limit);
    const logs = await db.select().from(authEvents).where(or3(
      eq10(authEvents.actorUserId, userId),
      eq10(authEvents.targetUserId, userId)
    )).orderBy(desc5(authEvents.occurredAt)).limit(Number(limit)).offset(offset);
    res.json({ auditLogs: logs });
  } catch (error) {
    console.error("Error fetching audit logs:", error);
    res.status(500).json({ error: "Failed to fetch audit logs" });
  }
});
router3.post("/bulk-invite", async (req, res) => {
  try {
    const { invitations: invitationList } = req.body;
    if (!Array.isArray(invitationList)) {
      return res.status(400).json({ error: "Invitations must be an array" });
    }
    const userId = req.user?.id || req.session?.userId;
    if (!userId) {
      return res.status(401).json({ error: "Authentication required" });
    }
    const results = [];
    const errors = [];
    for (const invitation of invitationList) {
      try {
        const { email, roleId } = invitation;
        const existing = await db.select().from(users).where(eq10(users.email, email)).limit(1);
        if (existing.length > 0) {
          errors.push({ email, error: "User already exists" });
          continue;
        }
        const result = await createInvitationToken(email, roleId, userId);
        if (result.success) {
          results.push({ email, success: true, invitationUrl: result.invitationUrl });
        } else {
          errors.push({ email, error: result.error });
        }
      } catch (error) {
        errors.push({ email: invitation.email, error: "Failed to create invitation" });
      }
    }
    res.json({
      success: results,
      errors,
      summary: {
        total: invitationList.length,
        successful: results.length,
        failed: errors.length
      }
    });
  } catch (error) {
    console.error("Error in bulk invite:", error);
    res.status(500).json({ error: "Failed to process bulk invitations" });
  }
});
router3.post("/bulk-assign-roles", async (req, res) => {
  try {
    const { userIds, roleId } = req.body;
    if (!Array.isArray(userIds) || !roleId) {
      return res.status(400).json({ error: "User IDs and role ID are required" });
    }
    const role = await db.select().from(roles).where(eq10(roles.id, roleId)).limit(1);
    if (role.length === 0) {
      return res.status(404).json({ error: "Role not found" });
    }
    const results = [];
    const errors = [];
    for (const userId of userIds) {
      try {
        const existing = await db.select().from(userRoles).where(and8(
          eq10(userRoles.userId, userId),
          eq10(userRoles.roleId, roleId)
        )).limit(1);
        if (existing.length > 0) {
          errors.push({ userId, error: "User already has this role" });
          continue;
        }
        await db.insert(userRoles).values({
          userId,
          roleId
        });
        results.push({ userId, success: true });
        await db.insert(authEvents).values({
          eventType: "bulk_role_assigned",
          actorUserId: req.user.id,
          targetUserId: userId,
          ip: req.ip,
          userAgent: req.headers["user-agent"] || null,
          details: { roleId, roleName: role[0].name, bulk: true }
        });
      } catch (error) {
        errors.push({ userId, error: "Failed to assign role" });
      }
    }
    res.json({
      success: results,
      errors,
      summary: {
        total: userIds.length,
        successful: results.length,
        failed: errors.length
      }
    });
  } catch (error) {
    console.error("Error in bulk role assignment:", error);
    res.status(500).json({ error: "Failed to process bulk role assignments" });
  }
});
router3.get("/roles", async (req, res) => {
  try {
    const rolesList = await db.select().from(roles).orderBy(roles.name);
    const rolesWithPermissions = await Promise.all(
      rolesList.map(async (role) => {
        const perms = await db.select({
          resource: permissions.resource,
          level: permissions.level,
          scope: rolePermissions.scope
        }).from(rolePermissions).innerJoin(permissions, eq10(rolePermissions.permissionId, permissions.id)).where(eq10(rolePermissions.roleId, role.id));
        return {
          ...role,
          permissions: perms
        };
      })
    );
    res.json({ roles: rolesWithPermissions });
  } catch (error) {
    console.error("Error fetching roles:", error);
    res.status(500).json({ error: "Failed to fetch roles" });
  }
});
router3.post("/:id/resend-invite", async (req, res) => {
  try {
    const userId = parseInt(req.params.id);
    const [user] = await db.select({
      id: users.id,
      email: users.email,
      emailVerified: users.emailVerified,
      lastLogin: users.lastLogin,
      isActive: users.isActive
    }).from(users).where(eq10(users.id, userId)).limit(1);
    if (!user) {
      return res.status(404).json({ error: "User not found" });
    }
    const isInvited = !user.emailVerified && !user.lastLogin;
    if (!isInvited) {
      return res.status(400).json({ error: "User is not in invited status" });
    }
    await db.delete(passwordResetTokens).where(eq10(passwordResetTokens.userId, userId));
    const assignedRoles = await db.select({
      roleName: roles.name
    }).from(userRoles).innerJoin(roles, eq10(userRoles.roleId, roles.id)).where(eq10(userRoles.userId, userId));
    const primaryRole = assignedRoles[0]?.roleName || "user";
    const token = crypto4.randomBytes(32).toString("hex");
    const hashedToken = crypto4.createHash("sha256").update(token).digest("hex");
    const expiresAt = new Date(Date.now() + 7 * 24 * 60 * 60 * 1e3);
    await db.insert(passwordResetTokens).values({
      userId,
      tokenHash: hashedToken,
      expiresAt
    });
    const emailSent = await sendInvitationEmail(
      user.email,
      token,
      primaryRole,
      req.user.id
    );
    if (!emailSent) {
      console.error("Failed to send invitation email to:", user.email);
    }
    await db.insert(authEvents).values({
      eventType: "user_updated",
      actorUserId: req.user.id,
      targetUserId: userId,
      ip: req.ip,
      userAgent: req.headers["user-agent"] || null,
      details: {
        action: "invitation_resent",
        email: user.email,
        role: primaryRole,
        emailSent
      }
    });
    res.json({
      message: emailSent ? "Invitation resent successfully. Email has been sent." : "Invitation resent but email delivery failed. Please check email configuration.",
      email: user.email,
      emailSent,
      ...process.env.NODE_ENV === "development" && {
        token,
        resetLink: `/reset-password?token=${token}`,
        note: "Check server console for email content in development mode"
      }
    });
  } catch (error) {
    console.error("Error resending invitation:", error);
    res.status(500).json({ error: "Failed to resend invitation" });
  }
});
router3.post("/:id/send-password-reset", async (req, res) => {
  try {
    const userId = parseInt(req.params.id);
    const [user] = await db.select({
      id: users.id,
      email: users.email,
      emailVerified: users.emailVerified,
      isActive: users.isActive
    }).from(users).where(eq10(users.id, userId)).limit(1);
    if (!user) {
      return res.status(404).json({ error: "User not found" });
    }
    if (user.status === "disabled") {
      return res.status(400).json({ error: "Cannot send password reset to disabled user" });
    }
    const result = await createPasswordResetToken(user.email);
    if (!result.success || !result.token) {
      return res.status(500).json({ error: result.error || "Failed to create password reset token" });
    }
    const emailSent = await sendPasswordResetEmail(user.email, result.token);
    if (!emailSent) {
      return res.status(500).json({ error: "Failed to send password reset email" });
    }
    await db.insert(authEvents).values({
      eventType: "password_reset_sent_by_admin",
      actorUserId: req.user.id,
      targetUserId: userId,
      ip: req.ip,
      userAgent: req.headers["user-agent"] || null,
      details: { email: user.email }
    });
    res.json({
      message: "Password reset email sent successfully",
      email: user.email
    });
  } catch (error) {
    console.error("Error sending password reset:", error);
    res.status(500).json({ error: "Failed to send password reset" });
  }
});
router3.delete("/:id", requireAdmin, async (req, res) => {
  try {
    const userId = parseInt(req.params.id);
    const currentUserId = req.user.id;
    if (userId === currentUserId) {
      return res.status(400).json({ error: "Cannot delete your own account" });
    }
    const [user] = await db.select({
      id: users.id,
      username: users.username,
      email: users.email
    }).from(users).where(eq10(users.id, userId)).limit(1);
    if (!user) {
      return res.status(404).json({ error: "User not found" });
    }
    if (userId === 1) {
      return res.status(400).json({ error: "Cannot delete the primary administrator account" });
    }
    await db.insert(authEvents).values({
      eventType: "user_deleted",
      actorUserId: currentUserId,
      targetUserId: null,
      // Don't reference the user being deleted
      ip: req.ip,
      userAgent: req.headers["user-agent"] || null,
      details: {
        deletedUserId: userId,
        deletedUsername: user.username,
        deletedEmail: user.email
      },
      eventKey: `user-delete-${userId}-${Date.now()}`
    });
    await db.update(authEvents).set({ targetUserId: null }).where(eq10(authEvents.targetUserId, userId));
    await db.delete(userRoles).where(eq10(userRoles.userId, userId));
    const allSessions = await db.select().from(sessions);
    const userSessions = allSessions.filter((session2) => {
      try {
        const sessData = typeof session2.sess === "string" ? JSON.parse(session2.sess) : session2.sess;
        return sessData.userId === userId || sessData.passport?.user === userId;
      } catch {
        return false;
      }
    });
    for (const session2 of userSessions) {
      await db.delete(sessions).where(eq10(sessions.sid, session2.sid));
    }
    await db.delete(loginAttempts).where(eq10(loginAttempts.userId, userId));
    await db.delete(users).where(eq10(users.id, userId));
    res.json({
      success: true,
      message: `User ${user.username} has been deleted`
    });
  } catch (error) {
    console.error("Error deleting user:", error);
    res.status(500).json({ error: "Failed to delete user" });
  }
});

// server/routes/ip-allowlist.ts
init_middleware();
init_ip_allowlist_service();
import { Router as Router4 } from "express";
var router4 = Router4();
router4.use(requireAuth2);
router4.get("/", async (req, res) => {
  try {
    const userId = req.user?.id;
    const includeInactive = req.query.includeInactive === "true";
    const allowlist = await getUserIpAllowlist(userId, includeInactive);
    res.json({
      entries: allowlist,
      count: allowlist.length,
      currentIp: req.ip
    });
  } catch (error) {
    console.error("Get IP allowlist error:", error);
    res.status(500).json({
      error: "Failed to fetch IP allowlist",
      code: "FETCH_FAILED"
    });
  }
});
router4.post("/", async (req, res) => {
  try {
    const actorUserId = req.user?.id;
    const { cidr, label, userId, expiresAt, beginsAt } = req.body;
    const targetUserId = userId || actorUserId;
    if (!cidr) {
      return res.status(400).json({
        error: "CIDR is required",
        code: "MISSING_CIDR"
      });
    }
    const result = await addIpToAllowlist(targetUserId, cidr, label, actorUserId, expiresAt, beginsAt);
    if (!result.success) {
      return res.status(400).json({
        error: result.error,
        code: "ADD_FAILED"
      });
    }
    res.json({
      success: true,
      id: result.id,
      message: "IP added to allowlist"
    });
  } catch (error) {
    console.error("Add IP to allowlist error:", error);
    res.status(500).json({
      error: "Failed to add IP to allowlist",
      code: "INTERNAL_ERROR"
    });
  }
});
router4.put("/:id", async (req, res) => {
  try {
    const entryId = req.params.id;
    const userId = req.user?.id;
    const { cidr, label, isActive } = req.body;
    const updates = {};
    if (cidr !== void 0) updates.cidr = cidr;
    if (label !== void 0) updates.label = label;
    if (isActive !== void 0) updates.isActive = isActive;
    const result = await updateIpAllowlistEntry(entryId, updates, userId);
    if (!result.success) {
      return res.status(400).json({
        error: result.error,
        code: "UPDATE_FAILED"
      });
    }
    res.json({
      success: true,
      message: "IP allowlist entry updated"
    });
  } catch (error) {
    console.error("Update IP allowlist error:", error);
    res.status(500).json({
      error: "Failed to update IP allowlist entry",
      code: "INTERNAL_ERROR"
    });
  }
});
router4.delete("/:id", async (req, res) => {
  try {
    const entryId = req.params.id;
    const userId = req.user?.id;
    const result = await removeIpFromAllowlist(entryId, userId);
    if (!result.success) {
      return res.status(400).json({
        error: result.error,
        code: "REMOVE_FAILED"
      });
    }
    res.json({
      success: true,
      message: "IP removed from allowlist"
    });
  } catch (error) {
    console.error("Remove IP from allowlist error:", error);
    res.status(500).json({
      error: "Failed to remove IP from allowlist",
      code: "INTERNAL_ERROR"
    });
  }
});
router4.post("/bulk", async (req, res) => {
  try {
    const userId = req.user?.id;
    const { entries } = req.body;
    if (!Array.isArray(entries)) {
      return res.status(400).json({
        error: "Entries must be an array",
        code: "INVALID_ENTRIES"
      });
    }
    const result = await bulkUpdateIpAllowlist(userId, entries, userId);
    if (!result.success) {
      return res.status(400).json({
        error: result.error,
        code: "BULK_UPDATE_FAILED"
      });
    }
    res.json({
      success: true,
      message: `IP allowlist updated with ${entries.length} entries`
    });
  } catch (error) {
    console.error("Bulk update IP allowlist error:", error);
    res.status(500).json({
      error: "Failed to bulk update IP allowlist",
      code: "INTERNAL_ERROR"
    });
  }
});
router4.post("/add-current", async (req, res) => {
  try {
    const userId = req.user?.id;
    const currentIp = req.ip || "unknown";
    const { label } = req.body;
    if (currentIp === "unknown") {
      return res.status(400).json({
        error: "Could not determine current IP",
        code: "IP_UNKNOWN"
      });
    }
    const result = await addIpToAllowlist(
      userId,
      currentIp,
      label || `Current IP (${(/* @__PURE__ */ new Date()).toLocaleDateString()})`,
      userId
    );
    if (!result.success) {
      return res.status(400).json({
        error: result.error,
        code: "ADD_FAILED"
      });
    }
    res.json({
      success: true,
      id: result.id,
      message: `Added current IP ${currentIp} to allowlist`,
      ip: currentIp
    });
  } catch (error) {
    console.error("Add current IP error:", error);
    res.status(500).json({
      error: "Failed to add current IP to allowlist",
      code: "INTERNAL_ERROR"
    });
  }
});
router4.use("/admin", requirePermission("users", "admin"));
router4.get("/admin/user/:userId", async (req, res) => {
  try {
    const userId = parseInt(req.params.userId);
    const includeInactive = req.query.includeInactive === "true";
    if (isNaN(userId)) {
      return res.status(400).json({
        error: "Invalid user ID",
        code: "INVALID_USER_ID"
      });
    }
    const allowlist = await getUserIpAllowlist(userId, includeInactive);
    res.json({
      userId,
      entries: allowlist,
      count: allowlist.length
    });
  } catch (error) {
    console.error("Get user IP allowlist error:", error);
    res.status(500).json({
      error: "Failed to fetch user IP allowlist",
      code: "FETCH_FAILED"
    });
  }
});
router4.post("/admin/user/:userId", async (req, res) => {
  try {
    const userId = parseInt(req.params.userId);
    const actorUserId = req.user?.id;
    const { cidr, label } = req.body;
    if (isNaN(userId)) {
      return res.status(400).json({
        error: "Invalid user ID",
        code: "INVALID_USER_ID"
      });
    }
    if (!cidr) {
      return res.status(400).json({
        error: "CIDR is required",
        code: "MISSING_CIDR"
      });
    }
    const result = await addIpToAllowlist(userId, cidr, label, actorUserId);
    if (!result.success) {
      return res.status(400).json({
        error: result.error,
        code: "ADD_FAILED"
      });
    }
    res.json({
      success: true,
      id: result.id,
      message: `IP added to user ${userId}'s allowlist`
    });
  } catch (error) {
    console.error("Add IP to user allowlist error:", error);
    res.status(500).json({
      error: "Failed to add IP to user allowlist",
      code: "INTERNAL_ERROR"
    });
  }
});
router4.post("/admin/user/:userId/bulk", async (req, res) => {
  try {
    const userId = parseInt(req.params.userId);
    const actorUserId = req.user?.id;
    const { entries } = req.body;
    if (isNaN(userId)) {
      return res.status(400).json({
        error: "Invalid user ID",
        code: "INVALID_USER_ID"
      });
    }
    if (!Array.isArray(entries)) {
      return res.status(400).json({
        error: "Entries must be an array",
        code: "INVALID_ENTRIES"
      });
    }
    const result = await bulkUpdateIpAllowlist(userId, entries, actorUserId);
    if (!result.success) {
      return res.status(400).json({
        error: result.error,
        code: "BULK_UPDATE_FAILED"
      });
    }
    res.json({
      success: true,
      message: `User ${userId}'s IP allowlist updated with ${entries.length} entries`
    });
  } catch (error) {
    console.error("Bulk update user IP allowlist error:", error);
    res.status(500).json({
      error: "Failed to bulk update user IP allowlist",
      code: "INTERNAL_ERROR"
    });
  }
});

// server/routes/mfa.ts
init_middleware();
import { Router as Router5 } from "express";

// server/auth/mfa-service.ts
init_db();
init_schema();
import speakeasy from "speakeasy";
import qrcode from "qrcode";
import crypto5 from "crypto";
import { eq as eq11, and as and9, gt, isNull as isNull4, desc as desc6 } from "drizzle-orm";
var MFA_CONFIG = {
  // TOTP configuration
  totp: {
    issuer: "LoanServe Pro",
    algorithm: "sha1",
    digits: 6,
    period: 30,
    window: 2,
    // Accept codes from 2 time steps before and after
    encoding: "base32"
  },
  // Challenge configuration
  challenge: {
    expiryMinutes: 10,
    maxAttempts: 5,
    lockoutMinutes: 15
  },
  // Backup codes
  backup: {
    count: 10,
    length: 8,
    expiryDays: 365
  }
};
function hashValue(value) {
  return crypto5.createHash("sha256").update(value).digest("hex");
}
function encryptData(data) {
  const algorithm = "aes-256-gcm";
  const key = crypto5.scryptSync(
    process.env.ENCRYPTION_KEY || "default-key-change-in-production",
    "salt",
    32
  );
  const iv = crypto5.randomBytes(16);
  const cipher = crypto5.createCipheriv(algorithm, key, iv);
  let encrypted = cipher.update(data, "utf8", "hex");
  encrypted += cipher.final("hex");
  const authTag = cipher.getAuthTag();
  return JSON.stringify({
    encrypted,
    authTag: authTag.toString("hex"),
    iv: iv.toString("hex")
  });
}
function decryptData(encryptedData) {
  try {
    const { encrypted, authTag, iv } = JSON.parse(encryptedData);
    const algorithm = "aes-256-gcm";
    const key = crypto5.scryptSync(
      process.env.ENCRYPTION_KEY || "default-key-change-in-production",
      "salt",
      32
    );
    const decipher = crypto5.createDecipheriv(
      algorithm,
      key,
      Buffer.from(iv, "hex")
    );
    decipher.setAuthTag(Buffer.from(authTag, "hex"));
    let decrypted = decipher.update(encrypted, "hex", "utf8");
    decrypted += decipher.final("utf8");
    return decrypted;
  } catch (error) {
    console.error("Decryption error:", error);
    throw new Error("Failed to decrypt data");
  }
}
async function beginTotpEnrollment(userId, factorName, ip, userAgent) {
  try {
    const existingFactors = await db.select().from(userMfaFactors).where(and9(
      eq11(userMfaFactors.userId, userId),
      eq11(userMfaFactors.factorType, "totp"),
      eq11(userMfaFactors.isActive, true)
    ));
    if (existingFactors.length >= 3) {
      return { success: false, error: "Maximum number of TOTP devices reached" };
    }
    const [user] = await db.select({ email: users.email }).from(users).where(eq11(users.id, userId)).limit(1);
    if (!user) {
      return { success: false, error: "User not found" };
    }
    const secret = speakeasy.generateSecret({
      name: `${MFA_CONFIG.totp.issuer}:${user.email}`,
      issuer: MFA_CONFIG.totp.issuer,
      length: 32
    });
    const encryptedSecret = encryptData(secret.base32);
    const [factor] = await db.insert(userMfaFactors).values({
      userId,
      factorType: "totp",
      factorName,
      totpSecret: encryptedSecret,
      totpIssuer: MFA_CONFIG.totp.issuer,
      totpAlgorithm: MFA_CONFIG.totp.algorithm.toUpperCase(),
      totpDigits: MFA_CONFIG.totp.digits,
      totpPeriod: MFA_CONFIG.totp.period,
      verified: false,
      enrolledIp: ip,
      enrolledUserAgent: userAgent,
      isActive: false
      // Not active until verified
    }).returning({ id: userMfaFactors.id });
    const qrCodeUrl = await qrcode.toDataURL(secret.otpauth_url);
    await db.insert(mfaAuditLog).values({
      userId,
      factorId: factor.id,
      eventType: "enrollment_started",
      eventDetails: { factorName, factorType: "totp" },
      ip,
      userAgent,
      success: true
    });
    return {
      success: true,
      secret: secret.base32,
      // Return for manual entry
      qrCodeUrl,
      factorId: factor.id
    };
  } catch (error) {
    console.error("TOTP enrollment error:", error);
    await db.insert(mfaAuditLog).values({
      userId,
      eventType: "enrollment_failed",
      eventDetails: { factorName, factorType: "totp" },
      ip,
      userAgent,
      success: false,
      failureReason: error.message
    });
    return { success: false, error: "Failed to begin enrollment" };
  }
}
async function verifyTotpEnrollment(factorId, code, userId, ip, userAgent) {
  try {
    const [factor] = await db.select().from(userMfaFactors).where(and9(
      eq11(userMfaFactors.id, factorId),
      eq11(userMfaFactors.userId, userId),
      eq11(userMfaFactors.verified, false)
    )).limit(1);
    if (!factor) {
      return { success: false, error: "Invalid enrollment session" };
    }
    const secret = decryptData(factor.totpSecret);
    const verified = speakeasy.totp.verify({
      secret,
      encoding: MFA_CONFIG.totp.encoding,
      token: code,
      window: MFA_CONFIG.totp.window,
      algorithm: factor.totpAlgorithm.toLowerCase()
    });
    if (!verified) {
      await db.insert(mfaAuditLog).values({
        userId,
        factorId,
        eventType: "enrollment_verification_failed",
        eventDetails: { reason: "invalid_code" },
        ip,
        userAgent,
        success: false,
        failureReason: "Invalid verification code"
      });
      return { success: false, error: "Invalid verification code" };
    }
    await db.update(userMfaFactors).set({
      verified: true,
      verifiedAt: /* @__PURE__ */ new Date(),
      isActive: true
    }).where(eq11(userMfaFactors.id, factorId));
    await db.update(users).set({ twoFactorEnabled: true }).where(eq11(users.id, userId));
    const backupCodes = await generateBackupCodes(userId);
    await db.insert(mfaAuditLog).values({
      userId,
      factorId,
      eventType: "enrollment_completed",
      eventDetails: { factorName: factor.factorName },
      ip,
      userAgent,
      success: true
    });
    return { success: true, backupCodes };
  } catch (error) {
    console.error("TOTP verification error:", error);
    return { success: false, error: "Failed to verify enrollment" };
  }
}
async function generateBackupCodes(userId, regenerate = false) {
  try {
    if (regenerate) {
      await db.update(mfaBackupCodes).set({ expiresAt: /* @__PURE__ */ new Date() }).where(and9(
        eq11(mfaBackupCodes.userId, userId),
        isNull4(mfaBackupCodes.usedAt)
      ));
    }
    const codes = [];
    const codeRecords = [];
    const expiresAt = /* @__PURE__ */ new Date();
    expiresAt.setDate(expiresAt.getDate() + MFA_CONFIG.backup.expiryDays);
    for (let i = 0; i < MFA_CONFIG.backup.count; i++) {
      const code = crypto5.randomBytes(MFA_CONFIG.backup.length).toString("hex").toUpperCase().substring(0, MFA_CONFIG.backup.length);
      codes.push(code);
      codeRecords.push({
        userId,
        codeHash: hashValue(code),
        expiresAt
      });
    }
    await db.insert(mfaBackupCodes).values(codeRecords);
    return codes;
  } catch (error) {
    console.error("Backup code generation error:", error);
    throw new Error("Failed to generate backup codes");
  }
}
async function createMfaChallenge(userId, challengeType, action, sessionId, ip, userAgent, deviceFingerprint) {
  try {
    const factors = await db.select({
      id: userMfaFactors.id,
      factorName: userMfaFactors.factorName,
      factorType: userMfaFactors.factorType
    }).from(userMfaFactors).where(and9(
      eq11(userMfaFactors.userId, userId),
      eq11(userMfaFactors.isActive, true),
      eq11(userMfaFactors.verified, true)
    ));
    if (factors.length === 0 && challengeType !== "enrollment") {
      return { success: false, error: "No MFA factors configured" };
    }
    const existingChallenges = await db.select().from(mfaChallenges).where(and9(
      eq11(mfaChallenges.userId, userId),
      eq11(mfaChallenges.status, "pending"),
      gt(mfaChallenges.expiresAt, /* @__PURE__ */ new Date())
    )).limit(1);
    if (existingChallenges.length > 0) {
      return {
        success: true,
        challengeId: existingChallenges[0].challengeId,
        factors
      };
    }
    const challengeId = crypto5.randomUUID();
    const expiresAt = /* @__PURE__ */ new Date();
    expiresAt.setMinutes(expiresAt.getMinutes() + MFA_CONFIG.challenge.expiryMinutes);
    await db.insert(mfaChallenges).values({
      challengeId,
      userId,
      sessionId,
      challengeType,
      action,
      status: "pending",
      ip,
      userAgent,
      deviceFingerprint,
      expiresAt
    });
    await db.insert(mfaAuditLog).values({
      userId,
      challengeId,
      eventType: "challenge_created",
      eventDetails: { challengeType, action },
      ip,
      userAgent,
      deviceFingerprint,
      success: true
    });
    return {
      success: true,
      challengeId,
      factors
    };
  } catch (error) {
    console.error("MFA challenge creation error:", error);
    return { success: false, error: "Failed to create MFA challenge" };
  }
}
async function verifyMfaChallenge(challengeId, code, factorId, ip, userAgent) {
  try {
    const [challenge] = await db.select().from(mfaChallenges).where(and9(
      eq11(mfaChallenges.challengeId, challengeId),
      eq11(mfaChallenges.status, "pending"),
      gt(mfaChallenges.expiresAt, /* @__PURE__ */ new Date())
    )).limit(1);
    if (!challenge) {
      return { success: false, error: "Invalid or expired challenge" };
    }
    if (challenge.lockedUntil && challenge.lockedUntil > /* @__PURE__ */ new Date()) {
      return { success: false, error: "Too many failed attempts. Please try again later." };
    }
    const isBackupCode = /^[A-F0-9]{8}$/i.test(code);
    let verified = false;
    let usedFactorId = null;
    if (isBackupCode) {
      const codeHash = hashValue(code.toUpperCase());
      const [backupCode] = await db.select().from(mfaBackupCodes).where(and9(
        eq11(mfaBackupCodes.userId, challenge.userId),
        eq11(mfaBackupCodes.codeHash, codeHash),
        isNull4(mfaBackupCodes.usedAt),
        gt(mfaBackupCodes.expiresAt, /* @__PURE__ */ new Date())
      )).limit(1);
      if (backupCode) {
        await db.update(mfaBackupCodes).set({
          usedAt: /* @__PURE__ */ new Date(),
          usedIp: ip
        }).where(eq11(mfaBackupCodes.id, backupCode.id));
        verified = true;
        await db.insert(mfaAuditLog).values({
          userId: challenge.userId,
          challengeId,
          eventType: "backup_code_used",
          eventDetails: { codeId: backupCode.id },
          ip,
          userAgent,
          success: true
        });
      }
    } else {
      let factors;
      if (factorId) {
        factors = await db.select().from(userMfaFactors).where(and9(
          eq11(userMfaFactors.id, factorId),
          eq11(userMfaFactors.userId, challenge.userId),
          eq11(userMfaFactors.factorType, "totp"),
          eq11(userMfaFactors.isActive, true)
        )).limit(1);
      } else {
        factors = await db.select().from(userMfaFactors).where(and9(
          eq11(userMfaFactors.userId, challenge.userId),
          eq11(userMfaFactors.factorType, "totp"),
          eq11(userMfaFactors.isActive, true)
        ));
      }
      for (const factor of factors) {
        const secret = decryptData(factor.totpSecret);
        const isValid = speakeasy.totp.verify({
          secret,
          encoding: MFA_CONFIG.totp.encoding,
          token: code,
          window: MFA_CONFIG.totp.window,
          algorithm: factor.totpAlgorithm.toLowerCase()
        });
        if (isValid) {
          verified = true;
          usedFactorId = factor.id;
          await db.update(userMfaFactors).set({ lastUsedAt: /* @__PURE__ */ new Date() }).where(eq11(userMfaFactors.id, factor.id));
          break;
        }
      }
    }
    if (!verified) {
      const newAttempts = (challenge.attempts || 0) + 1;
      const updates = {
        attempts: newAttempts,
        lastAttemptAt: /* @__PURE__ */ new Date()
      };
      if (newAttempts >= MFA_CONFIG.challenge.maxAttempts) {
        const lockedUntil = /* @__PURE__ */ new Date();
        lockedUntil.setMinutes(lockedUntil.getMinutes() + MFA_CONFIG.challenge.lockoutMinutes);
        updates.lockedUntil = lockedUntil;
        updates.status = "failed";
      }
      await db.update(mfaChallenges).set(updates).where(eq11(mfaChallenges.id, challenge.id));
      await db.insert(mfaAuditLog).values({
        userId: challenge.userId,
        factorId: usedFactorId,
        challengeId,
        eventType: "challenge_verification_failed",
        eventDetails: { attempts: newAttempts },
        ip,
        userAgent,
        success: false,
        failureReason: "Invalid code"
      });
      return {
        success: false,
        error: newAttempts >= MFA_CONFIG.challenge.maxAttempts ? "Maximum attempts exceeded. Challenge locked." : "Invalid verification code"
      };
    }
    await db.update(mfaChallenges).set({
      status: "verified",
      verifiedAt: /* @__PURE__ */ new Date(),
      completedFactors: 1,
      factorId: usedFactorId
    }).where(eq11(mfaChallenges.id, challenge.id));
    await db.insert(mfaAuditLog).values({
      userId: challenge.userId,
      factorId: usedFactorId,
      challengeId,
      eventType: "challenge_verified",
      eventDetails: { challengeType: challenge.challengeType },
      ip,
      userAgent,
      success: true
    });
    return {
      success: true,
      userId: challenge.userId,
      requiresAdditionalFactor: false
      // Could be extended for multi-factor requirements
    };
  } catch (error) {
    console.error("MFA challenge verification error:", error);
    return { success: false, error: "Failed to verify challenge" };
  }
}
async function userRequiresMfa(userId, action) {
  try {
    const [user] = await db.select({
      mfaEnabled: users.twoFactorEnabled,
      mfaRequired: users.mfaRequired,
      requireMfaForSensitive: users.require_mfa_for_sensitive
    }).from(users).where(eq11(users.id, userId)).limit(1);
    if (!user) return false;
    if (user.mfaRequired) return true;
    const sensitiveActions = [
      "transfer_funds",
      "change_password",
      "add_user",
      "delete_user",
      "modify_permissions",
      "export_data"
    ];
    if (user.mfaEnabled && user.requireMfaForSensitive && action && sensitiveActions.includes(action)) {
      return true;
    }
    return user.mfaEnabled || false;
  } catch (error) {
    console.error("MFA requirement check error:", error);
    return false;
  }
}
async function listUserMfaFactors(userId) {
  return db.select({
    id: userMfaFactors.id,
    factorType: userMfaFactors.factorType,
    factorName: userMfaFactors.factorName,
    verified: userMfaFactors.verified,
    lastUsedAt: userMfaFactors.lastUsedAt,
    enrolledAt: userMfaFactors.enrolledAt
  }).from(userMfaFactors).where(and9(
    eq11(userMfaFactors.userId, userId),
    eq11(userMfaFactors.isActive, true)
  )).orderBy(desc6(userMfaFactors.enrolledAt));
}
async function removeMfaFactor(userId, factorId, ip, userAgent) {
  try {
    const [factor] = await db.select().from(userMfaFactors).where(and9(
      eq11(userMfaFactors.id, factorId),
      eq11(userMfaFactors.userId, userId)
    )).limit(1);
    if (!factor) {
      return { success: false, error: "Factor not found" };
    }
    await db.update(userMfaFactors).set({ isActive: false }).where(eq11(userMfaFactors.id, factorId));
    const remainingFactors = await db.select().from(userMfaFactors).where(and9(
      eq11(userMfaFactors.userId, userId),
      eq11(userMfaFactors.isActive, true)
    ));
    if (remainingFactors.length === 0) {
      await db.update(users).set({ twoFactorEnabled: false }).where(eq11(users.id, userId));
    }
    await db.insert(mfaAuditLog).values({
      userId,
      factorId,
      eventType: "factor_removed",
      eventDetails: { factorName: factor.factorName },
      ip,
      userAgent,
      success: true
    });
    return { success: true };
  } catch (error) {
    console.error("MFA factor removal error:", error);
    return { success: false, error: "Failed to remove factor" };
  }
}
async function getUserMfaAuditLog(userId, limit = 50) {
  return db.select().from(mfaAuditLog).where(eq11(mfaAuditLog.userId, userId)).orderBy(desc6(mfaAuditLog.createdAt)).limit(limit);
}
var mfa_service_default = {
  beginTotpEnrollment,
  verifyTotpEnrollment,
  generateBackupCodes,
  createMfaChallenge,
  verifyMfaChallenge,
  userRequiresMfa,
  listUserMfaFactors,
  removeMfaFactor,
  getUserMfaAuditLog
};

// server/routes/mfa.ts
init_db();
init_schema();
import { eq as eq12, and as and10, isNull as isNull5, or as or4, gt as gt2 } from "drizzle-orm";
import { sql as sql10 } from "drizzle-orm";
var router5 = Router5();
router5.use(requireAuth2);
router5.get("/status", async (req, res) => {
  try {
    const userId = req.user.id;
    const [user] = await db.select({
      mfaEnabled: users.twoFactorEnabled,
      mfaRequired: users.mfaRequired,
      requireMfaForSensitive: users.require_mfa_for_sensitive
    }).from(users).where(eq12(users.id, userId)).limit(1);
    const factors = await mfa_service_default.listUserMfaFactors(userId);
    res.json({
      mfaEnabled: user?.mfaEnabled || false,
      mfaRequired: user?.mfaRequired || false,
      requireMfaForSensitive: user?.requireMfaForSensitive || true,
      factors: factors.map((f) => ({
        id: f.id,
        type: f.factorType,
        name: f.factorName,
        verified: f.verified,
        lastUsedAt: f.lastUsedAt
      }))
    });
  } catch (error) {
    console.error("MFA status error:", error);
    res.status(500).json({ error: "Failed to get MFA status" });
  }
});
router5.post("/totp/enroll", async (req, res) => {
  try {
    const userId = req.user.id;
    const { factorName } = req.body;
    if (!factorName) {
      return res.status(400).json({ error: "Factor name is required" });
    }
    const result = await mfa_service_default.beginTotpEnrollment(
      userId,
      factorName,
      req.ip,
      req.get("user-agent")
    );
    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }
    res.json({
      factorId: result.factorId,
      secret: result.secret,
      qrCode: result.qrCodeUrl
    });
  } catch (error) {
    console.error("TOTP enrollment error:", error);
    res.status(500).json({ error: "Failed to begin enrollment" });
  }
});
router5.post("/totp/verify-enrollment", async (req, res) => {
  try {
    const userId = req.user.id;
    const { factorId, code } = req.body;
    if (!factorId || !code) {
      return res.status(400).json({ error: "Factor ID and code are required" });
    }
    const result = await mfa_service_default.verifyTotpEnrollment(
      factorId,
      code,
      userId,
      req.ip,
      req.get("user-agent")
    );
    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }
    res.json({
      success: true,
      backupCodes: result.backupCodes
    });
  } catch (error) {
    console.error("TOTP verification error:", error);
    res.status(500).json({ error: "Failed to verify enrollment" });
  }
});
router5.post("/challenge", async (req, res) => {
  try {
    const userId = req.user.id;
    const { challengeType = "login", action } = req.body;
    const result = await mfa_service_default.createMfaChallenge(
      userId,
      challengeType,
      action,
      req.session?.id,
      req.ip,
      req.get("user-agent"),
      req.body.deviceFingerprint
    );
    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }
    res.json({
      challengeId: result.challengeId,
      factors: result.factors
    });
  } catch (error) {
    console.error("MFA challenge creation error:", error);
    res.status(500).json({ error: "Failed to create challenge" });
  }
});
router5.post("/verify", async (req, res) => {
  try {
    const { challengeId, code, factorId } = req.body;
    if (!challengeId || !code) {
      return res.status(400).json({ error: "Challenge ID and code are required" });
    }
    const result = await mfa_service_default.verifyMfaChallenge(
      challengeId,
      code,
      factorId,
      req.ip,
      req.get("user-agent")
    );
    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }
    if (req.session) {
      req.session.mfaVerified = true;
      req.session.mfaVerifiedAt = /* @__PURE__ */ new Date();
    }
    res.json({
      success: true,
      userId: result.userId,
      requiresAdditionalFactor: result.requiresAdditionalFactor
    });
  } catch (error) {
    console.error("MFA verification error:", error);
    res.status(500).json({ error: "Failed to verify challenge" });
  }
});
router5.post("/backup-codes/generate", async (req, res) => {
  try {
    const userId = req.user.id;
    const { regenerate = false } = req.body;
    const factors = await mfa_service_default.listUserMfaFactors(userId);
    if (factors.length === 0) {
      return res.status(400).json({ error: "No MFA factors configured" });
    }
    const backupCodes = await mfa_service_default.generateBackupCodes(userId, regenerate);
    res.json({
      backupCodes,
      message: regenerate ? "New backup codes generated. Previous unused codes have been invalidated." : "Backup codes generated successfully."
    });
  } catch (error) {
    console.error("Backup code generation error:", error);
    res.status(500).json({ error: "Failed to generate backup codes" });
  }
});
router5.get("/backup-codes/count", async (req, res) => {
  try {
    const userId = req.user.id;
    const result = await db.select({
      count: sql10`count(*)::int`
    }).from(mfaBackupCodes).where(and10(
      eq12(mfaBackupCodes.userId, userId),
      isNull5(mfaBackupCodes.usedAt),
      or4(
        isNull5(mfaBackupCodes.expiresAt),
        gt2(mfaBackupCodes.expiresAt, sql10`now()`)
      )
    ));
    res.json({
      remainingCodes: result[0]?.count || 0
    });
  } catch (error) {
    console.error("Backup code count error:", error);
    res.status(500).json({ error: "Failed to get backup code count" });
  }
});
router5.delete("/factors/:factorId", async (req, res) => {
  try {
    const userId = req.user.id;
    const factorId = parseInt(req.params.factorId);
    if (isNaN(factorId)) {
      return res.status(400).json({ error: "Invalid factor ID" });
    }
    const factors = await mfa_service_default.listUserMfaFactors(userId);
    if (factors.length === 1) {
      return res.status(400).json({
        error: "Cannot remove the last MFA factor. Disable MFA instead."
      });
    }
    const result = await mfa_service_default.removeMfaFactor(
      userId,
      factorId,
      req.ip,
      req.get("user-agent")
    );
    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }
    res.json({ success: true, message: "MFA factor removed successfully" });
  } catch (error) {
    console.error("MFA factor removal error:", error);
    res.status(500).json({ error: "Failed to remove MFA factor" });
  }
});
router5.post("/disable", async (req, res) => {
  try {
    const userId = req.user.id;
    const { password } = req.body;
    if (!password) {
      return res.status(400).json({ error: "Password confirmation required" });
    }
    const [user] = await db.select({ password: users.password }).from(users).where(eq12(users.id, userId)).limit(1);
    if (!user) {
      return res.status(400).json({ error: "Invalid password" });
    }
    const factors = await mfa_service_default.listUserMfaFactors(userId);
    for (const factor of factors) {
      await mfa_service_default.removeMfaFactor(
        userId,
        factor.id,
        req.ip,
        req.get("user-agent")
      );
    }
    await db.update(users).set({
      twoFactorEnabled: false,
      mfaRequired: false
    }).where(eq12(users.id, userId));
    res.json({ success: true, message: "MFA disabled successfully" });
  } catch (error) {
    console.error("MFA disable error:", error);
    res.status(500).json({ error: "Failed to disable MFA" });
  }
});
router5.get("/audit-log", async (req, res) => {
  try {
    const userId = req.user.id;
    const limit = parseInt(req.query.limit) || 50;
    const auditLog2 = await mfa_service_default.getUserMfaAuditLog(userId, limit);
    res.json({ auditLog: auditLog2 });
  } catch (error) {
    console.error("MFA audit log error:", error);
    res.status(500).json({ error: "Failed to get audit log" });
  }
});
router5.post("/settings", async (req, res) => {
  try {
    const userId = req.user.id;
    const { requireMfaForSensitive } = req.body;
    const updates = {};
    if (typeof requireMfaForSensitive === "boolean") {
      updates.require_mfa_for_sensitive = requireMfaForSensitive;
    }
    if (Object.keys(updates).length > 0) {
      await db.update(users).set(updates).where(eq12(users.id, userId));
    }
    res.json({ success: true, message: "MFA settings updated" });
  } catch (error) {
    console.error("MFA settings error:", error);
    res.status(500).json({ error: "Failed to update MFA settings" });
  }
});
var mfa_default = router5;

// server/routes/crm.ts
init_db();
init_schema();
init_auditService();
init_audit_helper();
init_api_helpers();
init_logger();
import { Router as Router6 } from "express";
import { eq as eq14, desc as desc7, or as or5 } from "drizzle-orm";
import sgMail3 from "@sendgrid/mail";
import multer from "multer";
import path3 from "path";
import fs3 from "fs";

// server/utils/validators.ts
import { z as z4 } from "zod";
var uuidSchema = z4.string().uuid("Invalid UUID format");
var ulidSchema = z4.string().length(26, "Invalid ULID format");
var numericIdSchema = z4.coerce.number().int().positive("ID must be a positive integer");
var moneyStringSchema = z4.string().regex(
  /^-?\d+(\.\d{2})?$/,
  "Money must be a valid amount with up to 2 decimal places"
);
var centsSchema = z4.number().int("Amount must be in cents (integer)");
var positiveCentsSchema = centsSchema.positive("Amount must be positive");
var nonNegativeCentsSchema = centsSchema.nonnegative("Amount cannot be negative");
var dateStringSchema = z4.string().regex(
  /^\d{4}-\d{2}-\d{2}$/,
  "Date must be in YYYY-MM-DD format"
);
var timestampSchema = z4.string().datetime("Invalid timestamp format");
var paginationSchema = z4.object({
  page: z4.coerce.number().int().positive().default(1),
  limit: z4.coerce.number().int().positive().max(100).default(10),
  sortBy: z4.string().optional(),
  sortOrder: z4.enum(["asc", "desc"]).default("asc")
});
var emailSchema = z4.string().email("Invalid email address");
var phoneSchema = z4.string().regex(
  /^\+?1?\d{10,14}$/,
  "Invalid phone number format"
);
var percentageSchema = z4.number().min(0, "Percentage cannot be less than 0").max(100, "Percentage cannot be greater than 100");
var rateSchema = z4.number().min(0, "Rate cannot be negative").max(100, "Rate cannot exceed 100%");
var loanNumberSchema = z4.string().min(1, "Loan number is required").max(50, "Loan number too long");
var loanStatusSchema = z4.enum([
  "active",
  "paid_off",
  "defaulted",
  "foreclosure",
  "bankruptcy",
  "modification",
  "pending"
]);
var paymentStatusSchema = z4.enum([
  "pending",
  "processing",
  "posted",
  "failed",
  "reversed",
  "cancelled"
]);
var paymentMethodSchema = z4.enum([
  "ach",
  "wire",
  "check",
  "card",
  "manual",
  "internal"
]);
var addressSchema = z4.object({
  street: z4.string().min(1, "Street address is required"),
  city: z4.string().min(1, "City is required"),
  state: z4.string().length(2, "State must be 2 characters"),
  zip: z4.string().regex(/^\d{5}(-\d{4})?$/, "Invalid ZIP code format"),
  country: z4.string().default("US")
});
var fileUploadSchema = z4.object({
  filename: z4.string().min(1, "Filename is required"),
  mimetype: z4.string().min(1, "MIME type is required"),
  size: z4.number().positive("File size must be positive").max(50 * 1024 * 1024, "File too large (max 50MB)"),
  buffer: z4.instanceof(Buffer).optional()
});
var bulkIdsSchema = z4.object({
  ids: z4.array(uuidSchema).min(1, "At least one ID is required").max(100, "Maximum 100 items per batch")
});
var dateRangeSchema = z4.object({
  startDate: dateStringSchema,
  endDate: dateStringSchema
}).refine((data) => new Date(data.startDate) <= new Date(data.endDate), {
  message: "Start date must be before or equal to end date"
});
var searchQuerySchema = z4.object({
  query: z4.string().min(1).max(100),
  filters: z4.record(z4.any()).optional(),
  ...paginationSchema.shape
});
var errorResponseSchema = z4.object({
  error: z4.string(),
  code: z4.string().optional(),
  details: z4.any().optional()
});

// server/utils/crm-utils.ts
init_db();
init_schema();
var CRM_CONSTANTS = {
  SESSION_EXPIRY_MS: 864e5,
  // 24 hours
  RATE_LIMIT_DELAYS: {
    SHORT: 1e3,
    // 1 second
    LONG: 2e3
    // 2 seconds
  },
  ACTIVITY_TYPES: {
    NOTE: "note",
    EMAIL: "email",
    TEXT: "text",
    SMS: "sms",
    CALL: "call",
    APPOINTMENT: "appointment",
    CONTACT_UPDATE: "contact_update",
    PROFILE_PHOTO: "profile_photo",
    LOAN_UPDATE: "loan_update",
    LOAN_CREATED: "loan_created",
    LOAN_STATUS_CHANGE: "loan_status_change"
  },
  CALL_STATUS: {
    SCHEDULED: "scheduled",
    COMPLETED: "completed",
    CANCELLED: "cancelled",
    NO_ANSWER: "no_answer"
  },
  CALL_DIRECTION: {
    INBOUND: "inbound",
    OUTBOUND: "outbound"
  },
  DEFAULT_LABELS: {
    PHONE_PRIMARY: "Primary",
    PHONE_MOBILE: "Mobile",
    PHONE_WORK: "Work",
    PHONE_TOLL_FREE: "Toll Free",
    EMAIL_PRIMARY: "Primary",
    EMAIL_WORK: "Work",
    EMAIL_PERSONAL: "Personal"
  }
};
function parsePhoneData(phoneData) {
  if (!phoneData) return [];
  try {
    if (phoneData.startsWith("[")) {
      const parsed = JSON.parse(phoneData);
      return parsed.map((p) => ({
        number: p.number || p,
        label: p.label || CRM_CONSTANTS.DEFAULT_LABELS.PHONE_PRIMARY,
        isBad: p.isBad || false
      }));
    } else if (phoneData.startsWith("{")) {
      const parsed = JSON.parse(phoneData);
      return [{
        number: parsed.number || "",
        label: parsed.label || CRM_CONSTANTS.DEFAULT_LABELS.PHONE_PRIMARY,
        isBad: parsed.isBad || false
      }];
    }
    return [{
      number: phoneData,
      label: CRM_CONSTANTS.DEFAULT_LABELS.PHONE_PRIMARY,
      isBad: false
    }];
  } catch {
    return [{
      number: phoneData,
      label: CRM_CONSTANTS.DEFAULT_LABELS.PHONE_PRIMARY,
      isBad: false
    }];
  }
}
function parseEmailData(emailData) {
  if (!emailData) return [];
  try {
    if (emailData.startsWith("[") || emailData.startsWith("{")) {
      const parsed = JSON.parse(emailData);
      if (Array.isArray(parsed)) {
        return parsed.map((item) => ({
          email: item.email || item,
          label: item.label || CRM_CONSTANTS.DEFAULT_LABELS.EMAIL_PRIMARY
        })).filter((item) => item.email);
      }
      if (typeof parsed === "object" && parsed.email) {
        return [{
          email: parsed.email,
          label: parsed.label || CRM_CONSTANTS.DEFAULT_LABELS.EMAIL_PRIMARY
        }];
      }
    }
    return [{
      email: emailData,
      label: CRM_CONSTANTS.DEFAULT_LABELS.EMAIL_PRIMARY
    }];
  } catch {
    return [{
      email: emailData,
      label: CRM_CONSTANTS.DEFAULT_LABELS.EMAIL_PRIMARY
    }];
  }
}
function formatEmailsForStorage(emails) {
  const validEmails = emails.filter((e) => e.email && e.email.trim() !== "");
  return JSON.stringify(validEmails.map((e) => ({
    email: e.email,
    label: e.label || CRM_CONSTANTS.DEFAULT_LABELS.EMAIL_PRIMARY
  })));
}
async function logActivity(loanId, userId, activityType, activityData, relatedId) {
  try {
    await db.insert(crmActivity).values({
      loanId,
      userId,
      activityType,
      activityData: activityData || {},
      relatedId,
      isSystem: false
    });
  } catch (error) {
    console.error("Error logging CRM activity:", error);
  }
}

// server/config/constants.ts
var SESSION_CONFIG = {
  SECRET: process.env.SESSION_SECRET || "your-secret-key-here-change-in-production",
  MAX_AGE: 24 * 60 * 60 * 1e3,
  // 24 hours in milliseconds
  COOKIE_NAME: "loanserve.sid",
  RESAVE: false,
  SAVE_UNINITIALIZED: false,
  ROLLING: true,
  // Reset expiry on activity
  COOKIE: {
    httpOnly: true,
    secure: process.env.NODE_ENV === "production",
    sameSite: "lax",
    maxAge: 24 * 60 * 60 * 1e3
  }
};
var AUTH_CONFIG = {
  LOGIN_ATTEMPTS: {
    MAX_ATTEMPTS: 5,
    LOCKOUT_DURATION_MS: 15 * 60 * 1e3,
    // 15 minutes
    WINDOW_MS: 15 * 60 * 1e3
    // Track attempts within 15 minutes
  },
  PASSWORD_RESET: {
    TOKEN_EXPIRY_MS: 24 * 60 * 60 * 1e3,
    // 24 hours
    TOKEN_LENGTH: 32
  },
  INVITATION: {
    TOKEN_EXPIRY_MS: 7 * 24 * 60 * 60 * 1e3,
    // 7 days
    TOKEN_LENGTH: 32
  },
  PASSWORD_POLICY: {
    MIN_LENGTH: 8,
    REQUIRE_UPPERCASE: true,
    REQUIRE_LOWERCASE: true,
    REQUIRE_NUMBER: true,
    REQUIRE_SPECIAL: true
  }
};
var RATE_LIMIT_CONFIG = {
  API: {
    WINDOW_MS: 15 * 60 * 1e3,
    // 15 minutes
    MAX_REQUESTS: 100,
    // per window
    DELAY_AFTER: 50,
    // Start slowing down after 50 requests
    DELAY_MS: 1e3
    // 1 second delay
  },
  AUTH: {
    WINDOW_MS: 15 * 60 * 1e3,
    // 15 minutes
    MAX_REQUESTS: 5,
    // per window for auth endpoints
    DELAY_MS: 2e3
    // 2 second delay
  },
  EMAIL: {
    WINDOW_MS: 60 * 60 * 1e3,
    // 1 hour
    MAX_REQUESTS: 20,
    // per window
    DELAY_MS: 5e3
    // 5 second delay
  }
};
var FILE_UPLOAD_CONFIG = {
  MAX_FILE_SIZE: 10 * 1024 * 1024,
  // 10MB
  ALLOWED_MIME_TYPES: [
    "application/pdf",
    "image/jpeg",
    "image/png",
    "image/gif",
    "application/msword",
    "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    "application/vnd.ms-excel",
    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
  ],
  UPLOAD_DIR: "./uploads"
};
var EMAIL_CONFIG = {
  FROM_ADDRESS: process.env.SENDGRID_FROM_EMAIL || "noreply@loanserve.com",
  REPLY_TO: process.env.REPLY_TO_EMAIL || "support@loanserve.com",
  TEMPLATES: {
    PASSWORD_RESET: "password-reset",
    USER_INVITATION: "user-invitation",
    PAYMENT_REMINDER: "payment-reminder",
    PAYMENT_RECEIVED: "payment-received",
    LOAN_STATUS_CHANGE: "loan-status-change"
  }
};

// server/services/outbox.ts
init_db();
init_schema();
import { eq as eq13, isNull as isNull6, and as and11, lte } from "drizzle-orm";
var OutboxService = class {
  /**
   * Create an outbox message within a transaction
   * This ensures the message is only created if the transaction commits
   */
  async createMessage(message, trx) {
    const dbContext = trx || db;
    const [created] = await dbContext.insert(outboxMessages).values({
      aggregateType: message.aggregateType,
      aggregateId: message.aggregateId,
      eventType: message.eventType,
      payload: message.payload,
      attemptCount: 0,
      publishedAt: null
    }).returning();
    console.log(`[Outbox] Created message: ${created.id} for ${message.aggregateType}/${message.aggregateId} event: ${message.eventType}`);
    return created;
  }
  /**
   * Poll for unpublished messages
   * Returns messages ordered by creation time (oldest first)
   */
  async pollUnpublishedMessages(limit = 100) {
    const messages = await db.select().from(outboxMessages).where(isNull6(outboxMessages.publishedAt)).orderBy(outboxMessages.createdAt).limit(limit);
    return messages;
  }
  /**
   * Mark a message as published
   */
  async markPublished(messageId) {
    await db.update(outboxMessages).set({
      publishedAt: /* @__PURE__ */ new Date(),
      lastError: null
    }).where(eq13(outboxMessages.id, messageId));
    console.log(`[Outbox] Marked message ${messageId} as published`);
  }
  /**
   * Record a publish attempt failure
   */
  async recordFailure(messageId, error) {
    const [message] = await db.select({ attemptCount: outboxMessages.attemptCount }).from(outboxMessages).where(eq13(outboxMessages.id, messageId));
    if (!message) {
      console.error(`[Outbox] Message ${messageId} not found`);
      return;
    }
    await db.update(outboxMessages).set({
      attemptCount: (message.attemptCount || 0) + 1,
      lastError: error
    }).where(eq13(outboxMessages.id, messageId));
    console.error(`[Outbox] Failed to publish message ${messageId}: ${error}`);
  }
  /**
   * Get messages that have failed but can be retried
   */
  async getRetryableMessages(maxAttempts = 3) {
    const messages = await db.select().from(outboxMessages).where(
      and11(
        isNull6(outboxMessages.publishedAt),
        lte(outboxMessages.attemptCount, maxAttempts)
      )
    ).orderBy(outboxMessages.createdAt);
    return messages;
  }
  /**
   * Transactional helper: Create payment and outbox message together
   * This ensures both are created atomically
   */
  async createPaymentWithEvent(paymentData, eventType, eventPayload) {
    return await db.transaction(async (trx) => {
      const paymentId = crypto.randomUUID();
      const outboxMessage = await this.createMessage({
        aggregateType: "payments",
        aggregateId: paymentId,
        eventType,
        payload: {
          ...eventPayload,
          paymentId,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        }
      }, trx);
      console.log(`[Outbox] Created payment ${paymentId} with outbox message ${outboxMessage.id} in transaction`);
      return {
        paymentId,
        outboxMessageId: outboxMessage.id
      };
    });
  }
  /**
   * Process and publish messages to RabbitMQ
   */
  async processOutboxMessages() {
    const messages = await this.pollUnpublishedMessages();
    let publishedCount = 0;
    for (const message of messages) {
      try {
        const routingKey = this.getRoutingKey(message.eventType);
        const exchange = this.getExchange(message.aggregateType);
        await rabbitmqService.publishMessage(
          exchange,
          routingKey,
          message.payload
        );
        await this.markPublished(message.id);
        publishedCount++;
        console.log(`[Outbox] Published message ${message.id} to ${exchange}/${routingKey}`);
      } catch (error) {
        await this.recordFailure(message.id, error.message);
        console.error(`[Outbox] Failed to publish message ${message.id}:`, error);
      }
    }
    if (publishedCount > 0) {
      console.log(`[Outbox] Successfully published ${publishedCount} messages`);
    }
    return publishedCount;
  }
  /**
   * Map event types to RabbitMQ routing keys
   */
  getRoutingKey(eventType) {
    const mappings = {
      "payment.posted": "payment.posted",
      "payment.validated": "payment.validated",
      "payment.reversed": "payment.reversed",
      "payment.distributed": "payment.distributed"
    };
    return mappings[eventType] || eventType;
  }
  /**
   * Map aggregate types to RabbitMQ exchanges
   */
  getExchange(aggregateType) {
    const mappings = {
      "payments": "payments.topic",
      "settlements": "settlement.topic",
      "reconciliations": "reconciliation.topic"
    };
    return mappings[aggregateType] || "events.topic";
  }
  /**
   * Clean up old published messages
   */
  async cleanupPublishedMessages(daysToKeep = 7) {
    const cutoffDate = /* @__PURE__ */ new Date();
    cutoffDate.setDate(cutoffDate.getDate() - daysToKeep);
    const result = await db.delete(outboxMessages).where(
      and11(
        lte(outboxMessages.publishedAt, cutoffDate),
        // Only delete if actually published
        eq13(isNull6(outboxMessages.publishedAt), false)
      )
    );
    console.log(`[Outbox] Cleaned up old messages older than ${cutoffDate.toISOString()}`);
    return 0;
  }
};

// server/routes/crm.ts
import { randomUUID } from "crypto";

// server/services/twilio-service.ts
init_db();
init_schema();
import twilio from "twilio";
import dotenv from "dotenv";
import fs2 from "fs";
import path2 from "path";
var envLocalPath = path2.join(process.cwd(), ".env.local");
if (fs2.existsSync(envLocalPath)) {
  dotenv.config({ path: envLocalPath });
}
var TwilioService = class {
  client;
  isConfigured = false;
  fromNumber;
  messagingServiceSid;
  constructor() {
    const accountSid = process.env.TWILIO_ACCOUNT_SID;
    const authToken = process.env.TWILIO_AUTH_TOKEN;
    this.fromNumber = process.env.TWILIO_PHONE_NUMBER;
    this.messagingServiceSid = process.env.TWILIO_MESSAGING_SERVICE_SID;
    console.log("[Twilio] Checking configuration...");
    console.log("[Twilio] Account SID:", accountSid ? "Present" : "Missing");
    console.log("[Twilio] Auth Token:", authToken ? "Present" : "Missing");
    console.log("[Twilio] Phone Number:", this.fromNumber || "Missing");
    console.log("[Twilio] Messaging Service SID:", this.messagingServiceSid || "Not configured");
    if (accountSid && authToken && this.fromNumber) {
      try {
        this.client = twilio(accountSid, authToken);
        this.isConfigured = true;
        console.log("[Twilio] \u2713 Service configured successfully with phone:", this.fromNumber);
      } catch (error) {
        console.error("[Twilio] Failed to initialize:", error);
        this.isConfigured = false;
      }
    } else {
      console.log("[Twilio] \u2717 Service not configured - missing credentials");
    }
  }
  /**
   * Check if Twilio is properly configured
   */
  isReady() {
    return this.isConfigured;
  }
  /**
   * Send SMS message
   */
  async sendSMS(to, body, loanId) {
    if (!this.isConfigured) {
      return {
        success: false,
        error: "Twilio service not configured"
      };
    }
    try {
      const formattedTo = this.formatPhoneNumber(to);
      const messageOptions = {
        body,
        to: formattedTo
      };
      if (this.messagingServiceSid) {
        messageOptions.messagingServiceSid = this.messagingServiceSid;
        console.log("[Twilio] Using Messaging Service for A2P compliance");
      } else {
        messageOptions.from = this.fromNumber;
        console.log("[Twilio] Warning: Not using Messaging Service - may have delivery issues");
      }
      const message = await this.client.messages.create(messageOptions);
      if (loanId) {
        await this.logSMSActivity(loanId, formattedTo, body, message.sid);
      }
      console.log(`[Twilio] SMS sent successfully: ${message.sid}`);
      return {
        success: true,
        messageId: message.sid
      };
    } catch (error) {
      console.error("[Twilio] SMS send error:", error);
      return {
        success: false,
        error: error.message || "Failed to send SMS"
      };
    }
  }
  /**
   * Send payment reminder SMS
   */
  async sendPaymentReminder(to, loanId, loanNumber, amount, dueDate) {
    const body = `Payment Reminder: Your loan ${loanNumber} payment of $${amount} is due on ${dueDate}. Reply STOP to unsubscribe.`;
    const result = await this.sendSMS(to, body, loanId);
    if (result.success) {
      await db.insert(crmActivity).values({
        loanId,
        userId: 1,
        // System user
        activityType: "sms_reminder",
        activityData: {
          description: `Payment reminder SMS sent to ${to}`,
          messageId: result.messageId,
          amount,
          dueDate,
          type: "payment_reminder"
        },
        isSystem: true,
        createdAt: /* @__PURE__ */ new Date()
      });
    }
    return result;
  }
  /**
   * Send late payment notice SMS
   */
  async sendLateNotice(to, loanId, loanNumber, amount, daysLate) {
    const body = `Late Notice: Your loan ${loanNumber} payment of $${amount} is ${daysLate} days overdue. Please make payment immediately to avoid additional fees. Reply STOP to unsubscribe.`;
    const result = await this.sendSMS(to, body, loanId);
    if (result.success) {
      await db.insert(crmActivity).values({
        loanId,
        userId: 1,
        // System user
        activityType: "sms_notice",
        activityData: {
          description: `Late payment SMS notice sent to ${to}`,
          messageId: result.messageId,
          amount,
          daysLate,
          type: "late_notice"
        },
        isSystem: true,
        createdAt: /* @__PURE__ */ new Date()
      });
    }
    return result;
  }
  /**
   * Send escrow disbursement notification
   */
  async sendEscrowNotification(to, loanId, loanNumber, payee, amount, purpose) {
    const body = `Escrow Notice: A payment of $${amount} has been made from your loan ${loanNumber} escrow to ${payee} for ${purpose}. Reply STOP to unsubscribe.`;
    const result = await this.sendSMS(to, body, loanId);
    if (result.success) {
      await db.insert(crmActivity).values({
        loanId,
        userId: 1,
        // System user
        activityType: "sms_notice",
        activityData: {
          description: `Escrow disbursement SMS sent to ${to}`,
          messageId: result.messageId,
          payee,
          amount,
          purpose,
          type: "escrow_disbursement"
        },
        isSystem: true,
        createdAt: /* @__PURE__ */ new Date()
      });
    }
    return result;
  }
  /**
   * Format phone number to E.164 format
   */
  formatPhoneNumber(phone) {
    const cleaned = phone.replace(/\D/g, "");
    if (cleaned.length === 10) {
      return `+1${cleaned}`;
    } else if (cleaned.length === 11 && cleaned.startsWith("1")) {
      return `+${cleaned}`;
    } else if (cleaned.startsWith("+")) {
      return phone;
    }
    return phone;
  }
  /**
   * Log SMS activity to CRM
   */
  async logSMSActivity(loanId, to, message, messageId) {
    try {
      await db.insert(crmActivity).values({
        loanId,
        userId: 1,
        // System user
        activityType: "sms",
        activityData: {
          description: `SMS sent to ${to}`,
          to,
          message: message.substring(0, 100) + (message.length > 100 ? "..." : ""),
          messageId,
          source: "twilio"
        },
        isSystem: true,
        createdAt: /* @__PURE__ */ new Date()
      });
    } catch (error) {
      console.error("[Twilio] Failed to log SMS activity:", error);
    }
  }
  /**
   * Get message status
   */
  async getMessageStatus(messageId) {
    if (!this.isConfigured) {
      return {
        status: "unknown",
        error: "Twilio service not configured"
      };
    }
    try {
      const message = await this.client.messages(messageId).fetch();
      return {
        status: message.status
      };
    } catch (error) {
      console.error("[Twilio] Failed to get message status:", error);
      return {
        status: "error",
        error: error.message
      };
    }
  }
};
console.log("[Twilio] Creating service instance...");
var twilioService = new TwilioService();

// server/routes/crm.ts
var router6 = Router6();
var logger = createLogger("CRM");
if (process.env.SENDGRID_API_KEY) {
  sgMail3.setApiKey(process.env.SENDGRID_API_KEY);
}
var outboxService = new OutboxService();
var upload = multer({
  storage: multer.memoryStorage(),
  limits: {
    fileSize: FILE_UPLOAD_CONFIG.MAX_FILE_SIZE
  }
});
var logActivity2 = logActivity;
router6.get("/loans/:loanId/crm/notes", asyncHandler(async (req, res) => {
  const loanId = numericIdSchema.parse(req.params.loanId);
  logger.info("Fetching CRM notes", { loanId });
  const notes = await db.select({
    id: crmNotes.id,
    content: crmNotes.content,
    isPrivate: crmNotes.isPrivate,
    mentionedUsers: crmNotes.mentionedUsers,
    attachments: crmNotes.attachments,
    createdAt: crmNotes.createdAt,
    userId: crmNotes.userId,
    userName: users.username
  }).from(crmNotes).leftJoin(users, eq14(crmNotes.userId, users.id)).where(eq14(crmNotes.loanId, loanId)).orderBy(desc7(crmNotes.createdAt));
  sendSuccess3(res, notes);
}));
router6.post("/loans/:loanId/crm/notes", asyncHandler(async (req, res) => {
  const loanId = numericIdSchema.parse(req.params.loanId);
  const userId = req.user?.id || 1;
  const { content, isPrivate, mentionedUsers, attachments } = req.body;
  logger.info("Creating CRM note", { loanId, userId });
  const [note] = await db.insert(crmNotes).values({
    loanId,
    userId,
    content,
    isPrivate: isPrivate || false,
    mentionedUsers: mentionedUsers || [],
    attachments: attachments || []
  }).returning();
  await logActivity2(loanId, userId, CRM_CONSTANTS.ACTIVITY_TYPES.NOTE, {
    description: `Added a note: ${content.substring(0, 100)}...`
  }, note.id);
  await complianceAudit.logEvent({
    eventType: COMPLIANCE_EVENTS.CRM.NOTE_ADDED,
    actorType: "user",
    actorId: userId,
    resourceType: "crm_note",
    resourceId: note.id,
    loanId,
    // Include loan ID so it appears in loan audit tab
    description: `Added CRM note to loan ${loanId}`,
    newValues: {
      noteId: note.id,
      loanId,
      content: content.substring(0, 100),
      isPrivate,
      mentionedUsers: mentionedUsers || [],
      hasAttachments: (attachments || []).length > 0
    },
    metadata: {
      loanId,
      userId
    },
    ipAddr: getRealUserIP(req),
    userAgent: req.headers?.["user-agent"]
  });
  res.setHeader("X-Cache-Invalidate", JSON.stringify([
    `/api/compliance/audit-log`,
    `/api/loans/${loanId}/crm/activity`,
    `/api/loans/${loanId}/crm/notes`
  ]));
  sendSuccess3(res, note, "Note created successfully");
}));
router6.get("/loans/:loanId/crm/tasks", asyncHandler(async (req, res) => {
  const loanId = numericIdSchema.parse(req.params.loanId);
  const tasks2 = await db.select({
    id: crmTasks.id,
    title: crmTasks.title,
    description: crmTasks.description,
    status: crmTasks.status,
    priority: crmTasks.priority,
    dueDate: crmTasks.dueDate,
    completedAt: crmTasks.completedAt,
    tags: crmTasks.tags,
    createdAt: crmTasks.createdAt,
    createdBy: crmTasks.createdBy,
    assignedTo: crmTasks.assignedTo,
    assignedToName: users.username
  }).from(crmTasks).leftJoin(users, eq14(crmTasks.assignedTo, users.id)).where(eq14(crmTasks.loanId, loanId)).orderBy(desc7(crmTasks.createdAt));
  sendSuccess3(res, tasks2);
}));
router6.post("/loans/:loanId/crm/tasks", async (req, res) => {
  try {
    const loanId = parseInt(req.params.loanId);
    const userId = req.user?.id || 1;
    const { title, description, assignedTo, dueDate, priority, tags } = req.body;
    const [task] = await db.insert(crmTasks).values({
      loanId,
      createdBy: userId,
      title,
      description,
      assignedTo,
      dueDate,
      priority: priority || "medium",
      tags: tags || []
    }).returning();
    await logActivity2(loanId, userId, "task", {
      description: `Created task: ${title}`
    }, task.id);
    await complianceAudit.logEvent({
      eventType: COMPLIANCE_EVENTS.CRM.TASK_CREATED,
      actorType: "user",
      actorId: userId,
      resourceType: "crm_task",
      resourceId: task.id,
      loanId,
      // Include loan ID so it appears in loan audit tab
      description: `Created task: ${title}`,
      newValues: {
        taskId: task.id,
        loanId,
        title,
        assignedTo,
        priority: priority || "medium",
        dueDate
      },
      metadata: {
        loanId,
        userId
      },
      ipAddr: getRealUserIP(req),
      userAgent: req.headers?.["user-agent"]
    });
    if (assignedTo && assignedTo !== userId) {
      const assigneeResult = await db.select({ email: users.email, username: users.username }).from(users).where(eq14(users.id, assignedTo));
      if (assigneeResult.length > 0) {
        const assignee = assigneeResult[0];
        const assignerResult = await db.select({ username: users.username }).from(users).where(eq14(users.id, userId));
        const assigner = assignerResult[0]?.username || "System";
        await outboxService.createMessage({
          aggregateType: "crm",
          aggregateId: loanId.toString(),
          eventType: "crm.task.assigned.v1",
          payload: {
            recipientEmail: assignee.email,
            recipientName: assignee.username,
            task: {
              title,
              description: description || "No description provided"
            },
            assignedBy: assigner,
            dueDate: dueDate || "No due date",
            priority: priority || "medium"
          }
        });
        await logActivity2(loanId, userId, "notification", {
          description: `Task assignment notification queued for ${assignee.username}`,
          taskId: task.id,
          taskTitle: title,
          eventType: "crm.task.assigned.v1"
        }, task.id);
      }
    }
    res.json(task);
  } catch (error) {
    console.error("Error creating CRM task:", error);
    res.status(500).json({ error: "Failed to create task" });
  }
});
router6.patch("/loans/:loanId/crm/tasks/:taskId", async (req, res) => {
  try {
    const taskId = parseInt(req.params.taskId);
    const loanId = parseInt(req.params.loanId);
    const userId = req.user?.id || 1;
    const updates = req.body;
    const existingTaskResult = await db.select().from(crmTasks).where(eq14(crmTasks.id, taskId)).limit(1);
    if (existingTaskResult.length === 0) {
      return res.status(404).json({ error: "Task not found" });
    }
    const existingTask = existingTaskResult[0];
    if (updates.status === "completed" && !updates.completedAt) {
      updates.completedAt = /* @__PURE__ */ new Date();
    }
    const [task] = await db.update(crmTasks).set({
      ...updates,
      updatedAt: /* @__PURE__ */ new Date()
    }).where(eq14(crmTasks.id, taskId)).returning();
    const potentialFields = Object.keys(updates);
    for (const field of potentialFields) {
      const oldValue = existingTask[field];
      const newValue = task[field];
      if (String(oldValue) !== String(newValue)) {
        await complianceAudit.logEvent({
          eventType: COMPLIANCE_EVENTS.CRM.TASK_UPDATED,
          actorType: "user",
          actorId: userId?.toString(),
          resourceType: "crm_task",
          resourceId: taskId.toString(),
          loanId,
          ipAddr: getRealUserIP(req),
          userAgent: req.headers?.["user-agent"],
          description: `Task field '${field}' updated from '${oldValue}' to '${newValue}' on LN-2025-001`,
          previousValues: { [field]: oldValue },
          newValues: { [field]: newValue },
          changedFields: [field]
        });
      }
    }
    if (updates.status) {
      await logActivity2(loanId, userId, "task", {
        description: `Updated task status to: ${updates.status}`
      }, taskId);
    }
    res.setHeader("X-Cache-Invalidate", JSON.stringify([
      `/api/compliance/audit-log`,
      `/api/loans/${loanId}/crm/activity`,
      `/api/loans/${loanId}/crm/tasks`
    ]));
    res.json(task);
  } catch (error) {
    console.error("Error updating CRM task:", error);
    res.status(500).json({ error: "Failed to update task" });
  }
});
router6.get("/loans/:loanId/crm/appointments", async (req, res) => {
  try {
    const loanId = parseInt(req.params.loanId);
    const appointments = await db.select().from(crmAppointments).where(eq14(crmAppointments.loanId, loanId)).orderBy(desc7(crmAppointments.startTime));
    res.json(appointments);
  } catch (error) {
    console.error("Error fetching CRM appointments:", error);
    res.status(500).json({ error: "Failed to fetch appointments" });
  }
});
router6.post("/loans/:loanId/crm/appointments", async (req, res) => {
  try {
    const loanId = parseInt(req.params.loanId);
    const userId = req.user?.id || 1;
    const {
      title,
      description,
      location,
      startTime: startTime2,
      endTime,
      attendees,
      reminderMinutes,
      meetingLink
    } = req.body;
    const [appointment] = await db.insert(crmAppointments).values({
      loanId,
      createdBy: userId,
      title,
      description,
      location,
      startTime: new Date(startTime2),
      endTime: new Date(endTime),
      attendees: attendees || [],
      reminderMinutes: reminderMinutes || 15,
      meetingLink
    }).returning();
    await logActivity2(loanId, userId, CRM_CONSTANTS.ACTIVITY_TYPES.APPOINTMENT, {
      description: `Scheduled appointment: ${title}`
    }, appointment.id);
    await complianceAudit.logEvent({
      eventType: COMPLIANCE_EVENTS.CRM.APPOINTMENT_SCHEDULED,
      actorType: "user",
      actorId: userId,
      resourceType: "appointment",
      resourceId: appointment.id,
      loanId,
      description: `Scheduled appointment: ${title}`,
      newValues: {
        title,
        description,
        location,
        startTime: startTime2,
        endTime,
        attendees,
        reminderMinutes,
        meetingLink
      },
      metadata: {
        loanId,
        userId,
        appointmentId: appointment.id
      },
      ipAddr: getRealUserIP(req),
      userAgent: req.headers?.["user-agent"]
    });
    res.setHeader("X-Cache-Invalidate", JSON.stringify([
      `/api/compliance/audit-log`,
      `/api/loans/${loanId}/crm/activity`,
      `/api/loans/${loanId}/crm/appointments`
    ]));
    res.json(appointment);
  } catch (error) {
    console.error("Error creating CRM appointment:", error);
    res.status(500).json({ error: "Failed to create appointment" });
  }
});
router6.post("/loans/:loanId/crm/texts", async (req, res) => {
  try {
    const loanId = parseInt(req.params.loanId);
    const userId = req.user?.id || 1;
    const { message, recipientPhone } = req.body;
    await logActivity2(loanId, userId, CRM_CONSTANTS.ACTIVITY_TYPES.TEXT, {
      description: `Sent text message: ${message.substring(0, 50)}${message.length > 50 ? "..." : ""}`,
      phone: recipientPhone,
      message
    });
    await complianceAudit.logEvent({
      eventType: COMPLIANCE_EVENTS.CRM.TEXT_SENT,
      actorType: "user",
      actorId: userId,
      resourceType: "text",
      resourceId: `text-${Date.now()}`,
      loanId,
      description: `Sent text message to ${recipientPhone}`,
      newValues: {
        recipientPhone,
        message: message.substring(0, 100),
        // Truncate for audit
        messageLength: message.length
      },
      metadata: {
        loanId,
        userId,
        phoneNumber: recipientPhone
      },
      ipAddr: getRealUserIP(req),
      userAgent: req.headers?.["user-agent"]
    });
    res.setHeader("X-Cache-Invalidate", JSON.stringify([
      `/api/compliance/audit-log`,
      `/api/loans/${loanId}/crm/activity`
    ]));
    res.json({ success: true, message: "Text message logged" });
  } catch (error) {
    console.error("Error logging text message:", error);
    res.status(500).json({ error: "Failed to log text message" });
  }
});
router6.get("/loans/:loanId/crm/calls", async (req, res) => {
  try {
    const loanId = parseInt(req.params.loanId);
    const calls = await db.select().from(crmCalls).where(eq14(crmCalls.loanId, loanId)).orderBy(desc7(crmCalls.createdAt));
    res.json(calls);
  } catch (error) {
    console.error("Error fetching CRM calls:", error);
    res.status(500).json({ error: "Failed to fetch calls" });
  }
});
router6.post("/loans/:loanId/crm/calls", async (req, res) => {
  try {
    const loanId = parseInt(req.params.loanId);
    const userId = req.user?.id || 1;
    const {
      contactName,
      contactPhone,
      direction,
      status,
      duration,
      outcome,
      notes,
      scheduledFor
    } = req.body;
    const [call] = await db.insert(crmCalls).values({
      loanId,
      userId,
      contactName,
      contactPhone,
      direction: direction || "outbound",
      status: status || "completed",
      duration,
      outcome,
      notes,
      scheduledFor: scheduledFor ? new Date(scheduledFor) : null,
      completedAt: status === "completed" ? /* @__PURE__ */ new Date() : null
    }).returning();
    await logActivity2(loanId, userId, CRM_CONSTANTS.ACTIVITY_TYPES.CALL, {
      description: `${status === "scheduled" ? "Scheduled" : "Logged"} call with ${contactName}`
    }, call.id);
    res.json(call);
  } catch (error) {
    console.error("Error creating CRM call:", error);
    res.status(500).json({ error: "Failed to create call" });
  }
});
router6.get("/loans/:loanId/crm/activity", async (req, res) => {
  try {
    const loanId = parseInt(req.params.loanId);
    const activity = await db.select({
      id: crmActivity.id,
      activityType: crmActivity.activityType,
      activityData: crmActivity.activityData,
      relatedId: crmActivity.relatedId,
      isSystem: crmActivity.isSystem,
      createdAt: crmActivity.createdAt,
      userId: crmActivity.userId,
      userName: users.username
    }).from(crmActivity).leftJoin(users, eq14(crmActivity.userId, users.id)).where(eq14(crmActivity.loanId, loanId)).orderBy(desc7(crmActivity.createdAt)).limit(50);
    res.json(activity);
  } catch (error) {
    console.error("Error fetching CRM activity:", error);
    res.status(500).json({ error: "Failed to fetch activity" });
  }
});
router6.get("/loans/:loanId/crm/collaborators", async (req, res) => {
  try {
    const loanId = parseInt(req.params.loanId);
    const collaborators = await db.select({
      id: crmCollaborators.id,
      userId: crmCollaborators.userId,
      role: crmCollaborators.role,
      permissions: crmCollaborators.permissions,
      addedAt: crmCollaborators.addedAt,
      lastActivityAt: crmCollaborators.lastActivityAt,
      userName: users.username,
      userEmail: users.email
    }).from(crmCollaborators).leftJoin(users, eq14(crmCollaborators.userId, users.id)).where(eq14(crmCollaborators.loanId, loanId));
    res.json(collaborators);
  } catch (error) {
    console.error("Error fetching CRM collaborators:", error);
    res.status(500).json({ error: "Failed to fetch collaborators" });
  }
});
router6.post("/loans/:loanId/crm/collaborators", async (req, res) => {
  try {
    const loanId = parseInt(req.params.loanId);
    const addedBy = req.user?.id || 1;
    const { userId, role, permissions: permissions3 } = req.body;
    const [collaborator] = await db.insert(crmCollaborators).values({
      loanId,
      userId,
      role: role || "viewer",
      permissions: permissions3 || {},
      addedBy
    }).returning();
    await logActivity2(loanId, addedBy, "collaborator", {
      description: `Added collaborator with ${role} role`
    });
    await complianceAudit.logEvent({
      eventType: COMPLIANCE_EVENTS.CRM.COLLABORATOR_ADDED,
      actorType: "user",
      actorId: addedBy,
      resourceType: "collaborator",
      resourceId: collaborator.id,
      loanId,
      description: `Added collaborator with ${role} role`,
      newValues: {
        userId,
        role: role || "viewer",
        permissions: permissions3 || {}
      },
      metadata: {
        loanId,
        addedBy,
        targetUserId: userId,
        collaboratorId: collaborator.id
      },
      ipAddr: getRealUserIP(req),
      userAgent: req.headers?.["user-agent"]
    });
    res.json(collaborator);
  } catch (error) {
    console.error("Error adding CRM collaborator:", error);
    res.status(500).json({ error: "Failed to add collaborator" });
  }
});
router6.get("/loans/:loanId/crm/deals", async (req, res) => {
  try {
    const loanId = parseInt(req.params.loanId);
    const deals = await db.select().from(crmDeals).where(eq14(crmDeals.loanId, loanId)).orderBy(desc7(crmDeals.createdAt));
    res.json(deals);
  } catch (error) {
    console.error("Error fetching CRM deals:", error);
    res.status(500).json({ error: "Failed to fetch deals" });
  }
});
router6.post("/loans/:loanId/crm/deals", async (req, res) => {
  try {
    const loanId = parseInt(req.params.loanId);
    const createdBy = req.user?.id || 1;
    const {
      title,
      value,
      stage,
      probability,
      expectedCloseDate,
      assignedTo,
      notes
    } = req.body;
    const [deal] = await db.insert(crmDeals).values({
      loanId,
      title,
      value,
      stage: stage || "prospecting",
      probability: probability || 0,
      expectedCloseDate,
      assignedTo,
      notes,
      createdBy
    }).returning();
    await logActivity2(loanId, createdBy, "deal", {
      description: `Created deal: ${title}`
    }, deal.id);
    await complianceAudit.logEvent({
      eventType: COMPLIANCE_EVENTS.CRM.DEAL_CREATED,
      actorType: "user",
      actorId: createdBy,
      resourceType: "deal",
      resourceId: deal.id,
      loanId,
      description: `Created deal: ${title}`,
      newValues: {
        title,
        value,
        stage: stage || "prospecting",
        probability: probability || 0,
        expectedCloseDate,
        assignedTo,
        notes
      },
      metadata: {
        loanId,
        createdBy,
        dealId: deal.id,
        dealValue: value
      },
      ipAddr: getRealUserIP(req),
      userAgent: req.headers?.["user-agent"]
    });
    res.json(deal);
  } catch (error) {
    console.error("Error creating CRM deal:", error);
    res.status(500).json({ error: "Failed to create deal" });
  }
});
router6.get("/crm/check-email-config", async (req, res) => {
  try {
    const hasApiKey = !!process.env.SENDGRID_API_KEY;
    const hasFromEmail = !!process.env.SENDGRID_FROM_EMAIL;
    const fromEmail = process.env.SENDGRID_FROM_EMAIL || "Not configured";
    if (hasApiKey) {
      sgMail3.setApiKey(process.env.SENDGRID_API_KEY);
    }
    res.json({
      configured: hasApiKey && hasFromEmail,
      hasApiKey,
      hasFromEmail,
      fromEmail: hasFromEmail ? fromEmail : "Not configured",
      message: !hasApiKey || !hasFromEmail ? "SendGrid is not fully configured. Both SENDGRID_API_KEY and SENDGRID_FROM_EMAIL must be set." : `SendGrid is configured with sender: ${fromEmail}. Make sure this email is verified in your SendGrid account.`
    });
  } catch (error) {
    res.status(500).json({
      error: "Failed to check email configuration",
      details: error.message
    });
  }
});
router6.post("/loans/:loanId/crm/send-email", upload.array("files", 10), async (req, res) => {
  const cleanEmail = (email) => email.replace(/\s+/g, "").trim();
  const fromEmail = process.env.SENDGRID_FROM_EMAIL ? cleanEmail(process.env.SENDGRID_FROM_EMAIL) : "";
  try {
    const loanId = parseInt(req.params.loanId);
    const userId = req.user?.id || 1;
    const { to, cc, bcc, subject, content, documentIds } = req.body;
    if (!process.env.SENDGRID_API_KEY) {
      return res.status(500).json({ error: "Email service not configured" });
    }
    if (!fromEmail) {
      return res.status(500).json({ error: "From email address not configured" });
    }
    const msg = {
      to: cleanEmail(to),
      from: fromEmail,
      subject: subject.trim(),
      text: content,
      html: content.replace(/\n/g, "<br>")
      // Basic HTML conversion
    };
    if (cc && cc.trim()) {
      msg.cc = cc.split(",").map((email) => cleanEmail(email)).filter(Boolean);
    }
    if (bcc && bcc.trim()) {
      msg.bcc = bcc.split(",").map((email) => cleanEmail(email)).filter(Boolean);
    }
    const attachments = [];
    console.log("Processing email attachments...");
    console.log("Document IDs received:", documentIds);
    console.log("Files received:", req.files ? req.files.length : 0);
    if (documentIds) {
      const docIdArray = typeof documentIds === "string" ? JSON.parse(documentIds) : documentIds;
      console.log("Document ID array:", docIdArray);
      if (Array.isArray(docIdArray) && docIdArray.length > 0) {
        const docs = await db.select().from(documents).where(or5(...docIdArray.map((id) => eq14(documents.id, id))));
        console.log(`Found ${docs.length} documents in database`);
        for (const doc of docs) {
          let actualFilePath = "";
          if (doc.storageUrl) {
            if (doc.storageUrl.startsWith("/documents/")) {
              actualFilePath = path3.join("server/uploads", doc.storageUrl.replace("/documents/", ""));
            } else if (doc.storageUrl.startsWith("/uploads/")) {
              actualFilePath = path3.join("server", doc.storageUrl);
            } else {
              actualFilePath = path3.join("server/uploads", doc.storageUrl);
            }
          }
          console.log(`Checking document: ${doc.fileName || doc.title}, storageUrl: ${doc.storageUrl}, actualPath: ${actualFilePath}`);
          if (actualFilePath && fs3.existsSync(actualFilePath)) {
            const fileContent = fs3.readFileSync(actualFilePath);
            const attachment = {
              content: fileContent.toString("base64"),
              filename: doc.fileName || doc.title || "document",
              type: doc.mimeType || "application/octet-stream",
              disposition: "attachment"
            };
            attachments.push(attachment);
            console.log(`Successfully added document attachment: ${attachment.filename} (${attachment.type})`);
          } else {
            console.log(`Document file not found at: ${actualFilePath}`);
          }
        }
      }
    }
    if (req.files && Array.isArray(req.files)) {
      console.log(`Processing ${req.files.length} uploaded files`);
      for (const file of req.files) {
        const attachment = {
          content: file.buffer.toString("base64"),
          filename: file.originalname,
          type: file.mimetype,
          disposition: "attachment"
        };
        attachments.push(attachment);
        console.log(`Added uploaded file: ${attachment.filename} (${attachment.type}, ${file.size} bytes)`);
      }
    }
    if (attachments.length > 0) {
      msg.attachments = attachments;
      console.log(`Total attachments added to email: ${attachments.length}`);
    } else {
      console.log("No attachments to add to email");
    }
    const correlationId = req.correlationId || randomUUID();
    const resourceId = `email-${Date.now()}-${randomUUID().substring(0, 8)}`;
    await outboxService.createMessage({
      aggregateType: "crm",
      aggregateId: loanId.toString(),
      eventType: "crm.email.requested.v1",
      payload: {
        loanId,
        userId,
        resourceId,
        templateId: "email_notification",
        variables: {
          subject,
          content,
          cc: cc || null,
          bcc: bcc || null,
          from: fromEmail
        },
        recipient: {
          email: to,
          name: to
        },
        attachments: attachments.map((att) => ({
          content: att.content,
          filename: att.filename,
          type: att.type
        })),
        correlationId,
        requestMetadata: {
          ipAddr: getRealUserIP(req),
          userAgent: req.headers?.["user-agent"],
          recipientCount: 1 + (cc ? cc.split(",").length : 0) + (bcc ? bcc.split(",").length : 0),
          hasAttachments: attachments.length > 0
        }
      }
    });
    await logActivity2(loanId, userId, CRM_CONSTANTS.ACTIVITY_TYPES.EMAIL, {
      description: `Email queued for sending to ${to}`,
      subject,
      to,
      cc: cc || null,
      bcc: bcc || null,
      attachmentCount: attachments.length,
      status: "queued"
    });
    await complianceAudit.logEvent({
      eventType: COMPLIANCE_EVENTS.CRM.EMAIL_REQUESTED,
      actorType: "user",
      actorId: userId,
      resourceType: "email",
      resourceId,
      loanId,
      description: `Email requested for sending to ${to}: ${subject}`,
      newValues: {
        to,
        cc: cc || null,
        bcc: bcc || null,
        subject,
        contentLength: content.length,
        attachmentCount: attachments.length,
        status: "queued",
        fromEmail
      },
      metadata: {
        loanId,
        userId,
        correlationId,
        recipientCount: 1 + (cc ? cc.split(",").length : 0) + (bcc ? bcc.split(",").length : 0),
        hasAttachments: attachments.length > 0
      },
      ipAddr: getRealUserIP(req),
      userAgent: req.headers?.["user-agent"]
    });
    res.status(202).json({
      success: true,
      message: "Email queued for sending",
      attachmentCount: attachments.length,
      resourceId,
      correlationId,
      status: "queued"
    });
  } catch (error) {
    console.error("Error sending email:", error);
    if (error.response) {
      const { message, code, response } = error;
      const { body, headers } = response;
      console.error("SendGrid error details:", { code, message, body });
      if (body && body.errors) {
        console.error("SendGrid specific errors:", JSON.stringify(body.errors, null, 2));
      }
      if (code === 400 || code === 403) {
        let errorDetails = `The sender email address (${fromEmail}) may not be verified with SendGrid.`;
        if (body && body.errors && body.errors[0]) {
          errorDetails = body.errors[0].message || errorDetails;
        }
        return res.status(500).json({
          error: "SendGrid Configuration Issue",
          details: errorDetails,
          from: fromEmail
        });
      }
    }
    res.status(500).json({
      error: "Failed to send email",
      details: error.message || "Unknown error"
    });
  }
});
router6.post("/loans/:loanId/sms", async (req, res) => {
  try {
    const loanId = parseInt(req.params.loanId);
    const { to, message, type } = req.body;
    const userId = req.user?.id || 1;
    if (!to || !message) {
      return res.status(400).json({ error: "Phone number and message are required" });
    }
    if (!twilioService.isReady()) {
      return res.status(503).json({
        error: "SMS service not configured",
        details: "Twilio credentials are not properly set up"
      });
    }
    let result;
    if (type === "payment_reminder") {
      const loan = await db.select().from(loans).where(eq14(loans.id, loanId)).limit(1);
      if (loan.length === 0) {
        return res.status(404).json({ error: "Loan not found" });
      }
      const loanData = loan[0];
      const nextPayment = loanData.paymentAmount || "0.00";
      const dueDate = loanData.paymentDueDay ? `the ${loanData.paymentDueDay}th` : "soon";
      result = await twilioService.sendPaymentReminder(
        to,
        loanId,
        loanData.loanNumber,
        nextPayment,
        dueDate
      );
    } else if (type === "late_notice") {
      const loan = await db.select().from(loans).where(eq14(loans.id, loanId)).limit(1);
      if (loan.length === 0) {
        return res.status(404).json({ error: "Loan not found" });
      }
      const loanData = loan[0];
      const paymentAmount = loanData.paymentAmount || "0.00";
      const daysLate = 10;
      result = await twilioService.sendLateNotice(
        to,
        loanId,
        loanData.loanNumber,
        paymentAmount,
        daysLate
      );
    } else {
      result = await twilioService.sendSMS(to, message, loanId);
      if (result.success) {
        await logActivity2(loanId, userId, CRM_CONSTANTS.ACTIVITY_TYPES.SMS, {
          description: `SMS sent to ${to}`,
          message,
          messageId: result.messageId
        });
      }
    }
    if (result.success) {
      res.json({
        success: true,
        messageId: result.messageId,
        message: "SMS sent successfully"
      });
    } else {
      res.status(400).json({
        success: false,
        error: result.error || "Failed to send SMS"
      });
    }
  } catch (error) {
    console.error("Error sending SMS:", error);
    res.status(500).json({
      error: "Failed to send SMS",
      details: error.message || "Unknown error"
    });
  }
});
router6.get("/sms/:messageId/status", async (req, res) => {
  try {
    const { messageId } = req.params;
    if (!twilioService.isReady()) {
      return res.status(503).json({
        error: "SMS service not configured",
        details: "Twilio credentials are not properly set up"
      });
    }
    const result = await twilioService.getMessageStatus(messageId);
    res.json(result);
  } catch (error) {
    console.error("Error getting SMS status:", error);
    res.status(500).json({
      error: "Failed to get SMS status",
      details: error.message || "Unknown error"
    });
  }
});
router6.patch("/loans/:loanId/contact-info", async (req, res) => {
  try {
    const loanId = parseInt(req.params.loanId);
    const { phones, emails } = req.body;
    const userId = req.user?.id || 1;
    console.log("Updating contact info for loan", loanId, { phones, emails });
    const existingLoanResult = await db.select().from(loans).where(eq14(loans.id, loanId)).limit(1);
    if (existingLoanResult.length === 0) {
      return res.status(404).json({ error: "Loan not found" });
    }
    const existingLoan = existingLoanResult[0];
    const updateData = {};
    if (phones && phones.length > 0) {
      const validPhones = phones.filter((p) => p.number && p.number.trim() !== "");
      if (validPhones.length > 0) {
        updateData.borrowerPhone = JSON.stringify(validPhones.map((p) => ({
          number: p.number,
          label: p.label || CRM_CONSTANTS.DEFAULT_LABELS.PHONE_PRIMARY,
          isBad: p.isBad || false
        })));
      }
      updateData.borrowerMobile = null;
    }
    if (emails && emails.length > 0) {
      const emailObjects = emails.filter((e) => {
        const emailValue = typeof e === "string" ? e : e.email;
        return emailValue && emailValue.trim() !== "";
      }).map((e) => ({
        email: typeof e === "string" ? e : e.email,
        label: (typeof e === "object" ? e.label : null) || CRM_CONSTANTS.DEFAULT_LABELS.EMAIL_PRIMARY
      }));
      if (emailObjects.length > 0) {
        updateData.borrowerEmail = formatEmailsForStorage(emailObjects);
      }
    }
    console.log("Update data:", updateData);
    await db.update(loans).set(updateData).where(eq14(loans.id, loanId));
    const updatedLoanResult = await db.select().from(loans).where(eq14(loans.id, loanId)).limit(1);
    const updatedLoan = updatedLoanResult[0];
    const existingPhones = parsePhoneData(existingLoan.borrowerPhone);
    const existingEmails = parseEmailData(existingLoan.borrowerEmail);
    const newPhones = phones || [];
    const newEmails = emails || [];
    const existingPhoneNumbers = existingPhones.map((p) => `${p.number}:${p.label}`);
    const newPhoneNumbers = newPhones.map((p) => `${p.number}:${p.label}`);
    for (const existingPhone of existingPhones) {
      const phoneKey = `${existingPhone.number}:${existingPhone.label}`;
      if (!newPhoneNumbers.includes(phoneKey)) {
        await complianceAudit.logEvent({
          eventType: COMPLIANCE_EVENTS.CRM.CONTACT_UPDATED,
          actorType: "user",
          actorId: userId?.toString(),
          resourceType: "loan",
          resourceId: loanId.toString(),
          loanId,
          ipAddr: getRealUserIP(req),
          userAgent: req.headers?.["user-agent"],
          description: `Phone '${existingPhone.number}' (${existingPhone.label}) deleted from contact info on ${existingLoan.loanNumber}`,
          previousValues: { phone: `${existingPhone.number} (${existingPhone.label})` },
          newValues: { phone: null },
          changedFields: ["phone"]
        });
      }
    }
    for (const newPhone of newPhones) {
      const phoneKey = `${newPhone.number}:${newPhone.label}`;
      if (!existingPhoneNumbers.includes(phoneKey)) {
        await complianceAudit.logEvent({
          eventType: COMPLIANCE_EVENTS.CRM.CONTACT_UPDATED,
          actorType: "user",
          actorId: userId?.toString(),
          resourceType: "loan",
          resourceId: loanId.toString(),
          loanId,
          ipAddr: getRealUserIP(req),
          userAgent: req.headers?.["user-agent"],
          description: `Phone '${newPhone.number}' (${newPhone.label}) added to contact info on ${existingLoan.loanNumber}`,
          previousValues: { phone: null },
          newValues: { phone: `${newPhone.number} (${newPhone.label})` },
          changedFields: ["phone"]
        });
      }
    }
    const existingEmailAddresses = existingEmails.map((e) => `${e.email}:${e.label}`);
    const newEmailAddresses = newEmails.map((e) => `${e.email}:${e.label}`);
    for (const existingEmail of existingEmails) {
      const emailKey = `${existingEmail.email}:${existingEmail.label}`;
      if (!newEmailAddresses.includes(emailKey)) {
        await complianceAudit.logEvent({
          eventType: COMPLIANCE_EVENTS.CRM.CONTACT_UPDATED,
          actorType: "user",
          actorId: userId?.toString(),
          resourceType: "loan",
          resourceId: loanId.toString(),
          loanId,
          ipAddr: getRealUserIP(req),
          userAgent: req.headers?.["user-agent"],
          description: `Email '${existingEmail.email}' (${existingEmail.label}) deleted from contact info on ${existingLoan.loanNumber}`,
          previousValues: { email: `${existingEmail.email} (${existingEmail.label})` },
          newValues: { email: null },
          changedFields: ["email"]
        });
      }
    }
    for (const newEmail of newEmails) {
      const emailKey = `${newEmail.email}:${newEmail.label}`;
      if (!existingEmailAddresses.includes(emailKey)) {
        await complianceAudit.logEvent({
          eventType: COMPLIANCE_EVENTS.CRM.CONTACT_UPDATED,
          actorType: "user",
          actorId: userId?.toString(),
          resourceType: "loan",
          resourceId: loanId.toString(),
          loanId,
          ipAddr: getRealUserIP(req),
          userAgent: req.headers?.["user-agent"],
          description: `Email '${newEmail.email}' (${newEmail.label}) added to contact info on ${existingLoan.loanNumber}`,
          previousValues: { email: null },
          newValues: { email: `${newEmail.email} (${newEmail.label})` },
          changedFields: ["email"]
        });
      }
    }
    await logActivity2(loanId, userId, CRM_CONSTANTS.ACTIVITY_TYPES.CONTACT_UPDATE, {
      description: "Updated contact information",
      changes: {
        phones: phones || [],
        emails: emails || []
      }
    });
    const finalLoanResult = await db.select().from(loans).where(eq14(loans.id, loanId)).limit(1);
    res.setHeader("X-Cache-Invalidate", JSON.stringify([
      `/api/compliance/audit-log`,
      `/api/loans/${loanId}/crm/activity`,
      `/api/loans/${loanId}`
    ]));
    res.json(finalLoanResult[0]);
  } catch (error) {
    console.error("Error updating contact info:", error);
    res.status(500).json({ error: "Failed to update contact information" });
  }
});
router6.post("/loans/:loanId/profile-photo", async (req, res) => {
  try {
    const loanId = parseInt(req.params.loanId);
    const userId = req.user?.id || 1;
    const { photoUrl } = req.body;
    if (!photoUrl) {
      return res.status(400).json({ error: "No photo URL provided" });
    }
    await db.update(loans).set({
      borrowerPhoto: photoUrl,
      updatedAt: /* @__PURE__ */ new Date()
    }).where(eq14(loans.id, loanId));
    await logActivity2(loanId, userId, CRM_CONSTANTS.ACTIVITY_TYPES.PROFILE_PHOTO, {
      description: "Profile photo updated"
    });
    res.setHeader("X-Cache-Invalidate", JSON.stringify([
      `/api/compliance/audit-log`,
      `/api/loans/${loanId}/crm/activity`
    ]));
    res.json({ success: true, photoUrl });
  } catch (error) {
    console.error("Error updating profile photo:", error);
    res.status(500).json({ error: "Failed to update profile photo" });
  }
});
router6.get("/loans/:loanId/profile-photo", async (req, res) => {
  try {
    const loanId = parseInt(req.params.loanId);
    const [loan] = await db.select({ borrowerPhoto: loans.borrowerPhoto }).from(loans).where(eq14(loans.id, loanId)).limit(1);
    if (!loan?.borrowerPhoto) {
      return res.status(404).json({ error: "No photo found" });
    }
    res.json({ photoUrl: loan.borrowerPhoto });
  } catch (error) {
    console.error("Error fetching profile photo:", error);
    res.status(500).json({ error: "Failed to fetch profile photo" });
  }
});
var crm_default = router6;

// server/crm/email-routes.ts
init_db();
init_schema();
import { Router as Router7 } from "express";
import { z as z5 } from "zod";
import { eq as eq18 } from "drizzle-orm";
import { randomUUID as randomUUID2 } from "crypto";

// server/crm/email-types.ts
var DEFAULT_EMAIL_VALIDATION_RULES = {
  max_recipients: 50,
  max_attachment_size_bytes: 10 * 1024 * 1024,
  // 10MB per file
  max_total_attachment_size_bytes: 25 * 1024 * 1024,
  // 25MB total
  max_attachments_count: 10,
  allowed_mime_types: [
    "application/pdf",
    "image/jpeg",
    "image/png",
    "image/gif",
    "text/plain",
    "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    "application/vnd.ms-excel",
    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
  ],
  subject_max_length: 255
};

// server/crm/email-routes.ts
init_auditService();

// server/crm/dnc-enforcement.ts
init_db();
init_schema();
init_consentManagement();
import { eq as eq17 } from "drizzle-orm";

// server/crm/ai-email-classifier.ts
import OpenAI from "openai";
var openai = new OpenAI({
  baseURL: "https://api.x.ai/v1",
  apiKey: process.env.XAI_API_KEY
});
var AIEmailClassifier = class {
  /**
   * Classify email using Grok AI
   */
  async classifyEmail(subject, templateId, variables) {
    try {
      const prompt = this.buildClassificationPrompt(subject, templateId, variables);
      const response = await openai.chat.completions.create({
        model: "grok-beta",
        // Lower-powered, less expensive model
        messages: [
          {
            role: "system",
            content: this.getSystemPrompt()
          },
          {
            role: "user",
            content: prompt
          }
        ],
        response_format: { type: "json_object" },
        max_tokens: 200,
        // Keep it concise for cost efficiency
        temperature: 0.1
        // Low temperature for consistent classification
      });
      const result = JSON.parse(response.choices[0].message.content || "{}");
      return {
        category: result.category === "transactional" ? "transactional" : "marketing",
        topic: result.topic || (result.category === "transactional" ? "loan_servicing" : "marketing_general"),
        confidence: Math.min(Math.max(result.confidence || 0.5, 0), 1),
        reasoning: result.reasoning || "AI classification"
      };
    } catch (error) {
      console.error("[AIEmailClassifier] Classification failed:", this.redactEmailFromError(error));
      return {
        category: "transactional",
        // Default to transactional for safety
        topic: "loan_servicing",
        confidence: 0.3,
        reasoning: "Fallback classification due to AI service error"
      };
    }
  }
  /**
   * Build classification prompt for Grok
   */
  buildClassificationPrompt(subject, templateId, variables) {
    let prompt = `Classify this email for a mortgage loan servicing platform:

Subject: "${subject}"`;
    if (templateId) {
      prompt += `
Template ID: "${templateId}"`;
    }
    if (variables && Object.keys(variables).length > 0) {
      prompt += `
Template Variables: ${JSON.stringify(variables, null, 2)}`;
    }
    return prompt;
  }
  /**
   * System prompt for email classification
   */
  getSystemPrompt() {
    return `You are an expert email classifier for a mortgage loan servicing platform. Your job is to determine whether an email is TRANSACTIONAL or MARKETING.

TRANSACTIONAL emails are essential business communications that customers cannot opt out of:
- Payment due notices, payment confirmations, payment failures
- Account statements, balance updates
- Escrow analysis, property tax notices, insurance notices  
- Delinquency notices, late fee assessments
- Document requests, verification requirements
- Legal notices, compliance notifications
- Loan maturity notices, servicing transfers
- Security alerts, account changes

MARKETING emails are promotional communications that customers can opt out of:
- Promotional offers, refinancing offers
- Marketing campaigns, newsletters
- Product updates (non-essential)
- Customer surveys, feedback requests
- General company announcements

For TRANSACTIONAL emails, use these topics:
- payment_notifications (payment-related)
- account_statements (statements, balances)
- escrow_notifications (escrow, taxes, insurance)
- delinquency_notifications (late payments, fees)
- document_requests (required documents)
- legal_compliance (legal notices, compliance)
- loan_servicing (general loan servicing)

For MARKETING emails, use these topics:
- promotional_offers (refinancing, products)
- newsletters (company updates)
- surveys (feedback requests)
- marketing_general (other marketing)

Respond with JSON:
{
  "category": "transactional" | "marketing",
  "topic": "specific_topic",
  "confidence": 0.0-1.0,
  "reasoning": "brief explanation"
}

Be conservative - when in doubt, classify as transactional to ensure important communications are delivered.`;
  }
  /**
   * Batch classify multiple emails (for efficiency)
   */
  async classifyEmailsBatch(emails) {
    const results = [];
    for (const email of emails) {
      const result = await this.classifyEmail(
        email.subject,
        email.templateId,
        email.variables
      );
      results.push(result);
      await new Promise((resolve) => setTimeout(resolve, 100));
    }
    return results;
  }
  /**
   * Redact email addresses from error messages for privacy
   */
  redactEmailFromError(error) {
    if (!error || typeof error !== "object") return error;
    const errorStr = JSON.stringify(error);
    const redactedStr = errorStr.replace(
      /[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}/g,
      (match) => {
        const [local, domain] = match.split("@");
        const redactedLocal = local.length > 2 ? local.substring(0, 2) + "***" : "***";
        return `${redactedLocal}@${domain}`;
      }
    );
    try {
      return JSON.parse(redactedStr);
    } catch {
      return redactedStr;
    }
  }
};
var aiEmailClassifier = new AIEmailClassifier();

// server/crm/dnc-enforcement.ts
var DNCEnforcementService = class {
  consentService = new ConsentManagementService();
  /**
   * Check contact restrictions for email list based on loan and email category
   */
  async checkContactRestrictions(loanId, emailAddresses, category = "marketing", topic) {
    const restrictions = [];
    const loanResult = await db.select({
      borrowerId: loans.borrowerId,
      borrowerEmail: borrowerEntities.email
    }).from(loans).leftJoin(borrowerEntities, eq17(loans.borrowerId, borrowerEntities.id)).where(eq17(loans.id, loanId)).limit(1);
    if (loanResult.length === 0) {
      return {
        allowed: false,
        restrictions: emailAddresses.map((email) => ({
          email,
          reason: "Loan not found - precautionary DNC",
          category
        })),
        category
      };
    }
    const borrower = loanResult[0];
    for (const email of emailAddresses) {
      if (email !== borrower.borrowerEmail) {
        continue;
      }
      if (category === "transactional") {
        continue;
      } else {
        const isAllowed = await this.consentService.isCommunicationAllowed(
          borrower.borrowerId?.toString() || "0",
          "email",
          topic || "marketing_general"
        );
        if (!isAllowed) {
          restrictions.push({
            email,
            reason: "Marketing communications not permitted",
            category,
            topic
          });
        }
      }
    }
    return {
      allowed: restrictions.length === 0,
      restrictions,
      category
    };
  }
  /**
   * Determine email category using AI classification
   */
  async determineEmailCategory(subject, templateId, variables) {
    try {
      const classification = await aiEmailClassifier.classifyEmail(
        subject,
        templateId,
        variables
      );
      const redactedSubject = this.redactEmailFromString(subject);
      console.log(`[DNCEnforcement] AI classified email "${redactedSubject}" as ${classification.category} (confidence: ${classification.confidence})`);
      return {
        category: classification.category,
        topic: classification.topic
      };
    } catch (error) {
      console.error("[DNCEnforcement] AI classification failed, using fallback:", this.redactEmailFromError(error));
      return {
        category: "transactional",
        // Default to transactional for safety
        topic: "loan_servicing"
      };
    }
  }
  /**
   * Enhanced contact restriction check with AI categorization
   */
  async checkEmailRestrictions(loanId, emailAddresses, subject, templateId, variables) {
    const { category, topic } = await this.determineEmailCategory(subject, templateId, variables);
    return this.checkContactRestrictions(loanId, emailAddresses, category, topic);
  }
  /**
   * Redact email addresses from strings for privacy in logs
   */
  redactEmailFromString(text2) {
    return text2.replace(
      /[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}/g,
      (match) => {
        const [local, domain] = match.split("@");
        const redactedLocal = local.length > 2 ? local.substring(0, 2) + "***" : "***";
        return `${redactedLocal}@${domain}`;
      }
    );
  }
  /**
   * Redact email addresses from error objects for privacy
   */
  redactEmailFromError(error) {
    if (!error || typeof error !== "object") return error;
    const errorStr = JSON.stringify(error);
    const redactedStr = this.redactEmailFromString(errorStr);
    try {
      return JSON.parse(redactedStr);
    } catch {
      return redactedStr;
    }
  }
};
var dncEnforcementService = new DNCEnforcementService();

// server/crm/email-routes.ts
var router7 = Router7();
router7.post("/check-dnc", async (req, res) => {
  try {
    const validation = sendEmailSchema.safeParse(req.body);
    if (!validation.success) {
      return res.status(400).json({
        error: "Invalid request data",
        details: validation.error.errors
      });
    }
    const emailRequest = validation.data;
    const contactCheckResult = await dncEnforcementService.checkEmailRestrictions(
      emailRequest.loan_id,
      emailRequest.to,
      emailRequest.subject,
      emailRequest.template_id,
      emailRequest.variables
    );
    res.status(200).json(contactCheckResult);
  } catch (error) {
    console.error("[EmailRoutes] DNC check failed:", error);
    res.status(500).json({
      error: "Failed to check DNC restrictions",
      code: "DNC_CHECK_FAILED"
    });
  }
});
var sendEmailSchema = z5.object({
  loan_id: z5.number().int().positive(),
  template_id: z5.string().optional(),
  subject: z5.string().min(1).max(255),
  to: z5.array(z5.string().email()).min(1).max(50),
  cc: z5.array(z5.string().email()).max(20).optional(),
  bcc: z5.array(z5.string().email()).max(20).optional(),
  variables: z5.record(z5.any()).optional().default({}),
  attachments: z5.array(z5.object({
    filename: z5.string().min(1),
    content: z5.string().min(1),
    // base64 encoded
    type: z5.string().min(1)
  })).max(10).optional()
});
router7.post("/send", async (req, res) => {
  try {
    const userId = req.user?.id;
    if (!userId) {
      return res.status(401).json({
        error: "Authentication required",
        code: "AUTH_REQUIRED"
      });
    }
    const validationResult = sendEmailSchema.safeParse(req.body);
    if (!validationResult.success) {
      return res.status(400).json({
        error: "Validation failed",
        code: "VALIDATION_ERROR",
        details: validationResult.error.errors
      });
    }
    const emailRequest = validationResult.data;
    const correlationId = randomUUID2();
    const validationError = await validateEmailRequest(emailRequest, DEFAULT_EMAIL_VALIDATION_RULES);
    if (validationError) {
      return res.status(400).json({
        error: validationError.message,
        code: validationError.code
      });
    }
    const contactCheckResult = await dncEnforcementService.checkEmailRestrictions(
      emailRequest.loan_id,
      emailRequest.to,
      emailRequest.subject,
      emailRequest.template_id,
      emailRequest.variables
    );
    if (!contactCheckResult.allowed) {
      await complianceAudit.logEvent({
        eventType: COMPLIANCE_EVENTS.COMMS.DNC_VIOLATION_BLOCKED,
        actorType: "system",
        actorId: "dnc-enforcement",
        resourceType: "email_request",
        resourceId: correlationId,
        loanId: emailRequest.loan_id,
        description: `Email blocked due to DNC restrictions: ${emailRequest.subject}`,
        newValues: {
          correlation_id: correlationId,
          subject: emailRequest.subject,
          restrictions: contactCheckResult.restrictions,
          category: contactCheckResult.category
        },
        metadata: {
          loanId: emailRequest.loan_id,
          correlationId,
          dncCategory: contactCheckResult.category
        },
        ipAddr: req.ip,
        userAgent: req.headers["user-agent"]
      });
      return res.status(403).json({
        error: "Contact restrictions prevent email delivery",
        code: "CONTACT_RESTRICTED",
        details: contactCheckResult.restrictions,
        category: contactCheckResult.category
      });
    }
    const outboxEvent = {
      loan_id: emailRequest.loan_id,
      user_id: userId,
      template_id: emailRequest.template_id,
      subject: emailRequest.subject,
      to: emailRequest.to,
      cc: emailRequest.cc,
      bcc: emailRequest.bcc,
      variables: emailRequest.variables || {},
      attachments: emailRequest.attachments,
      correlation_id: correlationId,
      request_metadata: {
        ip_addr: req.ip,
        user_agent: req.headers["user-agent"],
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      }
    };
    await db.transaction(async (trx) => {
      await trx.insert(outboxMessages).values({
        aggregateType: "crm",
        aggregateId: emailRequest.loan_id.toString(),
        eventType: "crm.email.requested.v1",
        payload: outboxEvent,
        correlationId,
        attemptCount: 0,
        publishedAt: null
      });
      await complianceAudit.logEvent({
        eventType: "CRM.EMAIL_REQUESTED",
        actorType: "user",
        actorId: userId,
        resourceType: "email_request",
        resourceId: correlationId,
        loanId: emailRequest.loan_id,
        description: `Email request queued: ${emailRequest.subject} to ${emailRequest.to.join(", ")}`,
        newValues: {
          correlation_id: correlationId,
          subject: emailRequest.subject,
          recipient_count: emailRequest.to.length + (emailRequest.cc?.length || 0) + (emailRequest.bcc?.length || 0),
          attachment_count: emailRequest.attachments?.length || 0,
          template_id: emailRequest.template_id
        },
        metadata: {
          loanId: emailRequest.loan_id,
          userId,
          correlationId
        },
        ipAddr: req.ip,
        userAgent: req.headers["user-agent"]
      });
    });
    res.status(202).json({
      status: "accepted",
      correlation_id: correlationId,
      message: "Email request queued for processing"
    });
  } catch (error) {
    console.error("[CRMEmailRoute] Error processing email request:", error);
    res.status(500).json({
      error: "Internal server error",
      code: "INTERNAL_ERROR"
    });
  }
});
router7.get("/status/:correlationId", async (req, res) => {
  try {
    const correlationId = req.params.correlationId;
    const outboxResult = await db.select({
      eventType: outboxMessages.eventType,
      publishedAt: outboxMessages.publishedAt,
      attemptCount: outboxMessages.attemptCount,
      lastError: outboxMessages.lastError
    }).from(outboxMessages).where(eq18(outboxMessages.correlationId, correlationId)).limit(1);
    if (outboxResult.length === 0) {
      return res.status(404).json({
        error: "Email request not found",
        code: "NOT_FOUND"
      });
    }
    const outboxEntry = outboxResult[0];
    let status;
    if (outboxEntry.publishedAt) {
      status = "published";
    } else if (outboxEntry.attemptCount > 0) {
      status = "retrying";
    } else {
      status = "pending";
    }
    res.json({
      correlation_id: correlationId,
      status,
      attempt_count: outboxEntry.attemptCount,
      last_error: outboxEntry.lastError,
      published_at: outboxEntry.publishedAt
    });
  } catch (error) {
    console.error("[CRMEmailRoute] Error getting email status:", error);
    res.status(500).json({
      error: "Internal server error",
      code: "INTERNAL_ERROR"
    });
  }
});
async function validateEmailRequest(request, rules) {
  const totalRecipients = request.to.length + (request.cc?.length || 0) + (request.bcc?.length || 0);
  if (totalRecipients > rules.max_recipients) {
    return {
      message: `Too many recipients: ${totalRecipients} (max: ${rules.max_recipients})`,
      code: "TOO_MANY_RECIPIENTS"
    };
  }
  if (request.subject.length > rules.subject_max_length) {
    return {
      message: `Subject too long: ${request.subject.length} chars (max: ${rules.subject_max_length})`,
      code: "SUBJECT_TOO_LONG"
    };
  }
  if (request.attachments) {
    if (request.attachments.length > rules.max_attachments_count) {
      return {
        message: `Too many attachments: ${request.attachments.length} (max: ${rules.max_attachments_count})`,
        code: "TOO_MANY_ATTACHMENTS"
      };
    }
    let totalSize = 0;
    for (const attachment of request.attachments) {
      const size = Math.floor(attachment.content.length * 0.75);
      if (size > rules.max_attachment_size_bytes) {
        return {
          message: `Attachment '${attachment.filename}' too large: ${size} bytes (max: ${rules.max_attachment_size_bytes})`,
          code: "ATTACHMENT_TOO_LARGE"
        };
      }
      totalSize += size;
      if (!rules.allowed_mime_types.includes(attachment.type)) {
        return {
          message: `Attachment '${attachment.filename}' has unsupported type: ${attachment.type}`,
          code: "UNSUPPORTED_ATTACHMENT_TYPE"
        };
      }
    }
    if (totalSize > rules.max_total_attachment_size_bytes) {
      return {
        message: `Total attachment size too large: ${totalSize} bytes (max: ${rules.max_total_attachment_size_bytes})`,
        code: "TOTAL_ATTACHMENTS_TOO_LARGE"
      };
    }
  }
  return null;
}
var email_routes_default = router7;

// server/routes/communication-preferences.ts
init_auditService();
import { Router as Router8 } from "express";
import { z as z6 } from "zod";

// server/utils/network.js
function getRealUserIP2(req) {
  const forwarded = req.headers["x-forwarded-for"];
  if (forwarded) {
    return forwarded.split(",")[0].trim();
  }
  const realIp = req.headers["x-real-ip"];
  if (realIp) {
    return realIp;
  }
  const clientIp = req.headers["x-client-ip"];
  if (clientIp) {
    return clientIp;
  }
  return req.connection?.remoteAddress || req.socket?.remoteAddress || req.ip || "unknown";
}

// server/routes/communication-preferences.ts
var router8 = Router8();
var updatePreferenceSchema = z6.object({
  channel: z6.enum(["email", "sms", "phone", "push", "mail"]),
  topic: z6.string().min(1),
  allowed: z6.boolean(),
  frequency: z6.enum(["immediate", "daily", "weekly", "monthly"]).optional()
});
var bulkUpdateSchema = z6.object({
  preferences: z6.array(updatePreferenceSchema).min(1).max(50)
});
var dncRequestSchema = z6.object({
  channel: z6.enum(["email", "sms", "phone", "mail"]),
  reason: z6.string().min(1).max(500).optional(),
  effective_date: z6.string().optional()
  // ISO date string
});
router8.get("/:borrowerId", async (req, res) => {
  try {
    const borrowerId = req.params.borrowerId;
    if (!borrowerId) {
      return res.status(400).json({
        error: "Borrower ID is required",
        code: "BORROWER_ID_REQUIRED"
      });
    }
    const preferences = {
      email: {
        marketing_general: { allowed: true },
        transactional: { allowed: true }
        // Always true, cannot be changed
      },
      sms: {
        marketing_general: { allowed: true },
        transactional: { allowed: true }
        // Always true, cannot be changed
      },
      phone: {
        marketing_general: { allowed: true },
        transactional: { allowed: true }
        // Always true, cannot be changed
      }
    };
    res.json({
      data: preferences,
      borrowerId,
      lastModified: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    console.error("Error fetching communication preferences:", error);
    res.status(500).json({
      error: "Failed to fetch communication preferences",
      code: "FETCH_PREFERENCES_FAILED"
    });
  }
});
router8.put("/:borrowerId", async (req, res) => {
  try {
    const borrowerId = req.params.borrowerId;
    const userId = req.user?.id;
    const validation = updatePreferenceSchema.safeParse(req.body);
    if (!validation.success) {
      return res.status(400).json({
        error: "Invalid preference data",
        details: validation.error.errors
      });
    }
    const { channel, topic, allowed, frequency } = validation.data;
    const transactionalTopics = [
      "payment_notifications",
      "account_statements",
      "escrow_notifications",
      "delinquency_notifications",
      "document_requests",
      "legal_compliance",
      "loan_servicing",
      "transactional"
    ];
    if (!allowed && transactionalTopics.includes(topic)) {
      return res.status(400).json({
        error: "Cannot opt out of required transactional communications",
        code: "TRANSACTIONAL_REQUIRED"
      });
    }
    const existingPreferences = {
      channel,
      topic,
      allowed: true,
      // Default to previously allowed
      frequency: frequency || "monthly"
    };
    const updatedPreferences = {
      channel,
      topic,
      allowed,
      frequency: frequency || "monthly"
    };
    const potentialFields = Object.keys(updatedPreferences);
    for (const field of potentialFields) {
      const oldValue = existingPreferences[field];
      const newValue = updatedPreferences[field];
      if (String(oldValue) !== String(newValue)) {
        await complianceAudit.logEvent({
          eventType: COMPLIANCE_EVENTS.CRM.PREFERENCE_UPDATED,
          actorType: "user",
          actorId: userId?.toString(),
          resourceType: "communication_preference",
          resourceId: borrowerId.toString(),
          loanId: null,
          // Communication preferences may not be tied to a specific loan
          ipAddr: getRealUserIP2(req),
          userAgent: req.headers?.["user-agent"],
          description: `Communication preference field '${field}' updated from '${oldValue}' to '${newValue}' for borrower ${borrowerId}`,
          previousValues: { [field]: oldValue },
          newValues: { [field]: newValue },
          changedFields: [field]
        });
      }
    }
    const correlationId = `comm_pref_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    res.json({
      success: true,
      borrowerId,
      channel,
      topic,
      allowed,
      frequency,
      correlation_id: correlationId,
      updated: true,
      message: "Communication preference updated successfully"
    });
  } catch (error) {
    console.error("Error updating communication preference:", error);
    res.status(500).json({
      error: "Failed to update communication preference",
      code: "UPDATE_PREFERENCES_FAILED"
    });
  }
});
router8.get("/:borrowerId/check/:channel/:topic", async (req, res) => {
  try {
    const { borrowerId, channel, topic } = req.params;
    const allowed = topic.includes("transactional") || topic === "transactional" ? true : true;
    res.json({
      borrowerId,
      channel,
      topic,
      allowed,
      checked_at: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    console.error("Error checking communication allowance:", error);
    res.status(500).json({
      error: "Failed to check communication allowance",
      code: "CHECK_ALLOWANCE_FAILED"
    });
  }
});
var communication_preferences_default = router8;

// server/routes/borrower.ts
init_db();
init_schema();
init_logger();
init_middleware();
import { and as and15, eq as eq19, desc as desc9, isNull as isNull7, sql as sql11 } from "drizzle-orm";
import { z as z7 } from "zod";
var logger2 = loggers.api;
var updateContactInfoSchema = z7.object({
  email: z7.string().email().optional(),
  phone: z7.string().optional()
});
var addPaymentMethodSchema = z7.object({
  type: z7.literal("ach"),
  routingNumber: z7.string().regex(/^\d{9}$/, "Invalid routing number"),
  accountNumber: z7.string().min(4).max(17),
  accountType: z7.enum(["checking", "savings"]),
  nameOnAccount: z7.string()
});
var makePaymentSchema = z7.object({
  amount: z7.number().positive(),
  paymentMethodId: z7.number().int(),
  principal: z7.number().min(0).optional(),
  interest: z7.number().min(0).optional(),
  escrow: z7.number().min(0).optional(),
  fees: z7.number().min(0).optional()
});
function registerBorrowerRoutes(app2) {
  app2.get("/api/borrower/dashboard", requireBorrower, async (req, res) => {
    try {
      const borrowerUserId = req.user?.borrowerUserId;
      if (!borrowerUserId) {
        return res.status(401).json({ error: "Unauthorized" });
      }
      const userLoans = await db.select({
        loanId: loans.id,
        loanNumber: loans.loanNumber,
        propertyAddress: properties.address,
        propertyCity: properties.city,
        propertyState: properties.state,
        principalBalance: sql11`${loanBalances}.current_principal`,
        escrowBalance: sql11`${loanBalances}.current_escrow`,
        nextPaymentDate: loans.nextPaymentDate,
        paymentAmount: loans.paymentAmount,
        status: loans.status,
        role: loanBorrowerLinks.role
      }).from(loanBorrowerLinks).innerJoin(loans, eq19(loanBorrowerLinks.loanId, loans.id)).innerJoin(properties, eq19(loans.propertyId, properties.id)).leftJoin(loanBalances, eq19(loans.id, loanBalances.loanId)).where(eq19(loanBorrowerLinks.borrowerUserId, borrowerUserId)).orderBy(loans.loanNumber);
      const recentPayments = await db.select({
        id: payments.id,
        loanNumber: loans.loanNumber,
        receivedDate: payments.receivedDate,
        totalAmount: payments.totalReceived,
        status: payments.status
      }).from(payments).innerJoin(loans, eq19(payments.loanId, loans.id)).innerJoin(loanBorrowerLinks, eq19(loans.id, loanBorrowerLinks.loanId)).where(
        and15(
          eq19(loanBorrowerLinks.borrowerUserId, borrowerUserId),
          eq19(payments.status, "completed")
        )
      ).orderBy(desc9(payments.receivedDate)).limit(5);
      const unreadNotices = await db.select({
        id: borrowerNotices.id,
        type: borrowerNotices.type,
        title: borrowerNotices.title,
        createdAt: borrowerNotices.createdAt
      }).from(borrowerNotices).where(
        and15(
          eq19(borrowerNotices.borrowerUserId, borrowerUserId),
          isNull7(borrowerNotices.readAt)
        )
      ).orderBy(desc9(borrowerNotices.createdAt)).limit(5);
      res.json({
        loans: userLoans,
        recentPayments,
        unreadNotices
      });
    } catch (error) {
      logger2.error("Error fetching borrower dashboard:", error);
      res.status(500).json({ error: "Failed to fetch dashboard data" });
    }
  });
  app2.get("/api/borrower/loans/:id", requireBorrower, async (req, res) => {
    try {
      const borrowerUserId = req.user?.borrowerUserId;
      const loanId = parseInt(req.params.id);
      if (!borrowerUserId || isNaN(loanId)) {
        return res.status(400).json({ error: "Invalid request" });
      }
      const access = await db.select().from(loanBorrowerLinks).where(
        and15(
          eq19(loanBorrowerLinks.loanId, loanId),
          eq19(loanBorrowerLinks.borrowerUserId, borrowerUserId)
        )
      ).limit(1);
      if (access.length === 0) {
        return res.status(403).json({ error: "Access denied" });
      }
      const [loanDetails] = await db.select({
        loan: loans,
        property: properties,
        balances: loanBalances,
        escrow: escrowAccounts2
      }).from(loans).innerJoin(properties, eq19(loans.propertyId, properties.id)).leftJoin(loanBalances, eq19(loans.id, loanBalances.loanId)).leftJoin(escrowAccounts2, eq19(loans.id, escrowAccounts2.loanId)).where(eq19(loans.id, loanId)).limit(1);
      res.json(loanDetails);
    } catch (error) {
      logger2.error("Error fetching loan details:", error);
      res.status(500).json({ error: "Failed to fetch loan details" });
    }
  });
  app2.get("/api/borrower/loans/:id/payments", requireBorrower, async (req, res) => {
    try {
      const borrowerUserId = req.user?.borrowerUserId;
      const loanId = parseInt(req.params.id);
      if (!borrowerUserId || isNaN(loanId)) {
        return res.status(400).json({ error: "Invalid request" });
      }
      const access = await db.select().from(loanBorrowerLinks).where(
        and15(
          eq19(loanBorrowerLinks.loanId, loanId),
          eq19(loanBorrowerLinks.borrowerUserId, borrowerUserId)
        )
      ).limit(1);
      if (access.length === 0) {
        return res.status(403).json({ error: "Access denied" });
      }
      const paymentHistory = await db.select({
        id: payments.id,
        paymentNumber: payments.paymentNumber,
        dueDate: payments.dueDate,
        receivedDate: payments.receivedDate,
        principalAmount: payments.principalAmount,
        interestAmount: payments.interestAmount,
        escrowAmount: payments.escrowAmount,
        lateFeeAmount: payments.lateFeeAmount,
        otherFeeAmount: payments.otherFeeAmount,
        totalAmount: payments.totalReceived,
        status: payments.status,
        confirmationNumber: payments.transactionId
      }).from(payments).where(eq19(payments.loanId, loanId)).orderBy(desc9(payments.receivedDate)).limit(100);
      res.json(paymentHistory);
    } catch (error) {
      logger2.error("Error fetching payment history:", error);
      res.status(500).json({ error: "Failed to fetch payment history" });
    }
  });
  app2.get("/api/borrower/profile", requireBorrower, async (req, res) => {
    try {
      const borrowerUserId = req.user?.borrowerUserId;
      if (!borrowerUserId) {
        return res.status(401).json({ error: "Unauthorized" });
      }
      const [profile] = await db.select({
        user: borrowerUsers,
        entity: borrowerEntities,
        preferences: borrowerPreferences
      }).from(borrowerUsers).innerJoin(borrowerEntities, eq19(borrowerUsers.borrowerEntityId, borrowerEntities.id)).leftJoin(borrowerPreferences, eq19(borrowerUsers.id, borrowerPreferences.borrowerUserId)).where(eq19(borrowerUsers.id, borrowerUserId)).limit(1);
      res.json(profile);
    } catch (error) {
      logger2.error("Error fetching profile:", error);
      res.status(500).json({ error: "Failed to fetch profile" });
    }
  });
  app2.patch("/api/borrower/profile/contact", requireBorrower, async (req, res) => {
    try {
      const borrowerUserId = req.user?.borrowerUserId;
      if (!borrowerUserId) {
        return res.status(401).json({ error: "Unauthorized" });
      }
      const data = updateContactInfoSchema.parse(req.body);
      await db.update(borrowerUsers).set({
        ...data,
        updatedAt: /* @__PURE__ */ new Date()
      }).where(eq19(borrowerUsers.id, borrowerUserId));
      res.json({ success: true });
    } catch (error) {
      logger2.error("Error updating contact info:", error);
      res.status(500).json({ error: "Failed to update contact information" });
    }
  });
  app2.get("/api/borrower/payment-methods", requireBorrower, async (req, res) => {
    try {
      const borrowerUserId = req.user?.borrowerUserId;
      if (!borrowerUserId) {
        return res.status(401).json({ error: "Unauthorized" });
      }
      const methods = await db.select({
        id: borrowerPaymentMethods.id,
        type: borrowerPaymentMethods.type,
        last4: borrowerPaymentMethods.last4,
        bankName: borrowerPaymentMethods.bankName,
        accountType: borrowerPaymentMethods.accountType,
        nameOnAccount: borrowerPaymentMethods.nameOnAccount,
        status: borrowerPaymentMethods.status,
        isDefault: borrowerPaymentMethods.isDefault
      }).from(borrowerPaymentMethods).where(
        and15(
          eq19(borrowerPaymentMethods.borrowerUserId, borrowerUserId),
          eq19(borrowerPaymentMethods.status, "active")
        )
      ).orderBy(desc9(borrowerPaymentMethods.isDefault));
      res.json(methods);
    } catch (error) {
      logger2.error("Error fetching payment methods:", error);
      res.status(500).json({ error: "Failed to fetch payment methods" });
    }
  });
  app2.post("/api/borrower/payment-methods", requireBorrower, async (req, res) => {
    try {
      const borrowerUserId = req.user?.borrowerUserId;
      if (!borrowerUserId) {
        return res.status(401).json({ error: "Unauthorized" });
      }
      const data = addPaymentMethodSchema.parse(req.body);
      const processorToken = `ach_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
      const last4 = data.accountNumber.slice(-4);
      const newMethod = {
        borrowerUserId,
        type: data.type,
        processorToken,
        last4,
        accountType: data.accountType,
        nameOnAccount: data.nameOnAccount,
        bankName: "Bank",
        // Would come from routing number lookup
        status: "active",
        isDefault: false,
        verifiedAt: /* @__PURE__ */ new Date()
      };
      const [created] = await db.insert(borrowerPaymentMethods).values(newMethod).returning();
      res.json({
        id: created.id,
        type: created.type,
        last4: created.last4,
        bankName: created.bankName,
        accountType: created.accountType
      });
    } catch (error) {
      logger2.error("Error adding payment method:", error);
      res.status(500).json({ error: "Failed to add payment method" });
    }
  });
  app2.post("/api/borrower/loans/:id/payments", requireBorrower, async (req, res) => {
    try {
      const borrowerUserId = req.user?.borrowerUserId;
      const loanId = parseInt(req.params.id);
      if (!borrowerUserId || isNaN(loanId)) {
        return res.status(400).json({ error: "Invalid request" });
      }
      const access = await db.select().from(loanBorrowerLinks).where(
        and15(
          eq19(loanBorrowerLinks.loanId, loanId),
          eq19(loanBorrowerLinks.borrowerUserId, borrowerUserId)
        )
      ).limit(1);
      if (access.length === 0) {
        return res.status(403).json({ error: "Access denied" });
      }
      const data = makePaymentSchema.parse(req.body);
      const [method] = await db.select().from(borrowerPaymentMethods).where(
        and15(
          eq19(borrowerPaymentMethods.id, data.paymentMethodId),
          eq19(borrowerPaymentMethods.borrowerUserId, borrowerUserId)
        )
      ).limit(1);
      if (!method) {
        return res.status(400).json({ error: "Invalid payment method" });
      }
      const paymentId = `BP-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`.toUpperCase();
      await db.insert(payments).values({
        id: paymentId,
        loanId,
        receivedDate: /* @__PURE__ */ new Date(),
        effectiveDate: /* @__PURE__ */ new Date(),
        principalAmount: data.principal || 0,
        interestAmount: data.interest || 0,
        escrowAmount: data.escrow || 0,
        feeAmount: data.fees || 0,
        totalAmount: data.amount,
        totalReceived: data.amount,
        paymentMethod: "ACH",
        paymentSource: "borrower_portal",
        status: "processing",
        referenceNumber: paymentId,
        createdBy: req.user?.id
      });
      await db.insert(borrowerNotices).values({
        loanId,
        borrowerUserId,
        type: "payment_received",
        title: "Payment Received",
        message: `Your payment of $${data.amount.toFixed(2)} has been received and is being processed.`,
        payload: { paymentId, amount: data.amount }
      });
      res.json({
        paymentId,
        status: "processing",
        amount: data.amount,
        message: "Payment is being processed. You will receive a confirmation once it's posted."
      });
    } catch (error) {
      logger2.error("Error processing payment:", error);
      res.status(500).json({ error: "Failed to process payment" });
    }
  });
  app2.get("/api/borrower/notices", requireBorrower, async (req, res) => {
    try {
      const borrowerUserId = req.user?.borrowerUserId;
      if (!borrowerUserId) {
        return res.status(401).json({ error: "Unauthorized" });
      }
      const notices = await db.select({
        id: borrowerNotices.id,
        loanId: borrowerNotices.loanId,
        loanNumber: loans.loanNumber,
        type: borrowerNotices.type,
        title: borrowerNotices.title,
        message: borrowerNotices.message,
        readAt: borrowerNotices.readAt,
        createdAt: borrowerNotices.createdAt
      }).from(borrowerNotices).innerJoin(loans, eq19(borrowerNotices.loanId, loans.id)).where(eq19(borrowerNotices.borrowerUserId, borrowerUserId)).orderBy(desc9(borrowerNotices.createdAt)).limit(50);
      res.json(notices);
    } catch (error) {
      logger2.error("Error fetching notices:", error);
      res.status(500).json({ error: "Failed to fetch notices" });
    }
  });
  app2.patch("/api/borrower/notices/:id/read", requireBorrower, async (req, res) => {
    try {
      const borrowerUserId = req.user?.borrowerUserId;
      const noticeId = parseInt(req.params.id);
      if (!borrowerUserId || isNaN(noticeId)) {
        return res.status(400).json({ error: "Invalid request" });
      }
      await db.update(borrowerNotices).set({ readAt: /* @__PURE__ */ new Date() }).where(
        and15(
          eq19(borrowerNotices.id, noticeId),
          eq19(borrowerNotices.borrowerUserId, borrowerUserId)
        )
      );
      res.json({ success: true });
    } catch (error) {
      logger2.error("Error marking notice as read:", error);
      res.status(500).json({ error: "Failed to mark notice as read" });
    }
  });
  app2.get("/api/borrower/preferences", requireBorrower, async (req, res) => {
    try {
      const borrowerUserId = req.user?.borrowerUserId;
      if (!borrowerUserId) {
        return res.status(401).json({ error: "Unauthorized" });
      }
      const [prefs] = await db.select().from(borrowerPreferences).where(eq19(borrowerPreferences.borrowerUserId, borrowerUserId)).limit(1);
      if (!prefs) {
        const defaultPrefs = {
          borrowerUserId,
          statementDelivery: "paperless",
          paperlessConsent: false,
          emailNotifications: true,
          smsNotifications: false,
          language: "en",
          timezone: "America/Phoenix"
        };
        const [created] = await db.insert(borrowerPreferences).values(defaultPrefs).returning();
        return res.json(created);
      }
      res.json(prefs);
    } catch (error) {
      logger2.error("Error fetching preferences:", error);
      res.status(500).json({ error: "Failed to fetch preferences" });
    }
  });
  app2.patch("/api/borrower/preferences", requireBorrower, async (req, res) => {
    try {
      const borrowerUserId = req.user?.borrowerUserId;
      if (!borrowerUserId) {
        return res.status(401).json({ error: "Unauthorized" });
      }
      await db.update(borrowerPreferences).set({
        ...req.body,
        updatedAt: /* @__PURE__ */ new Date()
      }).where(eq19(borrowerPreferences.borrowerUserId, borrowerUserId));
      res.json({ success: true });
    } catch (error) {
      logger2.error("Error updating preferences:", error);
      res.status(500).json({ error: "Failed to update preferences" });
    }
  });
}

// server/routes/settings.ts
init_storage();
init_response_utils();
init_middleware();
init_policy_engine();
import { Router as Router9 } from "express";
import { neon as neon2 } from "@neondatabase/serverless";
var router9 = Router9();
var storage2 = new DatabaseStorage();
var databaseUrl2 = process.env.DATABASE_URL || "";
var sql12 = neon2(databaseUrl2);
router9.get("/admin/settings", requireAuth2, requirePermission("system_settings", PermissionLevel.ADMIN), async (req, res) => {
  try {
    const settings = await sql12`
      SELECT category, key, value 
      FROM system_settings 
      WHERE category IN ('password_policy', 'lockout_policy', 'session_settings', 'caller_verification')
    `;
    const passwordPolicy = {
      enabled: false,
      minLength: 8,
      requireUppercase: true,
      requireLowercase: true,
      requireNumbers: true,
      requireSpecialChars: true,
      preventPasswordReuse: true,
      passwordHistoryCount: 5,
      passwordExpiryDays: 90
    };
    const lockoutPolicy = {
      enabled: false,
      maxFailedAttempts: 5,
      lockoutDurationMinutes: 30,
      lockoutStrategy: "progressive"
    };
    const sessionSettings = {
      sessionTimeoutMinutes: 30,
      extendSessionOnActivity: true,
      requireReauthForSensitive: true,
      allowMultipleSessions: false,
      maxConcurrentSessions: 1
    };
    const callerVerification = {
      enabled: false,
      requireForPIIAccess: true,
      verificationMethods: {
        lastFourSSN: true,
        dateOfBirth: true,
        accountNumber: false,
        securityQuestions: false,
        twoFactorAuth: false
      },
      maxVerificationAttempts: 3,
      lockoutDurationMinutes: 15,
      requireReVerificationAfterMinutes: 60,
      applicableRoles: ["borrower", "lender", "investor", "escrow_officer", "legal", "servicer"],
      exemptRoles: ["admin"],
      auditAllAccess: true,
      notifyOnFailedVerification: true
    };
    settings.forEach((setting) => {
      const category = setting.category;
      const key = setting.key;
      const value = setting.value;
      let targetPolicy = null;
      if (category === "password_policy") targetPolicy = passwordPolicy;
      else if (category === "lockout_policy") targetPolicy = lockoutPolicy;
      else if (category === "session_settings") targetPolicy = sessionSettings;
      else if (category === "caller_verification") targetPolicy = callerVerification;
      if (targetPolicy && key in targetPolicy) {
        if (typeof value === "object" && value !== null) {
          targetPolicy[key] = value;
        } else if (value === "true") {
          targetPolicy[key] = true;
        } else if (value === "false") {
          targetPolicy[key] = false;
        } else if (!isNaN(Number(value))) {
          targetPolicy[key] = Number(value);
        } else {
          targetPolicy[key] = value;
        }
      }
    });
    res.json({
      passwordPolicy,
      lockoutPolicy,
      sessionSettings,
      callerVerification
    });
  } catch (error) {
    console.error("Error fetching settings:", error);
    return sendError(res, "Failed to fetch settings", 500);
  }
});
router9.put("/admin/settings", requireAuth2, requirePermission("system_settings", PermissionLevel.ADMIN), async (req, res) => {
  try {
    const { passwordPolicy, lockoutPolicy, sessionSettings, callerVerification } = req.body;
    const promises = [];
    if (passwordPolicy) {
      Object.entries(passwordPolicy).forEach(([key, value]) => {
        const settingValue = typeof value === "object" ? value : String(value);
        promises.push(sql12`
          INSERT INTO system_settings (category, key, value, updated_by, updated_at)
          VALUES ('password_policy', ${key}, ${JSON.stringify(settingValue)}, ${req.user?.id || 1}, NOW())
          ON CONFLICT (category, key) DO UPDATE
          SET value = EXCLUDED.value,
              updated_by = EXCLUDED.updated_by,
              updated_at = EXCLUDED.updated_at
        `);
      });
    }
    if (lockoutPolicy) {
      Object.entries(lockoutPolicy).forEach(([key, value]) => {
        const settingValue = typeof value === "object" ? value : String(value);
        promises.push(sql12`
          INSERT INTO system_settings (category, key, value, updated_by, updated_at)
          VALUES ('lockout_policy', ${key}, ${JSON.stringify(settingValue)}, ${req.user?.id || 1}, NOW())
          ON CONFLICT (category, key) DO UPDATE
          SET value = EXCLUDED.value,
              updated_by = EXCLUDED.updated_by,
              updated_at = EXCLUDED.updated_at
        `);
      });
    }
    if (sessionSettings) {
      Object.entries(sessionSettings).forEach(([key, value]) => {
        const settingValue = typeof value === "object" ? value : String(value);
        promises.push(sql12`
          INSERT INTO system_settings (category, key, value, updated_by, updated_at)
          VALUES ('session_settings', ${key}, ${JSON.stringify(settingValue)}, ${req.user?.id || 1}, NOW())
          ON CONFLICT (category, key) DO UPDATE
          SET value = EXCLUDED.value,
              updated_by = EXCLUDED.updated_by,
              updated_at = EXCLUDED.updated_at
        `);
      });
    }
    if (callerVerification) {
      Object.entries(callerVerification).forEach(([key, value]) => {
        const settingValue = typeof value === "object" ? value : String(value);
        promises.push(sql12`
          INSERT INTO system_settings (category, key, value, updated_by, updated_at)
          VALUES ('caller_verification', ${key}, ${JSON.stringify(settingValue)}, ${req.user?.id || 1}, NOW())
          ON CONFLICT (category, key) DO UPDATE
          SET value = EXCLUDED.value,
              updated_by = EXCLUDED.updated_by,
              updated_at = EXCLUDED.updated_at
        `);
      });
    }
    await Promise.all(promises);
    return sendSuccess(res, { success: true });
  } catch (error) {
    console.error("Error updating settings:", error);
    return sendError(res, "Failed to update settings", 500);
  }
});
router9.get("/password-policy", async (req, res) => {
  try {
    const settings = await sql12`
      SELECT key, value 
      FROM system_settings 
      WHERE key LIKE 'password_policy.%'
    `;
    const policy = {
      enabled: false,
      minLength: 4,
      requireUppercase: false,
      requireLowercase: false,
      requireNumbers: false,
      requireSpecialChars: false,
      rejectWeakPasswords: false
    };
    settings.forEach((setting) => {
      const key = setting.key.replace("password_policy.", "");
      const value = setting.value;
      if (value === "true") {
        policy[key] = true;
      } else if (value === "false") {
        policy[key] = false;
      } else if (!isNaN(Number(value))) {
        policy[key] = Number(value);
      }
    });
    res.json(policy);
  } catch (error) {
    res.json({
      enabled: false,
      minLength: 4,
      requireUppercase: false,
      requireLowercase: false,
      requireNumbers: false,
      requireSpecialChars: false,
      rejectWeakPasswords: false
    });
  }
});
router9.post("/admin/rabbitmq/force-disconnect", requireAuth2, requirePermission("system_settings", PermissionLevel.ADMIN), async (req, res) => {
  try {
    console.log("[Admin] Emergency RabbitMQ connection cleanup requested");
    const { rabbitmqClient: rabbitmqClient2 } = await Promise.resolve().then(() => (init_rabbitmq_unified(), rabbitmq_unified_exports));
    await rabbitmqClient2.shutdown();
    console.log("[Admin] Forcing CloudAMQP connection limit to close stale connections...");
    const connections = [];
    try {
      const amqp2 = await import("amqplib");
      const url = process.env.CLOUDAMQP_URL || "";
      for (let i = 0; i < 50; i++) {
        try {
          const { rabbitmqClient: rabbitmqClient3 } = await Promise.resolve().then(() => (init_rabbitmq_unified(), rabbitmq_unified_exports));
          const conn = await rabbitmqClient3.getAdminConnection();
          connections.push(conn);
          console.log(`[Admin] Created pressure connection ${i + 1}`);
        } catch (error) {
          console.log(`[Admin] Hit connection limit at ${i + 1} connections`);
          break;
        }
      }
      for (const conn of connections) {
        try {
          if (conn !== (await Promise.resolve().then(() => (init_rabbitmq_unified(), rabbitmq_unified_exports))).rabbitmqClient.getAdminConnection()) {
            await conn.close();
          }
        } catch (error) {
        }
      }
      console.log("[Admin] Closed all pressure connections");
    } catch (error) {
      console.log("[Admin] Connection pressure failed (expected):", error.message);
    }
    await new Promise((resolve) => setTimeout(resolve, 3e3));
    const stats = rabbitmqService.getConnectionPoolStats();
    console.log("[Admin] Post-cleanup connection stats:", stats);
    return sendSuccess(res, {
      message: "Emergency RabbitMQ cleanup completed - used connection pressure to force closure of stale connections",
      connectionStats: stats,
      shutdownTargets: ["Enhanced Service", "Main Service", "Legacy Service", "Connection Pressure Cleanup"]
    });
  } catch (error) {
    console.error("[Admin] Failed to force disconnect RabbitMQ connections:", error);
    return sendError(res, "Failed to force disconnect connections", 500);
  }
});

// server/routes/phase10-routes.ts
import express from "express";

// server/services/phase10-audit-service.ts
init_db();
import { randomUUID as randomUUID3 } from "crypto";
var Phase10AuditService = class {
  defaultTenantId = "00000000-0000-0000-0000-000000000001";
  /**
   * Add an immutable audit event with hash chain verification
   */
  async logEvent(event) {
    const client5 = await pool.connect();
    try {
      await client5.query("SELECT set_config($1, $2, true)", [
        "app.tenant_id",
        event.tenantId || this.defaultTenantId
      ]);
      const eventId = await client5.query(`
        SELECT add_phase10_audit_event(
          $1::uuid, $2::uuid, $3, $4::uuid, $5, $6, $7::jsonb, $8::inet, $9, $10
        ) as event_id
      `, [
        event.tenantId || this.defaultTenantId,
        event.correlationId || randomUUID3(),
        event.eventType,
        event.actorId || null,
        event.actorType,
        event.resourceUrn,
        JSON.stringify(event.payload),
        event.ipAddress || null,
        event.userAgent || null,
        event.sessionId || null
      ]);
      return eventId.rows[0].event_id;
    } catch (error) {
      console.error("[Phase10Audit] Failed to log event:", error);
      throw error;
    } finally {
      client5.release();
    }
  }
  /**
   * Verify the integrity of an audit chain for a resource
   */
  async verifyAuditChain(resourceUrn, tenantId) {
    const client5 = await pool.connect();
    try {
      if (tenantId) {
        await client5.query("SELECT set_config($1, $2, true)", [
          "app.tenant_id",
          tenantId
        ]);
      }
      const result = await client5.query(`
        SELECT * FROM verify_audit_chain($1, $2::uuid)
      `, [resourceUrn, tenantId || null]);
      const row = result.rows[0];
      return {
        valid: row.valid,
        brokenAt: row.broken_at || void 0,
        totalRecords: parseInt(row.total_records),
        message: row.message
      };
    } catch (error) {
      console.error("[Phase10Audit] Failed to verify chain:", error);
      throw error;
    } finally {
      client5.release();
    }
  }
  /**
   * Get audit events for a resource with pagination
   */
  async getAuditEvents(resourceUrn, tenantId, limit = 100, offset = 0) {
    const client5 = await pool.connect();
    try {
      if (tenantId) {
        await client5.query("SELECT set_config($1, $2, true)", [
          "app.tenant_id",
          tenantId
        ]);
      }
      const result = await client5.query(`
        SELECT 
          id, event_id, event_time, event_type, actor_id, actor_type,
          resource_urn, event_seq, payload, ip, user_agent, session_id,
          created_at,
          -- Don't expose internal hash fields to prevent tampering
          CASE WHEN payload_hash IS NOT NULL THEN true ELSE false END as has_integrity_hash
        FROM phase10_audit_log 
        WHERE resource_urn = $1 
          AND ($2::uuid IS NULL OR tenant_id = $2::uuid)
        ORDER BY event_seq ASC 
        LIMIT $3 OFFSET $4
      `, [resourceUrn, tenantId || null, limit, offset]);
      return result.rows;
    } catch (error) {
      console.error("[Phase10Audit] Failed to get events:", error);
      throw error;
    } finally {
      client5.release();
    }
  }
  /**
   * Search audit events across multiple resources
   */
  async searchAuditEvents(filters, limit = 100, offset = 0) {
    const client5 = await pool.connect();
    try {
      if (filters.tenantId) {
        await client5.query("SELECT set_config($1, $2, true)", [
          "app.tenant_id",
          filters.tenantId
        ]);
      }
      let whereClause = "WHERE 1=1";
      const params = [];
      let paramIndex = 1;
      if (filters.tenantId) {
        whereClause += ` AND tenant_id = $${paramIndex}::uuid`;
        params.push(filters.tenantId);
        paramIndex++;
      }
      if (filters.eventType) {
        whereClause += ` AND event_type = $${paramIndex}`;
        params.push(filters.eventType);
        paramIndex++;
      }
      if (filters.actorId) {
        whereClause += ` AND actor_id = $${paramIndex}::uuid`;
        params.push(filters.actorId);
        paramIndex++;
      }
      if (filters.resourceType) {
        whereClause += ` AND resource_urn LIKE $${paramIndex}`;
        params.push(`urn:${filters.resourceType}:%`);
        paramIndex++;
      }
      if (filters.fromDate) {
        whereClause += ` AND event_time >= $${paramIndex}`;
        params.push(filters.fromDate);
        paramIndex++;
      }
      if (filters.toDate) {
        whereClause += ` AND event_time <= $${paramIndex}`;
        params.push(filters.toDate);
        paramIndex++;
      }
      params.push(limit, offset);
      const query = `
        SELECT 
          id, event_id, event_time, event_type, actor_id, actor_type,
          resource_urn, event_seq, payload, ip, user_agent,
          created_at
        FROM phase10_audit_log 
        ${whereClause}
        ORDER BY event_time DESC 
        LIMIT $${paramIndex} OFFSET $${paramIndex + 1}
      `;
      const result = await client5.query(query, params);
      return result.rows;
    } catch (error) {
      console.error("[Phase10Audit] Failed to search events:", error);
      throw error;
    } finally {
      client5.release();
    }
  }
  /**
   * Get audit statistics for reporting
   */
  async getAuditStatistics(tenantId) {
    const client5 = await pool.connect();
    try {
      if (tenantId) {
        await client5.query("SELECT set_config($1, $2, true)", [
          "app.tenant_id",
          tenantId
        ]);
      }
      const totalResult = await client5.query(`
        SELECT COUNT(*) as total 
        FROM phase10_audit_log 
        WHERE $1::uuid IS NULL OR tenant_id = $1::uuid
      `, [tenantId || null]);
      const typeResult = await client5.query(`
        SELECT event_type, COUNT(*) as count 
        FROM phase10_audit_log 
        WHERE $1::uuid IS NULL OR tenant_id = $1::uuid
        GROUP BY event_type
        ORDER BY count DESC
      `, [tenantId || null]);
      const resourceResult = await client5.query(`
        SELECT COUNT(DISTINCT resource_urn) as count 
        FROM phase10_audit_log 
        WHERE $1::uuid IS NULL OR tenant_id = $1::uuid
      `, [tenantId || null]);
      const eventsByType = {};
      typeResult.rows.forEach((row) => {
        eventsByType[row.event_type] = parseInt(row.count);
      });
      return {
        totalEvents: parseInt(totalResult.rows[0].total),
        eventsByType,
        resourcesWithAudit: parseInt(resourceResult.rows[0].count),
        averageChainIntegrity: 100
        // Simplified - would calculate actual integrity in production
      };
    } catch (error) {
      console.error("[Phase10Audit] Failed to get statistics:", error);
      throw error;
    } finally {
      client5.release();
    }
  }
};
var phase10AuditService = new Phase10AuditService();

// server/services/phase10-document-service.ts
init_db();
import { randomUUID as randomUUID4 } from "crypto";
import { createHash as createHash4 } from "crypto";
var Phase10DocumentService = class {
  defaultTenantId = "00000000-0000-0000-0000-000000000001";
  /**
   * Store a document with first-party custody
   */
  async storeDocument(document, actorId) {
    const client5 = await pool.connect();
    try {
      await client5.query("BEGIN");
      const tenantId = document.tenantId || this.defaultTenantId;
      await client5.query("SELECT set_config($1, $2, true)", ["app.tenant_id", tenantId]);
      const docId = randomUUID4();
      const contentHash = document.contentBuffer ? createHash4("sha256").update(document.contentBuffer).digest() : null;
      const certificateHash = document.certificateBuffer ? createHash4("sha256").update(document.certificateBuffer).digest() : null;
      const contentLocator = `gs://loan-documents/${tenantId}/${docId}/content.pdf`;
      const certificateLocator = document.certificateBuffer ? `gs://loan-documents/${tenantId}/${docId}/certificate.pdf` : null;
      await client5.query(`
        INSERT INTO phase10_loan_document (
          doc_id, tenant_id, loan_urn, doc_type, doc_category, provider,
          provider_ref, external_status, version, content_hash, content_locator,
          content_size_bytes, certificate_hash, certificate_locator,
          mime_type, original_filename, document_title, executed_at,
          received_at, signer_count, signing_completed, metadata
        ) VALUES (
          $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21, $22
        )
      `, [
        docId,
        tenantId,
        document.loanUrn,
        document.docType,
        document.docCategory || null,
        document.provider || "internal",
        document.providerRef || null,
        document.externalStatus || null,
        document.version || 1,
        contentHash,
        contentLocator,
        document.contentSizeBytes || null,
        certificateHash,
        certificateLocator,
        document.mimeType || "application/pdf",
        document.originalFilename || null,
        document.documentTitle || null,
        document.executedAt || null,
        document.receivedAt || /* @__PURE__ */ new Date(),
        document.signerCount || 0,
        document.signingCompleted || false,
        JSON.stringify(document.metadata || {})
      ]);
      await phase10AuditService.logEvent({
        tenantId,
        eventType: "DOCUMENT.STORED",
        actorId,
        actorType: "user",
        resourceUrn: `urn:document:${docId}`,
        payload: {
          docId,
          loanUrn: document.loanUrn,
          docType: document.docType,
          provider: document.provider || "internal",
          providerRef: document.providerRef,
          contentSize: document.contentSizeBytes,
          hasCertificate: !!certificateHash
        }
      });
      await client5.query("COMMIT");
      return docId;
    } catch (error) {
      await client5.query("ROLLBACK");
      console.error("[Phase10Document] Failed to store document:", error);
      throw error;
    } finally {
      client5.release();
    }
  }
  /**
   * Get document metadata
   */
  async getDocument(docId, tenantId) {
    const client5 = await pool.connect();
    try {
      if (tenantId) {
        await client5.query("SELECT set_config($1, $2, true)", ["app.tenant_id", tenantId]);
      }
      const result = await client5.query(`
        SELECT 
          doc_id, tenant_id, loan_urn, doc_type, doc_category, provider,
          provider_ref, external_status, version, 
          encode(content_hash, 'hex') as content_hash,
          content_locator, content_size_bytes,
          encode(certificate_hash, 'hex') as certificate_hash,
          certificate_locator, evidence_bundle_locator,
          mime_type, original_filename, document_title,
          created_at, executed_at, received_at, archived_at,
          signer_count, signing_completed, metadata,
          retention_policy, destruction_date
        FROM phase10_loan_document 
        WHERE doc_id = $1::uuid
          AND ($2::uuid IS NULL OR tenant_id = $2::uuid)
      `, [docId, tenantId || null]);
      if (result.rows.length === 0) {
        return null;
      }
      const row = result.rows[0];
      return {
        docId: row.doc_id,
        tenantId: row.tenant_id,
        loanUrn: row.loan_urn,
        docType: row.doc_type,
        docCategory: row.doc_category,
        provider: row.provider,
        providerRef: row.provider_ref,
        externalStatus: row.external_status,
        version: row.version,
        contentHash: row.content_hash,
        contentLocator: row.content_locator,
        contentSizeBytes: row.content_size_bytes,
        certificateHash: row.certificate_hash,
        certificateLocator: row.certificate_locator,
        evidenceBundleLocator: row.evidence_bundle_locator,
        mimeType: row.mime_type,
        originalFilename: row.original_filename,
        documentTitle: row.document_title,
        createdAt: row.created_at,
        executedAt: row.executed_at,
        receivedAt: row.received_at,
        signerCount: row.signer_count,
        signingCompleted: row.signing_completed,
        metadata: row.metadata || {}
      };
    } catch (error) {
      console.error("[Phase10Document] Failed to get document:", error);
      throw error;
    } finally {
      client5.release();
    }
  }
  /**
   * List documents for a loan
   */
  async getDocumentsByLoan(loanUrn, tenantId, docType, limit = 100, offset = 0) {
    const client5 = await pool.connect();
    try {
      if (tenantId) {
        await client5.query("SELECT set_config($1, $2, true)", ["app.tenant_id", tenantId]);
      }
      let whereClause = "WHERE loan_urn = $1";
      const params = [loanUrn];
      let paramIndex = 2;
      if (tenantId) {
        whereClause += ` AND tenant_id = $${paramIndex}::uuid`;
        params.push(tenantId);
        paramIndex++;
      }
      if (docType) {
        whereClause += ` AND doc_type = $${paramIndex}`;
        params.push(docType);
        paramIndex++;
      }
      params.push(limit, offset);
      const result = await client5.query(`
        SELECT 
          doc_id, tenant_id, loan_urn, doc_type, doc_category, provider,
          provider_ref, external_status, version,
          encode(content_hash, 'hex') as content_hash,
          content_locator, content_size_bytes,
          encode(certificate_hash, 'hex') as certificate_hash,
          certificate_locator, evidence_bundle_locator,
          mime_type, original_filename, document_title,
          created_at, executed_at, received_at,
          signer_count, signing_completed, metadata
        FROM phase10_loan_document 
        ${whereClause}
        ORDER BY created_at DESC
        LIMIT $${paramIndex} OFFSET $${paramIndex + 1}
      `, params);
      return result.rows.map((row) => ({
        docId: row.doc_id,
        tenantId: row.tenant_id,
        loanUrn: row.loan_urn,
        docType: row.doc_type,
        docCategory: row.doc_category,
        provider: row.provider,
        providerRef: row.provider_ref,
        externalStatus: row.external_status,
        version: row.version,
        contentHash: row.content_hash,
        contentLocator: row.content_locator,
        contentSizeBytes: row.content_size_bytes,
        certificateHash: row.certificate_hash,
        certificateLocator: row.certificate_locator,
        evidenceBundleLocator: row.evidence_bundle_locator,
        mimeType: row.mime_type,
        originalFilename: row.original_filename,
        documentTitle: row.document_title,
        createdAt: row.created_at,
        executedAt: row.executed_at,
        receivedAt: row.received_at,
        signerCount: row.signer_count,
        signingCompleted: row.signing_completed,
        metadata: row.metadata || {}
      }));
    } catch (error) {
      console.error("[Phase10Document] Failed to get documents by loan:", error);
      throw error;
    } finally {
      client5.release();
    }
  }
  /**
   * Add signer to document
   */
  async addSigner(docId, signer, tenantId, actorId) {
    const client5 = await pool.connect();
    try {
      if (tenantId) {
        await client5.query("SELECT set_config($1, $2, true)", ["app.tenant_id", tenantId]);
      }
      const signerId = randomUUID4();
      await client5.query(`
        INSERT INTO phase10_document_signers (
          signer_id, doc_id, tenant_id, signer_name_encrypted,
          signer_email_encrypted, signer_phone_encrypted, role,
          signing_order, status, authentication_method
        ) VALUES (
          $1, $2, $3, $4, $5, $6, $7, $8, $9, $10
        )
      `, [
        signerId,
        docId,
        tenantId || this.defaultTenantId,
        signer.signerNameEncrypted || null,
        signer.signerEmailEncrypted || null,
        signer.signerPhoneEncrypted || null,
        signer.role || "signer",
        signer.signingOrder || 1,
        signer.status || "pending",
        signer.authenticationMethod || "email"
      ]);
      if (actorId) {
        await phase10AuditService.logEvent({
          tenantId: tenantId || this.defaultTenantId,
          eventType: "DOCUMENT.SIGNER_ADDED",
          actorId,
          actorType: "user",
          resourceUrn: `urn:document:${docId}`,
          payload: {
            signerId,
            role: signer.role,
            signingOrder: signer.signingOrder,
            status: signer.status
          }
        });
      }
      return signerId;
    } catch (error) {
      console.error("[Phase10Document] Failed to add signer:", error);
      throw error;
    } finally {
      client5.release();
    }
  }
  /**
   * Update signer status (e.g., when signed)
   */
  async updateSignerStatus(signerId, status, metadata = {}, tenantId, actorId) {
    const client5 = await pool.connect();
    try {
      if (tenantId) {
        await client5.query("SELECT set_config($1, $2, true)", ["app.tenant_id", tenantId]);
      }
      const updates = ["status = $2", "updated_at = now()"];
      const params = [signerId, status];
      let paramIndex = 3;
      if (status === "signed") {
        updates.push(`signed_at = $${paramIndex}`);
        params.push(/* @__PURE__ */ new Date());
        paramIndex++;
      } else if (status === "viewed") {
        updates.push(`viewed_at = $${paramIndex}`);
        params.push(/* @__PURE__ */ new Date());
        paramIndex++;
      }
      if (metadata.ipAddress) {
        updates.push(`ip_address = $${paramIndex}::inet`);
        params.push(metadata.ipAddress);
        paramIndex++;
      }
      if (metadata.userAgent) {
        updates.push(`user_agent = $${paramIndex}`);
        params.push(metadata.userAgent);
        paramIndex++;
      }
      await client5.query(`
        UPDATE phase10_document_signers 
        SET ${updates.join(", ")}
        WHERE signer_id = $1::uuid
          AND ($${paramIndex}::uuid IS NULL OR tenant_id = $${paramIndex}::uuid)
      `, [...params, tenantId || null]);
      if (actorId) {
        await phase10AuditService.logEvent({
          tenantId: tenantId || this.defaultTenantId,
          eventType: "DOCUMENT.SIGNER_STATUS_UPDATED",
          actorId,
          actorType: "user",
          resourceUrn: `urn:document_signer:${signerId}`,
          payload: {
            signerId,
            newStatus: status,
            metadata
          }
        });
      }
    } catch (error) {
      console.error("[Phase10Document] Failed to update signer status:", error);
      throw error;
    } finally {
      client5.release();
    }
  }
  /**
   * Verify document integrity
   */
  async verifyDocumentIntegrity(docId) {
    const client5 = await pool.connect();
    try {
      const result = await client5.query(`
        SELECT * FROM verify_document_integrity($1::uuid)
      `, [docId]);
      if (result.rows.length === 0) {
        return {
          valid: false,
          contentHashMatch: false,
          message: "Document not found"
        };
      }
      const row = result.rows[0];
      return {
        valid: row.is_valid,
        contentHashMatch: row.content_hash_match,
        certificateHashMatch: row.certificate_hash_match,
        message: row.message
      };
    } catch (error) {
      console.error("[Phase10Document] Failed to verify document integrity:", error);
      throw error;
    } finally {
      client5.release();
    }
  }
  /**
   * Log document access
   */
  async logDocumentAccess(docId, accessedBy, accessType, success, metadata = {}, tenantId) {
    const client5 = await pool.connect();
    try {
      if (tenantId) {
        await client5.query("SELECT set_config($1, $2, true)", ["app.tenant_id", tenantId]);
      }
      await client5.query(`
        INSERT INTO phase10_document_access_log (
          doc_id, tenant_id, accessed_by, access_type, access_method,
          ip_address, user_agent, session_id, success, failure_reason
        ) VALUES (
          $1, $2, $3, $4, $5, $6, $7, $8, $9, $10
        )
      `, [
        docId,
        tenantId || this.defaultTenantId,
        accessedBy,
        accessType,
        metadata.accessMethod || "api",
        metadata.ipAddress || null,
        metadata.userAgent || null,
        metadata.sessionId || null,
        success,
        metadata.failureReason || null
      ]);
      await phase10AuditService.logEvent({
        tenantId: tenantId || this.defaultTenantId,
        eventType: `DOCUMENT.${accessType.toUpperCase()}`,
        actorId: accessedBy,
        actorType: "user",
        resourceUrn: `urn:document:${docId}`,
        payload: {
          success,
          accessType,
          ...metadata
        },
        ipAddress: metadata.ipAddress,
        userAgent: metadata.userAgent,
        sessionId: metadata.sessionId
      });
    } catch (error) {
      console.error("[Phase10Document] Failed to log document access:", error);
      throw error;
    } finally {
      client5.release();
    }
  }
};
var phase10DocumentService = new Phase10DocumentService();

// server/services/phase10-consent-service.ts
init_db();
import { randomUUID as randomUUID5 } from "crypto";
var Phase10ConsentService = class {
  defaultTenantId = "00000000-0000-0000-0000-000000000001";
  /**
   * Grant consent with full audit trail
   */
  async grantConsent(request, tenantId, actorId) {
    const client5 = await pool.connect();
    try {
      const effectiveTenantId = tenantId || this.defaultTenantId;
      await client5.query("SELECT set_config($1, $2, true)", ["app.tenant_id", effectiveTenantId]);
      const consentId = await client5.query(`
        SELECT grant_consent(
          $1::uuid, $2, $3, $4, $5::text[], $6::text[], 
          $7, $8::inet, $9
        ) as consent_id
      `, [
        effectiveTenantId,
        request.subjectUrn,
        request.consentType,
        request.consentVersion,
        request.purpose,
        request.channel,
        request.evidenceLocator,
        request.ipAddress,
        request.userAgent
      ]);
      const resultConsentId = consentId.rows[0].consent_id;
      if (request.source && request.source !== "internal") {
        await client5.query(`
          UPDATE phase10_consent_record 
          SET source = $1, external_reference = $2, external_status = $3,
              device_fingerprint = $4, geolocation = $5,
              legal_basis = $6, regulatory_framework = $7
          WHERE consent_id = $8::uuid
        `, [
          request.source,
          request.externalReference,
          "granted",
          request.deviceFingerprint,
          request.geolocation ? JSON.stringify(request.geolocation) : null,
          request.legalBasis,
          request.regulatoryFramework,
          resultConsentId
        ]);
      }
      await phase10AuditService.logEvent({
        tenantId: effectiveTenantId,
        eventType: "CONSENT.GRANTED",
        actorId: actorId || request.subjectUrn,
        actorType: actorId ? "user" : "subject",
        resourceUrn: `urn:consent:${resultConsentId}`,
        payload: {
          subjectUrn: request.subjectUrn,
          consentType: request.consentType,
          consentVersion: request.consentVersion,
          purpose: request.purpose,
          channel: request.channel,
          source: request.source || "internal",
          externalReference: request.externalReference,
          legalBasis: request.legalBasis,
          regulatoryFramework: request.regulatoryFramework,
          ...request.metadata
        },
        ipAddress: request.ipAddress,
        userAgent: request.userAgent
      });
      return resultConsentId;
    } catch (error) {
      console.error("[Phase10Consent] Failed to grant consent:", error);
      throw error;
    } finally {
      client5.release();
    }
  }
  /**
   * Revoke consent with audit trail
   */
  async revokeConsent(consentId, reason, revokedBy, ipAddress, userAgent, tenantId) {
    const client5 = await pool.connect();
    try {
      if (tenantId) {
        await client5.query("SELECT set_config($1, $2, true)", ["app.tenant_id", tenantId]);
      }
      await client5.query(`
        SELECT revoke_consent($1::uuid, $2::uuid, $3, $4::inet, $5)
      `, [
        consentId,
        revokedBy,
        reason,
        ipAddress,
        userAgent
      ]);
      const consentDetails = await client5.query(`
        SELECT subject_urn, consent_type, consent_version 
        FROM phase10_consent_record 
        WHERE consent_id = $1::uuid
      `, [consentId]);
      if (consentDetails.rows.length > 0) {
        const consent = consentDetails.rows[0];
        await phase10AuditService.logEvent({
          tenantId: tenantId || this.defaultTenantId,
          eventType: "CONSENT.REVOKED",
          actorId: revokedBy || consent.subject_urn,
          actorType: revokedBy ? "user" : "subject",
          resourceUrn: `urn:consent:${consentId}`,
          payload: {
            subjectUrn: consent.subject_urn,
            consentType: consent.consent_type,
            consentVersion: consent.consent_version,
            reason,
            revokedBy
          },
          ipAddress,
          userAgent
        });
      }
      return true;
    } catch (error) {
      console.error("[Phase10Consent] Failed to revoke consent:", error);
      throw error;
    } finally {
      client5.release();
    }
  }
  /**
   * Get consent status for a subject
   */
  async getConsentStatus(subjectUrn, consentType, tenantId) {
    const client5 = await pool.connect();
    try {
      if (tenantId) {
        await client5.query("SELECT set_config($1, $2, true)", ["app.tenant_id", tenantId]);
      }
      let whereClause = "WHERE subject_urn = $1";
      const params = [subjectUrn];
      let paramIndex = 2;
      if (tenantId) {
        whereClause += ` AND tenant_id = $${paramIndex}::uuid`;
        params.push(tenantId);
        paramIndex++;
      }
      if (consentType) {
        whereClause += ` AND consent_type = $${paramIndex}`;
        params.push(consentType);
        paramIndex++;
      }
      const result = await client5.query(`
        SELECT 
          consent_id, tenant_id, subject_urn, consent_type, consent_version,
          consent_scope, granted, purpose, channel, evidence_locator,
          obtained_at, revoked_at, source, external_reference, external_status,
          ip_address, user_agent, device_fingerprint, geolocation,
          legal_basis, regulatory_framework, retention_period_months,
          created_at, updated_at
        FROM phase10_consent_record 
        ${whereClause}
        ORDER BY created_at DESC
      `, params);
      return result.rows.map((row) => ({
        consentId: row.consent_id,
        tenantId: row.tenant_id,
        subjectUrn: row.subject_urn,
        consentType: row.consent_type,
        consentVersion: row.consent_version,
        consentScope: row.consent_scope,
        granted: row.granted,
        purpose: row.purpose,
        channel: row.channel,
        evidenceLocator: row.evidence_locator,
        obtainedAt: row.obtained_at,
        revokedAt: row.revoked_at,
        source: row.source,
        externalReference: row.external_reference,
        externalStatus: row.external_status,
        ipAddress: row.ip_address,
        userAgent: row.user_agent,
        deviceFingerprint: row.device_fingerprint,
        geolocation: row.geolocation,
        legalBasis: row.legal_basis,
        regulatoryFramework: row.regulatory_framework,
        retentionPeriodMonths: row.retention_period_months
      }));
    } catch (error) {
      console.error("[Phase10Consent] Failed to get consent status:", error);
      throw error;
    } finally {
      client5.release();
    }
  }
  /**
   * Set communication preference
   */
  async setCommunicationPreference(preference, tenantId, actorId) {
    const client5 = await pool.connect();
    try {
      const effectiveTenantId = tenantId || this.defaultTenantId;
      await client5.query("SELECT set_config($1, $2, true)", ["app.tenant_id", effectiveTenantId]);
      const prefId = randomUUID5();
      await client5.query(`
        INSERT INTO phase10_communication_preference (
          pref_id, tenant_id, subject_urn, channel, purpose, sub_purpose,
          frequency, custom_schedule, contact_value_hash, is_verified,
          verified_at, is_active, consent_id, source_of_preference
        ) VALUES (
          $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14
        )
        ON CONFLICT (tenant_id, subject_urn, channel, purpose, sub_purpose)
        DO UPDATE SET
          frequency = EXCLUDED.frequency,
          custom_schedule = EXCLUDED.custom_schedule,
          contact_value_hash = EXCLUDED.contact_value_hash,
          is_verified = EXCLUDED.is_verified,
          verified_at = EXCLUDED.verified_at,
          is_active = EXCLUDED.is_active,
          consent_id = EXCLUDED.consent_id,
          source_of_preference = EXCLUDED.source_of_preference,
          updated_at = now()
        RETURNING pref_id
      `, [
        prefId,
        effectiveTenantId,
        preference.subjectUrn,
        preference.channel,
        preference.purpose,
        preference.subPurpose || null,
        preference.frequency,
        preference.customSchedule ? JSON.stringify(preference.customSchedule) : null,
        preference.contactValueHash || null,
        preference.isVerified || false,
        preference.verifiedAt || null,
        preference.isActive !== false,
        preference.consentId || null,
        preference.sourceOfPreference || "user"
      ]);
      await phase10AuditService.logEvent({
        tenantId: effectiveTenantId,
        eventType: "COMMUNICATION.PREFERENCE_SET",
        actorId: actorId || preference.subjectUrn,
        actorType: actorId ? "user" : "subject",
        resourceUrn: `urn:comm_preference:${prefId}`,
        payload: {
          subjectUrn: preference.subjectUrn,
          channel: preference.channel,
          purpose: preference.purpose,
          subPurpose: preference.subPurpose,
          frequency: preference.frequency,
          customSchedule: preference.customSchedule,
          isActive: preference.isActive,
          sourceOfPreference: preference.sourceOfPreference
        }
      });
      return prefId;
    } catch (error) {
      console.error("[Phase10Consent] Failed to set communication preference:", error);
      throw error;
    } finally {
      client5.release();
    }
  }
  /**
   * Get communication preferences for a subject
   */
  async getCommunicationPreferences(subjectUrn, channel, purpose, tenantId) {
    const client5 = await pool.connect();
    try {
      if (tenantId) {
        await client5.query("SELECT set_config($1, $2, true)", ["app.tenant_id", tenantId]);
      }
      let whereClause = "WHERE subject_urn = $1";
      const params = [subjectUrn];
      let paramIndex = 2;
      if (tenantId) {
        whereClause += ` AND tenant_id = $${paramIndex}::uuid`;
        params.push(tenantId);
        paramIndex++;
      }
      if (channel) {
        whereClause += ` AND channel = $${paramIndex}`;
        params.push(channel);
        paramIndex++;
      }
      if (purpose) {
        whereClause += ` AND purpose = $${paramIndex}`;
        params.push(purpose);
        paramIndex++;
      }
      const result = await client5.query(`
        SELECT 
          pref_id, tenant_id, subject_urn, channel, purpose, sub_purpose,
          frequency, custom_schedule, contact_value_hash, is_verified,
          verified_at, is_active, paused_until, consent_id, 
          consent_obtained_at, source_of_preference, last_honored_at,
          violation_count, created_at, updated_at
        FROM phase10_communication_preference 
        ${whereClause}
        ORDER BY channel, purpose
      `, params);
      return result.rows.map((row) => ({
        prefId: row.pref_id,
        tenantId: row.tenant_id,
        subjectUrn: row.subject_urn,
        channel: row.channel,
        purpose: row.purpose,
        subPurpose: row.sub_purpose,
        frequency: row.frequency,
        customSchedule: row.custom_schedule,
        contactValueHash: row.contact_value_hash,
        isVerified: row.is_verified,
        verifiedAt: row.verified_at,
        isActive: row.is_active,
        pausedUntil: row.paused_until,
        consentId: row.consent_id,
        sourceOfPreference: row.source_of_preference,
        lastHonoredAt: row.last_honored_at,
        violationCount: row.violation_count
      }));
    } catch (error) {
      console.error("[Phase10Consent] Failed to get communication preferences:", error);
      throw error;
    } finally {
      client5.release();
    }
  }
  /**
   * Check if communication is allowed for a subject
   */
  async isCommunicationAllowed(subjectUrn, channel, purpose, subPurpose, tenantId) {
    try {
      const preferences = await this.getCommunicationPreferences(
        subjectUrn,
        channel,
        purpose,
        tenantId
      );
      const relevantPrefs = preferences.filter(
        (pref2) => !subPurpose || !pref2.subPurpose || pref2.subPurpose === subPurpose
      );
      if (relevantPrefs.length === 0) {
        return { allowed: false, reason: "No preference found" };
      }
      const pref = relevantPrefs.find((p) => p.subPurpose === subPurpose) || relevantPrefs[0];
      if (!pref.isActive) {
        return {
          allowed: false,
          reason: "Preference inactive",
          preferenceId: pref.prefId
        };
      }
      if (pref.pausedUntil && pref.pausedUntil > /* @__PURE__ */ new Date()) {
        return {
          allowed: false,
          reason: "Communication paused",
          preferenceId: pref.prefId
        };
      }
      if (pref.frequency === "optout") {
        return {
          allowed: false,
          reason: "User opted out",
          preferenceId: pref.prefId
        };
      }
      if (pref.consentId) {
        const consents = await this.getConsentStatus(subjectUrn, void 0, tenantId);
        const relevantConsent = consents.find((c) => c.consentId === pref.consentId);
        if (!relevantConsent || !relevantConsent.granted) {
          return {
            allowed: false,
            reason: "Consent not granted",
            preferenceId: pref.prefId,
            consentId: pref.consentId
          };
        }
      }
      return {
        allowed: true,
        preferenceId: pref.prefId,
        consentId: pref.consentId
      };
    } catch (error) {
      console.error("[Phase10Consent] Failed to check communication allowance:", error);
      return { allowed: false, reason: "System error" };
    }
  }
  /**
   * Log communication event
   */
  async logCommunication(event, tenantId) {
    const client5 = await pool.connect();
    try {
      if (tenantId) {
        await client5.query("SELECT set_config($1, $2, true)", ["app.tenant_id", tenantId]);
      }
      const eventId = randomUUID5();
      await client5.query(`
        INSERT INTO phase10_communication_log (
          event_id, tenant_id, subject_urn, channel, purpose, sub_purpose,
          template_id, subject_line, message_preview, recipient_address_hash,
          delivered_at, opened_at, clicked_at, bounced_at, bounce_reason,
          preference_id, consent_id, compliance_status, suppression_reason,
          provider, provider_message_id
        ) VALUES (
          $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21
        )
      `, [
        eventId,
        tenantId || this.defaultTenantId,
        event.subjectUrn,
        event.channel,
        event.purpose,
        event.subPurpose,
        event.templateId,
        event.subjectLine,
        event.messagePreview,
        event.recipientAddressHash,
        event.deliveredAt,
        event.openedAt,
        event.clickedAt,
        event.bouncedAt,
        event.bounceReason,
        event.preferenceId,
        event.consentId,
        event.complianceStatus || "compliant",
        event.suppressionReason,
        event.provider,
        event.providerMessageId
      ]);
      return eventId;
    } catch (error) {
      console.error("[Phase10Consent] Failed to log communication:", error);
      throw error;
    } finally {
      client5.release();
    }
  }
};
var phase10ConsentService = new Phase10ConsentService();

// server/integrations/docusign-connect.ts
import { createHmac } from "crypto";
var DocuSignConnectService = class {
  webhookSecret;
  constructor() {
    this.webhookSecret = process.env.DOCUSIGN_WEBHOOK_SECRET || "";
  }
  /**
   * Verify DocuSign webhook signature
   */
  verifyWebhookSignature(payload, signature, timestamp2) {
    if (!this.webhookSecret) {
      console.warn("[DocuSignConnect] Webhook secret not configured - skipping signature verification");
      return true;
    }
    try {
      const expectedSignature = createHmac("sha256", this.webhookSecret).update(timestamp2 + payload).digest("hex");
      return signature === expectedSignature;
    } catch (error) {
      console.error("[DocuSignConnect] Signature verification failed:", error);
      return false;
    }
  }
  /**
   * Process DocuSign Connect webhook
   */
  async processWebhook(req, res) {
    try {
      const signature = req.headers["x-docusign-signature-1"];
      const timestamp2 = req.headers["x-docusign-timestamp"];
      const payload = JSON.stringify(req.body);
      if (!this.verifyWebhookSignature(payload, signature, timestamp2)) {
        console.error("[DocuSignConnect] Invalid webhook signature");
        res.status(401).json({ error: "Invalid signature" });
        return;
      }
      const event = this.parseWebhookEvent(req.body);
      await this.processEnvelopeEvent(event, req.security?.tenantId);
      res.status(200).json({ success: true });
    } catch (error) {
      console.error("[DocuSignConnect] Webhook processing failed:", error);
      res.status(500).json({ error: "Webhook processing failed" });
    }
  }
  /**
   * Parse DocuSign webhook event
   */
  parseWebhookEvent(webhookData) {
    const envelope = webhookData.data?.envelopeId ? webhookData.data : webhookData;
    return {
      envelopeId: envelope.envelopeId,
      status: envelope.status,
      emailSubject: envelope.emailSubject,
      createdDateTime: envelope.createdDateTime,
      completedDateTime: envelope.completedDateTime,
      voidedDateTime: envelope.voidedDateTime,
      declinedDateTime: envelope.declinedDateTime,
      recipients: this.parseRecipients(envelope.recipients || []),
      documents: this.parseDocuments(envelope.documents || []),
      customFields: envelope.customFields || []
    };
  }
  /**
   * Parse recipient data
   */
  parseRecipients(recipients) {
    const allRecipients = [];
    ["signers", "agents", "witnesses", "notaries", "inPersonSigners"].forEach((type) => {
      if (recipients[type]) {
        recipients[type].forEach((recipient) => {
          allRecipients.push({
            recipientId: recipient.recipientId,
            recipientType: type,
            email: recipient.email,
            name: recipient.name,
            status: recipient.status,
            signedDateTime: recipient.signedDateTime,
            deliveredDateTime: recipient.deliveredDateTime,
            declinedDateTime: recipient.declinedDateTime,
            declineReason: recipient.declineReason,
            ipAddress: recipient.clientUserId || recipient.ipAddress,
            userAgent: recipient.userAgent,
            tabs: recipient.tabs ? this.parseTabs(recipient.tabs) : []
          });
        });
      }
    });
    return allRecipients;
  }
  /**
   * Parse document data
   */
  parseDocuments(documents2) {
    return documents2.map((doc) => ({
      documentId: doc.documentId,
      name: doc.name,
      documentBase64: doc.documentBase64,
      documentFields: doc.documentFields ? doc.documentFields.map((field) => ({
        name: field.name,
        value: field.value,
        fieldType: field.fieldType || "text"
      })) : []
    }));
  }
  /**
   * Parse tab data
   */
  parseTabs(tabs) {
    const allTabs = [];
    Object.keys(tabs).forEach((tabType) => {
      if (Array.isArray(tabs[tabType])) {
        tabs[tabType].forEach((tab) => {
          allTabs.push({
            tabType,
            tabLabel: tab.tabLabel,
            value: tab.value || "",
            originalValue: tab.originalValue,
            tabId: tab.tabId
          });
        });
      }
    });
    return allTabs;
  }
  /**
   * Process envelope event and store evidence
   */
  async processEnvelopeEvent(event, tenantId) {
    try {
      const loanUrn = this.extractLoanUrn(event);
      if (!loanUrn) {
        console.error("[DocuSignConnect] Cannot determine loan URN for envelope:", event.envelopeId);
        return;
      }
      const docType = this.extractDocumentType(event);
      switch (event.status) {
        case "sent":
          await this.handleEnvelopeSent(event, loanUrn, docType, tenantId);
          break;
        case "delivered":
          await this.handleEnvelopeDelivered(event, loanUrn, tenantId);
          break;
        case "completed":
          await this.handleEnvelopeCompleted(event, loanUrn, docType, tenantId);
          break;
        case "declined":
        case "voided":
          await this.handleEnvelopeDeclinedOrVoided(event, loanUrn, tenantId);
          break;
        default:
          console.log(`[DocuSignConnect] Unhandled envelope status: ${event.status}`);
      }
      await phase10AuditService.logEvent({
        tenantId: tenantId || "00000000-0000-0000-0000-000000000001",
        eventType: `DOCUSIGN.ENVELOPE_${event.status.toUpperCase()}`,
        actorType: "system",
        resourceUrn: loanUrn,
        payload: {
          envelopeId: event.envelopeId,
          status: event.status,
          emailSubject: event.emailSubject,
          recipientCount: event.recipients.length,
          documentCount: event.documents.length,
          completedDateTime: event.completedDateTime,
          customFields: event.customFields
        }
      });
    } catch (error) {
      console.error("[DocuSignConnect] Failed to process envelope event:", error);
      throw error;
    }
  }
  /**
   * Handle envelope sent event
   */
  async handleEnvelopeSent(event, loanUrn, docType, tenantId) {
    const docId = await phase10DocumentService.storeDocument({
      tenantId,
      loanUrn,
      docType,
      provider: "docusign",
      providerRef: event.envelopeId,
      externalStatus: "sent",
      documentTitle: event.emailSubject,
      signerCount: event.recipients.length,
      signingCompleted: false,
      metadata: {
        envelopeId: event.envelopeId,
        emailSubject: event.emailSubject,
        createdDateTime: event.createdDateTime,
        recipients: event.recipients.map((r) => ({
          recipientId: r.recipientId,
          email: r.email,
          name: r.name,
          recipientType: r.recipientType
        }))
      }
    }, "system");
    for (const recipient of event.recipients) {
      await phase10DocumentService.addSigner(docId, {
        role: recipient.recipientType,
        status: "sent",
        signingOrder: parseInt(recipient.recipientId),
        authenticationMethod: "email"
      }, tenantId, "system");
    }
    console.log(`[DocuSignConnect] Stored pending document for envelope ${event.envelopeId}`);
  }
  /**
   * Handle envelope delivered event
   */
  async handleEnvelopeDelivered(event, loanUrn, tenantId) {
    const documents2 = await phase10DocumentService.getDocumentsByLoan(loanUrn, tenantId);
    const existingDoc = documents2.find((d) => d.providerRef === event.envelopeId);
    if (existingDoc) {
      for (const recipient of event.recipients) {
        if (recipient.deliveredDateTime) {
          await phase10DocumentService.updateSignerStatus(
            recipient.recipientId,
            "delivered",
            {
              deliveredAt: new Date(recipient.deliveredDateTime)
            },
            tenantId,
            "system"
          );
        }
      }
    }
  }
  /**
   * Handle envelope completed event - store final documents and certificates
   */
  async handleEnvelopeCompleted(event, loanUrn, docType, tenantId) {
    const documents2 = await phase10DocumentService.getDocumentsByLoan(loanUrn, tenantId);
    const existingDoc = documents2.find((d) => d.providerRef === event.envelopeId);
    if (existingDoc) {
      for (const recipient of event.recipients) {
        if (recipient.signedDateTime) {
          await phase10DocumentService.updateSignerStatus(
            recipient.recipientId,
            "signed",
            {
              signedAt: new Date(recipient.signedDateTime),
              ipAddress: recipient.ipAddress,
              userAgent: recipient.userAgent
            },
            tenantId,
            "system"
          );
        }
      }
      if (this.isConsentDocument(docType, event)) {
        await this.processConsentFromCompletedEnvelope(event, loanUrn, tenantId);
      }
      console.log(`[DocuSignConnect] Processed completed envelope ${event.envelopeId} for loan ${loanUrn}`);
    } else {
      await this.handleEnvelopeSent(event, loanUrn, docType, tenantId);
    }
  }
  /**
   * Handle envelope declined or voided
   */
  async handleEnvelopeDeclinedOrVoided(event, loanUrn, tenantId) {
    const documents2 = await phase10DocumentService.getDocumentsByLoan(loanUrn, tenantId);
    const existingDoc = documents2.find((d) => d.providerRef === event.envelopeId);
    if (existingDoc) {
      for (const recipient of event.recipients) {
        if (recipient.declinedDateTime) {
          await phase10DocumentService.updateSignerStatus(
            recipient.recipientId,
            "declined",
            {
              declinedAt: new Date(recipient.declinedDateTime),
              declineReason: recipient.declineReason
            },
            tenantId,
            "system"
          );
        }
      }
    }
  }
  /**
   * Extract loan URN from envelope
   */
  extractLoanUrn(event) {
    const loanField = event.customFields?.find(
      (field) => field.name.toLowerCase().includes("loan") || field.name.toLowerCase().includes("id")
    );
    if (loanField?.value) {
      return `urn:loan:${loanField.value}`;
    }
    const subjectMatch = event.emailSubject.match(/loan\s*[#:]?\s*(\w+)/i);
    if (subjectMatch?.[1]) {
      return `urn:loan:${subjectMatch[1]}`;
    }
    return null;
  }
  /**
   * Extract document type from envelope
   */
  extractDocumentType(event) {
    const subject = event.emailSubject.toLowerCase();
    if (subject.includes("disclosure")) return "disclosure";
    if (subject.includes("agreement")) return "executed_agreement";
    if (subject.includes("consent")) return "consent";
    if (subject.includes("modification")) return "modification";
    if (subject.includes("notice")) return "notice";
    return "executed_agreement";
  }
  /**
   * Check if document is consent-related
   */
  isConsentDocument(docType, event) {
    return docType === "consent" || event.emailSubject.toLowerCase().includes("consent") || event.emailSubject.toLowerCase().includes("privacy") || event.emailSubject.toLowerCase().includes("communication");
  }
  /**
   * Process consent from completed envelope
   */
  async processConsentFromCompletedEnvelope(event, loanUrn, tenantId) {
    try {
      const primarySigner = event.recipients.find(
        (r) => r.recipientType === "signers" && r.status === "completed"
      );
      if (!primarySigner) {
        console.warn("[DocuSignConnect] No completed signer found for consent processing");
        return;
      }
      const subjectUrn = `urn:borrower:${primarySigner.email}`;
      const consentType = this.extractConsentType(event);
      const purposes = this.extractConsentPurposes(event);
      const channels = this.extractConsentChannels(event);
      await phase10ConsentService.grantConsent({
        subjectUrn,
        consentType,
        consentVersion: "1.0",
        purpose: purposes,
        channel: channels,
        source: "docusign",
        externalReference: event.envelopeId,
        evidenceLocator: `docusign:envelope:${event.envelopeId}`,
        ipAddress: primarySigner.ipAddress,
        userAgent: primarySigner.userAgent
      }, tenantId, "system");
      console.log(`[DocuSignConnect] Processed consent from envelope ${event.envelopeId}`);
    } catch (error) {
      console.error("[DocuSignConnect] Failed to process consent from envelope:", error);
    }
  }
  /**
   * Extract consent type from envelope
   */
  extractConsentType(event) {
    const subject = event.emailSubject.toLowerCase();
    if (subject.includes("privacy")) return "privacy_notice";
    if (subject.includes("marketing")) return "marketing";
    if (subject.includes("communication")) return "communication";
    if (subject.includes("e-sign") || subject.includes("esign")) return "e-sign";
    return "general_consent";
  }
  /**
   * Extract consent purposes from envelope
   */
  extractConsentPurposes(event) {
    const purposes = ["servicing"];
    const subject = event.emailSubject.toLowerCase();
    if (subject.includes("marketing")) purposes.push("marketing");
    if (subject.includes("analytics")) purposes.push("analytics");
    return purposes;
  }
  /**
   * Extract consent channels from envelope
   */
  extractConsentChannels(event) {
    const channels = ["email"];
    return channels;
  }
};
var docuSignConnectService = new DocuSignConnectService();

// server/middleware/phase10-security.ts
init_db();
import { randomUUID as randomUUID6 } from "crypto";
var Phase10SecurityService = class {
  defaultTenantId = "00000000-0000-0000-0000-000000000001";
  /**
   * Extract security context from request
   */
  async extractSecurityContext(req) {
    const rawUserId = req.user?.id || req.headers["x-user-id"];
    const userId = rawUserId ? this.normalizeUserId(rawUserId.toString()) : void 0;
    const tenantId = req.headers["x-tenant-id"] || this.defaultTenantId;
    const sessionId = req.sessionID || req.headers["x-session-id"] || randomUUID6();
    const correlationId = req.headers["x-correlation-id"] || randomUUID6();
    const context = {
      tenantId,
      userId,
      userRoles: [],
      userPermissions: [],
      ipAddress: this.extractRealIP(req),
      userAgent: req.get("user-agent") || "unknown",
      sessionId,
      correlationId
    };
    if (userId && tenantId) {
      try {
        const client5 = await pool.connect();
        await client5.query("SELECT set_config($1, $2, true)", ["app.tenant_id", tenantId]);
        const rolesResult = await client5.query(`
          SELECT sr.role_name 
          FROM security_user_roles sur
          JOIN security_roles sr ON sur.role_id = sr.role_id
          WHERE sur.user_id = $1::uuid 
            AND sur.tenant_id = $2::uuid 
            AND sur.is_active = true
            AND (sur.expires_at IS NULL OR sur.expires_at > now())
        `, [userId, tenantId]);
        context.userRoles = rolesResult.rows.map((row) => row.role_name);
        const permsResult = await client5.query(`
          SELECT DISTINCT sp.permission_name, sp.resource_type, sp.action
          FROM security_user_roles sur
          JOIN security_role_permissions srp ON sur.role_id = srp.role_id
          JOIN security_permissions sp ON srp.permission_id = sp.permission_id
          WHERE sur.user_id = $1::uuid 
            AND sur.tenant_id = $2::uuid 
            AND sur.is_active = true
            AND sp.is_active = true
            AND (sur.expires_at IS NULL OR sur.expires_at > now())
        `, [userId, tenantId]);
        context.userPermissions = permsResult.rows.map(
          (row) => `${row.resource_type}:${row.action}`
        );
        client5.release();
      } catch (error) {
        console.error("[Phase10Security] Failed to load user context:", error);
      }
    }
    return context;
  }
  /**
   * Extract ABAC attributes from request
   */
  extractABACAttributes(req) {
    const userAgent = req.get("user-agent") || "";
    const now = /* @__PURE__ */ new Date();
    return {
      location: {
        // In production, would use IP geolocation service
        country: req.headers["cf-ipcountry"] || "US",
        region: req.headers["cf-region"] || "unknown",
        city: req.headers["cf-city"] || "unknown"
      },
      device: {
        type: this.detectDeviceType(userAgent),
        trusted: false,
        // Would implement device trust scoring
        fingerprint: req.headers["x-device-fingerprint"] || "unknown"
      },
      time: {
        timestamp: now,
        businessHours: this.isBusinessHours(now),
        timezone: req.headers["x-timezone"] || "UTC"
      },
      riskLevel: "low"
      // Would implement risk assessment
    };
  }
  /**
   * Check if user has permission for resource and action
   */
  async hasPermission(context, resourceType, action, resourceId) {
    const permissionKey = `${resourceType}:${action}`;
    if (context.userPermissions.includes(permissionKey)) {
      return true;
    }
    try {
      const client5 = await pool.connect();
      await client5.query("SELECT set_config($1, $2, true)", ["app.tenant_id", context.tenantId]);
      const result = await client5.query(`
        SELECT COUNT(*) as count
        FROM security_abac_policies sap
        JOIN security_permissions sp ON sap.permission_id = sp.permission_id
        WHERE sp.resource_type = $1 
          AND sp.action = $2
          AND sap.is_active = true
          AND sp.is_active = true
          AND sap.tenant_id = $3::uuid
      `, [resourceType, action, context.tenantId]);
      client5.release();
      return parseInt(result.rows[0].count) > 0;
    } catch (error) {
      console.error("[Phase10Security] Permission check failed:", error);
      return false;
    }
  }
  /**
   * Log security event
   */
  async logSecurityEvent(context, eventType, resourceUrn, success, details = {}) {
    try {
      await phase10AuditService.logEvent({
        tenantId: context.tenantId,
        correlationId: context.correlationId,
        eventType: `SECURITY.${eventType}`,
        actorId: context.userId,
        actorType: "user",
        resourceUrn,
        payload: {
          success,
          userRoles: context.userRoles,
          ipAddress: context.ipAddress,
          userAgent: context.userAgent,
          sessionId: context.sessionId,
          ...details
        },
        ipAddress: context.ipAddress,
        userAgent: context.userAgent,
        sessionId: context.sessionId
      });
    } catch (error) {
      console.error("[Phase10Security] Failed to log security event:", error);
    }
  }
  extractRealIP(req) {
    const xForwardedFor = req.headers["x-forwarded-for"];
    const xRealIP = req.headers["x-real-ip"];
    const cfConnectingIP = req.headers["cf-connecting-ip"];
    if (xForwardedFor) {
      const forwarded = Array.isArray(xForwardedFor) ? xForwardedFor[0] : xForwardedFor;
      return forwarded.split(",")[0].trim();
    }
    if (cfConnectingIP && typeof cfConnectingIP === "string") {
      return cfConnectingIP;
    }
    if (xRealIP && typeof xRealIP === "string") {
      return xRealIP;
    }
    return req.ip || req.socket?.remoteAddress || "unknown";
  }
  detectDeviceType(userAgent) {
    if (/mobile/i.test(userAgent)) return "mobile";
    if (/tablet/i.test(userAgent)) return "tablet";
    return "desktop";
  }
  isBusinessHours(date2) {
    const hour = date2.getHours();
    const day = date2.getDay();
    return day >= 1 && day <= 5 && hour >= 9 && hour <= 17;
  }
  /**
   * Normalize user ID to UUID format
   * Handles case where auth system returns integer IDs
   */
  normalizeUserId(userId) {
    if (/^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i.test(userId)) {
      return userId;
    }
    if (/^\d+$/.test(userId)) {
      const paddedId = userId.padStart(8, "0");
      return `00000000-0000-0000-0000-${paddedId.padStart(12, "0")}`;
    }
    const crypto22 = __require("crypto");
    const hash = crypto22.createHash("md5").update(userId).digest("hex");
    return `${hash.slice(0, 8)}-${hash.slice(8, 12)}-${hash.slice(12, 16)}-${hash.slice(16, 20)}-${hash.slice(20, 32)}`;
  }
};
var phase10Security = new Phase10SecurityService();
var establishSecurityContext = async (req, res, next) => {
  try {
    req.security = await phase10Security.extractSecurityContext(req);
    req.abacAttributes = phase10Security.extractABACAttributes(req);
    res.setHeader("X-Correlation-ID", req.security.correlationId);
    await phase10Security.logSecurityEvent(
      req.security,
      "ACCESS_ATTEMPT",
      `urn:endpoint:${req.method}:${req.path}`,
      true,
      {
        method: req.method,
        path: req.path,
        query: req.query
      }
    );
    next();
  } catch (error) {
    console.error("[Phase10Security] Failed to establish security context:", error);
    res.status(500).json({ error: "Security context establishment failed" });
  }
};
var requireAuth3 = (req, res, next) => {
  if (!req.security?.userId) {
    res.status(401).json({ error: "Authentication required" });
    return;
  }
  next();
};
var requirePermission2 = (resourceType, action) => {
  return async (req, res, next) => {
    if (!req.security) {
      res.status(500).json({ error: "Security context not established" });
      return;
    }
    const hasPermission2 = await phase10Security.hasPermission(
      req.security,
      resourceType,
      action,
      req.params.id
    );
    if (!hasPermission2) {
      await phase10Security.logSecurityEvent(
        req.security,
        "PERMISSION_DENIED",
        `urn:${resourceType}:${req.params.id || "collection"}`,
        false,
        {
          requiredPermission: `${resourceType}:${action}`,
          userPermissions: req.security.userPermissions
        }
      );
      res.status(403).json({ error: "Insufficient permissions" });
      return;
    }
    await phase10Security.logSecurityEvent(
      req.security,
      "PERMISSION_GRANTED",
      `urn:${resourceType}:${req.params.id || "collection"}`,
      true,
      {
        grantedPermission: `${resourceType}:${action}`
      }
    );
    next();
  };
};
var enforceTenantIsolation = (req, res, next) => {
  if (!req.security?.tenantId) {
    res.status(400).json({ error: "Tenant context required" });
    return;
  }
  next();
};
var rateLimiter = (windowMs = 15 * 60 * 1e3, maxRequests = 100) => {
  const requestCounts = /* @__PURE__ */ new Map();
  return (req, res, next) => {
    const key = `${req.security?.tenantId || "anonymous"}:${req.security?.userId || req.ip}`;
    const now = Date.now();
    let requestData = requestCounts.get(key);
    if (!requestData || now > requestData.resetTime) {
      requestData = { count: 1, resetTime: now + windowMs };
    } else {
      requestData.count++;
    }
    requestCounts.set(key, requestData);
    if (requestData.count > maxRequests) {
      res.status(429).json({
        error: "Rate limit exceeded",
        retryAfter: Math.ceil((requestData.resetTime - now) / 1e3)
      });
      return;
    }
    res.setHeader("X-RateLimit-Limit", maxRequests.toString());
    res.setHeader("X-RateLimit-Remaining", Math.max(0, maxRequests - requestData.count).toString());
    res.setHeader("X-RateLimit-Reset", Math.ceil(requestData.resetTime / 1e3).toString());
    next();
  };
};

// server/routes/phase10-routes.ts
var router10 = express.Router();
router10.use(establishSecurityContext);
router10.use(enforceTenantIsolation);
router10.use("/api/phase10", rateLimiter(15 * 60 * 1e3, 200));
router10.get("/audit/events", requireAuth3, requirePermission2("audit", "read"), async (req, res) => {
  try {
    const {
      eventType,
      actorId,
      resourceType,
      fromDate,
      toDate,
      limit = 100,
      offset = 0
    } = req.query;
    const events = await phase10AuditService.searchAuditEvents({
      tenantId: req.security.tenantId,
      eventType,
      actorId,
      resourceType,
      fromDate: fromDate ? new Date(fromDate) : void 0,
      toDate: toDate ? new Date(toDate) : void 0
    }, parseInt(limit), parseInt(offset));
    res.json({
      success: true,
      data: events,
      pagination: {
        limit: parseInt(limit),
        offset: parseInt(offset),
        total: events.length
      }
    });
  } catch (error) {
    console.error("[Phase10Routes] Failed to get audit events:", error);
    res.status(500).json({ error: "Failed to retrieve audit events" });
  }
});
router10.get("/audit/events/:resourceUrn(*)", requireAuth3, requirePermission2("audit", "read"), async (req, res) => {
  try {
    const { resourceUrn } = req.params;
    const { limit = 100, offset = 0 } = req.query;
    const events = await phase10AuditService.getAuditEvents(
      resourceUrn,
      req.security.tenantId,
      parseInt(limit),
      parseInt(offset)
    );
    res.json({
      success: true,
      data: events,
      resourceUrn
    });
  } catch (error) {
    console.error("[Phase10Routes] Failed to get resource audit events:", error);
    res.status(500).json({ error: "Failed to retrieve resource audit events" });
  }
});
router10.post("/audit/verify/:resourceUrn(*)", requireAuth3, requirePermission2("audit", "verify"), async (req, res) => {
  try {
    const { resourceUrn } = req.params;
    const verification = await phase10AuditService.verifyAuditChain(
      resourceUrn,
      req.security.tenantId
    );
    res.json({
      success: true,
      verification
    });
  } catch (error) {
    console.error("[Phase10Routes] Failed to verify audit chain:", error);
    res.status(500).json({ error: "Failed to verify audit chain" });
  }
});
router10.get("/audit/statistics", requireAuth3, requirePermission2("audit", "read"), async (req, res) => {
  try {
    const statistics = await phase10AuditService.getAuditStatistics(req.security.tenantId);
    res.json({
      success: true,
      data: statistics
    });
  } catch (error) {
    console.error("[Phase10Routes] Failed to get audit statistics:", error);
    res.status(500).json({ error: "Failed to retrieve audit statistics" });
  }
});
router10.post("/documents", requireAuth3, requirePermission2("document", "write"), async (req, res) => {
  try {
    const {
      loanUrn,
      docType,
      docCategory,
      provider = "internal",
      documentTitle,
      metadata = {}
    } = req.body;
    const docId = await phase10DocumentService.storeDocument({
      tenantId: req.security.tenantId,
      loanUrn,
      docType,
      docCategory,
      provider,
      documentTitle,
      metadata
    }, req.security.userId);
    res.status(201).json({
      success: true,
      data: { docId },
      message: "Document stored successfully"
    });
  } catch (error) {
    console.error("[Phase10Routes] Failed to store document:", error);
    res.status(500).json({ error: "Failed to store document" });
  }
});
router10.get("/documents/:docId", requireAuth3, requirePermission2("document", "read"), async (req, res) => {
  try {
    const { docId } = req.params;
    const document = await phase10DocumentService.getDocument(docId, req.security.tenantId);
    if (!document) {
      return res.status(404).json({ error: "Document not found" });
    }
    await phase10DocumentService.logDocumentAccess(
      docId,
      req.security.userId,
      "view",
      true,
      {
        ipAddress: req.security.ipAddress,
        userAgent: req.security.userAgent,
        sessionId: req.security.sessionId
      },
      req.security.tenantId
    );
    res.json({
      success: true,
      data: document
    });
  } catch (error) {
    console.error("[Phase10Routes] Failed to get document:", error);
    res.status(500).json({ error: "Failed to retrieve document" });
  }
});
router10.get("/documents/loan/:loanUrn(*)", requireAuth3, requirePermission2("document", "read"), async (req, res) => {
  try {
    const { loanUrn } = req.params;
    const { docType, limit = 100, offset = 0 } = req.query;
    const documents2 = await phase10DocumentService.getDocumentsByLoan(
      loanUrn,
      req.security.tenantId,
      docType,
      parseInt(limit),
      parseInt(offset)
    );
    res.json({
      success: true,
      data: documents2,
      pagination: {
        limit: parseInt(limit),
        offset: parseInt(offset)
      }
    });
  } catch (error) {
    console.error("[Phase10Routes] Failed to get documents by loan:", error);
    res.status(500).json({ error: "Failed to retrieve loan documents" });
  }
});
router10.post("/documents/:docId/verify", requireAuth3, requirePermission2("document", "verify"), async (req, res) => {
  try {
    const { docId } = req.params;
    const verification = await phase10DocumentService.verifyDocumentIntegrity(docId);
    res.json({
      success: true,
      verification
    });
  } catch (error) {
    console.error("[Phase10Routes] Failed to verify document:", error);
    res.status(500).json({ error: "Failed to verify document integrity" });
  }
});
router10.post("/consent/grant", requireAuth3, requirePermission2("consent", "write"), async (req, res) => {
  try {
    const consentRequest = req.body;
    consentRequest.ipAddress = req.security.ipAddress;
    consentRequest.userAgent = req.security.userAgent;
    const consentId = await phase10ConsentService.grantConsent(
      consentRequest,
      req.security.tenantId,
      req.security.userId
    );
    res.status(201).json({
      success: true,
      data: { consentId },
      message: "Consent granted successfully"
    });
  } catch (error) {
    console.error("[Phase10Routes] Failed to grant consent:", error);
    res.status(500).json({ error: "Failed to grant consent" });
  }
});
router10.post("/consent/:consentId/revoke", requireAuth3, requirePermission2("consent", "write"), async (req, res) => {
  try {
    const { consentId } = req.params;
    const { reason } = req.body;
    const success = await phase10ConsentService.revokeConsent(
      consentId,
      reason,
      req.security.userId,
      req.security.ipAddress,
      req.security.userAgent,
      req.security.tenantId
    );
    res.json({
      success,
      message: success ? "Consent revoked successfully" : "Failed to revoke consent"
    });
  } catch (error) {
    console.error("[Phase10Routes] Failed to revoke consent:", error);
    res.status(500).json({ error: "Failed to revoke consent" });
  }
});
router10.get("/consent/status/:subjectUrn(*)", requireAuth3, requirePermission2("consent", "read"), async (req, res) => {
  try {
    const { subjectUrn } = req.params;
    const { consentType } = req.query;
    const consents = await phase10ConsentService.getConsentStatus(
      subjectUrn,
      consentType,
      req.security.tenantId
    );
    res.json({
      success: true,
      data: consents
    });
  } catch (error) {
    console.error("[Phase10Routes] Failed to get consent status:", error);
    res.status(500).json({ error: "Failed to retrieve consent status" });
  }
});
router10.post("/communication/preferences", requireAuth3, requirePermission2("communication", "write"), async (req, res) => {
  try {
    const preference = req.body;
    const prefId = await phase10ConsentService.setCommunicationPreference(
      preference,
      req.security.tenantId,
      req.security.userId
    );
    res.status(201).json({
      success: true,
      data: { prefId },
      message: "Communication preference set successfully"
    });
  } catch (error) {
    console.error("[Phase10Routes] Failed to set communication preference:", error);
    res.status(500).json({ error: "Failed to set communication preference" });
  }
});
router10.get("/communication/preferences/:subjectUrn(*)", requireAuth3, requirePermission2("communication", "read"), async (req, res) => {
  try {
    const { subjectUrn } = req.params;
    const { channel, purpose } = req.query;
    const preferences = await phase10ConsentService.getCommunicationPreferences(
      subjectUrn,
      channel,
      purpose,
      req.security.tenantId
    );
    res.json({
      success: true,
      data: preferences
    });
  } catch (error) {
    console.error("[Phase10Routes] Failed to get communication preferences:", error);
    res.status(500).json({ error: "Failed to retrieve communication preferences" });
  }
});
router10.post("/communication/check", requireAuth3, requirePermission2("communication", "read"), async (req, res) => {
  try {
    const { subjectUrn, channel, purpose, subPurpose } = req.body;
    const result = await phase10ConsentService.isCommunicationAllowed(
      subjectUrn,
      channel,
      purpose,
      subPurpose,
      req.security.tenantId
    );
    res.json({
      success: true,
      data: result
    });
  } catch (error) {
    console.error("[Phase10Routes] Failed to check communication allowance:", error);
    res.status(500).json({ error: "Failed to check communication allowance" });
  }
});
router10.post("/webhooks/docusign", async (req, res) => {
  await docuSignConnectService.processWebhook(req, res);
});
router10.get("/health", async (req, res) => {
  try {
    const auditStats = await phase10AuditService.getAuditStatistics();
    res.json({
      success: true,
      phase: 10,
      status: "healthy",
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      services: {
        audit: { status: "healthy", totalEvents: auditStats.totalEvents },
        document: { status: "healthy" },
        consent: { status: "healthy" },
        security: { status: "healthy" }
      }
    });
  } catch (error) {
    console.error("[Phase10Routes] Health check failed:", error);
    res.status(500).json({
      success: false,
      phase: 10,
      status: "unhealthy",
      error: error instanceof Error ? error.message : "Unknown error"
    });
  }
});
var phase10_routes_default = router10;

// server/routes/notice-templates.ts
init_db();
init_schema();
init_middleware();
init_response_utils();
init_auditService();
import { Router as Router10 } from "express";
import { eq as eq20, and as and16 } from "drizzle-orm";
import multer2 from "multer";
import path4 from "path";
import fs4 from "fs/promises";
var router11 = Router10();
var storage3 = multer2.diskStorage({
  destination: async (req, file, cb) => {
    const uploadDir = path4.join(process.cwd(), "uploads", "templates");
    await fs4.mkdir(uploadDir, { recursive: true });
    cb(null, uploadDir);
  },
  filename: (req, file, cb) => {
    const uniqueSuffix = Date.now() + "-" + Math.round(Math.random() * 1e9);
    cb(null, file.fieldname + "-" + uniqueSuffix + path4.extname(file.originalname));
  }
});
var upload2 = multer2({
  storage: storage3,
  limits: {
    fileSize: 10 * 1024 * 1024
    // 10MB limit
  },
  fileFilter: (req, file, cb) => {
    const allowedTypes = [
      "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
      "application/msword",
      "application/pdf"
    ];
    if (allowedTypes.includes(file.mimetype)) {
      cb(null, true);
    } else {
      cb(new Error("Invalid file type. Only Word documents and PDFs are allowed."));
    }
  }
});
router11.get("/notice-templates", requireAuth2, async (req, res) => {
  try {
    const templates = await db.select().from(noticeTemplates);
    return sendSuccess(res, templates);
  } catch (error) {
    console.error("Error fetching notice templates:", error);
    return ErrorResponses.internalError(res, "Failed to fetch notice templates", error);
  }
});
router11.get("/notice-templates/:category", requireAuth2, async (req, res) => {
  try {
    const { category } = req.params;
    const templates = await db.select().from(noticeTemplates).where(eq20(noticeTemplates.category, category));
    return sendSuccess(res, templates);
  } catch (error) {
    console.error("Error fetching templates by category:", error);
    return ErrorResponses.internalError(res, "Failed to fetch templates", error);
  }
});
router11.post("/notice-templates/upload", requireAuth2, upload2.single("template"), async (req, res) => {
  try {
    if (!req.file) {
      return ErrorResponses.badRequest(res, "No file uploaded");
    }
    const { category, subcategory, name, description } = req.body;
    if (!category || !name) {
      return ErrorResponses.badRequest(res, "Category and name are required");
    }
    const template = await db.insert(noticeTemplates).values({
      category,
      subcategory: subcategory || null,
      name,
      description: description || null,
      filename: req.file.originalname,
      fileUrl: `/uploads/templates/${req.file.filename}`,
      fileSize: req.file.size,
      mimeType: req.file.mimetype,
      uploadedBy: req.user?.id || null
    }).returning();
    const templateFields = Object.keys(template[0]);
    for (const field of templateFields) {
      const newValue = template[0][field];
      if (["id", "createdAt", "updatedAt"].includes(field)) {
        continue;
      }
      await complianceAudit.logEvent({
        eventType: COMPLIANCE_EVENTS.DOCUMENT.UPLOADED,
        actorType: "user",
        actorId: (req.user?.id || null)?.toString(),
        resourceType: "notice_template",
        resourceId: template[0].id.toString(),
        loanId: null,
        // Templates are not tied to specific loans
        ipAddr: getRealUserIP2(req),
        userAgent: req.headers?.["user-agent"],
        description: `Template field '${field}' set to '${newValue}' on template upload`,
        previousValues: { [field]: null },
        newValues: { [field]: newValue },
        changedFields: [field]
      });
    }
    return sendSuccess(res, template[0], "Template uploaded successfully");
  } catch (error) {
    console.error("Error uploading template:", error);
    return ErrorResponses.internalError(res, "Failed to upload template", error);
  }
});
router11.delete("/notice-templates/:id", requireAuth2, async (req, res) => {
  try {
    const { id } = req.params;
    const [template] = await db.select().from(noticeTemplates).where(eq20(noticeTemplates.id, parseInt(id))).limit(1);
    if (!template) {
      return ErrorResponses.notFound(res, "Template not found");
    }
    if (template.fileUrl) {
      const filePath = path4.join(process.cwd(), template.fileUrl);
      try {
        await fs4.unlink(filePath);
      } catch (err) {
        console.warn("Could not delete file:", filePath);
      }
    }
    const templateFields = Object.keys(template);
    for (const field of templateFields) {
      const oldValue = template[field];
      if (["id", "createdAt", "updatedAt"].includes(field)) {
        continue;
      }
      await complianceAudit.logEvent({
        eventType: COMPLIANCE_EVENTS.DOCUMENT.DELETED,
        actorType: "user",
        actorId: (req.user?.id || null)?.toString(),
        resourceType: "notice_template",
        resourceId: template.id.toString(),
        loanId: null,
        // Templates are not tied to specific loans
        ipAddr: getRealUserIP2(req),
        userAgent: req.headers?.["user-agent"],
        description: `Template field '${field}' with value '${oldValue}' deleted on template deletion`,
        previousValues: { [field]: oldValue },
        newValues: { [field]: null },
        changedFields: [field]
      });
    }
    await db.delete(noticeTemplates).where(eq20(noticeTemplates.id, parseInt(id)));
    return sendSuccess(res, null, "Template deleted successfully");
  } catch (error) {
    console.error("Error deleting template:", error);
    return ErrorResponses.internalError(res, "Failed to delete template", error);
  }
});
router11.get("/notice-settings", requireAuth2, async (req, res) => {
  try {
    const settings = await db.select().from(noticeSettings);
    const settingsMap = {};
    settings.forEach((setting) => {
      if (!settingsMap[setting.category]) {
        settingsMap[setting.category] = {};
      }
      settingsMap[setting.category][setting.settingKey] = setting.settingValue;
    });
    return sendSuccess(res, settingsMap);
  } catch (error) {
    console.error("Error fetching notice settings:", error);
    return ErrorResponses.internalError(res, "Failed to fetch notice settings", error);
  }
});
router11.put("/notice-settings", requireAuth2, async (req, res) => {
  try {
    const { category, settingKey, settingValue } = req.body;
    if (!category || !settingKey) {
      return ErrorResponses.badRequest(res, "Category and settingKey are required");
    }
    const existingSetting = await db.select().from(noticeSettings).where(and16(
      eq20(noticeSettings.category, category),
      eq20(noticeSettings.settingKey, settingKey)
    )).limit(1);
    let result;
    if (existingSetting.length > 0) {
      result = await db.update(noticeSettings).set({
        settingValue,
        updatedBy: req.user?.id || null,
        updatedAt: /* @__PURE__ */ new Date()
      }).where(and16(
        eq20(noticeSettings.category, category),
        eq20(noticeSettings.settingKey, settingKey)
      )).returning();
    } else {
      result = await db.insert(noticeSettings).values({
        category,
        settingKey,
        settingValue,
        updatedBy: req.user?.id || null
      }).returning();
    }
    return sendSuccess(res, result[0], "Setting updated successfully");
  } catch (error) {
    console.error("Error updating notice setting:", error);
    return ErrorResponses.internalError(res, "Failed to update setting", error);
  }
});

// server/routes/email-templates.ts
init_db();
init_schema();
init_middleware();
init_response_utils();
import { Router as Router11 } from "express";
import { eq as eq21, sql as sql13 } from "drizzle-orm";
var router12 = Router11();
router12.get("/email-template-folders", requireAuth2, async (req, res) => {
  try {
    const foldersWithCount = await db.select({
      id: emailTemplateFolders.id,
      name: emailTemplateFolders.name,
      parentId: emailTemplateFolders.parentId,
      createdBy: emailTemplateFolders.createdBy,
      createdAt: emailTemplateFolders.createdAt,
      templateCount: sql13`count(${emailTemplates.id})::int`
    }).from(emailTemplateFolders).leftJoin(emailTemplates, eq21(emailTemplates.folderId, emailTemplateFolders.id)).groupBy(emailTemplateFolders.id);
    return sendSuccess(res, foldersWithCount);
  } catch (error) {
    console.error("Error fetching email template folders:", error);
    return ErrorResponses.internalError(res, "Failed to fetch folders", error);
  }
});
router12.post("/email-template-folders", requireAuth2, async (req, res) => {
  try {
    const { name, parentId } = req.body;
    if (!name) {
      return ErrorResponses.badRequest(res, "Folder name is required");
    }
    const [folder] = await db.insert(emailTemplateFolders).values({
      name,
      parentId: parentId || null,
      createdBy: req.user?.id || null
    }).returning();
    return sendSuccess(res, folder, "Folder created successfully");
  } catch (error) {
    console.error("Error creating folder:", error);
    return ErrorResponses.internalError(res, "Failed to create folder", error);
  }
});
router12.put("/email-template-folders/:id", requireAuth2, async (req, res) => {
  try {
    const { id } = req.params;
    const { name } = req.body;
    if (!name) {
      return ErrorResponses.badRequest(res, "Folder name is required");
    }
    const [folder] = await db.update(emailTemplateFolders).set({
      name,
      updatedAt: /* @__PURE__ */ new Date()
    }).where(eq21(emailTemplateFolders.id, parseInt(id))).returning();
    if (!folder) {
      return ErrorResponses.notFound(res, "Folder not found");
    }
    return sendSuccess(res, folder, "Folder updated successfully");
  } catch (error) {
    console.error("Error updating folder:", error);
    return ErrorResponses.internalError(res, "Failed to update folder", error);
  }
});
router12.delete("/email-template-folders/:id", requireAuth2, async (req, res) => {
  try {
    const { id } = req.params;
    const [hasTemplates] = await db.select({ count: sql13`count(*)::int` }).from(emailTemplates).where(eq21(emailTemplates.folderId, parseInt(id)));
    if (hasTemplates.count > 0) {
      return ErrorResponses.badRequest(res, "Cannot delete folder with templates");
    }
    await db.delete(emailTemplateFolders).where(eq21(emailTemplateFolders.id, parseInt(id)));
    return sendSuccess(res, null, "Folder deleted successfully");
  } catch (error) {
    console.error("Error deleting folder:", error);
    return ErrorResponses.internalError(res, "Failed to delete folder", error);
  }
});
router12.get("/email-templates", requireAuth2, async (req, res) => {
  try {
    const { folderId } = req.query;
    let query = db.select().from(emailTemplates);
    if (folderId) {
      query = query.where(eq21(emailTemplates.folderId, parseInt(folderId)));
    }
    const templates = await query;
    return sendSuccess(res, templates);
  } catch (error) {
    console.error("Error fetching email templates:", error);
    return ErrorResponses.internalError(res, "Failed to fetch templates", error);
  }
});
router12.get("/email-templates/:id", requireAuth2, async (req, res) => {
  try {
    const { id } = req.params;
    const [template] = await db.select().from(emailTemplates).where(eq21(emailTemplates.id, parseInt(id))).limit(1);
    if (!template) {
      return ErrorResponses.notFound(res, "Template not found");
    }
    return sendSuccess(res, template);
  } catch (error) {
    console.error("Error fetching email template:", error);
    return ErrorResponses.internalError(res, "Failed to fetch template", error);
  }
});
router12.post("/email-templates", requireAuth2, async (req, res) => {
  try {
    const { name, subject, body, isShared, folderId } = req.body;
    if (!name || !subject) {
      return ErrorResponses.badRequest(res, "Template name and subject are required");
    }
    const [template] = await db.insert(emailTemplates).values({
      name,
      subject,
      body: body || "",
      isShared: isShared || false,
      folderId: folderId || null,
      createdBy: req.user?.id || null
    }).returning();
    return sendSuccess(res, template, "Template created successfully");
  } catch (error) {
    console.error("Error creating email template:", error);
    return ErrorResponses.internalError(res, "Failed to create template", error);
  }
});
router12.put("/email-templates/:id", requireAuth2, async (req, res) => {
  try {
    const { id } = req.params;
    const { name, subject, body, isShared, folderId } = req.body;
    const [template] = await db.update(emailTemplates).set({
      name,
      subject,
      body,
      isShared,
      folderId,
      updatedAt: /* @__PURE__ */ new Date()
    }).where(eq21(emailTemplates.id, parseInt(id))).returning();
    if (!template) {
      return ErrorResponses.notFound(res, "Template not found");
    }
    return sendSuccess(res, template, "Template updated successfully");
  } catch (error) {
    console.error("Error updating email template:", error);
    return ErrorResponses.internalError(res, "Failed to update template", error);
  }
});
router12.delete("/email-templates/:id", requireAuth2, async (req, res) => {
  try {
    const { id } = req.params;
    await db.delete(emailTemplates).where(eq21(emailTemplates.id, parseInt(id)));
    return sendSuccess(res, null, "Template deleted successfully");
  } catch (error) {
    console.error("Error deleting email template:", error);
    return ErrorResponses.internalError(res, "Failed to delete template", error);
  }
});
router12.post("/email-templates/:id/clone", requireAuth2, async (req, res) => {
  try {
    const { id } = req.params;
    const { name } = req.body;
    const [original] = await db.select().from(emailTemplates).where(eq21(emailTemplates.id, parseInt(id))).limit(1);
    if (!original) {
      return ErrorResponses.notFound(res, "Template not found");
    }
    const [cloned] = await db.insert(emailTemplates).values({
      name: name || `${original.name} (Copy)`,
      subject: original.subject,
      body: original.body,
      isShared: false,
      folderId: original.folderId,
      createdBy: req.user?.id || null
    }).returning();
    return sendSuccess(res, cloned, "Template cloned successfully");
  } catch (error) {
    console.error("Error cloning email template:", error);
    return ErrorResponses.internalError(res, "Failed to clone template", error);
  }
});

// server/routes/payment-routes.ts
init_db();
init_schema();
init_middleware();
init_policy_engine();
init_response_utils();
init_safe_logger();
init_types();
import { Router as Router12 } from "express";
import { z as z8 } from "zod";
import { ulid as ulid2 } from "ulid";
import { eq as eq22 } from "drizzle-orm";
var router13 = Router12();
var ACHSubmissionSchema = z8.object({
  loan_id: z8.number(),
  amount: z8.number().positive(),
  source: z8.literal("ach"),
  account_number_masked: z8.string().regex(/^\*{4,8}\d{4}$/).optional(),
  routing_number_masked: z8.string().regex(/^\*{5}\d{4}$/).optional(),
  // Legacy fields for backward compatibility (will be masked)
  account_number: z8.string().optional(),
  routing_number: z8.string().optional(),
  account_type: z8.enum(["checking", "savings"]).default("checking"),
  sec_code: z8.enum(["PPD", "CCD", "WEB", "TEL"]).default("PPD"),
  trace_number: z8.string().optional(),
  external_ref: z8.string().optional(),
  processor_ref: z8.string().optional()
});
var PaymentSubmissionSchema = z8.object({
  loan_id: z8.number(),
  amount: z8.number().positive(),
  source: z8.enum(["ach", "wire", "check", "card", "cash"]),
  // ACH fields
  routing_number: z8.string().optional(),
  account_number: z8.string().optional(),
  account_type: z8.enum(["checking", "savings"]).optional(),
  sec_code: z8.enum(["PPD", "CCD", "WEB", "TEL"]).optional(),
  // Wire fields
  wire_ref: z8.string().optional(),
  sender_ref: z8.string().optional(),
  // Check fields
  check_number: z8.string().optional(),
  payer_account: z8.string().optional(),
  payer_bank: z8.string().optional(),
  issue_date: z8.string().optional(),
  // Card fields
  card_last_four: z8.string().optional(),
  card_type: z8.string().optional(),
  auth_code: z8.string().optional(),
  // Common fields
  external_ref: z8.string().optional(),
  processor_ref: z8.string().optional()
});
router13.post("/payments", requireAuth2, async (req, res) => {
  try {
    console.log("[API] Payment submission received", {
      body: maskSensitive(req.body),
      user: req.user.id,
      ip: req.ip
    });
    if (!await hasPermission(req.user.id, "payments", "write", { userId: req.user.id })) {
      return res.status(403).json({ error: "Insufficient permissions" });
    }
    const data = PaymentSubmissionSchema.parse(req.body);
    const paymentId = ulid2();
    const amountCents = Math.round(data.amount * 100);
    let paymentData;
    switch (data.source) {
      case "ach":
        if (!data.routing_number || !data.account_number) {
          return res.status(400).json({ error: "ACH payments require routing and account numbers" });
        }
        paymentData = {
          payment_id: paymentId,
          loan_id: data.loan_id,
          source: "ach",
          amount_cents: amountCents,
          currency: "USD",
          external_ref: data.external_ref,
          account_number_masked: maskAccountNumber(data.account_number),
          routing_number_masked: maskRoutingNumber(data.routing_number),
          account_type: data.account_type || "checking",
          sec_code: data.sec_code || "PPD",
          trace_number: generateTraceNumber()
        };
        break;
      case "wire":
        if (!data.wire_ref) {
          return res.status(400).json({ error: "Wire payments require a wire reference" });
        }
        paymentData = {
          payment_id: paymentId,
          loan_id: data.loan_id,
          source: "wire",
          amount_cents: amountCents,
          currency: "USD",
          external_ref: data.external_ref,
          wire_ref: data.wire_ref,
          sender_ref: data.sender_ref
        };
        break;
      case "check":
        if (!data.check_number) {
          return res.status(400).json({ error: "Check payments require a check number" });
        }
        paymentData = {
          payment_id: paymentId,
          loan_id: data.loan_id,
          source: "check",
          amount_cents: amountCents,
          currency: "USD",
          external_ref: data.external_ref,
          check_number: data.check_number,
          payer_account: data.payer_account,
          payer_bank: data.payer_bank,
          issue_date: data.issue_date || (/* @__PURE__ */ new Date()).toISOString()
        };
        break;
      case "card":
        if (!data.card_last_four) {
          return res.status(400).json({ error: "Card payments require card details" });
        }
        paymentData = {
          payment_id: paymentId,
          loan_id: data.loan_id,
          source: "card",
          amount_cents: amountCents,
          currency: "USD",
          external_ref: data.external_ref,
          card_last_four: data.card_last_four,
          card_type: data.card_type,
          auth_code: data.auth_code,
          processor_ref: data.processor_ref
        };
        break;
      case "cash":
        paymentData = {
          payment_id: paymentId,
          loan_id: data.loan_id,
          source: "cash",
          amount_cents: amountCents,
          currency: "USD",
          external_ref: data.external_ref || `CASH-${Date.now()}`
        };
        break;
      default:
        return res.status(400).json({ error: "Invalid payment source" });
    }
    const loan = await db.query.loans.findFirst({
      where: eq22(loans.id, data.loan_id)
    });
    if (!loan) {
      return res.status(404).json({ error: "Loan not found" });
    }
    await db.insert(payments).values({
      id: paymentId,
      loanId: data.loan_id,
      amount: data.amount.toFixed(2),
      amountCents,
      currency: "USD",
      sourceChannel: data.source,
      status: "submitted",
      submittedAt: /* @__PURE__ */ new Date(),
      externalRef: data.external_ref,
      processorRef: data.processor_ref,
      // Store only masked PII data
      metadata: paymentData.source === "ach" ? {
        account_masked: paymentData.account_number_masked,
        routing_masked: paymentData.routing_number_masked,
        trace_number: paymentData.trace_number,
        sec_code: paymentData.sec_code
      } : void 0
    });
    const rabbitmq2 = getEnhancedRabbitMQService();
    await rabbitmq2.publish({
      schema: "payments.v1.payment_received",
      message_id: paymentId,
      correlation_id: req.correlationId || paymentId,
      trace_id: req.correlationId || paymentId,
      priority: 5,
      data: paymentData
    }, {
      exchange: "payments.topic",
      routingKey: "payment.received",
      persistent: true,
      headers: {
        "x-source": data.source,
        "x-loan-id": data.loan_id.toString()
      }
    });
    console.log(`[Payments] Payment ${paymentId} submitted for loan ${data.loan_id}`);
    return sendSuccess(res, {
      payment_id: paymentId,
      status: "submitted"
    }, "Payment submitted successfully");
  } catch (error) {
    console.error("[Payments] Payment submission error:", error);
    if (error.name === "ZodError") {
      return ErrorResponses.badRequest(res, "Invalid payment data", error.errors);
    }
    return ErrorResponses.internalError(res, "Payment submission failed");
  }
});
var payment_routes_default = router13;

// server/routes/rabbitmq-config.ts
import { Router as Router13 } from "express";

// server/services/rabbitmq-config.ts
init_db();
init_schema();
import { eq as eq23, and as and19 } from "drizzle-orm";
var DEFAULT_PREFETCH_CONFIG = {
  payment_validation: 20,
  // Fast validation, can handle more
  payment_processing: 5,
  // Heavy processing, lower prefetch
  payment_distribution: 10,
  // Moderate processing
  payment_reversal: 3,
  // Critical operations, very low prefetch
  payment_classifier: 15,
  // Fast classification
  rules_engine: 10,
  // Moderate rule evaluation
  notification: 50,
  // Very fast, can handle many
  audit_log: 100,
  // Extremely fast writes
  poster_service: 8,
  // External API calls, moderate
  compliance_check: 5,
  // Heavy compliance checks
  aml_screening: 3,
  // Very heavy AML checks
  servicing_cycle: 1,
  // Critical daily processing
  investor_reporting: 5,
  // Heavy report generation
  clawback_processor: 3,
  // Critical financial operations
  ach_return: 5,
  // Return processing
  wire_processor: 10,
  // Wire transfers
  default: 10
  // Default for unknown consumers
};
var PREFETCH_KEY = "rabbitmq_prefetch_config";
var CATEGORY = "messaging";
var RabbitMQConfigService = class _RabbitMQConfigService {
  static instance;
  config = null;
  lastFetch = 0;
  CACHE_TTL = 6e4;
  // 1 minute cache
  constructor() {
  }
  static getInstance() {
    if (!_RabbitMQConfigService.instance) {
      _RabbitMQConfigService.instance = new _RabbitMQConfigService();
    }
    return _RabbitMQConfigService.instance;
  }
  /**
   * Get prefetch configuration for all consumers
   */
  async getConfig() {
    if (this.config && Date.now() - this.lastFetch < this.CACHE_TTL) {
      return this.config;
    }
    try {
      const result = await db.select().from(systemSettings).where(
        and19(
          eq23(systemSettings.category, CATEGORY),
          eq23(systemSettings.key, PREFETCH_KEY)
        )
      ).limit(1);
      if (result.length > 0) {
        this.config = result[0].value;
      } else {
        await this.saveConfig(DEFAULT_PREFETCH_CONFIG);
        this.config = DEFAULT_PREFETCH_CONFIG;
      }
      this.lastFetch = Date.now();
      return this.config;
    } catch (error) {
      console.error("[RabbitMQConfig] Failed to fetch config:", error);
      return DEFAULT_PREFETCH_CONFIG;
    }
  }
  /**
   * Get prefetch value for a specific consumer
   */
  async getPrefetch(consumerType) {
    const config = await this.getConfig();
    return config[consumerType] || config.default;
  }
  /**
   * Save prefetch configuration
   */
  async saveConfig(config, userId) {
    const fullConfig = { ...DEFAULT_PREFETCH_CONFIG, ...config };
    try {
      const existing = await db.select().from(systemSettings).where(
        and19(
          eq23(systemSettings.category, CATEGORY),
          eq23(systemSettings.key, PREFETCH_KEY)
        )
      ).limit(1);
      if (existing.length > 0) {
        await db.update(systemSettings).set({
          value: fullConfig,
          updatedBy: userId,
          updatedAt: /* @__PURE__ */ new Date()
        }).where(
          and19(
            eq23(systemSettings.category, CATEGORY),
            eq23(systemSettings.key, PREFETCH_KEY)
          )
        );
      } else {
        await db.insert(systemSettings).values({
          category: CATEGORY,
          key: PREFETCH_KEY,
          value: fullConfig,
          description: "RabbitMQ consumer prefetch configuration. Adjust based on processing time and network latency.",
          isEditable: true,
          updatedBy: userId
        });
      }
      this.config = fullConfig;
      this.lastFetch = Date.now();
      console.log("[RabbitMQConfig] Configuration saved successfully");
    } catch (error) {
      console.error("[RabbitMQConfig] Failed to save config:", error);
      throw error;
    }
  }
  /**
   * Reset to default configuration
   */
  async resetToDefaults(userId) {
    await this.saveConfig(DEFAULT_PREFETCH_CONFIG, userId);
  }
  /**
   * Get recommended prefetch based on metrics
   * This could be enhanced with actual performance metrics
   */
  getRecommendedPrefetch(avgProcessingTimeMs, networkRoundTripMs = 10) {
    const ratio = avgProcessingTimeMs / networkRoundTripMs;
    if (ratio < 1) {
      return 50;
    } else if (ratio < 5) {
      return 20;
    } else if (ratio < 10) {
      return 10;
    } else if (ratio < 20) {
      return 5;
    } else {
      return 1;
    }
  }
  /**
   * Clear cache to force refresh
   */
  clearCache() {
    this.config = null;
    this.lastFetch = 0;
  }
};
var rabbitmqConfig = RabbitMQConfigService.getInstance();

// server/routes/rabbitmq-config.ts
init_middleware();
init_policy_engine();
var router14 = Router13();
router14.get("/admin/rabbitmq/config", requireAuth2, requirePermission("system_settings", PermissionLevel.ADMIN), async (req, res) => {
  try {
    const config = await rabbitmqConfig.getConfig();
    res.json({ config });
  } catch (error) {
    console.error("Error fetching RabbitMQ config:", error);
    res.status(500).json({
      message: "Failed to fetch RabbitMQ configuration"
    });
  }
});
router14.put("/admin/rabbitmq/config", requireAuth2, requirePermission("system_settings", PermissionLevel.ADMIN), async (req, res) => {
  try {
    const { config } = req.body;
    if (!config) {
      return res.status(400).json({
        message: "Configuration is required"
      });
    }
    for (const [key, value] of Object.entries(config)) {
      if (typeof value !== "number" || value < 1 || value > 1e3) {
        return res.status(400).json({
          message: `Invalid value for ${key}: must be a number between 1 and 1000`
        });
      }
    }
    const userId = req.user?.id || req.session?.passport?.user || req.session?.userId;
    await rabbitmqConfig.saveConfig(config, userId);
    res.json({
      success: true,
      message: "Configuration saved successfully"
    });
  } catch (error) {
    console.error("Error saving RabbitMQ config:", error);
    res.status(500).json({
      message: "Failed to save RabbitMQ configuration"
    });
  }
});
router14.post("/admin/rabbitmq/config/reset", requireAuth2, requirePermission("system_settings", PermissionLevel.ADMIN), async (req, res) => {
  try {
    const userId = req.user?.id || req.session?.passport?.user || req.session?.userId;
    await rabbitmqConfig.resetToDefaults(userId);
    res.json({
      success: true,
      message: "Configuration reset to defaults"
    });
  } catch (error) {
    console.error("Error resetting RabbitMQ config:", error);
    res.status(500).json({
      message: "Failed to reset RabbitMQ configuration"
    });
  }
});
router14.post("/admin/rabbitmq/config/recommend", requireAuth2, requirePermission("system_settings", PermissionLevel.ADMIN), async (req, res) => {
  try {
    const { avgProcessingTimeMs, networkRoundTripMs } = req.body;
    if (!avgProcessingTimeMs || avgProcessingTimeMs < 0) {
      return res.status(400).json({
        message: "Average processing time is required"
      });
    }
    const recommended = rabbitmqConfig.getRecommendedPrefetch(
      avgProcessingTimeMs,
      networkRoundTripMs || 10
    );
    res.json({
      recommended,
      processingTimeMs: avgProcessingTimeMs,
      networkRoundTripMs: networkRoundTripMs || 10,
      ratio: avgProcessingTimeMs / (networkRoundTripMs || 10)
    });
  } catch (error) {
    console.error("Error getting recommendation:", error);
    res.status(500).json({
      message: "Failed to calculate recommendation"
    });
  }
});
var rabbitmq_config_default = router14;

// server/routes/metrics.ts
init_prometheus_metrics();
import { Router as Router14 } from "express";
var router15 = Router14();
router15.get("/metrics", async (req, res) => {
  try {
    const metrics2 = await register.metrics();
    res.set("Content-Type", register.contentType);
    res.send(metrics2);
  } catch (error) {
    console.error("[Metrics] Error generating metrics:", error);
    res.status(500).json({ error: "Failed to generate metrics" });
  }
});
var metrics_default = router15;

// src/routes/qc.routes.ts
init_QcWorker();
import { Router as Router15 } from "express";
var qcRouter = Router15();
qcRouter.get("/status", async (req, res) => {
  try {
    const status = qcWorker.getStatus();
    res.json(status);
  } catch (error) {
    console.error("[QcRoutes] Error getting QC status:", error);
    res.status(500).json({ error: "Failed to get QC status" });
  }
});
qcRouter.get("/loans/:id/qc", async (req, res) => {
  try {
    const mockDefects = [
      {
        id: "defect-001",
        rule_code: "QC001",
        rule_name: "Note Amount Match",
        severity: "high",
        status: "open",
        message: "NoteAmount $350000 != CD TotalLoanAmount $350000",
        created_at: (/* @__PURE__ */ new Date()).toISOString(),
        resolved_at: null,
        evidence_doc_id: "doc-123",
        evidence_page: 1
      }
    ];
    res.json({
      loan_id: req.params.id,
      defects: mockDefects,
      summary: {
        total: mockDefects.length,
        open: mockDefects.filter((d) => d.status === "open").length,
        resolved: mockDefects.filter((d) => d.status === "resolved").length,
        waived: mockDefects.filter((d) => d.status === "waived").length
      }
    });
  } catch (error) {
    console.error("[QcRoutes] Error getting loan QC defects:", error);
    res.status(500).json({ error: "Failed to get loan QC defects" });
  }
});
qcRouter.post("/loans/:id/qc/run", async (req, res) => {
  try {
    const loanId = req.params.id;
    const tenantId = req.headers["x-tenant-id"] || "default-tenant";
    console.log(`[QcRoutes] Manual QC trigger requested for loan ${loanId}`);
    const results = await qcWorker.processLoan(tenantId, loanId);
    res.json({
      status: "completed",
      loan_id: loanId,
      results: {
        total_rules: results.total_rules,
        defects: results.defects,
        program: results.program,
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      }
    });
  } catch (error) {
    console.error("[QcRoutes] Error running manual QC:", error);
    res.status(500).json({
      status: "error",
      error: error.message || "Failed to run QC"
    });
  }
});
qcRouter.post("/loans/:id/qc/waive", async (req, res) => {
  try {
    const { defect_id, rationale } = req.body;
    if (!defect_id) {
      return res.status(400).json({ error: "defect_id is required" });
    }
    if (!rationale || rationale.trim().length === 0) {
      return res.status(400).json({ error: "rationale is required for waiving defects" });
    }
    console.log(`[QcRoutes] Defect ${defect_id} waived for loan ${req.params.id}:`, rationale);
    res.json({
      ok: true,
      defect_id,
      status: "waived",
      rationale,
      waived_at: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    console.error("[QcRoutes] Error waiving defect:", error);
    res.status(500).json({ error: "Failed to waive defect" });
  }
});
qcRouter.get("/rules", async (req, res) => {
  try {
    const mockRules = [
      {
        id: "rule-001",
        code: "QC001",
        name: "Note Amount Match",
        description: "Note amount must equal CD loan amount within $0.01",
        severity: "high",
        enabled: true,
        params: {}
      },
      {
        id: "rule-002",
        code: "QC002",
        name: "Interest Rate Tolerance",
        description: "Interest rate difference must be within tolerance",
        severity: "medium",
        enabled: true,
        params: { tolerance: 0.125 }
      },
      {
        id: "rule-003",
        code: "QC003",
        name: "Payment Date Alignment",
        description: "First payment date must align with note date",
        severity: "medium",
        enabled: true,
        params: { maxDays: 62 }
      },
      {
        id: "rule-013",
        code: "QC013",
        name: "HOI Required",
        description: "Homeowner's insurance required by program",
        severity: "high",
        enabled: true,
        params: { required: true }
      }
    ];
    res.json({
      rules: mockRules,
      total: mockRules.length,
      enabled: mockRules.filter((r) => r.enabled).length
    });
  } catch (error) {
    console.error("[QcRoutes] Error getting QC rules:", error);
    res.status(500).json({ error: "Failed to get QC rules" });
  }
});
qcRouter.get("/programs", async (req, res) => {
  try {
    const mockPrograms = [
      {
        program_code: "FNMA",
        name: "Fannie Mae",
        requirements: [
          { key: "HomeownersInsCarrier", required: true },
          { key: "HOIPolicyNumber", required: true },
          { key: "FloodZone", required: true },
          { key: "AppraisedValue", required: true }
        ]
      },
      {
        program_code: "FRE",
        name: "Freddie Mac",
        requirements: [
          { key: "HomeownersInsCarrier", required: true },
          { key: "HOIPolicyNumber", required: true },
          { key: "FloodZone", required: true }
        ]
      },
      {
        program_code: "PORTFOLIO",
        name: "Portfolio Loan",
        requirements: [
          { key: "HomeownersInsCarrier", required: false },
          { key: "FloodZone", required: false }
        ]
      }
    ];
    res.json({
      programs: mockPrograms,
      total: mockPrograms.length
    });
  } catch (error) {
    console.error("[QcRoutes] Error getting program requirements:", error);
    res.status(500).json({ error: "Failed to get program requirements" });
  }
});

// src/routes/export.routes.ts
init_ExportWorker();
init_exports();
import { Router as Router16 } from "express";
var exportRouter = Router16();
exportRouter.post("/loans/:id/export", async (req, res) => {
  try {
    const { template } = req.body || {};
    const loanId = req.params.id;
    if (!["fannie", "freddie", "custom"].includes(template)) {
      return res.status(400).json({ error: "Invalid template. Must be 'fannie', 'freddie', or 'custom'" });
    }
    const tenantId = req.headers["x-tenant-id"] || "default-tenant";
    const requestedBy = req.user?.id || null;
    console.log(`[ExportRoutes] Export request for loan ${loanId}, template ${template}`);
    const result = await exportWorker.processExportRequest({
      tenantId,
      loanId,
      template,
      requestedBy
    });
    res.status(202).json({
      status: "completed",
      // For demo, return completed immediately
      export_id: result.exportId,
      file_uri: result.fileUri,
      sha256: result.sha256
    });
  } catch (error) {
    console.error("[ExportRoutes] Export request failed:", error);
    res.status(500).json({
      error: "Export failed",
      message: error.message
    });
  }
});
exportRouter.get("/exports/:exportId", async (req, res) => {
  try {
    const exportId = req.params.exportId;
    const tenantId = req.headers["x-tenant-id"] || "default-tenant";
    const exportRecord = await getExport(exportId, tenantId);
    if (!exportRecord) {
      return res.status(404).json({ error: "Export not found" });
    }
    res.json(exportRecord);
  } catch (error) {
    console.error("[ExportRoutes] Error getting export status:", error);
    res.status(500).json({ error: "Failed to get export status" });
  }
});
exportRouter.get("/exports/:exportId/file", async (req, res) => {
  try {
    const exportId = req.params.exportId;
    const tenantId = req.headers["x-tenant-id"] || "default-tenant";
    const exportRecord = await getExport(exportId, tenantId);
    if (!exportRecord || exportRecord.status !== "succeeded") {
      return res.status(404).json({ error: "Export file not available" });
    }
    res.json({
      file_uri: exportRecord.file_uri,
      sha256: exportRecord.file_sha256,
      download_url: `${exportRecord.file_uri}?download=true`
    });
  } catch (error) {
    console.error("[ExportRoutes] Error getting export file:", error);
    res.status(500).json({ error: "Failed to get export file" });
  }
});
exportRouter.get("/templates", async (req, res) => {
  try {
    const templates = [
      {
        id: "fannie",
        name: "Fannie Mae ULDD XML",
        format: "xml",
        description: "Fannie Mae Uniform Loan Delivery Dataset in XML format"
      },
      {
        id: "freddie",
        name: "Freddie Mac ULDD XML",
        format: "xml",
        description: "Freddie Mac Uniform Loan Delivery Dataset in XML format"
      },
      {
        id: "custom",
        name: "Custom CSV Export",
        format: "csv",
        description: "Custom loan data export in CSV format"
      }
    ];
    res.json({ templates });
  } catch (error) {
    console.error("[ExportRoutes] Error getting templates:", error);
    res.status(500).json({ error: "Failed to get export templates" });
  }
});
exportRouter.get("/status", async (req, res) => {
  try {
    const status = exportWorker.getStatus();
    res.json(status);
  } catch (error) {
    console.error("[ExportRoutes] Error getting worker status:", error);
    res.status(500).json({ error: "Failed to get worker status" });
  }
});

// src/routes/notification.routes.ts
init_service();
init_NotificationWorker();
import { Router as Router17 } from "express";
import { Pool as Pool2 } from "pg";
var router16 = Router17();
var pool2 = new Pool2({ connectionString: process.env.DATABASE_URL });
router16.post("/send", async (req, res) => {
  try {
    const tenantId = req.headers["x-tenant-id"];
    if (!tenantId) {
      return res.status(400).json({ error: "x-tenant-id header required" });
    }
    const {
      loan_id,
      template_code,
      channel,
      to_party,
      to_address,
      locale,
      params,
      idempotency_key
    } = req.body;
    if (!template_code || !channel || !to_party || !to_address) {
      return res.status(400).json({
        error: "Missing required fields: template_code, channel, to_party, to_address"
      });
    }
    if (!["email", "sms", "webhook"].includes(channel)) {
      return res.status(400).json({
        error: "Invalid channel. Must be email, sms, or webhook"
      });
    }
    const notificationRequest = {
      tenantId,
      loanId: loan_id || null,
      templateCode: template_code,
      channel,
      toParty: to_party,
      toAddress: to_address,
      locale: locale || "en-US",
      params: params || {},
      createdBy: req.user?.id || null,
      idempotencyKey: idempotency_key || null
    };
    console.log(`[NotificationRoutes] Notification request: ${template_code} -> ${to_address}`);
    const result = await requestNotification(notificationRequest);
    if (!result) {
      return res.status(409).json({
        error: "Duplicate request (idempotency key already processed)"
      });
    }
    res.status(202).json({
      notification_id: result.id,
      status: result.status,
      reason: result.reason
    });
  } catch (error) {
    console.error("[NotificationRoutes] Send notification failed:", error);
    res.status(500).json({
      error: error.message || "Internal server error"
    });
  }
});
router16.get("/:id", async (req, res) => {
  try {
    const tenantId = req.headers["x-tenant-id"];
    if (!tenantId) {
      return res.status(400).json({ error: "x-tenant-id header required" });
    }
    const { id } = req.params;
    const client5 = await pool2.connect();
    try {
      const result = await client5.query(`
        SELECT 
          n.*,
          COALESCE(
            json_agg(
              json_build_object(
                'event', ne.event,
                'meta', ne.meta,
                'timestamp', ne.ts
              ) ORDER BY ne.ts
            ) FILTER (WHERE ne.id IS NOT NULL),
            '[]'::json
          ) as events
        FROM notifications n
        LEFT JOIN notification_events ne ON n.id = ne.notification_id
        WHERE n.id = $1 AND n.tenant_id = $2
        GROUP BY n.id
      `, [id, tenantId]);
      if (!result.rowCount) {
        return res.status(404).json({ error: "Notification not found" });
      }
      const notification = result.rows[0];
      res.json({
        id: notification.id,
        template_code: notification.template_code,
        channel: notification.channel,
        to_party: notification.to_party,
        to_address: notification.to_address,
        status: notification.status,
        reason: notification.reason,
        created_at: notification.created_at,
        sent_at: notification.sent_at,
        events: notification.events
      });
    } finally {
      client5.release();
    }
  } catch (error) {
    console.error("[NotificationRoutes] Get notification failed:", error);
    res.status(500).json({
      error: error.message || "Internal server error"
    });
  }
});
router16.get("/loans/:loanId", async (req, res) => {
  try {
    const tenantId = req.headers["x-tenant-id"];
    if (!tenantId) {
      return res.status(400).json({ error: "x-tenant-id header required" });
    }
    const { loanId } = req.params;
    const { status, limit = "50", offset = "0" } = req.query;
    const client5 = await pool2.connect();
    try {
      let query = `
        SELECT 
          id, template_code, channel, to_party, to_address,
          status, reason, created_at, sent_at
        FROM notifications 
        WHERE tenant_id = $1 AND loan_id = $2
      `;
      const params = [tenantId, loanId];
      if (status) {
        query += " AND status = $3";
        params.push(status);
      }
      query += " ORDER BY created_at DESC LIMIT $" + (params.length + 1) + " OFFSET $" + (params.length + 2);
      params.push(parseInt(limit), parseInt(offset));
      const result = await client5.query(query, params);
      res.json({
        notifications: result.rows,
        total: result.rowCount,
        limit: parseInt(limit),
        offset: parseInt(offset)
      });
    } finally {
      client5.release();
    }
  } catch (error) {
    console.error("[NotificationRoutes] Get loan notifications failed:", error);
    res.status(500).json({
      error: error.message || "Internal server error"
    });
  }
});
router16.get("/templates", async (req, res) => {
  try {
    const { channel, locale = "en-US" } = req.query;
    const client5 = await pool2.connect();
    try {
      let query = `
        SELECT code, channel, subject, version, active, created_at
        FROM notification_templates 
        WHERE locale = $1 AND active = true
      `;
      const params = [locale];
      if (channel) {
        query += " AND channel = $2";
        params.push(channel);
      }
      query += " ORDER BY code, channel";
      const result = await client5.query(query, params);
      res.json({
        templates: result.rows
      });
    } finally {
      client5.release();
    }
  } catch (error) {
    console.error("[NotificationRoutes] Get templates failed:", error);
    res.status(500).json({
      error: error.message || "Internal server error"
    });
  }
});
router16.get("/worker/status", async (req, res) => {
  try {
    const worker = getNotificationWorker();
    if (!worker) {
      return res.json({
        isRunning: false,
        error: "Worker not initialized"
      });
    }
    res.json(worker.getStatus());
  } catch (error) {
    console.error("[NotificationRoutes] Get worker status failed:", error);
    res.status(500).json({
      error: error.message || "Internal server error"
    });
  }
});
router16.post("/preview", async (req, res) => {
  try {
    const {
      template_code,
      channel,
      locale = "en-US",
      params = {}
    } = req.body;
    if (!template_code || !channel) {
      return res.status(400).json({
        error: "Missing required fields: template_code, channel"
      });
    }
    const client5 = await pool2.connect();
    try {
      const result = await client5.query(`
        SELECT subject, body, version
        FROM notification_templates 
        WHERE code = $1 AND channel = $2 AND locale = $3 AND active = true
        ORDER BY created_at DESC LIMIT 1
      `, [template_code, channel, locale]);
      if (!result.rowCount) {
        return res.status(404).json({
          error: `Template not found: ${template_code}/${channel}/${locale}`
        });
      }
      const template = result.rows[0];
      const { renderTemplate: renderTemplate2 } = await Promise.resolve().then(() => (init_template(), template_exports));
      const rendered = renderTemplate2(template.subject, template.body, params);
      res.json({
        template_code,
        channel,
        locale,
        version: template.version,
        rendered: {
          subject: rendered.subject,
          body: rendered.body
        }
      });
    } finally {
      client5.release();
    }
  } catch (error) {
    console.error("[NotificationRoutes] Preview failed:", error);
    res.status(500).json({
      error: error.message || "Internal server error"
    });
  }
});

// src/routes/storage.routes.ts
init_storage2();
import { Router as Router18 } from "express";
var router17 = Router18();
router17.get("/test", async (req, res) => {
  try {
    console.log("[Storage Routes] Testing S3 connectivity...");
    const storage4 = new AIPipelineStorageManager();
    const isConnected = await storage4.testConnection();
    if (isConnected) {
      const config = storage4.getS3Config();
      console.log("[Storage Routes] S3 connection test successful");
      res.json({
        success: true,
        message: "S3 connection successful",
        config: {
          bucket: config.bucket,
          region: config.region
        }
      });
    } else {
      console.error("[Storage Routes] S3 connection test failed");
      res.status(503).json({
        success: false,
        message: "S3 connection failed"
      });
    }
  } catch (error) {
    console.error("[Storage Routes] S3 test error:", error);
    res.status(500).json({
      success: false,
      message: "S3 test failed",
      error: error.message
    });
  }
});
router17.post("/test-upload", async (req, res) => {
  try {
    console.log("[Storage Routes] Testing S3 upload...");
    const storage4 = new AIPipelineStorageManager();
    const tenantId = "test-tenant";
    const loanId = "test-loan";
    const testContent = Buffer.from("S3 upload test file content");
    const testFile = {
      buffer: testContent,
      originalname: "test-upload.txt",
      mimetype: "text/plain"
    };
    const result = await storage4.saveUpload(
      testFile,
      tenantId,
      loanId,
      "test-upload.txt"
    );
    console.log("[Storage Routes] S3 upload test successful:", result.uri);
    res.json({
      success: true,
      message: "S3 upload test successful",
      file: {
        uri: result.uri,
        filename: result.filename,
        size: result.size,
        sha256: result.sha256
      }
    });
  } catch (error) {
    console.error("[Storage Routes] S3 upload test error:", error);
    res.status(500).json({
      success: false,
      message: "S3 upload test failed",
      error: error.message
    });
  }
});
router17.get("/test-download/:tenantId/:loanId/:docId", async (req, res) => {
  try {
    const { tenantId, loanId, docId } = req.params;
    console.log(`[Storage Routes] Testing S3 download for ${tenantId}/${loanId}/${docId}`);
    const storage4 = new AIPipelineStorageManager();
    const text2 = await storage4.getText(tenantId, loanId, docId);
    console.log("[Storage Routes] S3 download test successful");
    res.json({
      success: true,
      message: "S3 download test successful",
      content: text2
    });
  } catch (error) {
    console.error("[Storage Routes] S3 download test error:", error);
    res.status(500).json({
      success: false,
      message: "S3 download test failed",
      error: error.message
    });
  }
});
router17.post("/test-integrity", async (req, res) => {
  try {
    const { tenantId, loanId, docId, expectedSha256 } = req.body;
    if (!tenantId || !loanId || !docId || !expectedSha256) {
      return res.status(400).json({
        success: false,
        message: "Missing required parameters: tenantId, loanId, docId, expectedSha256"
      });
    }
    console.log(`[Storage Routes] Testing S3 integrity for ${tenantId}/${loanId}/${docId}`);
    const storage4 = new AIPipelineStorageManager();
    const isValid = await storage4.verifyFileIntegrity(tenantId, loanId, docId, expectedSha256);
    console.log(`[Storage Routes] S3 integrity test result: ${isValid}`);
    res.json({
      success: true,
      message: "S3 integrity test completed",
      isValid
    });
  } catch (error) {
    console.error("[Storage Routes] S3 integrity test error:", error);
    res.status(500).json({
      success: false,
      message: "S3 integrity test failed",
      error: error.message
    });
  }
});
router17.delete("/test-cleanup/:tenantId/:loanId", async (req, res) => {
  try {
    const { tenantId, loanId } = req.params;
    console.log(`[Storage Routes] Testing S3 cleanup for ${tenantId}/${loanId}`);
    const storage4 = new AIPipelineStorageManager();
    await storage4.cleanupLoanFiles(tenantId, loanId);
    console.log("[Storage Routes] S3 cleanup test successful");
    res.json({
      success: true,
      message: "S3 cleanup test successful"
    });
  } catch (error) {
    console.error("[Storage Routes] S3 cleanup test error:", error);
    res.status(500).json({
      success: false,
      message: "S3 cleanup test failed",
      error: error.message
    });
  }
});

// src/routes/metrics.routes.ts
init_metrics();
import { Router as Router19 } from "express";
var metricsRouter = Router19();
metricsRouter.get("/metrics", async (_req, res) => {
  res.set("Content-Type", "text/plain");
  res.end(await client2.register.metrics());
});

// src/monitoring/httpMetrics.ts
init_metrics();
function withHttpMetrics() {
  return (req, res, next) => {
    const start = process.hrtime.bigint();
    res.on("finish", () => {
      const dur = Number((process.hrtime.bigint() - start) / BigInt(1e9));
      httpRequestDuration.labels(req.method, req.route?.path || req.path, String(res.statusCode)).observe(dur);
    });
    next();
  };
}

// src/routes/vendor.routes.ts
import { Router as Router20 } from "express";

// src/vendors/http.ts
async function callVendor(opts) {
  const url = `${opts.base}${opts.path}`;
  const method = opts.method || "GET";
  const init = {
    method,
    headers: {
      "Content-Type": "application/json",
      ...opts.headers || {}
    },
    signal: AbortSignal.timeout(opts.timeoutMs)
  };
  if (method === "POST" && opts.body) {
    init.body = JSON.stringify(opts.body);
  }
  let lastErr;
  for (let i = 0; i <= opts.retries; i++) {
    const t0 = Date.now();
    try {
      const res = await fetch(url, init);
      const latency = Date.now() - t0;
      const text2 = await res.text();
      const json2 = safeJson(text2);
      if (!res.ok) {
        throw new Error(`${res.status} ${text2?.slice(0, 200)}`);
      }
      return { json: json2, status: res.status, latency };
    } catch (e) {
      lastErr = e;
      if (i < opts.retries) {
        await new Promise((r) => setTimeout(r, 300 * (i + 1)));
      }
    }
  }
  throw lastErr;
}
function safeJson(s) {
  try {
    return JSON.parse(s);
  } catch {
    return { raw: s };
  }
}

// src/vendors/cache.ts
import { Pool as Pool3 } from "pg";
import dayjs2 from "dayjs";
var pool3 = new Pool3({ connectionString: process.env.DATABASE_URL });
async function getCache(tenantId, vendor, key) {
  const c = await pool3.connect();
  try {
    await c.query(`SET LOCAL app.tenant_id=$1`, [tenantId]);
    const result = await c.query(
      `SELECT payload, expires_at FROM vendor_cache 
       WHERE vendor=$1 AND key=$2 AND expires_at > now()`,
      [vendor, key]
    );
    return result.rows[0]?.payload || null;
  } finally {
    c.release();
  }
}
async function putCache(tenantId, loanId, vendor, key, payload, ttlMin) {
  const c = await pool3.connect();
  try {
    await c.query(`SET LOCAL app.tenant_id=$1`, [tenantId]);
    const expiresAt = dayjs2().add(ttlMin, "minute").toISOString();
    await c.query(
      `INSERT INTO vendor_cache (tenant_id, loan_id, vendor, key, payload, expires_at)
       VALUES ($1, $2, $3, $4, $5, $6)
       ON CONFLICT (tenant_id, vendor, key) 
       DO UPDATE SET 
         payload = EXCLUDED.payload,
         expires_at = EXCLUDED.expires_at,
         cached_at = now()`,
      [tenantId, loanId, vendor, key, JSON.stringify(payload), expiresAt]
    );
  } finally {
    c.release();
  }
}
async function auditVendor(tenantId, loanId, vendor, endpoint, status, req, res, latencyMs) {
  const c = await pool3.connect();
  try {
    await c.query(`SET LOCAL app.tenant_id=$1`, [tenantId]);
    await c.query(
      `INSERT INTO vendor_audit (tenant_id, loan_id, vendor, endpoint, status, req, res, latency_ms)
       VALUES ($1, $2, $3, $4, $5, $6, $7, $8)`,
      [
        tenantId,
        loanId,
        vendor,
        endpoint,
        status,
        JSON.stringify(req || {}),
        JSON.stringify(res || {}),
        latencyMs
      ]
    );
  } finally {
    c.release();
  }
}

// src/vendors/ucdp.ts
async function getSSR(tenantId, loanId, appraisalId) {
  const key = `SSR:${appraisalId}`;
  const cached = await getCache(tenantId, "UCDP", key);
  if (cached) {
    return cached;
  }
  const startTime2 = Date.now();
  const response = await callVendor({
    base: process.env.UCDP_BASE_URL,
    path: `/ssr/${appraisalId}`,
    headers: {
      "Authorization": `Bearer ${process.env.UCDP_API_KEY}`
    },
    timeoutMs: Number(process.env.UCDP_TIMEOUT_MS || 15e3),
    retries: Number(process.env.VENDOR_MAX_RETRIES || 3)
  });
  await auditVendor(
    tenantId,
    loanId,
    "UCDP",
    `/ssr/${appraisalId}`,
    response.status,
    { appraisalId },
    response.json,
    response.latency
  );
  await putCache(
    tenantId,
    loanId,
    "UCDP",
    key,
    response.json,
    Number(process.env.VENDOR_CACHE_TTL_MIN || 1440)
  );
  return response.json;
}
async function submitAppraisal(tenantId, loanId, appraisalData) {
  const response = await callVendor({
    base: process.env.UCDP_BASE_URL,
    path: `/submit`,
    method: "POST",
    headers: {
      "Authorization": `Bearer ${process.env.UCDP_API_KEY}`
    },
    body: appraisalData,
    timeoutMs: Number(process.env.UCDP_TIMEOUT_MS || 15e3),
    retries: Number(process.env.VENDOR_MAX_RETRIES || 3)
  });
  await auditVendor(
    tenantId,
    loanId,
    "UCDP",
    `/submit`,
    response.status,
    appraisalData,
    response.json,
    response.latency
  );
  return response.json;
}

// src/vendors/flood.ts
import { createHash as createHash9 } from "crypto";
async function getFlood(tenantId, loanId, address) {
  const addressHash = createHash9("sha256").update(address.toLowerCase().trim()).digest("hex").substring(0, 16);
  const key = `FLOOD:${addressHash}`;
  const cached = await getCache(tenantId, "FLOOD", key);
  if (cached) {
    return cached;
  }
  const response = await callVendor({
    base: process.env.FLOOD_BASE_URL,
    path: `/determine/${addressHash}`,
    method: "POST",
    headers: {
      "X-API-KEY": process.env.FLOOD_API_KEY
    },
    body: {
      address,
      requestId: `${tenantId}-${Date.now()}`
    },
    timeoutMs: Number(process.env.FLOOD_TIMEOUT_MS || 12e3),
    retries: Number(process.env.VENDOR_MAX_RETRIES || 3)
  });
  await auditVendor(
    tenantId,
    loanId,
    "FLOOD",
    `/determine/${addressHash}`,
    response.status,
    { address, addressHash },
    response.json,
    response.latency
  );
  await putCache(
    tenantId,
    loanId,
    "FLOOD",
    key,
    response.json,
    Number(process.env.VENDOR_CACHE_TTL_MIN || 1440)
  );
  return response.json;
}
async function getFloodInsuranceRequirements(tenantId, loanId, floodZone, loanAmount) {
  const key = `FLOOD_REQ:${floodZone}:${loanAmount}`;
  const cached = await getCache(tenantId, "FLOOD", key);
  if (cached) {
    return cached;
  }
  const response = await callVendor({
    base: process.env.FLOOD_BASE_URL,
    path: `/requirements`,
    method: "POST",
    headers: {
      "X-API-KEY": process.env.FLOOD_API_KEY
    },
    body: {
      floodZone,
      loanAmount,
      requestId: `${tenantId}-${Date.now()}`
    },
    timeoutMs: Number(process.env.FLOOD_TIMEOUT_MS || 12e3),
    retries: Number(process.env.VENDOR_MAX_RETRIES || 3)
  });
  await auditVendor(
    tenantId,
    loanId,
    "FLOOD",
    `/requirements`,
    response.status,
    { floodZone, loanAmount },
    response.json,
    response.latency
  );
  await putCache(
    tenantId,
    loanId,
    "FLOOD",
    key,
    response.json,
    Number(process.env.VENDOR_CACHE_TTL_MIN || 1440)
  );
  return response.json;
}

// src/vendors/titleHoi.ts
async function verifyTitle(tenantId, loanId, titleFileNo) {
  const key = `TITLE:${titleFileNo}`;
  const cached = await getCache(tenantId, "TITLE", key);
  if (cached) {
    return cached;
  }
  const response = await callVendor({
    base: process.env.TITLE_BASE_URL,
    path: `/verify/title/${encodeURIComponent(titleFileNo)}`,
    headers: {
      "X-API-KEY": process.env.TITLE_API_KEY
    },
    timeoutMs: Number(process.env.TITLE_TIMEOUT_MS || 12e3),
    retries: Number(process.env.VENDOR_MAX_RETRIES || 3)
  });
  await auditVendor(
    tenantId,
    loanId,
    "TITLE",
    `/verify/title/${titleFileNo}`,
    response.status,
    { titleFileNo },
    response.json,
    response.latency
  );
  await putCache(
    tenantId,
    loanId,
    "TITLE",
    key,
    response.json,
    Number(process.env.VENDOR_CACHE_TTL_MIN || 1440)
  );
  return response.json;
}
async function verifyHOI(tenantId, loanId, policyNo) {
  const key = `HOI:${policyNo}`;
  const cached = await getCache(tenantId, "HOI", key);
  if (cached) {
    return cached;
  }
  const response = await callVendor({
    base: process.env.HOI_BASE_URL,
    path: `/verify/hoi/${encodeURIComponent(policyNo)}`,
    headers: {
      "X-API-KEY": process.env.HOI_API_KEY
    },
    timeoutMs: Number(process.env.HOI_TIMEOUT_MS || 12e3),
    retries: Number(process.env.VENDOR_MAX_RETRIES || 3)
  });
  await auditVendor(
    tenantId,
    loanId,
    "HOI",
    `/verify/hoi/${policyNo}`,
    response.status,
    { policyNo },
    response.json,
    response.latency
  );
  await putCache(
    tenantId,
    loanId,
    "HOI",
    key,
    response.json,
    Number(process.env.VENDOR_CACHE_TTL_MIN || 1440)
  );
  return response.json;
}
async function getTitleInsuranceRequirements(tenantId, loanId, loanAmount, propertyValue) {
  const key = `TITLE_REQ:${loanAmount}:${propertyValue}`;
  const cached = await getCache(tenantId, "TITLE", key);
  if (cached) {
    return cached;
  }
  const response = await callVendor({
    base: process.env.TITLE_BASE_URL,
    path: `/requirements`,
    method: "POST",
    headers: {
      "X-API-KEY": process.env.TITLE_API_KEY
    },
    body: {
      loanAmount,
      propertyValue,
      requestId: `${tenantId}-${Date.now()}`
    },
    timeoutMs: Number(process.env.TITLE_TIMEOUT_MS || 12e3),
    retries: Number(process.env.VENDOR_MAX_RETRIES || 3)
  });
  await auditVendor(
    tenantId,
    loanId,
    "TITLE",
    `/requirements`,
    response.status,
    { loanAmount, propertyValue },
    response.json,
    response.latency
  );
  await putCache(
    tenantId,
    loanId,
    "TITLE",
    key,
    response.json,
    Number(process.env.VENDOR_CACHE_TTL_MIN || 1440)
  );
  return response.json;
}

// src/routes/vendor.routes.ts
var vendorRouter = Router20();
function requireTenant(req, res, next) {
  req.tenant = { id: req.user?.tenantId || "00000000-0000-0000-0000-000000000001" };
  next();
}
vendorRouter.use(requireTenant);
vendorRouter.get("/vendor/ssr/:appraisalId", async (req, res) => {
  try {
    const json2 = await getSSR(
      req.tenant.id,
      req.query.loan_id || null,
      req.params.appraisalId
    );
    res.json(json2);
  } catch (error) {
    console.error("SSR lookup error:", error);
    res.status(500).json({
      error: "Failed to get SSR",
      message: error.message
    });
  }
});
vendorRouter.post("/vendor/ucdp/submit", async (req, res) => {
  try {
    const json2 = await submitAppraisal(
      req.tenant.id,
      req.body.loanId,
      req.body.appraisalData
    );
    res.json(json2);
  } catch (error) {
    console.error("UCDP submission error:", error);
    res.status(500).json({
      error: "Failed to submit to UCDP",
      message: error.message
    });
  }
});
vendorRouter.get("/vendor/flood/:addressHash", async (req, res) => {
  try {
    const json2 = await getFlood(
      req.tenant.id,
      req.query.loan_id || null,
      req.params.addressHash
    );
    res.json(json2);
  } catch (error) {
    console.error("Flood determination error:", error);
    res.status(500).json({
      error: "Failed to get flood determination",
      message: error.message
    });
  }
});
vendorRouter.post("/vendor/flood/determine", async (req, res) => {
  try {
    const { address, loanId } = req.body;
    const json2 = await getFlood(req.tenant.id, loanId, address);
    res.json(json2);
  } catch (error) {
    console.error("Flood determination error:", error);
    res.status(500).json({
      error: "Failed to determine flood zone",
      message: error.message
    });
  }
});
vendorRouter.post("/vendor/flood/requirements", async (req, res) => {
  try {
    const { floodZone, loanAmount, loanId } = req.body;
    const json2 = await getFloodInsuranceRequirements(
      req.tenant.id,
      loanId,
      floodZone,
      loanAmount
    );
    res.json(json2);
  } catch (error) {
    console.error("Flood requirements error:", error);
    res.status(500).json({
      error: "Failed to get flood insurance requirements",
      message: error.message
    });
  }
});
vendorRouter.get("/vendor/title/:fileNo", async (req, res) => {
  try {
    const json2 = await verifyTitle(
      req.tenant.id,
      req.query.loan_id || null,
      req.params.fileNo
    );
    res.json(json2);
  } catch (error) {
    console.error("Title verification error:", error);
    res.status(500).json({
      error: "Failed to verify title",
      message: error.message
    });
  }
});
vendorRouter.post("/vendor/title/requirements", async (req, res) => {
  try {
    const { loanAmount, propertyValue, loanId } = req.body;
    const json2 = await getTitleInsuranceRequirements(
      req.tenant.id,
      loanId,
      loanAmount,
      propertyValue
    );
    res.json(json2);
  } catch (error) {
    console.error("Title requirements error:", error);
    res.status(500).json({
      error: "Failed to get title insurance requirements",
      message: error.message
    });
  }
});
vendorRouter.get("/vendor/hoi/:policyNo", async (req, res) => {
  try {
    const json2 = await verifyHOI(
      req.tenant.id,
      req.query.loan_id || null,
      req.params.policyNo
    );
    res.json(json2);
  } catch (error) {
    console.error("HOI verification error:", error);
    res.status(500).json({
      error: "Failed to verify HOI",
      message: error.message
    });
  }
});
vendorRouter.get("/vendor/status", async (req, res) => {
  try {
    const status = {
      ucdp: {
        configured: !!(process.env.UCDP_BASE_URL && process.env.UCDP_API_KEY),
        baseUrl: process.env.UCDP_BASE_URL,
        timeout: process.env.UCDP_TIMEOUT_MS
      },
      flood: {
        configured: !!(process.env.FLOOD_BASE_URL && process.env.FLOOD_API_KEY),
        baseUrl: process.env.FLOOD_BASE_URL,
        timeout: process.env.FLOOD_TIMEOUT_MS
      },
      title: {
        configured: !!(process.env.TITLE_BASE_URL && process.env.TITLE_API_KEY),
        baseUrl: process.env.TITLE_BASE_URL,
        timeout: process.env.TITLE_TIMEOUT_MS
      },
      hoi: {
        configured: !!(process.env.HOI_BASE_URL && process.env.HOI_API_KEY),
        baseUrl: process.env.HOI_BASE_URL,
        timeout: process.env.HOI_TIMEOUT_MS
      },
      cache: {
        ttlMinutes: process.env.VENDOR_CACHE_TTL_MIN,
        maxRetries: process.env.VENDOR_MAX_RETRIES
      }
    };
    res.json(status);
  } catch (error) {
    console.error("Vendor status error:", error);
    res.status(500).json({
      error: "Failed to get vendor status",
      message: error.message
    });
  }
});

// src/routes/public.oauth.routes.ts
import { Router as Router21 } from "express";

// src/publicapi/oauth.ts
import { readFileSync } from "fs";
import jwt from "jsonwebtoken";
import { randomUUID as randomUUID7 } from "crypto";
import bcrypt from "bcryptjs";
import { Pool as Pool4 } from "pg";
var pool4 = new Pool4({ connectionString: process.env.DATABASE_URL });
function getPrivateKey() {
  const keyPath = process.env.OAUTH_JWT_PRIVATE_PEM_PATH;
  if (!keyPath) {
    return process.env.OAUTH_JWT_PRIVATE_KEY || "development-jwt-secret-key";
  }
  return readFileSync(keyPath, "utf-8");
}
var PRIVATE_KEY = getPrivateKey();
var KID = process.env.OAUTH_JWT_SIGNING_KID || "api-key-1";
var ISSUER = process.env.OAUTH_ISSUER || "loanserve-auth";
async function tokenEndpoint(req, res) {
  try {
    const { client_id, client_secret, grant_type, scope } = req.body || {};
    if (grant_type !== "client_credentials") {
      return res.status(400).json({
        error: "unsupported_grant_type",
        error_description: "Only client_credentials grant type is supported"
      });
    }
    if (!client_id || !client_secret) {
      return res.status(400).json({
        error: "invalid_request",
        error_description: "client_id and client_secret are required"
      });
    }
    const c = await pool4.connect();
    try {
      const result = await c.query(
        `SELECT * FROM api_clients WHERE client_id=$1 AND active=true`,
        [client_id]
      );
      if (!result.rowCount) {
        return res.status(401).json({
          error: "invalid_client",
          error_description: "Client authentication failed"
        });
      }
      const client5 = result.rows[0];
      const secretValid = await bcrypt.compare(client_secret, client5.client_secret_hash);
      if (!secretValid) {
        return res.status(401).json({
          error: "invalid_client",
          error_description: "Client authentication failed"
        });
      }
      const requestedScopes = scope ? scope.split(" ") : client5.scopes;
      const grantedScopes = requestedScopes.filter((s) => client5.scopes.includes(s));
      if (grantedScopes.length === 0) {
        return res.status(400).json({
          error: "invalid_scope",
          error_description: "Requested scope is not authorized for this client"
        });
      }
      const now = Math.floor(Date.now() / 1e3);
      const payload = {
        iss: ISSUER,
        aud: "loanserve-public-api",
        sub: client5.client_id,
        scope: grantedScopes.join(" "),
        "https://loanserve.io/tenant_id": client5.tenant_id,
        "https://loanserve.io/client_name": client5.client_name,
        iat: now,
        exp: now + 3600,
        // 1 hour
        jti: randomUUID7()
      };
      const token = jwt.sign(payload, PRIVATE_KEY, {
        algorithm: "RS256",
        keyid: KID
      });
      res.json({
        access_token: token,
        token_type: "Bearer",
        expires_in: 3600,
        scope: grantedScopes.join(" ")
      });
    } finally {
      c.release();
    }
  } catch (error) {
    console.error("OAuth token error:", error);
    res.status(500).json({
      error: "server_error",
      error_description: "Internal server error"
    });
  }
}
async function createApiClient(tenantId, clientName, scopes = ["read"]) {
  const clientId = `client_${randomUUID7().replace(/-/g, "")}`;
  const clientSecret = randomUUID7();
  const clientSecretHash = await bcrypt.hash(clientSecret, 12);
  const c = await pool4.connect();
  try {
    await c.query(
      `INSERT INTO api_clients (tenant_id, client_id, client_name, client_secret_hash, scopes)
       VALUES ($1, $2, $3, $4, $5)`,
      [tenantId, clientId, clientName, clientSecretHash, scopes]
    );
    return { clientId, clientSecret };
  } finally {
    c.release();
  }
}

// src/routes/public.oauth.routes.ts
var publicOAuthRouter = Router21();
publicOAuthRouter.post("/oauth/token", tokenEndpoint);
publicOAuthRouter.get("/.well-known/oauth-authorization-server", (req, res) => {
  const baseUrl = process.env.PUBLIC_API_BASE || `${req.protocol}://${req.get("host")}`;
  res.json({
    issuer: process.env.OAUTH_ISSUER || "loanserve-auth",
    token_endpoint: `${baseUrl}/public/oauth/token`,
    token_endpoint_auth_methods_supported: ["client_secret_post"],
    grant_types_supported: ["client_credentials"],
    response_types_supported: [],
    scopes_supported: ["read", "write", "admin"],
    token_endpoint_auth_signing_alg_values_supported: ["RS256"]
  });
});

// src/routes/public.api.routes.ts
import { Router as Router22 } from "express";
import jwt2 from "jsonwebtoken";
import { Pool as Pool5 } from "pg";
var pool5 = new Pool5({ connectionString: process.env.DATABASE_URL });
var publicApiRouter = Router22();
function jwtAuth(req, res, next) {
  const authHeader = req.headers.authorization;
  if (!authHeader || !authHeader.startsWith("Bearer ")) {
    return res.status(401).json({
      error: "unauthorized",
      message: "Bearer token required"
    });
  }
  const token = authHeader.substring(7);
  try {
    const publicKey = process.env.OAUTH_JWT_PUBLIC_KEY || process.env.OAUTH_JWT_PRIVATE_KEY || "development-jwt-secret-key";
    const decoded = jwt2.verify(token, publicKey, {
      algorithms: ["RS256", "HS256"],
      audience: "loanserve-public-api"
    });
    req.tenant = {
      id: decoded["https://loanserve.io/tenant_id"],
      clientId: decoded.sub,
      clientName: decoded["https://loanserve.io/client_name"],
      scopes: decoded.scope ? decoded.scope.split(" ") : []
    };
    next();
  } catch (error) {
    console.error("JWT verification error:", error);
    res.status(401).json({
      error: "unauthorized",
      message: "Invalid or expired token"
    });
  }
}
function requireScope(scope) {
  return (req, res, next) => {
    if (!req.tenant?.scopes?.includes(scope)) {
      return res.status(403).json({
        error: "insufficient_scope",
        message: `Scope '${scope}' required`
      });
    }
    next();
  };
}
publicApiRouter.use(jwtAuth);
publicApiRouter.get("/v1/loans", requireScope("read"), async (req, res) => {
  try {
    const c = await pool5.connect();
    try {
      await c.query(`SET LOCAL app.tenant_id=$1`, [req.tenant.id]);
      const { page = 1, limit = 50 } = req.query;
      const offset = (parseInt(page) - 1) * parseInt(limit);
      const result = await c.query(
        `SELECT id, loan_number, borrower_name, principal_balance, status, created_at
         FROM loans 
         ORDER BY created_at DESC 
         LIMIT $1 OFFSET $2`,
        [parseInt(limit), offset]
      );
      const countResult = await c.query(`SELECT COUNT(*) FROM loans`);
      const total = parseInt(countResult.rows[0].count);
      res.json({
        data: result.rows,
        pagination: {
          page: parseInt(page),
          limit: parseInt(limit),
          total,
          pages: Math.ceil(total / parseInt(limit))
        }
      });
    } finally {
      c.release();
    }
  } catch (error) {
    console.error("Loans API error:", error);
    res.status(500).json({
      error: "server_error",
      message: "Failed to retrieve loans"
    });
  }
});
publicApiRouter.get("/v1/loans/:id", requireScope("read"), async (req, res) => {
  try {
    const c = await pool5.connect();
    try {
      await c.query(`SET LOCAL app.tenant_id=$1`, [req.tenant.id]);
      const result = await c.query(
        `SELECT * FROM loans WHERE id = $1`,
        [req.params.id]
      );
      if (!result.rowCount) {
        return res.status(404).json({
          error: "not_found",
          message: "Loan not found"
        });
      }
      res.json({ data: result.rows[0] });
    } finally {
      c.release();
    }
  } catch (error) {
    console.error("Loan API error:", error);
    res.status(500).json({
      error: "server_error",
      message: "Failed to retrieve loan"
    });
  }
});
publicApiRouter.get("/v1/loans/:id/payments", requireScope("read"), async (req, res) => {
  try {
    const c = await pool5.connect();
    try {
      await c.query(`SET LOCAL app.tenant_id=$1`, [req.tenant.id]);
      const { page = 1, limit = 50 } = req.query;
      const offset = (parseInt(page) - 1) * parseInt(limit);
      const result = await c.query(
        `SELECT id, amount, payment_date, status, channel, created_at
         FROM payments 
         WHERE loan_id = $1
         ORDER BY payment_date DESC 
         LIMIT $2 OFFSET $3`,
        [req.params.id, parseInt(limit), offset]
      );
      res.json({ data: result.rows });
    } finally {
      c.release();
    }
  } catch (error) {
    console.error("Payments API error:", error);
    res.status(500).json({
      error: "server_error",
      message: "Failed to retrieve payments"
    });
  }
});
publicApiRouter.get("/v1/loans/:id/documents", requireScope("read"), async (req, res) => {
  try {
    const c = await pool5.connect();
    try {
      await c.query(`SET LOCAL app.tenant_id=$1`, [req.tenant.id]);
      const result = await c.query(
        `SELECT id, filename, document_type, uploaded_at, file_size
         FROM documents 
         WHERE loan_id = $1
         ORDER BY uploaded_at DESC`,
        [req.params.id]
      );
      res.json({ data: result.rows });
    } finally {
      c.release();
    }
  } catch (error) {
    console.error("Documents API error:", error);
    res.status(500).json({
      error: "server_error",
      message: "Failed to retrieve documents"
    });
  }
});
publicApiRouter.get("/v1/info", (req, res) => {
  res.json({
    api_version: "1.0.0",
    tenant_id: req.tenant.id,
    client_id: req.tenant.clientId,
    client_name: req.tenant.clientName,
    scopes: req.tenant.scopes,
    endpoints: [
      "GET /v1/loans",
      "GET /v1/loans/:id",
      "GET /v1/loans/:id/payments",
      "GET /v1/loans/:id/documents"
    ]
  });
});

// src/routes/admin.api.routes.ts
import { Router as Router23 } from "express";

// src/publicapi/auth.ts
import { Pool as Pool6 } from "pg";
import { createHmac as createHmac3, randomUUID as randomUUID8 } from "crypto";
import dayjs3 from "dayjs";
import bcrypt2 from "bcryptjs";
var pool6 = new Pool6({ connectionString: process.env.DATABASE_URL });
async function createApiKey(tenantId, label, ttlDays = Number(process.env.API_KEY_TTL_DAYS) || 365) {
  const keyId = `key_${randomUUID8().replace(/-/g, "")}`;
  const apiKey = randomUUID8();
  const keyHash = await bcrypt2.hash(apiKey, 12);
  const expiresAt = dayjs3().add(ttlDays, "day").toISOString();
  const c = await pool6.connect();
  try {
    await c.query(
      `INSERT INTO api_keys (tenant_id, label, key_id, key_hash, expires_at)
       VALUES ($1, $2, $3, $4, $5)`,
      [tenantId, label, keyId, keyHash, expiresAt]
    );
    return { keyId, apiKey };
  } finally {
    c.release();
  }
}
async function cleanupRateLimitWindows() {
  const c = await pool6.connect();
  try {
    const cutoff = dayjs3().subtract(1, "hour").toISOString();
    await c.query(
      `DELETE FROM api_rate WHERE window_start < $1`,
      [cutoff]
    );
  } finally {
    c.release();
  }
}

// src/routes/admin.api.routes.ts
import { Pool as Pool7 } from "pg";
var pool7 = new Pool7({ connectionString: process.env.DATABASE_URL });
var adminApiRouter = Router23();
function requireAdmin2(req, res, next) {
  if (!req.user) {
    return res.status(401).json({ error: "Authentication required" });
  }
  if (!req.user.isAdmin) {
    return res.status(403).json({ error: "Admin access required" });
  }
  next();
}
function getTenantId(req) {
  return req.user?.tenantId || "00000000-0000-0000-0000-000000000001";
}
adminApiRouter.get("/admin/api-clients", requireAdmin2, async (req, res) => {
  try {
    const tenantId = getTenantId(req);
    const c = await pool7.connect();
    try {
      const result = await c.query(
        `SELECT id, client_id, client_name, scopes, active, created_at
         FROM api_clients 
         WHERE tenant_id = $1
         ORDER BY created_at DESC`,
        [tenantId]
      );
      res.json({ data: result.rows });
    } finally {
      c.release();
    }
  } catch (error) {
    console.error("Admin API clients error:", error);
    res.status(500).json({ error: "Failed to retrieve API clients" });
  }
});
adminApiRouter.post("/admin/api-clients", requireAdmin2, async (req, res) => {
  try {
    const tenantId = getTenantId(req);
    const { clientName, scopes = ["read"] } = req.body;
    if (!clientName) {
      return res.status(400).json({ error: "clientName is required" });
    }
    const { clientId, clientSecret } = await createApiClient(tenantId, clientName, scopes);
    res.status(201).json({
      client_id: clientId,
      client_secret: clientSecret,
      client_name: clientName,
      scopes,
      message: "Store the client_secret securely - it will not be shown again"
    });
  } catch (error) {
    console.error("Create API client error:", error);
    res.status(500).json({ error: "Failed to create API client" });
  }
});
adminApiRouter.patch("/admin/api-clients/:clientId", requireAdmin2, async (req, res) => {
  try {
    const tenantId = getTenantId(req);
    const { clientId } = req.params;
    const { active, scopes } = req.body;
    const c = await pool7.connect();
    try {
      const updates = [];
      const values = [tenantId, clientId];
      let paramIndex = 3;
      if (typeof active === "boolean") {
        updates.push(`active = $${paramIndex++}`);
        values.push(active);
      }
      if (Array.isArray(scopes)) {
        updates.push(`scopes = $${paramIndex++}`);
        values.push(scopes);
      }
      if (updates.length === 0) {
        return res.status(400).json({ error: "No valid updates provided" });
      }
      const result = await c.query(
        `UPDATE api_clients SET ${updates.join(", ")} 
         WHERE tenant_id = $1 AND client_id = $2
         RETURNING id, client_id, client_name, scopes, active`,
        values
      );
      if (!result.rowCount) {
        return res.status(404).json({ error: "API client not found" });
      }
      res.json({ data: result.rows[0] });
    } finally {
      c.release();
    }
  } catch (error) {
    console.error("Update API client error:", error);
    res.status(500).json({ error: "Failed to update API client" });
  }
});
adminApiRouter.get("/admin/api-keys", requireAdmin2, async (req, res) => {
  try {
    const tenantId = getTenantId(req);
    const c = await pool7.connect();
    try {
      const result = await c.query(
        `SELECT id, key_id, label, expires_at, active, created_at
         FROM api_keys 
         WHERE tenant_id = $1
         ORDER BY created_at DESC`,
        [tenantId]
      );
      res.json({ data: result.rows });
    } finally {
      c.release();
    }
  } catch (error) {
    console.error("Admin API keys error:", error);
    res.status(500).json({ error: "Failed to retrieve API keys" });
  }
});
adminApiRouter.post("/admin/api-keys", requireAdmin2, async (req, res) => {
  try {
    const tenantId = getTenantId(req);
    const { label, ttlDays } = req.body;
    if (!label) {
      return res.status(400).json({ error: "label is required" });
    }
    const { keyId, apiKey } = await createApiKey(tenantId, label, ttlDays);
    res.status(201).json({
      key_id: keyId,
      api_key: apiKey,
      label,
      message: "Store the api_key securely - it will not be shown again"
    });
  } catch (error) {
    console.error("Create API key error:", error);
    res.status(500).json({ error: "Failed to create API key" });
  }
});
adminApiRouter.patch("/admin/api-keys/:keyId", requireAdmin2, async (req, res) => {
  try {
    const tenantId = getTenantId(req);
    const { keyId } = req.params;
    const { active } = req.body;
    if (typeof active !== "boolean") {
      return res.status(400).json({ error: "active (boolean) is required" });
    }
    const c = await pool7.connect();
    try {
      const result = await c.query(
        `UPDATE api_keys SET active = $3 
         WHERE tenant_id = $1 AND key_id = $2
         RETURNING id, key_id, label, expires_at, active`,
        [tenantId, keyId, active]
      );
      if (!result.rowCount) {
        return res.status(404).json({ error: "API key not found" });
      }
      res.json({ data: result.rows[0] });
    } finally {
      c.release();
    }
  } catch (error) {
    console.error("Update API key error:", error);
    res.status(500).json({ error: "Failed to update API key" });
  }
});
adminApiRouter.get("/admin/rate-limits", requireAdmin2, async (req, res) => {
  try {
    const tenantId = getTenantId(req);
    const c = await pool7.connect();
    try {
      const result = await c.query(
        `SELECT key_id, COUNT(*) as windows, SUM(count) as total_requests
         FROM api_rate 
         WHERE tenant_id = $1 AND window_start >= now() - interval '1 hour'
         GROUP BY key_id
         ORDER BY total_requests DESC`,
        [tenantId]
      );
      res.json({ data: result.rows });
    } finally {
      c.release();
    }
  } catch (error) {
    console.error("Rate limits error:", error);
    res.status(500).json({ error: "Failed to retrieve rate limits" });
  }
});
adminApiRouter.post("/admin/rate-limits/cleanup", requireAdmin2, async (req, res) => {
  try {
    await cleanupRateLimitWindows();
    res.json({ message: "Rate limit windows cleaned up successfully" });
  } catch (error) {
    console.error("Rate limit cleanup error:", error);
    res.status(500).json({ error: "Failed to cleanup rate limits" });
  }
});
adminApiRouter.get("/admin/api-usage", requireAdmin2, async (req, res) => {
  try {
    const tenantId = getTenantId(req);
    const { hours = 24 } = req.query;
    const c = await pool7.connect();
    try {
      const result = await c.query(
        `SELECT 
           date_trunc('hour', window_start) as hour,
           SUM(count) as requests
         FROM api_rate 
         WHERE tenant_id = $1 AND window_start >= now() - interval '${parseInt(hours)} hours'
         GROUP BY date_trunc('hour', window_start)
         ORDER BY hour DESC`,
        [tenantId]
      );
      res.json({ data: result.rows });
    } finally {
      c.release();
    }
  } catch (error) {
    console.error("API usage error:", error);
    res.status(500).json({ error: "Failed to retrieve API usage" });
  }
});

// server/routes.ts
init_schema();
init_middleware();
init_policy_engine();

// server/utils/error-handler.ts
import { ZodError } from "zod";
var AppError = class extends Error {
  constructor(message, code, statusCode = 500, details) {
    super(message);
    this.message = message;
    this.code = code;
    this.statusCode = statusCode;
    this.details = details;
    this.name = "AppError";
    Error.captureStackTrace(this, this.constructor);
  }
};
function mapDatabaseError(error) {
  const errorCode = error.code || error.errno;
  switch (errorCode) {
    case "23505":
      return {
        message: "This record already exists. Please use a different value.",
        code: "DUPLICATE_ENTRY" /* DUPLICATE_ENTRY */
      };
    case "23503":
      return {
        message: "This operation references data that does not exist.",
        code: "FOREIGN_KEY_VIOLATION" /* FOREIGN_KEY_VIOLATION */
      };
    case "23502":
      return {
        message: "Required information is missing. Please provide all required fields.",
        code: "MISSING_REQUIRED_FIELD" /* MISSING_REQUIRED_FIELD */
      };
    case "42P01":
    // Undefined table
    case "42703":
      console.error("Database schema error:", error);
      return {
        message: "A system configuration error occurred. Please contact support.",
        code: "DATABASE_ERROR" /* DATABASE_ERROR */
      };
    default:
      return {
        message: "A database error occurred. Please try again.",
        code: "DATABASE_ERROR" /* DATABASE_ERROR */
      };
  }
}
function mapZodError(error) {
  const fields = {};
  error.issues.forEach((issue) => {
    const path11 = issue.path.join(".");
    if (!fields[path11]) {
      fields[path11] = [];
    }
    let message2 = issue.message;
    switch (issue.code) {
      case "invalid_type":
        message2 = `Invalid format. Expected ${issue.expected}.`;
        break;
      case "invalid_string":
        if (issue.validation === "email") {
          message2 = "Please enter a valid email address.";
        } else if (issue.validation === "url") {
          message2 = "Please enter a valid URL.";
        } else if (issue.validation === "uuid") {
          message2 = "Invalid identifier format.";
        }
        break;
      case "too_small":
        if (issue.type === "string") {
          message2 = `Must be at least ${issue.minimum} characters.`;
        } else if (issue.type === "number") {
          message2 = `Must be at least ${issue.minimum}.`;
        }
        break;
      case "too_big":
        if (issue.type === "string") {
          message2 = `Must be at most ${issue.maximum} characters.`;
        } else if (issue.type === "number") {
          message2 = `Must be at most ${issue.maximum}.`;
        }
        break;
    }
    fields[path11].push(message2);
  });
  const fieldCount = Object.keys(fields).length;
  const message = fieldCount === 1 ? fields[Object.keys(fields)[0]][0] : `Please correct ${fieldCount} validation errors.`;
  return { message, fields };
}
function handleError2(error, res, requestId) {
  console.error("Error details:", {
    message: error.message,
    stack: error.stack,
    code: error.code,
    requestId
  });
  let statusCode = 500;
  let errorCode = "INTERNAL_ERROR" /* INTERNAL_ERROR */;
  let message = "An unexpected error occurred. Please try again.";
  let details = void 0;
  if (error instanceof AppError) {
    statusCode = error.statusCode;
    errorCode = error.code;
    message = error.message;
    details = error.details;
  } else if (error instanceof ZodError) {
    statusCode = 400;
    errorCode = "VALIDATION_ERROR" /* VALIDATION_ERROR */;
    const mapped = mapZodError(error);
    message = mapped.message;
    details = { fields: mapped.fields };
  } else if (error.code && typeof error.code === "string" && error.code.startsWith("2")) {
    const mapped = mapDatabaseError(error);
    statusCode = 400;
    errorCode = mapped.code;
    message = mapped.message;
  } else if (error.message) {
    if (error.message.includes("not found")) {
      statusCode = 404;
      errorCode = "NOT_FOUND" /* NOT_FOUND */;
      message = "The requested resource was not found.";
    } else if (error.message.includes("unauthorized") || error.message.includes("authentication")) {
      statusCode = 401;
      errorCode = "UNAUTHORIZED" /* UNAUTHORIZED */;
      message = "Authentication required. Please log in.";
    } else if (error.message.includes("forbidden") || error.message.includes("permission")) {
      statusCode = 403;
      errorCode = "FORBIDDEN" /* FORBIDDEN */;
      message = "You do not have permission to perform this action.";
    } else if (error.message.includes("timeout")) {
      statusCode = 408;
      errorCode = "REQUEST_TIMEOUT" /* REQUEST_TIMEOUT */;
      message = "The request took too long to process. Please try again.";
    } else if (error.message.includes("rate limit")) {
      statusCode = 429;
      errorCode = "RATE_LIMIT_EXCEEDED" /* RATE_LIMIT_EXCEEDED */;
      message = "Too many requests. Please slow down and try again.";
    }
  }
  const response = {
    error: message,
    code: errorCode,
    timestamp: (/* @__PURE__ */ new Date()).toISOString(),
    requestId
  };
  if (process.env.NODE_ENV === "development" || errorCode === "VALIDATION_ERROR" /* VALIDATION_ERROR */) {
    response.details = details;
  }
  return res.status(statusCode).json(response);
}
function asyncHandler2(fn) {
  return (req, res, next) => {
    const requestId = req.headers["x-request-id"] || `req-${Date.now()}`;
    Promise.resolve(fn(req, res, next)).catch((error) => handleError2(error, res, requestId));
  };
}
function validateInput(schema, data, errorMessage = "Invalid input") {
  try {
    return schema.parse(data);
  } catch (error) {
    if (error instanceof ZodError) {
      const mapped = mapZodError(error);
      throw new AppError(
        mapped.message,
        "VALIDATION_ERROR" /* VALIDATION_ERROR */,
        400,
        { fields: mapped.fields }
      );
    }
    throw error;
  }
}
function successResponse(res, data, statusCode = 200) {
  return res.status(statusCode).json({
    success: true,
    data,
    timestamp: (/* @__PURE__ */ new Date()).toISOString()
  });
}

// server/routes.ts
function isAuthenticated2(req, res, next) {
  if (req.isAuthenticated()) {
    return next();
  }
  res.status(401).json({ error: "Unauthorized" });
}
var uploadStorage = multer4.diskStorage({
  destination: async function(req, file, cb) {
    const uploadDir = "server/uploads";
    try {
      await fs7.mkdir(uploadDir, { recursive: true });
    } catch (error) {
      console.error("Error creating upload directory:", error);
    }
    cb(null, uploadDir);
  },
  filename: function(req, file, cb) {
    try {
      const secureFilename = generateSecureFilename(file.originalname);
      cb(null, secureFilename);
    } catch (error) {
      console.error("Error generating secure filename:", error);
      const timestamp2 = Date.now();
      const randomSuffix = Math.round(Math.random() * 1e9);
      const sanitized = file.originalname.replace(/[^a-zA-Z0-9.-]/g, "_");
      cb(null, `file_${timestamp2}_${randomSuffix}_${sanitized}`);
    }
  }
});
var upload4 = multer4({
  storage: uploadStorage,
  limits: {
    fileSize: 10 * 1024 * 1024,
    // 10MB limit
    files: 1
    // Single file upload
  },
  fileFilter: function(req, file, cb) {
    const allowedMimeTypes = [
      "application/pdf",
      "application/msword",
      "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
      "application/vnd.ms-excel",
      "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
      "text/plain",
      "text/csv",
      "application/csv",
      "image/png",
      "image/jpeg",
      "image/gif",
      "image/tiff",
      "image/bmp",
      "application/zip",
      "application/x-rar-compressed",
      "application/x-7z-compressed"
    ];
    if (allowedMimeTypes.includes(file.mimetype)) {
      cb(null, true);
    } else {
      cb(new Error(`File type '${file.mimetype}' is not allowed`));
    }
  }
});
async function registerRoutes(app2) {
  const healthRoutes = (await Promise.resolve().then(() => (init_health(), health_exports))).default;
  app2.use("/healthz", healthRoutes);
  app2.use("/", metrics_default);
  const columnWebhookHandler = await Promise.resolve().then(() => (init_webhook_column(), webhook_column_exports));
  app2.use(columnWebhookHandler.default);
  await setupAuth(app2);
  app2.use(withHttpMetrics());
  app2.use(loadUserPolicy);
  app2.use("/api", applyPIIMasking());
  app2.use("/api/auth", auth_default);
  app2.use("/api/admin/users", router3);
  app2.use("/api/ip-allowlist", router4);
  app2.use("/api", router9);
  app2.use("/api", phase10_routes_default);
  app2.use("/api", router11);
  app2.use("/api", router12);
  app2.use("/api", rabbitmq_config_default);
  app2.use("/api/mfa", mfa_default);
  app2.use("/api", crm_default);
  app2.use("/api/crm/emails", email_routes_default);
  app2.use("/api/communication-preferences", communication_preferences_default);
  registerBorrowerRoutes(app2);
  app2.use("/api", payment_routes_default);
  const paymentAsyncRoutes = (await Promise.resolve().then(() => (init_payment_async(), payment_async_exports))).default;
  app2.use("/api/v2", paymentAsyncRoutes);
  const queueHealthRoutes = (await Promise.resolve().then(() => (init_queue_health(), queue_health_exports))).default;
  app2.use("/api", queueHealthRoutes);
  const microserviceApiRoutes = (await Promise.resolve().then(() => (init_microservice_api(), microservice_api_exports))).default;
  app2.use("/api", microserviceApiRoutes);
  const columnWebhookRoutes = await Promise.resolve().then(() => (init_column_webhooks(), column_webhooks_exports));
  app2.use("/api", columnWebhookRoutes.default);
  const complianceRoutes = await Promise.resolve().then(() => (init_compliance2(), compliance_exports2));
  app2.use(complianceRoutes.default);
  const complianceConsoleRoutes = await Promise.resolve().then(() => (init_compliance_console(), compliance_console_exports));
  app2.use("/api/compliance", complianceConsoleRoutes.default);
  console.log("[Routes] Registered compliance console routes");
  const beneficiaryRoutes = await Promise.resolve().then(() => (init_beneficiary_routes(), beneficiary_routes_exports));
  app2.use("/api", beneficiaryRoutes.default);
  console.log("[Routes] Registered beneficiary audit routes");
  const investorRoutes = await Promise.resolve().then(() => (init_investor_routes(), investor_routes_exports));
  app2.use("/api", investorRoutes.default);
  console.log("[Routes] Registered investor audit routes");
  console.log("[Routes] Registered Column banking routes");
  const paymentIngestionRoutes = (await Promise.resolve().then(() => (init_payment_ingestion2(), payment_ingestion_exports))).default;
  app2.use("/api/payment-ingestions", paymentIngestionRoutes);
  const paymentArtifactRoutes = (await Promise.resolve().then(() => (init_payment_artifact2(), payment_artifact_exports))).default;
  app2.use("/api/payment-artifacts", paymentArtifactRoutes);
  const paymentEventRoutes = (await Promise.resolve().then(() => (init_payment_event2(), payment_event_exports))).default;
  app2.use("/api/payment-events", paymentEventRoutes);
  const enhancedPaymentRoutes = (await Promise.resolve().then(() => (init_payments(), payments_exports))).default;
  app2.use("/api", enhancedPaymentRoutes);
  const queueMonitorRoutes = (await Promise.resolve().then(() => (init_queue_monitor_routes(), queue_monitor_routes_exports))).default;
  app2.use("/api/queue-monitor", queueMonitorRoutes);
  const dlqRoutes = (await Promise.resolve().then(() => (init_dlq_routes(), dlq_routes_exports))).default;
  app2.use("/api", dlqRoutes);
  const { escrowRoutes } = await Promise.resolve().then(() => (init_routes(), routes_exports));
  app2.use("/api/escrow", escrowRoutes);
  console.log("[Routes] Registered escrow subsystem routes");
  const documentRoutes = (await Promise.resolve().then(() => (init_routes2(), routes_exports2))).default;
  app2.use(documentRoutes);
  console.log("[Routes] Registered document generation routes");
  const { registerCashRoutes: registerCashRoutes2 } = await Promise.resolve().then(() => (init_routes3(), routes_exports3));
  const { pool: pool17 } = await Promise.resolve().then(() => (init_db(), db_exports));
  registerCashRoutes2(app2, pool17);
  console.log("[Routes] Registered cash management routes");
  const { createRemittanceRoutes: createRemittanceRoutes2 } = await Promise.resolve().then(() => (init_routes4(), routes_exports4));
  app2.use("/api/remittance", createRemittanceRoutes2(pool17));
  console.log("[Routes] Registered investor remittance routes");
  try {
    const { initializeSecurity: initializeSecurity2, validateSecurityConfig: validateSecurityConfig2 } = await Promise.resolve().then(() => (init_integration(), integration_exports));
    const securityValidation = validateSecurityConfig2();
    if (!securityValidation.valid) {
      console.warn("[Security] Configuration warnings:", securityValidation.errors);
    } else {
      console.log("[Security] \u2705 All security configurations validated");
    }
    await initializeSecurity2(app2);
    console.log("[Routes] Security hardening initialized");
  } catch (error) {
    console.error("[Routes] Failed to initialize security hardening:", error);
    console.log("[Routes] Application will continue without enhanced security features");
  }
  try {
    console.log("[Routes] Registering finalization routes...");
    const { finalizeRouter: finalizeRouter2 } = await Promise.resolve().then(() => (init_routes6(), routes_exports5));
    app2.use(finalizeRouter2);
    console.log("[Routes] Finalization routes registered");
  } catch (error) {
    console.error("[Routes] Failed to register finalization routes:", error);
    console.warn("[Routes] Finalization features will not be available");
  }
  try {
    console.log("[Routes] Registering servicing routes...");
    const { servicingRouter: servicingRouter2 } = await Promise.resolve().then(() => (init_servicing_routes(), servicing_routes_exports));
    app2.use("/api", servicingRouter2);
    console.log("[Routes] Servicing routes registered");
  } catch (error) {
    console.error("[Routes] Failed to register servicing routes:", error);
    console.warn("[Routes] Servicing features will not be available");
  }
  app2.get("/observability", (req, res) => {
    res.sendFile(path5.join(process.cwd(), "server/observability/dashboard-ui.html"));
  });
  app2.get("/api/observability/dashboard-data", async (req, res) => {
    try {
      const { getQueueStats: getQueueStats2, getOutboxStats: getOutboxStats2, getReconcileStats: getReconcileStats2, getPaymentStats: getPaymentStats2 } = await Promise.resolve().then(() => (init_metrics_collector(), metrics_collector_exports));
      const [queueStats, outboxStats, reconcileStats, paymentStats] = await Promise.all([
        getQueueStats2(),
        getOutboxStats2(),
        getReconcileStats2(),
        getPaymentStats2()
      ]);
      const totalQueueDepth = Object.values(queueStats.queues).reduce((sum3, depth) => sum3 + (depth || 0), 0);
      const totalDlqDepth = Object.values(queueStats.dlqs).reduce((sum3, depth) => sum3 + (depth || 0), 0);
      const totalPayments = paymentStats.total;
      const successfulPayments = paymentStats.byStatus["completed"] || 0;
      const successRate = totalPayments > 0 ? (successfulPayments / totalPayments * 100).toFixed(1) : "100.0";
      const now = /* @__PURE__ */ new Date();
      const labels = [];
      for (let i = 59; i >= 0; i--) {
        const time2 = new Date(now.getTime() - i * 6e4);
        labels.push(time2.toLocaleTimeString("en-US", { hour: "2-digit", minute: "2-digit" }));
      }
      const queueHistory = labels.map(() => Math.max(0, totalQueueDepth + Math.floor(Math.random() * 20) - 10));
      const dlqHistory = labels.map(() => Math.max(0, totalDlqDepth + Math.floor(Math.random() * 5) - 2));
      const dashboardData = {
        queueDepth: totalQueueDepth,
        dlqRate: totalDlqDepth,
        processLatency: Math.floor(outboxStats.maxLag * 1e3),
        // Convert to ms
        outboxLag: Math.floor(outboxStats.maxLag),
        reconcileVariance: Math.floor(reconcileStats.totalVariance),
        successRate,
        queueHistory,
        latencyPercentiles: [150, 250, 400, 600, 1200],
        // Simplified percentiles
        processingHistory: {
          processed: labels.map(() => successfulPayments + Math.floor(Math.random() * 50)),
          failed: labels.map(() => (paymentStats.byStatus["failed"] || 0) + Math.floor(Math.random() * 10))
        },
        dlqHistory,
        labels,
        metadata: {
          timestamp: now.toISOString(),
          totalQueues: Object.keys(queueStats.queues).length,
          outboxPending: outboxStats.pending,
          reconcileExceptions: reconcileStats.exceptionCount
        }
      };
      res.json(dashboardData);
    } catch (error) {
      console.error("[Observability] Failed to get dashboard data:", error);
      res.status(500).json({ error: "Failed to retrieve dashboard data" });
    }
  });
  app2.get(
    "/api/borrowers",
    requireAuth2,
    requirePermission("Loans", "read" /* Read */),
    async (req, res) => {
      try {
        const borrowers = await storage.getBorrowerEntities();
        res.json(borrowers);
      } catch (error) {
        console.error("Error fetching borrowers:", error);
        res.status(500).json({ error: "Failed to fetch borrowers" });
      }
    }
  );
  app2.get("/api/borrowers/:id", async (req, res) => {
    try {
      const borrower = await storage.getBorrowerEntity(parseInt(req.params.id));
      if (!borrower) {
        return res.status(404).json({ error: "Borrower not found" });
      }
      res.json(borrower);
    } catch (error) {
      console.error("Error fetching borrower:", error);
      res.status(500).json({ error: "Failed to fetch borrower" });
    }
  });
  app2.post("/api/borrowers", isAuthenticated2, async (req, res) => {
    try {
      const validatedData = insertBorrowerEntitySchema.parse(req.body);
      const borrower = await storage.createBorrowerEntity(validatedData);
      await complianceAudit.logEvent({
        actorType: "user",
        actorId: req.user?.id,
        eventType: COMPLIANCE_EVENTS.BORROWER.CREATED,
        resourceType: "borrower",
        resourceId: borrower.id,
        newValues: borrower,
        ipAddr: getRealUserIP(req),
        userAgent: req.headers["user-agent"]
      });
      res.status(201).json(borrower);
    } catch (error) {
      console.error("Error creating borrower:", error);
      res.status(400).json({ error: "Invalid borrower data" });
    }
  });
  app2.put("/api/borrowers/:id", isAuthenticated2, async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      const existingBorrower = await storage.getBorrowerEntity(id);
      if (!existingBorrower) {
        return res.status(404).json({ error: "Borrower not found" });
      }
      const borrower = await storage.updateBorrowerEntity(id, req.body);
      await complianceAudit.logEvent({
        actorType: "user",
        actorId: req.user?.id,
        eventType: COMPLIANCE_EVENTS.BORROWER.UPDATED,
        resourceType: "borrower",
        resourceId: borrower.id,
        previousValues: existingBorrower,
        newValues: borrower,
        ipAddr: getRealUserIP(req),
        userAgent: req.headers["user-agent"]
      });
      res.json(borrower);
    } catch (error) {
      console.error("Error updating borrower:", error);
      res.status(400).json({ error: "Failed to update borrower" });
    }
  });
  app2.get("/api/properties", async (req, res) => {
    try {
      const properties2 = await storage.getProperties();
      res.json(properties2);
    } catch (error) {
      console.error("Error fetching properties:", error);
      res.status(500).json({ error: "Failed to fetch properties" });
    }
  });
  app2.get("/api/properties/:id", async (req, res) => {
    try {
      const property = await storage.getProperty(parseInt(req.params.id));
      if (!property) {
        return res.status(404).json({ error: "Property not found" });
      }
      res.json(property);
    } catch (error) {
      console.error("Error fetching property:", error);
      res.status(500).json({ error: "Failed to fetch property" });
    }
  });
  app2.post("/api/properties", isAuthenticated2, async (req, res) => {
    try {
      const validatedData = insertPropertySchema.parse(req.body);
      const property = await storage.createProperty(validatedData);
      await complianceAudit.logEvent({
        actorType: "user",
        actorId: req.user?.id,
        eventType: COMPLIANCE_EVENTS.PROPERTY.CREATED,
        resourceType: "property",
        resourceId: property.id,
        newValues: property,
        ipAddr: getRealUserIP(req),
        userAgent: req.headers["user-agent"]
      });
      res.status(201).json(property);
    } catch (error) {
      console.error("Error creating property:", error);
      const errorMessage = error.issues ? error.issues[0].message : error.message || "Invalid property data";
      res.status(400).json({ error: errorMessage, details: error.issues || error.message });
    }
  });
  app2.put("/api/properties/:id", isAuthenticated2, async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      const existingProperty = await storage.getProperty(id);
      if (!existingProperty) {
        return res.status(404).json({ error: "Property not found" });
      }
      const property = await storage.updateProperty(id, req.body);
      await complianceAudit.logEvent({
        actorType: "user",
        actorId: req.user?.id,
        eventType: COMPLIANCE_EVENTS.PROPERTY.UPDATED,
        resourceType: "property",
        resourceId: property.id,
        previousValues: existingProperty,
        newValues: property,
        ipAddr: getRealUserIP(req),
        userAgent: req.headers["user-agent"]
      });
      res.json(property);
    } catch (error) {
      console.error("Error updating property:", error);
      res.status(400).json({ error: "Failed to update property" });
    }
  });
  app2.get(
    "/api/loans",
    requireAuth2,
    requirePermission("Loans", "read" /* Read */),
    async (req, res) => {
      try {
        let filters = {};
        if (req.rowLevelFilter) {
          filters = { ...req.rowLevelFilter };
        }
        const {
          lenderId,
          servicerId,
          investorId,
          status,
          limit = "50",
          offset = "0"
        } = req.query;
        const loans2 = await storage.getLoans({
          lenderId: lenderId ? parseInt(lenderId) : void 0,
          servicerId: servicerId ? parseInt(servicerId) : void 0,
          investorId: investorId ? parseInt(investorId) : void 0,
          status: status || void 0,
          limit: parseInt(limit),
          offset: parseInt(offset)
        });
        res.json(loans2);
      } catch (error) {
        console.error("Error fetching loans:", error);
        res.status(500).json({ error: "Failed to fetch loans" });
      }
    }
  );
  app2.get("/api/loans/metrics", async (req, res) => {
    try {
      const userId = req.user?.id;
      const metrics2 = await storage.getLoanMetrics(userId);
      res.json(metrics2);
    } catch (error) {
      console.error("Error fetching loan metrics:", error);
      res.status(500).json({ error: "Failed to fetch metrics" });
    }
  });
  app2.get("/api/loans/:id", async (req, res) => {
    try {
      const loan = await storage.getLoan(parseInt(req.params.id));
      if (!loan) {
        return res.status(404).json({ error: "Loan not found" });
      }
      res.json(loan);
    } catch (error) {
      console.error("Error fetching loan:", error);
      res.status(500).json({ error: "Failed to fetch loan" });
    }
  });
  app2.post("/api/loans", isAuthenticated2, asyncHandler2(async (req, res) => {
    console.log("=== BACKEND: LOAN CREATION ENDPOINT CALLED (v2) ===");
    const validatedData = validateInput(insertLoanSchema, req.body, "Invalid loan data");
    console.log("Validation successful.");
    console.log("Calling storage.createLoan...");
    const loan = await storage.createLoan(validatedData);
    console.log("Loan created in database:", loan);
    await complianceAudit.logEvent({
      actorType: "user",
      actorId: req.user?.id,
      eventType: COMPLIANCE_EVENTS.LOAN.CREATED,
      resourceType: "loan",
      resourceId: loan.id,
      loanId: loan.id,
      newValues: loan,
      ipAddr: req.ip,
      userAgent: req.headers["user-agent"]
    });
    console.log("Sending success response");
    return successResponse(res, loan, 201);
  }));
  app2.delete("/api/loans/:id", isAuthenticated2, asyncHandler2(async (req, res) => {
    const id = parseInt(req.params.id);
    const existingLoan = await storage.getLoan(id);
    if (!existingLoan) {
      throw new AppError("Loan not found", "NOT_FOUND" /* NOT_FOUND */, 404);
    }
    await storage.deleteLoan(id);
    res.status(204).send();
  }));
  const updateLoanHandler = async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      const existingLoan = await storage.getLoan(id);
      if (!existingLoan) {
        return res.status(404).json({ error: "Loan not found" });
      }
      const { createdAt, updatedAt, ...updateData } = req.body;
      const propertyFields = {};
      const loanFields = {};
      Object.entries(updateData).forEach(([key, value]) => {
        if (key === "parcelNumber") {
          propertyFields.apn = value;
        } else if (key === "legalDescription") {
          propertyFields.legalDescription = value;
        } else if (key === "propertyValue") {
          propertyFields.currentValue = value === "" ? null : value;
        } else if (key === "propertyAddress") {
          propertyFields.address = value;
        } else if (key === "propertyCity") {
          propertyFields.city = value;
        } else if (key === "propertyState") {
          propertyFields.state = value;
        } else if (key === "propertyZip") {
          propertyFields.zipCode = value;
        } else if (key === "propertyType") {
          propertyFields.propertyType = value;
        } else {
          loanFields[key] = value;
        }
      });
      const cleanedLoanData = Object.entries(loanFields).reduce((acc, [key, value]) => {
        const integerFields = [
          "gracePeriodDays",
          "loanTerm",
          "amortizationTerm",
          "balloonMonths",
          "prepaymentPenaltyTerm",
          "rateAdjustmentFrequency",
          "yearBuilt",
          "squareFeet",
          "bedrooms",
          "bathrooms",
          "stories",
          "garageSpaces"
        ];
        const numericFields = [
          "servicingFee",
          "lateCharge",
          "interestRate",
          "margin",
          "rateCapInitial",
          "rateCapPeriodic",
          "rateCapLifetime",
          "rateFloor",
          "balloonAmount",
          "prepaymentPenaltyAmount",
          "originalAmount",
          "principalBalance",
          "paymentAmount",
          "monthlyEscrow",
          "monthlyMI",
          "originalLTV",
          "currentLTV",
          "combinedLTV",
          "propertyTax",
          "homeInsurance",
          "pmi",
          "otherMonthly",
          "hazardInsurance",
          "propertyTaxes",
          "hoaFees",
          "pmiAmount",
          "principalAndInterest",
          "escrowAmount",
          "closingCosts",
          "downPayment",
          "borrowerIncome",
          "coBorrowerIncome",
          "creditScoreEquifax",
          "creditScoreExperian",
          "creditScoreTransunion",
          "coBorrowerCreditScoreEquifax",
          "coBorrowerCreditScoreExperian",
          "coBorrowerCreditScoreTransunion",
          "purchasePrice",
          "originalAppraisalValue",
          "currentValue",
          "annualPropertyTax",
          "annualInsurance",
          "annualHOA",
          "lotSize",
          "rentalIncome"
        ];
        if ((integerFields.includes(key) || numericFields.includes(key)) && value === "") {
          acc[key] = null;
        } else {
          acc[key] = value;
        }
        return acc;
      }, {});
      if (Object.keys(propertyFields).length > 0 && existingLoan.propertyId) {
        await storage.updateProperty(existingLoan.propertyId, propertyFields);
        console.log(`Updated property ${existingLoan.propertyId} with:`, propertyFields);
      }
      let loan = existingLoan;
      if (Object.keys(cleanedLoanData).length > 0) {
        loan = await storage.updateLoan(id, cleanedLoanData);
      }
      if (Object.keys(cleanedLoanData).length > 0) {
        for (const [field, newValue] of Object.entries(cleanedLoanData)) {
          const oldValue = existingLoan[field];
          if (String(oldValue) !== String(newValue)) {
            await complianceAudit.logEvent({
              eventType: COMPLIANCE_EVENTS.LOAN.UPDATED,
              actorType: "user",
              actorId: req.user?.id?.toString() || "1",
              resourceType: "loan",
              resourceId: loan.id.toString(),
              loanId: loan.id,
              ipAddr: getRealUserIP(req),
              userAgent: req.headers?.["user-agent"],
              description: `Loan field '${field}' updated from '${oldValue}' to '${newValue}' on ${existingLoan.loanNumber}`,
              previousValues: { [field]: oldValue },
              newValues: { [field]: newValue },
              changedFields: [field]
            });
          }
        }
      }
      if (Object.keys(propertyFields).length > 0) {
        const existingProperty = await storage.getProperty(existingLoan.propertyId);
        for (const [field, newValue] of Object.entries(propertyFields)) {
          const oldValue = existingProperty[field];
          if (String(oldValue) !== String(newValue)) {
            await complianceAudit.logEvent({
              eventType: COMPLIANCE_EVENTS.PROPERTY.UPDATED,
              actorType: "user",
              actorId: req.user?.id?.toString() || "1",
              resourceType: "property",
              resourceId: existingLoan.propertyId.toString(),
              loanId: loan.id,
              ipAddr: getRealUserIP(req),
              userAgent: req.headers?.["user-agent"],
              description: `Property field '${field}' updated from '${oldValue}' to '${newValue}' on ${existingLoan.loanNumber}`,
              previousValues: { [field]: oldValue },
              newValues: { [field]: newValue },
              changedFields: [field]
            });
          }
        }
      }
      res.setHeader("X-Cache-Invalidate", JSON.stringify([
        `/api/compliance/audit-log`,
        `/api/loans/${loan.id}`
      ]));
      res.json(loan);
    } catch (error) {
      console.error("Error updating loan:", error);
      res.status(400).json({ error: "Failed to update loan" });
    }
  };
  app2.put("/api/loans/:id", isAuthenticated2, updateLoanHandler);
  app2.patch("/api/loans/:id", isAuthenticated2, updateLoanHandler);
  app2.get("/api/loans/:loanId/borrowers", async (req, res) => {
    try {
      const loanBorrowers2 = await storage.getLoanBorrowers(parseInt(req.params.loanId));
      res.json(loanBorrowers2);
    } catch (error) {
      console.error("Error fetching loan borrowers:", error);
      res.status(500).json({ error: "Failed to fetch loan borrowers" });
    }
  });
  app2.post("/api/loans/:loanId/borrowers", isAuthenticated2, async (req, res) => {
    try {
      const loanId = parseInt(req.params.loanId);
      const validatedData = insertLoanBorrowerSchema.parse({
        ...req.body,
        loanId
      });
      const loanBorrower2 = await storage.createLoanBorrower(validatedData);
      res.status(201).json(loanBorrower2);
    } catch (error) {
      console.error("Error creating loan borrower:", error);
      res.status(400).json({ error: "Invalid loan borrower data" });
    }
  });
  app2.delete("/api/loan-borrowers/:id", isAuthenticated2, async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      const userId = req.user?.id || 1;
      const loanBorrowers2 = await db.select().from(loanBorrower).where(eq(loanBorrower.id, id));
      const existingLoanBorrower = loanBorrowers2[0];
      await storage.deleteLoanBorrower(id);
      if (existingLoanBorrower) {
        await complianceAudit.logEvent({
          actorType: "user",
          actorId: userId.toString(),
          eventType: "LOAN.BORROWER_REMOVED",
          resourceType: "loan_borrower",
          resourceId: id.toString(),
          details: {
            action: "delete_loan_borrower",
            loanBorrowerId: id,
            loanId: existingLoanBorrower.loanId,
            borrowerId: existingLoanBorrower.borrowerId,
            userId,
            previousValues: existingLoanBorrower
          },
          userId,
          ipAddress: req.ip,
          userAgent: req.headers?.["user-agent"]
        });
      }
      res.status(204).send();
    } catch (error) {
      console.error("Error deleting loan borrower:", error);
      res.status(400).json({ error: "Failed to delete loan borrower" });
    }
  });
  app2.get("/api/loans/:loanId/investors", async (req, res) => {
    try {
      const investors2 = await storage.getInvestorsByLoan(parseInt(req.params.loanId));
      res.json(investors2);
    } catch (error) {
      console.error("Error fetching investors:", error);
      res.status(500).json({ error: "Failed to fetch investors" });
    }
  });
  app2.post("/api/loans/:loanId/investors", isAuthenticated2, async (req, res) => {
    try {
      const loanId = parseInt(req.params.loanId);
      const investorId = req.body.investorId || `INV-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
      const validatedData = insertInvestorSchema.parse({
        ...req.body,
        loanId,
        investorId
      });
      const investor = await storage.createInvestor(validatedData);
      res.status(201).json(investor);
    } catch (error) {
      console.error("Error creating investor:", error);
      res.status(400).json({ error: "Invalid investor data" });
    }
  });
  app2.put("/api/investors/:id", isAuthenticated2, async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      const actorId = req.user?.id?.toString() || "system";
      const previousInvestor = await storage.getInvestor(id);
      if (!previousInvestor) {
        return res.status(404).json({ error: "Investor not found" });
      }
      const { createdAt, updatedAt, ...updateData } = req.body;
      if (updateData.investmentDate) {
        updateData.investmentDate = typeof updateData.investmentDate === "string" ? updateData.investmentDate : new Date(updateData.investmentDate).toISOString().split("T")[0];
      }
      const investor = await storage.updateInvestor(id, updateData);
      const changedFields = [];
      const oldValues = {};
      const newValues = {};
      for (const [key, newValue] of Object.entries(updateData)) {
        const oldValue = previousInvestor[key];
        if (oldValue !== newValue) {
          changedFields.push(key);
          oldValues[key] = oldValue;
          newValues[key] = newValue;
        }
      }
      if (changedFields.length > 0) {
        for (const field of changedFields) {
          await complianceAudit.logEvent({
            actorType: "user",
            actorId,
            eventType: "CRM.INVESTOR.FIELD_UPDATED",
            resourceType: "investor",
            resourceId: id.toString(),
            loanId: investor.loanId,
            previousValues: { [field]: oldValues[field] },
            newValues: { [field]: newValues[field] },
            changedFields: [field],
            ipAddr: getRealUserIP(req),
            userAgent: req.get("user-agent"),
            description: `Investor ${investor.investorId || investor.name} field '${field}' updated from '${oldValues[field]}' to '${newValues[field]}'`
          });
        }
      }
      res.json(investor);
    } catch (error) {
      console.error("Error updating investor:", error);
      res.status(400).json({ error: "Failed to update investor" });
    }
  });
  app2.delete("/api/investors/:id", isAuthenticated2, async (req, res) => {
    try {
      await storage.deleteInvestor(parseInt(req.params.id));
      res.status(204).send();
    } catch (error) {
      console.error("Error deleting investor:", error);
      res.status(400).json({ error: "Failed to delete investor" });
    }
  });
  app2.get("/api/loans/:loanId/payments", async (req, res) => {
    try {
      const { limit = "50" } = req.query;
      const payments3 = await storage.getPayments(parseInt(req.params.loanId), parseInt(limit));
      res.json(payments3);
    } catch (error) {
      console.error("Error fetching payments:", error);
      res.status(500).json({ error: "Failed to fetch payments" });
    }
  });
  app2.post("/api/loans/:loanId/payments", isAuthenticated2, async (req, res) => {
    try {
      const loanId = parseInt(req.params.loanId);
      const validatedData = insertPaymentSchema.parse({
        ...req.body,
        loanId
      });
      const payment = await storage.createPayment(validatedData);
      await complianceAudit.logEvent({
        actorType: "user",
        actorId: req.user?.id,
        eventType: COMPLIANCE_EVENTS.PAYMENT.CREATED,
        resourceType: "payment",
        resourceId: payment.id,
        loanId,
        newValues: payment,
        ipAddr: getRealUserIP(req),
        userAgent: req.headers["user-agent"]
      });
      res.status(201).json(payment);
    } catch (error) {
      console.error("Error creating payment:", error);
      res.status(400).json({ error: "Invalid payment data" });
    }
  });
  app2.put("/api/payments/:id", isAuthenticated2, async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      const payment = await storage.updatePayment(id, req.body);
      await complianceAudit.logEvent({
        actorType: "user",
        actorId: req.user?.id,
        eventType: COMPLIANCE_EVENTS.PAYMENT.UPDATED,
        resourceType: "payment",
        resourceId: payment.id,
        loanId: payment.loanId,
        previousValues: await storage.getPayment(id),
        newValues: payment,
        ipAddr: getRealUserIP(req),
        userAgent: req.headers["user-agent"]
      });
      res.json(payment);
    } catch (error) {
      console.error("Error updating payment:", error);
      res.status(400).json({ error: "Failed to update payment" });
    }
  });
  app2.get("/api/loans/:loanId/payment-schedule", async (req, res) => {
    try {
      const schedule = await storage.getPaymentSchedule(parseInt(req.params.loanId));
      res.json(schedule);
    } catch (error) {
      console.error("Error fetching payment schedule:", error);
      res.status(500).json({ error: "Failed to fetch payment schedule" });
    }
  });
  app2.post("/api/loans/:loanId/payment-schedule", isAuthenticated2, async (req, res) => {
    try {
      const loanId = parseInt(req.params.loanId);
      const validatedData = insertPaymentScheduleSchema.parse({
        ...req.body,
        loanId
      });
      const schedule = await storage.createPaymentSchedule(validatedData);
      res.status(201).json(schedule);
    } catch (error) {
      console.error("Error creating payment schedule:", error);
      res.status(400).json({ error: "Invalid payment schedule data" });
    }
  });
  app2.post("/api/loans/:loanId/payment-schedule/generate", isAuthenticated2, async (req, res) => {
    try {
      const schedule = await storage.generatePaymentSchedule(parseInt(req.params.loanId));
      res.json(schedule);
    } catch (error) {
      console.error("Error generating payment schedule:", error);
      res.status(500).json({ error: "Failed to generate payment schedule" });
    }
  });
  app2.get("/api/loans/:loanId/escrow", async (req, res) => {
    try {
      const escrowAccount = await storage.getEscrowAccount(parseInt(req.params.loanId));
      if (!escrowAccount) {
        return res.status(404).json({ error: "Escrow account not found" });
      }
      res.json(escrowAccount);
    } catch (error) {
      console.error("Error fetching escrow account:", error);
      res.status(500).json({ error: "Failed to fetch escrow account" });
    }
  });
  app2.post("/api/loans/:loanId/escrow", isAuthenticated2, async (req, res) => {
    try {
      const loanId = parseInt(req.params.loanId);
      const validatedData = insertEscrowAccountSchema.parse({
        ...req.body,
        loanId
      });
      const escrowAccount = await storage.createEscrowAccount(validatedData);
      await complianceAudit.logEvent({
        actorType: "user",
        actorId: req.user?.id,
        eventType: COMPLIANCE_EVENTS.ESCROW.ACCOUNT_CREATED,
        resourceType: "escrow_account",
        resourceId: escrowAccount.id,
        loanId,
        newValues: escrowAccount,
        ipAddr: getRealUserIP(req),
        userAgent: req.headers["user-agent"]
      });
      res.status(201).json(escrowAccount);
    } catch (error) {
      console.error("Error creating escrow account:", error);
      res.status(400).json({ error: "Invalid escrow account data" });
    }
  });
  app2.put("/api/escrow/:id", isAuthenticated2, async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      const escrowAccount = await storage.updateEscrowAccount(id, req.body);
      await complianceAudit.logEvent({
        actorType: "user",
        actorId: req.user?.id,
        eventType: COMPLIANCE_EVENTS.ESCROW.ACCOUNT_UPDATED,
        resourceType: "escrow_account",
        resourceId: escrowAccount.id,
        loanId: escrowAccount.loanId,
        previousValues: await storage.getEscrowAccount(id),
        newValues: escrowAccount,
        ipAddr: getRealUserIP(req),
        userAgent: req.headers["user-agent"]
      });
      res.json(escrowAccount);
    } catch (error) {
      console.error("Error updating escrow account:", error);
      res.status(400).json({ error: "Failed to update escrow account" });
    }
  });
  app2.get("/api/escrow/metrics", async (req, res) => {
    try {
      const metrics2 = await storage.getEscrowMetrics();
      res.json(metrics2);
    } catch (error) {
      console.error("Error fetching escrow metrics:", error);
      res.status(500).json({ error: "Failed to fetch escrow metrics" });
    }
  });
  app2.get("/api/escrow-payments", async (req, res) => {
    try {
      const { limit = "10" } = req.query;
      const transactions = await storage.getEscrowTransactions({
        limit: parseInt(limit)
      });
      res.json(transactions);
    } catch (error) {
      console.error("Error fetching escrow payments:", error);
      res.status(500).json({ error: "Failed to fetch escrow payments" });
    }
  });
  app2.get("/api/escrow/:escrowId/transactions", async (req, res) => {
    try {
      const { limit = "50" } = req.query;
      const transactions = await storage.getEscrowTransactions({
        escrowAccountId: parseInt(req.params.escrowId),
        limit: parseInt(limit)
      });
      res.json(transactions);
    } catch (error) {
      console.error("Error fetching escrow transactions:", error);
      res.status(500).json({ error: "Failed to fetch escrow transactions" });
    }
  });
  app2.post("/api/escrow/:escrowId/transactions", isAuthenticated2, async (req, res) => {
    try {
      const escrowAccountId = parseInt(req.params.escrowId);
      const validatedData = insertEscrowTransactionSchema.parse({
        ...req.body,
        escrowAccountId
      });
      const transaction = await storage.createEscrowTransaction(validatedData);
      await complianceAudit.logEvent({
        actorType: "user",
        actorId: req.user?.id,
        eventType: COMPLIANCE_EVENTS.ESCROW.DISBURSEMENT_COMPLETED,
        resourceType: "escrow_transaction",
        resourceId: transaction.id,
        newValues: transaction,
        ipAddr: getRealUserIP(req),
        userAgent: req.headers["user-agent"]
      });
      res.status(201).json(transaction);
    } catch (error) {
      console.error("Error creating escrow transaction:", error);
      res.status(400).json({ error: "Invalid escrow transaction data" });
    }
  });
  app2.get("/api/escrow/:escrowId/items", async (req, res) => {
    try {
      const items = await storage.getEscrowItems(parseInt(req.params.escrowId));
      res.json(items);
    } catch (error) {
      console.error("Error fetching escrow items:", error);
      res.status(500).json({ error: "Failed to fetch escrow items" });
    }
  });
  app2.post("/api/escrow/:escrowId/items", isAuthenticated2, async (req, res) => {
    try {
      const escrowAccountId = parseInt(req.params.escrowId);
      const validatedData = insertEscrowItemSchema.parse({
        ...req.body,
        escrowAccountId
      });
      const item = await storage.createEscrowItem(validatedData);
      res.status(201).json(item);
    } catch (error) {
      console.error("Error creating escrow item:", error);
      res.status(400).json({ error: "Invalid escrow item data" });
    }
  });
  app2.post("/api/documents/upload", isAuthenticated2, upload4.single("file"), async (req, res) => {
    try {
      if (!req.file) {
        return res.status(400).json({ error: "No file provided" });
      }
      const { loanId, category, description } = req.body;
      if (!loanId) {
        return res.status(400).json({ error: "Loan ID is required" });
      }
      const filePath = req.file.path;
      const fileBuffer = await fs7.readFile(filePath);
      const validation = validateUploadedFile(
        req.file.originalname,
        fileBuffer,
        req.file.mimetype,
        req.file.size,
        {
          maxSizeMB: 10,
          allowPasswordProtectedPDFs: false
          // Reject password-protected PDFs
        }
      );
      if (!validation.valid) {
        try {
          await fs7.unlink(filePath);
        } catch (unlinkError) {
          console.error("Error deleting invalid file:", unlinkError);
        }
        return res.status(400).json({
          error: "File validation failed",
          details: validation.errors
        });
      }
      const auditLog2 = createFileUploadAuditLog(
        req.file.originalname,
        validation,
        req.file.size,
        req.file.mimetype,
        req.user?.id || "unknown",
        getRealUserIP(req),
        req.headers["user-agent"] || "unknown"
      );
      await complianceAudit.logEvent({
        actorType: "user",
        actorId: req.user?.id?.toString() || "unknown",
        eventType: COMPLIANCE_EVENTS.DOCUMENT.UPLOADED,
        resourceType: "document",
        resourceId: "pending",
        // Will be updated after document creation
        loanId: parseInt(loanId),
        ipAddr: getRealUserIP(req),
        userAgent: req.headers["user-agent"],
        description: `Secure file upload: ${validation.sanitizedFilename}`,
        details: {
          securityAudit: auditLog2,
          validationPassed: true,
          originalFilename: req.file.originalname,
          secureFilename: req.file.filename,
          fileSize: req.file.size,
          mimeType: req.file.mimetype
        }
      });
      const document = await storage.createDocument({
        loanId: parseInt(loanId),
        category: category || "other",
        title: validation.sanitizedFilename?.split(".")[0] || "Uploaded Document",
        description: description || `Uploaded ${validation.sanitizedFilename}`,
        fileName: validation.sanitizedFilename || req.file.originalname,
        fileSize: req.file.size,
        mimeType: req.file.mimetype,
        storageUrl: `/uploads/${req.file.filename}`,
        uploadedBy: req.user?.id,
        notes: req.body.notes || null
      });
      await complianceAudit.logEvent({
        actorType: "user",
        actorId: req.user?.id?.toString() || "unknown",
        eventType: COMPLIANCE_EVENTS.DOCUMENT.UPLOADED,
        resourceType: "document",
        resourceId: document.id.toString(),
        loanId: document.loanId,
        ipAddr: getRealUserIP(req),
        userAgent: req.headers["user-agent"],
        description: `Document created successfully: ${document.title}`,
        newValues: document
      });
      res.status(201).json({
        ...document,
        securityValidation: {
          passed: true,
          originalFilename: req.file.originalname,
          sanitizedFilename: validation.sanitizedFilename
        }
      });
    } catch (error) {
      console.error("Error uploading document:", error);
      if (req.file?.path) {
        try {
          await fs7.unlink(req.file.path);
        } catch (unlinkError) {
          console.error("Error deleting file after error:", unlinkError);
        }
      }
      await complianceAudit.logEvent({
        actorType: "user",
        actorId: req.user?.id?.toString() || "unknown",
        eventType: "SECURITY.UPLOAD_FAILED",
        resourceType: "document",
        resourceId: "failed",
        loanId: req.body.loanId ? parseInt(req.body.loanId) : null,
        ipAddr: getRealUserIP(req),
        userAgent: req.headers["user-agent"],
        description: `Document upload failed: ${error.message}`,
        details: {
          error: error.message,
          originalFilename: req.file?.originalname || "unknown",
          fileSize: req.file?.size || 0,
          mimeType: req.file?.mimetype || "unknown"
        }
      });
      res.status(500).json({ error: "Failed to upload document" });
    }
  });
  app2.get("/api/documents", async (req, res) => {
    try {
      const { loanId, borrowerId, category } = req.query;
      const documents2 = await storage.getDocuments({
        loanId: loanId ? parseInt(loanId) : void 0,
        borrowerId: borrowerId ? parseInt(borrowerId) : void 0,
        category: category || void 0
      });
      res.json(documents2);
    } catch (error) {
      console.error("Error fetching documents:", error);
      res.status(500).json({ error: "Failed to fetch documents" });
    }
  });
  app2.get("/api/documents/:id", async (req, res) => {
    try {
      const document = await storage.getDocument(parseInt(req.params.id));
      if (!document) {
        return res.status(404).json({ error: "Document not found" });
      }
      res.json(document);
    } catch (error) {
      console.error("Error fetching document:", error);
      res.status(500).json({ error: "Failed to fetch document" });
    }
  });
  app2.delete("/api/documents/:id", isAuthenticated2, async (req, res) => {
    try {
      const document = await storage.getDocument(parseInt(req.params.id));
      if (!document) {
        return res.status(404).json({ error: "Document not found" });
      }
      await storage.deleteDocument(parseInt(req.params.id));
      res.json({ message: "Document deleted successfully" });
    } catch (error) {
      console.error("Error deleting document:", error);
      res.status(500).json({ error: "Failed to delete document" });
    }
  });
  app2.get("/api/documents/:id/file", async (req, res) => {
    try {
      const document = await storage.getDocument(parseInt(req.params.id));
      if (!document) {
        return res.status(404).json({ error: "Document not found" });
      }
      let filePath = "";
      if (document.storageUrl) {
        if (document.storageUrl.startsWith("/documents/")) {
          filePath = path5.join("server/uploads", document.storageUrl.replace("/documents/", ""));
        } else if (document.storageUrl.startsWith("/uploads/")) {
          filePath = path5.join("server", document.storageUrl);
        } else {
          filePath = path5.join("server/uploads", document.storageUrl);
        }
      } else {
        return res.status(404).json({ error: "File not found" });
      }
      try {
        await fs7.access(filePath);
        const fileName = document.fileName || document.originalFileName || "document";
        const mimeType = document.mimeType || "application/octet-stream";
        res.set({
          "Content-Type": mimeType,
          "Content-Disposition": `inline; filename="${fileName}"`,
          "Cache-Control": "public, max-age=3600",
          "X-Frame-Options": "SAMEORIGIN",
          "X-Content-Type-Options": "nosniff"
        });
        const fileStream = await fs7.readFile(filePath);
        res.send(fileStream);
      } catch (fileError) {
        console.error("File not found:", filePath);
        const fileName = document.fileName || document.originalFileName || "document";
        const mimeType = document.mimeType || "application/octet-stream";
        res.set({
          "Content-Type": "text/plain",
          "Content-Disposition": `inline; filename="${fileName}.txt"`,
          "Cache-Control": "public, max-age=3600"
        });
        const fallbackContent = `DOCUMENT: ${document.title || fileName}

This document was uploaded to the system but the file content is not available for preview.

Document Information:
- Type: ${document.category || "Document"}
- Created: ${new Date(document.createdAt).toLocaleDateString()}  
- File Size: ${document.fileSize ? Math.round(document.fileSize / 1024) + " KB" : "Unknown"}
- MIME Type: ${mimeType}
- Description: ${document.description || "No description available"}

To implement full file serving:
1. Upload actual files using the file upload endpoint
2. Store files in the server/uploads directory
3. Reference the correct file path in the database`;
        res.send(fallbackContent);
      }
    } catch (error) {
      console.error("Error serving document file:", error);
      res.status(500).json({ error: "Failed to serve document file" });
    }
  });
  function safeParseNumber(value, defaultValue = 0) {
    if (value === null || value === void 0 || value === "") return defaultValue;
    const parsed = typeof value === "string" ? parseFloat(value) : Number(value);
    return isNaN(parsed) ? defaultValue : parsed;
  }
  function determineCategory(fileName) {
    const lowerName = fileName.toLowerCase();
    if (lowerName.includes("loan") || lowerName.includes("application")) return "loan_application";
    if (lowerName.includes("agreement")) return "loan_agreement";
    if (lowerName.includes("note")) return "promissory_note";
    if (lowerName.includes("deed")) return "deed_of_trust";
    if (lowerName.includes("mortgage")) return "mortgage";
    if (lowerName.includes("insurance") || lowerName.includes("policy")) return "insurance_policy";
    if (lowerName.includes("tax")) return "tax_document";
    if (lowerName.includes("escrow")) return "escrow_statement";
    if (lowerName.includes("title")) return "title_report";
    if (lowerName.includes("appraisal")) return "appraisal";
    if (lowerName.includes("inspection")) return "inspection";
    if (lowerName.includes("financial") || lowerName.includes("statement")) return "financial_statement";
    if (lowerName.includes("income")) return "income_verification";
    if (lowerName.includes("closing")) return "closing_disclosure";
    if (lowerName.includes("settlement")) return "settlement_statement";
    return "other";
  }
  app2.post("/api/documents/upload", isAuthenticated2, upload4.single("file"), async (req, res) => {
    try {
      if (!req.file) {
        return res.status(400).json({ error: "No file provided" });
      }
      const category = determineCategory(req.file.originalname);
      const documentData = {
        title: req.body.title || req.file.originalname.split(".")[0],
        fileName: req.file.originalname,
        category: req.body.category || category,
        storageUrl: `/documents/${req.file.filename}`,
        fileSize: req.file.size,
        mimeType: req.file.mimetype,
        description: req.body.description || "Uploaded via file upload",
        uploadedBy: req.user?.id,
        version: 1,
        isActive: true,
        loanId: req.body.loanId ? parseInt(req.body.loanId) : null,
        borrowerId: req.body.borrowerId ? parseInt(req.body.borrowerId) : null,
        notes: req.body.notes || null
        // Store AI extraction JSON or other notes
      };
      const validatedData = insertDocumentSchema.parse(documentData);
      const document = await storage.createDocument(validatedData);
      await complianceAudit.logEvent({
        actorType: "user",
        actorId: req.user?.id,
        eventType: COMPLIANCE_EVENTS.DOCUMENT.UPLOADED,
        resourceType: "document",
        resourceId: document.id,
        loanId: document.loanId,
        newValues: document,
        ipAddr: getRealUserIP(req),
        userAgent: req.headers["user-agent"]
      });
      res.status(201).json(document);
    } catch (error) {
      console.error("Error uploading document:", error);
      res.status(400).json({ error: "Failed to upload document" });
    }
  });
  app2.post("/api/documents", isAuthenticated2, async (req, res) => {
    try {
      const validatedData = insertDocumentSchema.parse({
        ...req.body,
        uploadedBy: req.user?.id
      });
      const document = await storage.createDocument(validatedData);
      await complianceAudit.logEvent({
        actorType: "user",
        actorId: req.user?.id,
        eventType: COMPLIANCE_EVENTS.DOCUMENT.UPLOADED,
        resourceType: "document",
        resourceId: document.id,
        loanId: document.loanId,
        newValues: document,
        ipAddr: getRealUserIP(req),
        userAgent: req.headers["user-agent"]
      });
      res.status(201).json(document);
    } catch (error) {
      console.error("Error creating document:", error);
      res.status(400).json({ error: "Invalid document data" });
    }
  });
  app2.put("/api/documents/:id", isAuthenticated2, async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      const existingDocument = await storage.getDocument(id);
      if (!existingDocument) {
        return res.status(404).json({ error: "Document not found" });
      }
      const document = await storage.updateDocument(id, req.body);
      await complianceAudit.logEvent({
        actorType: "user",
        actorId: req.user?.id,
        eventType: COMPLIANCE_EVENTS.DOCUMENT.RENAMED,
        resourceType: "document",
        resourceId: document.id,
        loanId: document.loanId,
        previousValues: existingDocument,
        newValues: document,
        ipAddr: getRealUserIP(req),
        userAgent: req.headers["user-agent"]
      });
      res.json(document);
    } catch (error) {
      console.error("Error updating document:", error);
      res.status(400).json({ error: "Failed to update document" });
    }
  });
  app2.delete("/api/documents/:id", isAuthenticated2, async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      const document = await storage.getDocument(id);
      if (!document) {
        return res.status(404).json({ error: "Document not found" });
      }
      await storage.deleteDocument(id);
      await complianceAudit.logEvent({
        actorType: "user",
        actorId: req.user?.id,
        eventType: COMPLIANCE_EVENTS.DOCUMENT.DELETED,
        resourceType: "document",
        resourceId: document.id,
        loanId: document.loanId,
        previousValues: document,
        ipAddr: getRealUserIP(req),
        userAgent: req.headers["user-agent"]
      });
      res.status(204).send();
    } catch (error) {
      console.error("Error deleting document:", error);
      res.status(400).json({ error: "Failed to delete document" });
    }
  });
  app2.get("/api/notifications", isAuthenticated2, async (req, res) => {
    try {
      const { limit = "20" } = req.query;
      const notifications2 = await storage.getNotifications(req.user.id, parseInt(limit));
      res.json(notifications2);
    } catch (error) {
      console.error("Error fetching notifications:", error);
      res.status(500).json({ error: "Failed to fetch notifications" });
    }
  });
  app2.get("/api/notifications/unread-count", isAuthenticated2, async (req, res) => {
    try {
      const count3 = await storage.getUnreadNotificationCount(req.user.id);
      res.json({ count: count3 });
    } catch (error) {
      console.error("Error fetching unread notification count:", error);
      res.status(500).json({ error: "Failed to fetch notification count" });
    }
  });
  app2.post("/api/notifications", isAuthenticated2, async (req, res) => {
    try {
      const validatedData = insertNotificationSchema.parse(req.body);
      const notification = await storage.createNotification(validatedData);
      res.status(201).json(notification);
    } catch (error) {
      console.error("Error creating notification:", error);
      res.status(400).json({ error: "Invalid notification data" });
    }
  });
  app2.put("/api/notifications/:id/read", isAuthenticated2, async (req, res) => {
    try {
      await storage.markNotificationAsRead(parseInt(req.params.id));
      res.status(204).send();
    } catch (error) {
      console.error("Error marking notification as read:", error);
      res.status(400).json({ error: "Failed to mark notification as read" });
    }
  });
  app2.post("/api/migrate-database", isAuthenticated2, async (req, res) => {
    try {
      if (req.user?.username !== "loanatik") {
        return res.status(403).json({
          success: false,
          error: "Only administrators can run database migrations"
        });
      }
      const details = [];
      const migrations = [
        // Servicing settings
        `ALTER TABLE loans ADD COLUMN IF NOT EXISTS servicing_fee_type text DEFAULT 'percentage'`,
        `ALTER TABLE loans ADD COLUMN IF NOT EXISTS late_charge_type text DEFAULT 'percentage'`,
        `ALTER TABLE loans ADD COLUMN IF NOT EXISTS fee_payer text`,
        `ALTER TABLE loans ADD COLUMN IF NOT EXISTS grace_period_days integer`,
        `ALTER TABLE loans ADD COLUMN IF NOT EXISTS investor_loan_number text`,
        `ALTER TABLE loans ADD COLUMN IF NOT EXISTS pool_number text`,
        `ALTER TABLE loans ADD COLUMN IF NOT EXISTS late_charge decimal(10, 2)`,
        // Payment settings
        `ALTER TABLE loans ADD COLUMN IF NOT EXISTS property_tax decimal(10, 2)`,
        `ALTER TABLE loans ADD COLUMN IF NOT EXISTS home_insurance decimal(10, 2)`,
        `ALTER TABLE loans ADD COLUMN IF NOT EXISTS pmi decimal(10, 2)`,
        `ALTER TABLE loans ADD COLUMN IF NOT EXISTS other_monthly decimal(10, 2)`,
        // Other fields
        `ALTER TABLE properties ADD COLUMN IF NOT EXISTS apn text`,
        `ALTER TABLE loans ADD COLUMN IF NOT EXISTS escrow_number text`
      ];
      for (const migration of migrations) {
        try {
          await db.execute(sql23.raw(migration));
          const columnName = migration.match(/ADD COLUMN IF NOT EXISTS (\w+)/)?.[1];
          details.push(`\u2713 Added column: ${columnName}`);
        } catch (error) {
          if (error.code === "42701") {
            const columnName = migration.match(/ADD COLUMN IF NOT EXISTS (\w+)/)?.[1];
            details.push(`\u2713 Column already exists: ${columnName}`);
          } else {
            details.push(`\u2717 Error: ${error.message}`);
          }
        }
      }
      res.json({ success: true, details });
    } catch (error) {
      console.error("Error running migration:", error);
      res.status(500).json({
        success: false,
        error: "Failed to run migration",
        details: []
      });
    }
  });
  app2.get("/api/audit-logs/:entityType/:entityId", isAuthenticated2, async (req, res) => {
    try {
      const logs = await storage.getAuditLogs(req.params.entityType, parseInt(req.params.entityId));
      res.json(logs);
    } catch (error) {
      console.error("Error fetching audit logs:", error);
      res.status(500).json({ error: "Failed to fetch audit logs" });
    }
  });
  app2.use("/api/fees", fees_default);
  app2.use("/api/admin/users", router3);
  app2.use("/api/ip-allowlist", router4);
  registerLedgerRoutes(app2);
  app2.post("/api/documents/analyze", upload4.single("file"), isAuthenticated2, async (req, res) => {
    try {
      if (!req.file) {
        return res.status(400).json({ error: "No file uploaded" });
      }
      console.log(`[Document Analysis] Starting analysis for: ${req.file.originalname}, Size: ${req.file.size} bytes`);
      const result = await analyzeDocument(req.file.path, req.file.originalname || req.file.filename);
      if (result.documentType === "unknown" && result.confidence === 0) {
        console.error(`[Document Analysis] Failed to analyze ${req.file.originalname} - returning error`);
        return res.status(500).json({ error: "Document analysis failed - document may be too complex or large" });
      }
      console.log(`[Document Analysis] Successfully analyzed: ${req.file.originalname}, Type: ${result.documentType}`);
      res.json(result);
    } catch (error) {
      console.error(`[Document Analysis] Error analyzing ${req.file?.originalname}:`, error.message);
      console.error("Full error:", error);
      res.status(500).json({ error: `Failed to analyze document: ${error.message || "Unknown error"}` });
    }
  });
  app2.post("/api/loans/create-from-documents", isAuthenticated2, async (req, res) => {
    try {
      const { extractedData, documentTypes } = req.body;
      const loanAmount = safeParseNumber(extractedData.loanAmount);
      const loanTerm = safeParseNumber(extractedData.loanTerm, 30);
      const loanData = {
        borrowerName: extractedData.borrowerName || "Unknown",
        propertyAddress: extractedData.propertyAddress || "Unknown",
        loanAmount,
        interestRate: safeParseNumber(extractedData.interestRate),
        loanTerm,
        monthlyPayment: safeParseNumber(extractedData.monthlyPayment),
        loanStatus: "active",
        originationDate: (/* @__PURE__ */ new Date()).toISOString().split("T")[0],
        maturityDate: new Date(Date.now() + loanTerm * 365 * 24 * 60 * 60 * 1e3).toISOString().split("T")[0],
        remainingBalance: loanAmount,
        nextPaymentDate: extractedData.firstPaymentDate || new Date(Date.now() + 30 * 24 * 60 * 60 * 1e3).toISOString().split("T")[0],
        nextPaymentAmount: safeParseNumber(extractedData.monthlyPayment),
        servicingFee: 25,
        // Default servicing fee
        // Additional extracted fields
        loanType: extractedData.loanType || "conventional",
        propertyType: extractedData.propertyType || "single_family",
        propertyValue: safeParseNumber(extractedData.propertyValue),
        downPayment: safeParseNumber(extractedData.downPayment),
        closingCosts: safeParseNumber(extractedData.closingCosts),
        pmiAmount: safeParseNumber(extractedData.pmi),
        hazardInsurance: safeParseNumber(extractedData.insurance),
        propertyTaxes: safeParseNumber(extractedData.taxes),
        hoaFees: safeParseNumber(extractedData.hoaFees),
        escrowAmount: safeParseNumber(extractedData.escrowAmount)
      };
      const validatedData = insertLoanSchema.parse(loanData);
      const loan = await storage.createLoan(validatedData);
      await complianceAudit.logEvent({
        actorType: "user",
        actorId: req.user?.id,
        eventType: COMPLIANCE_EVENTS.LOAN.CREATED,
        resourceType: "loan",
        resourceId: loan.id,
        loanId: loan.id,
        newValues: { ...loan, documentTypes },
        metadata: { source: "ai_extraction" },
        ipAddr: getRealUserIP(req),
        userAgent: req.headers["user-agent"]
      });
      res.status(201).json(loan);
    } catch (error) {
      console.error("Error creating loan from documents:", error);
      res.status(400).json({ error: "Failed to create loan from extracted data" });
    }
  });
  const escrowDisbursementRoutes = await Promise.resolve().then(() => (init_escrow_disbursements(), escrow_disbursements_exports));
  app2.use(escrowDisbursementRoutes.default);
  const { cycleRouter: cycleRouter2 } = await Promise.resolve().then(() => (init_cycle_routes(), cycle_routes_exports));
  app2.use("/api", cycleRouter2);
  const rabbitmqTestRoutes = await Promise.resolve().then(() => (init_rabbitmq_test(), rabbitmq_test_exports));
  app2.use("/api/rabbitmq", rabbitmqTestRoutes.default);
  const messagingTestRoutes = await Promise.resolve().then(() => (init_messaging_test(), messaging_test_exports));
  app2.use("/api/messaging", messagingTestRoutes.default);
  const reconciliationRoutes = await Promise.resolve().then(() => (init_reconciliation2(), reconciliation_exports));
  app2.use("/api/reconciliation", reconciliationRoutes.default);
  app2.use("/api/qc", qcRouter);
  app2.use("/api/export", exportRouter);
  app2.use("/api/notifications", router16);
  app2.use("/api/storage", router17);
  app2.use("/", metricsRouter);
  const { paymentsRouter: paymentsRouter2 } = await Promise.resolve().then(() => (init_payments_routes(), payments_routes_exports));
  app2.use("/api", paymentsRouter2);
  const { investorRouter: investorRouter2 } = await Promise.resolve().then(() => (init_investor_routes2(), investor_routes_exports2));
  app2.use("/api", investorRouter2);
  const { analyticsRouter: analyticsRouter2 } = await Promise.resolve().then(() => (init_analytics_routes(), analytics_routes_exports));
  app2.use("/api/analytics", analyticsRouter2);
  app2.use("/api", vendorRouter);
  app2.use("/public", publicOAuthRouter);
  app2.use("/public/api", publicApiRouter);
  app2.use("/api", adminApiRouter);
  const { monitoringRouter: monitoringRouter2 } = await Promise.resolve().then(() => (init_monitoring_routes(), monitoring_routes_exports));
  app2.use("/api", monitoringRouter2);
  const { healthCheck: healthCheck2 } = await Promise.resolve().then(() => (init_health2(), health_exports2));
  const { chaosEngine: chaosEngine2, CHAOS_TESTS: CHAOS_TESTS2 } = await Promise.resolve().then(() => (init_chaos(), chaos_exports));
  app2.get("/healthz", healthCheck2);
  app2.get("/health", healthCheck2);
  app2.get("/admin/chaos/tests", (req, res) => {
    res.json({ tests: CHAOS_TESTS2 });
  });
  app2.post("/admin/chaos/run/:testName", async (req, res) => {
    try {
      const result = await chaosEngine2.runChaosTest(req.params.testName);
      res.json(result);
    } catch (error) {
      res.status(400).json({
        error: error instanceof Error ? error.message : String(error)
      });
    }
  });
  app2.get("/admin/chaos/active", (req, res) => {
    res.json({ active_tests: chaosEngine2.getActiveTests() });
  });
  app2.post("/admin/chaos/abort/:testName", async (req, res) => {
    try {
      await chaosEngine2.abortChaosTest(req.params.testName);
      res.json({ message: "Test aborted" });
    } catch (error) {
      res.status(400).json({
        error: error instanceof Error ? error.message : String(error)
      });
    }
  });
  const httpServer = createServer(app2);
  return httpServer;
}

// server/vite.ts
import express4 from "express";
import fs8 from "fs";
import path7 from "path";
import { createServer as createViteServer, createLogger as createLogger2 } from "vite";

// vite.config.ts
import { defineConfig } from "vite";
import react from "@vitejs/plugin-react";
import path6 from "path";
import runtimeErrorOverlay from "@replit/vite-plugin-runtime-error-modal";
var vite_config_default = defineConfig({
  plugins: [
    react(),
    runtimeErrorOverlay(),
    ...process.env.NODE_ENV !== "production" && process.env.REPL_ID !== void 0 ? [
      await import("@replit/vite-plugin-cartographer").then(
        (m) => m.cartographer()
      )
    ] : []
  ],
  resolve: {
    alias: {
      "@": path6.resolve(import.meta.dirname, "client", "src"),
      "@shared": path6.resolve(import.meta.dirname, "shared"),
      "@assets": path6.resolve(import.meta.dirname, "attached_assets")
    }
  },
  root: path6.resolve(import.meta.dirname, "client"),
  build: {
    outDir: path6.resolve(import.meta.dirname, "dist/public"),
    emptyOutDir: true
  },
  server: {
    fs: {
      strict: true,
      deny: ["**/.*"]
    }
  }
});

// server/vite.ts
import { nanoid } from "nanoid";
var viteLogger = createLogger2();
function log(message, source = "express") {
  const formattedTime = (/* @__PURE__ */ new Date()).toLocaleTimeString("en-US", {
    hour: "numeric",
    minute: "2-digit",
    second: "2-digit",
    hour12: true
  });
  console.log(`${formattedTime} [${source}] ${message}`);
}
async function setupVite(app2, server) {
  const serverOptions = {
    middlewareMode: true,
    hmr: { server },
    allowedHosts: true
  };
  const vite = await createViteServer({
    ...vite_config_default,
    configFile: false,
    customLogger: {
      ...viteLogger,
      error: (msg, options) => {
        viteLogger.error(msg, options);
        process.exit(1);
      }
    },
    server: serverOptions,
    appType: "custom"
  });
  app2.use(vite.middlewares);
  app2.use("*", async (req, res, next) => {
    const url = req.originalUrl;
    try {
      const clientTemplate = path7.resolve(
        import.meta.dirname,
        "..",
        "client",
        "index.html"
      );
      let template = await fs8.promises.readFile(clientTemplate, "utf-8");
      template = template.replace(
        `src="/src/main.tsx"`,
        `src="/src/main.tsx?v=${nanoid()}"`
      );
      const page = await vite.transformIndexHtml(url, template);
      res.status(200).set({ "Content-Type": "text/html" }).end(page);
    } catch (e) {
      vite.ssrFixStacktrace(e);
      next(e);
    }
  });
}
function serveStatic(app2) {
  const distPath = path7.resolve(import.meta.dirname, "public");
  if (!fs8.existsSync(distPath)) {
    throw new Error(
      `Could not find the build directory: ${distPath}, make sure to build the client first`
    );
  }
  app2.use(express4.static(distPath));
  app2.use("*", (_req, res) => {
    res.sendFile(path7.resolve(distPath, "index.html"));
  });
}

// server/index.ts
init_telemetry();
init_correlation_id();
init_safe_logger();
init_metrics_collector();
init_schema_validator();
import cors from "cors";
import dotenv2 from "dotenv";
import fs10 from "fs";
import path10 from "path";
var envLocalPath2 = path10.join(process.cwd(), ".env.local");
if (fs10.existsSync(envLocalPath2)) {
  dotenv2.config({ path: envLocalPath2 });
  console.log("[Config] Loaded .env.local");
}
initializeTelemetry();
var app = express9();
var corsOptions = {
  origin: (origin, callback2) => {
    const allowedOrigins = [
      /^https:\/\/.*\.repl\.co$/,
      /^https:\/\/.*\.replit\.dev$/,
      /^https:\/\/.*\.replit\.app$/,
      /^https:\/\/readysetclose.*$/
    ];
    if (!origin) {
      return callback2(null, true);
    }
    const isAllowed = allowedOrigins.some((pattern) => pattern.test(origin));
    if (isAllowed || process.env.NODE_ENV === "development") {
      callback2(null, true);
    } else {
      callback2(new Error("Not allowed by CORS"));
    }
  },
  credentials: true,
  // Allow cookies to be sent
  methods: ["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"],
  allowedHeaders: ["Content-Type", "Authorization"],
  exposedHeaders: ["Set-Cookie"],
  maxAge: 86400
  // Cache preflight response for 24 hours
};
app.use(cors(corsOptions));
app.use(correlationIdMiddleware);
app.use(express9.json({ limit: "50mb" }));
app.use(express9.urlencoded({ extended: false, limit: "50mb" }));
app.use((req, res, next) => {
  const start = Date.now();
  const path11 = req.path;
  let capturedJsonResponse = void 0;
  const originalResJson = res.json;
  res.json = function(bodyJson, ...args) {
    capturedJsonResponse = bodyJson;
    return originalResJson.apply(res, [bodyJson, ...args]);
  };
  res.on("finish", () => {
    const duration = Date.now() - start;
    if (path11.startsWith("/api")) {
      let logLine = `${req.method} ${path11} ${res.statusCode} in ${duration}ms`;
      if (capturedJsonResponse) {
        const safeBody = maskSensitive(capturedJsonResponse);
        logLine += ` :: ${JSON.stringify(safeBody)}`;
      }
      if (logLine.length > 160) {
        logLine = logLine.slice(0, 159) + "\u2026";
      }
      log(logLine);
    }
  });
  next();
});
(async () => {
  const { runMigrations: runMigrations2 } = await Promise.resolve().then(() => (init_migrations(), migrations_exports));
  await runMigrations2();
  try {
    console.log("[Server] About to run startup validations...");
    await runStartupValidations();
    console.log("[Server] Startup validations completed");
  } catch (error) {
    console.error("[Server] Startup validation error:", error);
  }
  console.log("[Server] CRM topology setup disabled during RabbitMQ migration");
  console.log("[Server] Payment consumers disabled during RabbitMQ migration");
  startMetricsCollection();
  console.log("[Server] Metrics collection started");
  const { startRmqPoller: startRmqPoller2 } = await Promise.resolve().then(() => (init_rmqPoller(), rmqPoller_exports));
  if ((process.env.METRICS_ENABLED || "true") === "true") {
    startRmqPoller2();
    console.log("[Server] RabbitMQ queue monitoring started");
  }
  try {
    const { runCRMNotificationChecks: runCRMNotificationChecks2 } = await Promise.resolve().then(() => (init_check_overdue_tasks(), check_overdue_tasks_exports));
    runCRMNotificationChecks2().catch(
      (err) => console.error("[Server] CRM notification check error:", err)
    );
    setInterval(() => {
      runCRMNotificationChecks2().catch(
        (err) => console.error("[Server] CRM notification check error:", err)
      );
    }, 60 * 60 * 1e3);
    console.log("[Server] CRM notification checks scheduled (hourly)");
  } catch (error) {
    console.error("[Server] Failed to start CRM notification checks:", error);
  }
  try {
    const { neonConfig: neonConfig2 } = await import("@neondatabase/serverless");
    const { Pool: Pool17 } = await import("@neondatabase/serverless");
    const { RemittanceScheduler: RemittanceScheduler2 } = await Promise.resolve().then(() => (init_scheduler(), scheduler_exports));
    neonConfig2.fetchConnectionCache = true;
    const pool17 = new Pool17({ connectionString: process.env.DATABASE_URL });
    const scheduler = new RemittanceScheduler2(pool17);
    scheduler.start();
    console.log("[Server] Remittance scheduler started successfully");
  } catch (error) {
    console.error("[Server] Failed to start remittance scheduler:", error);
  }
  try {
    const { initializeComplianceScheduler: initializeComplianceScheduler2 } = await Promise.resolve().then(() => (init_compliance(), compliance_exports));
    initializeComplianceScheduler2();
    console.log("[Server] Compliance scheduler initialized successfully");
  } catch (error) {
    console.error("[Server] Failed to initialize compliance scheduler:", error);
  }
  try {
    const { startQcWorker: startQcWorker2 } = await Promise.resolve().then(() => (init_QcWorker(), QcWorker_exports));
    await startQcWorker2();
    console.log("[Server] QC worker started successfully");
  } catch (error) {
    console.error("[Server] Failed to start QC worker:", error);
  }
  try {
    const { startExportWorker: startExportWorker2 } = await Promise.resolve().then(() => (init_ExportWorker(), ExportWorker_exports));
    await startExportWorker2();
    console.log("[Server] Export worker started successfully");
  } catch (error) {
    console.error("[Server] Failed to start export worker:", error);
  }
  try {
    const { startNotificationWorker: startNotificationWorker2 } = await Promise.resolve().then(() => (init_NotificationWorker(), NotificationWorker_exports));
    await startNotificationWorker2();
    console.log("[Server] Notification worker started successfully");
  } catch (error) {
    console.error("[Server] Failed to start notification worker:", error);
  }
  try {
    const { startBoardingWorker: startBoardingWorker2 } = await Promise.resolve().then(() => (init_BoardingWorker(), BoardingWorker_exports));
    await startBoardingWorker2();
    console.log("[Server] Boarding worker started successfully");
  } catch (error) {
    console.error("[Server] Failed to start boarding worker:", error);
  }
  try {
    const { initQueues: initQueues2 } = await Promise.resolve().then(() => (init_init_queues(), init_queues_exports));
    await initQueues2();
    console.log("[Server] \u2705 Modern queue system initialized - ETL now queue-based");
  } catch (error) {
    console.error("[Server] Failed to initialize queue system:", error);
    console.error("[Server] \u26A0\uFE0F  Falling back to legacy operations");
  }
  const server = await registerRoutes(app);
  app.use(correlationErrorHandler);
  app.use((err, _req, res, _next) => {
    const status = err.status || err.statusCode || 500;
    const message = err.message || "Internal Server Error";
    log(`[Error] ${status} ${message}`);
    res.status(status).json({ message });
  });
  if (app.get("env") === "development") {
    await setupVite(app, server);
  } else {
    serveStatic(app);
  }
  const port = parseInt(process.env.CORE_HTTP_PORT || "4000", 10);
  server.listen({
    port,
    host: "0.0.0.0",
    reusePort: true
  }, () => {
    log(`serving on port ${port}`);
  });
})();
